
                               1 of 41 DOCUMENTS

          Copyright (c) 2016 Wake Forest Law Review Association, Inc.
                             Wake Forest Law Review

                                   Fall, 2016

                             Wake Forest Law Review

                           51 Wake Forest L. Rev. 705

LENGTH: 20393 words

IMPLEMENTING DE-INCARCERATION STRATEGIES: POLICIES AND PRACTICES TO REDUCE CRIME
AND MASS INCARCERATION: ARTICLE & ESSAY: PREDICTIVE PROSECUTION

NAME: Andrew Guthrie Ferguson*

BIO: * Professor of Law, UDC David A. Clarke School of Law. Thank you to
Professor Kami Chavis for inviting me to the 2016 Spring Symposium of the Wake
Forest Law Review: Implementing De-Incarceration Strategies: Policies and
Practices to Reduce Crime and Mass Incarceration.

TEXT:
 [*705]

   Introduction


   Police in major metropolitan areas now use "predictive policing" technologies
to identify and deter crime. n1 Based on algorithmic forecasts from past crime
patterns and individual criminal risk factors, police claim to be able to
identify places and persons more likely to be involved in criminal activity. n2
This data-driven approach impacts police patrols, investigations, and public
health - like strategies to disrupt and monitor forecasted criminal activity. n3

   The early success of predictive policing has led a few prosecutors' offices
to adopt quasi-"predictive prosecution" strategies. n4 Predictive prosecution
involves identifying and targeting suspects deemed more at risk for future
serious criminal activity, and then using that information to shape bail
requests, charging decisions, and sentencing arguments. n5 The potential
problem, however, is that the data used to inform predictive prosecution
strategies may be subject to the same vulnerabilities currently limiting
predictive policing. n6 Data can be bad, biased, or based on erroneous
correlations. n7 Data-driven justice challenges  [*706]  values of transparency,
accountability, and autonomy. n8 And, while these problems matter when it comes
to questions of where to send a patrol car, or even whom to investigate, they
matter much more when data directly impacts a prosecutor's decision about
individual liberty.

   Fortunately, prosecutors, more so than police, may have the institutional
capacity and power to ensure an equitable and accountable use of predictive
technologies. Prosecutors, due to their ethic "to do justice," n9 may be in a
better position to ensure that issues of accuracy, transparency, validity,
error, and exculpatory information are addressed before widespread adoption.
Prosecutors may be able to capitalize on the innovation of predictive analytics
and promote stronger accountability mechanisms that could benefit the entire
criminal justice system. n10

   This Essay sets out the preliminary questions that prosecutors should ask
before adopting any type of quasi-predictive prosecution system. Part I provides
a brief overview of the growth of predictive policing and its evolution into
predictive prosecution. While still an experimental concept, certain predictive
policing techniques rely on prosecutorial involvement and action. Primary
attention will focus on two examples of predictive policing/prosecution in
Chicago, Illinois, and Manhattan, in New York. n11 The Chicago Police
Department, in conjunction with sociologists, computer scientists, and social
workers, has developed innovative strategies to identify individuals most likely
to be victims of gun violence or perpetrators of gun violence. n12 Once
identified, public health-like intervention  [*707]  strategies are used to
contact and monitor those targeted suspects. n13 Prosecutors warn targeted
suspects of potential consequences of future criminal action and then enforce
those warnings through enhanced bail, charging, and sentencing decisions. n14 In
New York City, Manhattan District Attorney, Cyrus Vance Jr., created the Crime
Strategies Unit to link and organize previously disparate prosecutorial
databases into a "central nervous system" n15 of information about suspected
criminal actors. n16 Under this "Moneyball" prosecution system, police and
prosecutors have targeted approximately nine thousand suspects for investigation
and prosecution. n17 Similar to the Chicago model, prosecutors shape bail,
charging, and sentencing decisions based on the information provided. n18

   Part II looks at the promise and perils of predictive prosecution. This part
examines three big questions about how predictive prosecution might impact: (1)
prosecutorial decision-making; (2) prosecutorial role; and (3) crime suppression
priorities. From one angle, predictive prosecution merely strengthens the type
of predictions and risk assessments already employed across the criminal justice
system, but with more extensive information-sharing capabilities. n19 From
another angle, predictive prosecution might be seen as a repackaging of the
longstanding "focused deterrence" theories used in some jurisdictions. n20
However, whether revolutionary or merely evolutionary, a risk assessment/public
health model of prosecution may have unintended consequences. If sentencing
decisions are ratcheted up because a suspect was placed on a target list, then
prosecutors better be sure that the list is an accurate and valid basis for a
sentencing enhancement. Correlation should not replace causation when it comes
to actual liberty deprivations. Further, if police officers link their databases
with  [*708]  prosecutors' offices, then prosecutors must take ownership of the
quality and accuracy of that information. This Part also looks at the legal
obligations of prosecutors relying on predictive systems. While generally
consistent with ethical duties and within the broad grant of prosecutorial
discretion, data-driven predictions should not be undertaken without internal
accountability mechanisms to ensure the accuracy and validity of the
predictions. In addition, the growing web of shared information may create Brady
obligations for prosecutors to turn over collectively available exculpatory
information. n21

   Part III concludes by suggesting that prosecutors may be in the best position
to create mechanisms to ensure accountability, transparency, and validity
consistent with due process and the fair administration of justice. Satisfactory
answers to the questions raised in Part II will be the first step in evaluating
the usefulness of predictive prosecution nationally. This Essay seeks to raise
preliminary questions about predictive prosecution, saving for a future day any
empirical assessment of its costs, benefits, and promise in practice.

   I. The Influence of Predictive Policing on Predictive Prosecution

 Predictive prosecution is an outgrowth of the reported success of predictive
policing. n22 Predictive policing involves the use of data collection and
analysis to predict areas of crime and individuals involved in crime. n23 The
generic term "predictive policing" encompasses a variety of different
techniques, proprietary products, and tactical uses. n24 Predictive-policing
technologies are shaping police strategies in a diverse list of places,
including major cities like Los Angeles, New York City, Chicago, Philadelphia,
Miami, Seattle, Kansas City, and Memphis, and smaller cities like Reading,
Pennsylvania and Alhambra, California. n25 The federal government  [*709]  has
funded pilot programs, n26 and large and small companies are competing for city
contracts. n27

   This section briefly details the history of predictive policing with a focus
on why the purported success of the technology might be appealing to
prosecutors. In three previous articles, I have described the full history of
predictive policing. n28 This section merely sets the stage for a discussion of
how predictive policing might impact predictive prosecution.

   A. A Brief History of Place-Based Predictive Policing

 The national emergence of predictive policing can be traced to Chief William
Bratton's appointment as Chief of Police of the Los Angeles Police Department
("LAPD"). n29 While the idea had been percolating before that moment, n30
Bratton promoted the idea in public forums and national media appearances. n31
Bratton had been a long-time believer in data-driven policing, having
restructured the New York Police Department based on data-driven accountability
metrics. n32 He brought his faith in data-driven policing to the West  [*710]
Coast and eventually partnered with a group of academics who had developed
algorithms to predict future crimes. n33

   The algorithmic approach to crime prediction was based on decades of social
science research showing that certain property crimes encouraged similar crimes
in a predictable manner. n34 A burglary in one neighborhood might encourage
additional burglaries in that same neighborhood. n35 An auto theft at a
particular time in one area might suggest future thefts in the same area. n36
The reasons for such a "near repeat phenomenon" n37 or "boost theory" n38 have
been debated, but the correlation of additional crime around the same area has
been regularly demonstrated. n39 Building off this insight and adding lessons
learned from environmental criminology, n40 hotspot policing, n41 and crime
[*711]  mapping, n42 academic researchers developed place-based predictive
software to predict certain property crimes. n43

   In practice, police officers might be told to focus attention on particular
geographic areas - usually block-sized, five hundred by five hundred foot areas
- and told to patrol those designated areas during the free times in their
shifts. n44 The areas would change daily depending on crime data. n45 The
presence of additional police in targeted areas was meant to deter criminal
activity. n46 Initial results showed a reduction in property crime, although
longer term trends remain unclear. n47 Criticisms have also been leveled that
certain crime reduction claims cannot be substantiated. n48

   These initial pilot projects eventually developed into a commercial business
to sell the predictive software. The company, PredPol, began marketing its
services to local police forces. n49 Santa Cruz, California became an early
adopter and demonstrated impressive initial results. n50 National press about
predictive policing fueled interest from other cities, n51 and PredPol soon
boasted a  [*712]  national roster of large and mid-size cities as customers.
n52 Other companies and technologies joined the quest to be able to predict
place-based property crime, and then violent crime. n53 Researchers at
Rutgers-Camden developed Risk Terrain Modeling ("RTM"), n54 which looks at
environmental factors such as bars, liquor stores, bus routes, and other urban
fixtures to map crime. n55 In a recent national study, RTM demonstrated
significant crime reduction across several jurisdictions. n56 HunchLab combines
the crime data focus of PredPol and the environmental focus of RTM and has
developed its own proprietary software for prediction based on machine-learning
technologies. n57

   Currently, more than half a dozen predictive policing companies, including
large corporations like IBM, Hitachi, and Motorola, are competing for business.
n58 These first predictive technologies have different names and different
theories, but share five commonalities. The technology involves crime data,
time, location, an algorithm, and a theory about why a particular area has a
heightened likelihood of criminal activity. n59 Place-based  [*713]  algorithms
have been used to target property crimes and violent crimes. n60 Many questions
still remain about the application, effectiveness, and promise of the
technology. But, as Commissioner Bratton stated in 2016, "Predictive policing
used to be the future, and now it is the present." n61

   B. The Development of Person-Based Prediction

 Person-based approaches to crime arose independently of predictive policing (at
least as defined by PredPol, RTM, or HunchLab) and were largely based on a
public health model of targeting crime. n62 For decades, sociologists identified
the reality that a small subset of individuals in any community committed the
vast majority of crimes. n63 Police recognized that targeting those individuals
could result in a disproportionate reduction of crime rates. n64 For violent
crimes, researchers studied shooting victims and, by tracking their social
networks, could identify likely future victims or criminal actors. n65 The
theory behind this approach was that most shootings involve a social network of
retaliation between rival groups (such as gangs, neighborhood crews, and drug
dealers) who respond in relatively predictable ways. n66 A shooting of a gang
member would lead to a retaliatory act. That act, in turn, would continue the
cycle of violence. Professor David Kennedy demonstrated that by targeting youth
violence through a public health model, police could dramatically curtail
shootings. n67 Andrew  [*714]  Papachristos, Anthony Braga, and David Hureau
investigated similar social network intervention strategies between rival gangs.
n68 Other scholars have investigated this same social network phenomenon. n69

   Despite arising from a different context, the social network model has
largely been subsumed into the greater predictive policing discussion because
media stories described person-based predictive techniques under the larger
rubric of "predictive policing," and because police administrators benefited
from the good will (i.e., good press) of predictive policing. n70 This Essay
continues that blurring of predictive methodologies, but it recognizes that
person-based prediction presents different issues than place-based prediction in
terms of liberty, autonomy, and due process.

   The best known person-based predictive policing system involves the Chicago
Police Department. The Chicago Police Department developed a data-driven process
to identify the most likely offenders of violent crime. n71 Entitled the "Heat
List," the concept is to identify young people who might engage in violence or
be victims of violence and intervene before the violence occurs. n72 This
identification is conducted by police officers (called District Intelligence
Officers) who evaluate past criminal activity, whether the target has been
identified as part of a gang audit, n73 and whether the target has been placed
on the "strategic subjects list" ("SSL"). n74 An official Chicago Police
Department Special Order S10-05 describes the SSL:



   The Strategic Subjects List (SSL) is a rank-order list of potential victims
and subjects with the greatest propensity for violence. The SSL model looks at
individuals with criminal records who are ranked according to their probability
of being involved in a shooting or murder, either as a victim or an offender,
known as a "Party to Violence" (PTV). The software is generated based on
empirical data that lists attributes of a person's criminal record, including
the record of violence  [*715]  among criminal associates, the degree to which
his criminal activities are on the rise, and the types of intensity of criminal
history. n75

 Once identified and placed on the "Heat List," a team of police officers,
social workers, and community leaders conduct a "custom notification" which
involves a face-to-face meeting and the delivery of a custom notification
letter. n76 This letter details the individual's prior contacts with the
criminal justice system, as well as potential future consequences for any
continued criminal activity. n77 These custom notification meetings usually
involve home visits. n78 Essentially, the young person is offered a choice: take
advantage of social services to prevent involvement in future violence or face
additional law enforcement surveillance - and perhaps punitive consequences. n79
Currently, the Chicago Police Department includes over 1300 names on its Heat
List. n80

   This suspect and social network-focused approach to policing has - under
different names and different programs - been adopted in Kansas City, Boston,
New Orleans, Los Angeles, and other cities. n81 Juvenile courts have also begun
to consider implementing similar identification processes for troubled youth.
n82 The open question, however, is how the algorithm scores the criminal record,
connections with associates, and intensity of criminal history, among other
considerations. With few exceptions, the types of identification mechanisms have
not been validated through scientific methods. n83

[*716]

   C. Early "Predictive Prosecution" Models

 The efficacy of predictive policing remains both alluring and unproven.
Significant research studies have yet to be conducted in any systemic way. n84
Questions remain as crime rates have fluctuated in cities using the
technologies. n85 Yet, despite the unknowns, prosecutor offices have embraced
the insight that predictive analytics and information sharing can identify risk
factors in a community and improve the prosecutorial function. n86 The same
broad tactical shift toward proactive law enforcement has thus begun influencing
proactive prosecutorial strategies. As the former head of the Manhattan Criminal
Strategies Unit stated, the change is as much one of philosophy as technology.
n87 The goal is to focus on crime, not cases. "Intelligence-driven" prosecutions
seek to take already existing information in prosecution offices, organize it,
manage it, and deploy it to target those most at risk of driving crime in a
community. n88

   While still in the very early stages, two distinct predictive prosecution
models have been developed. Here I describe them as the "Enforcer Model" and the
"Investigator Model." Neither, to be clear, involves pure algorithmic or machine
predictions. Just as predictive policing is more of a risk identification tool
than a predictive guess, so, too, predictive prosecution seeks to proactively
identify risk factors (areas and suspects) in a community and direct attention
to those problems. Predictive prosecution involves data-driven,
information-sharing innovations, but not pure algorithmic judgments about places
or people. As will be discussed, some blending of predictive policing techniques
and predictive prosecution techniques may occur in the future, but currently the
prosecution side has relied on more human rather than algorithmic predictions.

   1. Enforcer Model

 The Enforcer Model arises from person-based predictive policing strategies. In
this model, prosecutors play a role of enforcing warnings made to those
predicted to be involved in criminal activity (especially violence). In some
cases, this prosecutorial enforcement might be indirect, but in other cases, the
prosecutors might directly  [*717]  and personally provide verbal notice of
harsher enforcement penalties.

   For example, the Special Order detailing the process of custom notification
in Chicago makes explicit reference to prosecutorial involvement. n89 The
Special Order provides that when someone identified on the Heat List is
rearrested, the police will recommend the highest possible charges to
prosecutors, encourage community advocacy against bond release, and engage in
direct coordination with state prosecutors' offices. n90 Section V.D reads in
full:



   When a recipient of the custom notification engages in criminal activity for
which he or she is arrested, the district commander will ensure:



1. Notification to and coordination with the appropriate Bureau of Detectives
Area to ensure appropriate charging occurs. The highest possible charges will be
pursued for any individual in the VRS Custom Notification Program.



2. Court advocacy volunteers are notified of the date, time, and place of the
bond hearing or other court hearings and encourage attendance at the hearing to
demonstrate the community's support in decreasing the violence.



3. Coordination with the Cook County's State's Attorney Community Justice Center
Unit as appropriate. n91

 Prosecutors are, thus, directly influenced by a suspect's placement on the Heat
List.

   The Custom Notification Letters themselves "include a description of both
federal and state sentencing options" n92 demonstrating how prosecutorial
decisions will be impacted by this designation. In fact, in the definitions
section, the Custom Notification Letter is defined as an information tool to
make suspects aware of enhanced prosecution possibilities:



   The Custom Notification Letter will be used to inform individuals of the
arrest, prosecution, and sentencing consequences they may face if they choose to
or continue to engage in public violence. The letter will be specific to the
identified individual and incorporate those factors known about the individual
inclusive of prior arrests, impact of known associates, and potential sentencing
outcomes for future criminal acts. n93

  [*718]  The procedures and policy behind custom notification, thus, encourage
prosecutors to follow through on the charging, bond, and sentencing warnings
provided in the custom notification letters.

   Prosecutors play a more direct enforcer role in other gang violence reduction
strategies. n94 One strategy that has been adopted by law enforcement is called
"focused deterrence." n95 Focused deterrence involves a targeted message to a
small percentage of the population that prosecutors, police, and community
members know who is engaged in violence and that they are committed to stopping
it. n96

   For example, Chicago has developed a broad Gang Violence Reduction Strategy
that identifies gang members through "gang audits" and the SSL. n97 Identified
targets are then invited to "call-in" meetings with prosecutors, police, and
community members. For example, if a young man is identified through a gang
audit, the SSL, or some other targeting measure, n98 and asked to participate in
a community forum, it is not uncommon for a prosecutor to be present. n99 These
call-in meetings serve as a "scared straight" warning for individuals placed on
the Heat List. n100 The prosecutor symbolically and sometimes literally
describes the consequences for failing to heed the warning to stay away from
crime. As described by Andrew Papachristos and David Kirk:



   A federal partner, typically from the U.S. Attorney's Office, explains how
federal statutes might be leveraged against the faction, including continued
criminal enterprise and armed career criminal statutes. The point of this
message stresses the deterrent aspect of the program. Representatives from local
police and prosecutors provide examples of recent cases and shootings to
underscore the reach of the current violence  [*719]  and how they are working
in a coordinated fashion with others in the room. n101

 The message is made clear by prosecutors: if you violate the law again, you
will be punished harder because you have been warned. One U.S. Attorney
referenced a fifteen-year sentence for a single bullet for someone who had not
heeded the warnings. n102 The point was made clear that those predicted to be at
higher risk for crime had better turn their lives around or face additional
sanction by prosecuting authorities. n103

   As described above, prosecutors, as enforcers for predictive policing
techniques, remain in a fairly typical prosecutorial role with one exception:
the enforcement threats are influenced by predictive data. Clearly, prosecutors
have long held community meetings. Prosecutors have long held "scared straight"
talks in community forums. n104 Prosecutors have long stood arm in arm with
police to send a message that criminality will not be tolerated. The difference
here is that the targets of the community forum, and thus the subjects of
harsher punishment, were originally identified by predictive policing techniques
and other data-driven mechanisms. If those algorithmic or social network
correlations are in error, then the subsequent harsher punishment may be
unjustified. Evidence is very clear that arrest records are filled with
mistakes. n105 Similar  [*720]  problems exist with gang databases n106 and
offender registries. n107 If those "Heat Lists" are found to be flawed, then not
only police surveillance, but prosecutorial judgment becomes distorted.

   The Chicago Tribune interviewed a young man, Robert McDaniel, whose name
appeared on the Heat List because a friend of his had been shot. n108 Mr.
McDaniel's prior record consisted of a single misdemeanor conviction and a few
minor arrests. n109 But, by being placed on the list, Mr. McDaniel was now
associated with the worst of the worst. An enhanced sentence predicated in part
on a connection to a Heat List that later turns out to be unwarranted would be a
real unfairness to someone like Mr. McDaniel. If the prosecutor does not take on
an independent duty to double check the data, then the harm from such a
prediction could be significant. n110

   Prosecutors who are enforcing predictive policing or social network models
depend on the accuracy of those models for guidance. As will be discussed in
Part II, this enforcement role offers benefits and risks in its real world
application.

   2. Investigator Model

 The Investigator Model of predictive prosecution involves a more organic
prosecutor-led information-sharing system. Such a system, like the Crime
Strategies Units being developed in Manhattan, San Francisco, Philadelphia, and
Baton Rouge, n111 is data driven and targets identifiable criminal actors. n112
These systems are not based on algorithmic judgments, but on data of actual
crime patterns in a city. n113 Using data, prosecutors identify geographic areas
of concern based on reported shootings, thefts, or  [*721]  particular types of
crime. n114 Suspects are identified as being engaged in violence or gang
activity based on past criminal activity. n115 These individuals are monitored
through social media and traditional law enforcement surveillance. n116 The
predicted targets are then prosecuted using available prosecutorial leverage to
extract enhanced pleas or sentences from those identified. n117

   In general, this type of intelligence-driven prosecution involves five
modifications from the traditional police-prosecutor relationship. First,
prosecutors identify geographical areas of concern based on reported crime
patterns in a city. n118 The focus is again on crime, not cases, meaning even
unsolved crimes also capture the attention of prosecutors. Second, prosecutors
identify individuals who are considered the crime drivers in a community and
include them in an "arrest alert system." n119 These individuals become the
"primary targets" of prosecution, under the theory that by removing these
violent actors, overall violence levels will fall. n120 As will be discussed,
the arrest alert system triggers heightened attention for a prosecutor to
incapacitate these predicted bad actors through existing legal mechanisms.
Third, less traditional data points enter into the calculation of whom to
target. Social media posts, a past lack of cooperation with police, status as a
victim of violence, and other less formal bits of information are included in
the risk assessments of whom to target. n121 Fourth, the information sharing
between police and prosecutors is prioritized and strengthened. n122
Intelligence-driven prosecution is not just about being smarter, but developing
actionable intelligence about crime patterns in an area. Finally, all of this
information about past criminal activities is memorialized in a searchable
dataset for future action. n123

   As one example, the Crime Strategies Unit in Manhattan has developed a new
information-sharing system to proactively identify the "most wanted" of New
York's criminal actors. n124 These individuals have significant past criminal
records, but the data  [*722]  focuses on future criminal risk. The logic being
that past instigators of criminal activity are at greater risk to be the future
drivers of crime. This database of approximately nine thousand names has become
critical to several major prosecutions. n125 In essence, prosecutors have
predicted that incapacitating these criminal actors will lead to an overall
reduction in crime. As explained by David O'Keefe, the past Head of the
Manhattan District Attorney's Crime Strategies Unit ("CSU"), "Working with our
partners in the precincts, we also identified hot spots and the names of the
people committing the most crimes in each area. The question became, what can we
do to incapacitate these people?" n126

   This focus on incapacitating "primary targets" has significant practical
effects on traditional prosecution practices. Routinely now, if someone listed
in the CSU arrest alert system is arrested, even for a low-level offense, the
full power of the prosecutors' office is directed against them. n127 This means
that ordinary arrests may result in extraordinary outcomes where those marked as
predicted troublemakers are punished to the full extent of the law. n128

    [*723]  The Investigator Model of predictive prosecution, thus, influences
several aspects of the traditional prosecution process. First, the targeting
system impacts bail decisions, as prosecutors might be instructed to ask for
higher bail for those identified in the arrest alert system. n129 Before the
arrest occurs, CSU drafts particularized bail applications on predicted
individuals advocating for strict bail positions. n130 Second, targeted
individuals could face enhanced criminal charges in order to maximize
prosecutorial leverage. n131 This means that prosecutors would be instructed to
seek the maximum charges justified under law. n132 These initial charging
decisions obviously impact later plea deals and impede plea negotiations as
defendants face much harsher potential punishments. n133 Sentencing decisions
can also be ratcheted up as prosecutors seek to ensure the maximum penalty
possible. n134 Maximum sentences on minor crimes result in extended
incarceration. Even after convictions and sentencing, prosecutors have been
known to weigh in on parole decisions and requirements of release. n135

   Beyond direct prosecution, CSU also impacts how uncooperative witnesses may
be handled. n136 Whereas in the ordinary course, an  [*724]  uncooperative
witness might enter and rapidly leave the criminal justice system on a minor
charge, now prosecutors will be alerted to the witnesses' arrest and legal
predicament. n137 As one of the Chief Prosecutors in Manhattan explained in a
news article on the CSU:



   Every morning, I talk to my five A.D.A.s, who are experts in their areas. We
decide whom we should try to pull out for a debriefing... . We pull people
arrested on low-level misdemeanor charges, maybe two or three a week. We read
them their Miranda rights. About 80 percent of them will talk. n138

 These debriefings are not unusual or unethical, but the new alert system makes
the ability of prosecutors to locate witnesses much easier. The simple truth is
that additional leverage can make initially uncooperative witnesses more
cooperative. n139

   The Crime Strategies Unit also provides additional information about crime
patterns and criminal activities in localized geographic areas. n140 Prosecutors
create intelligence reports on criminal hotspots, develop a violence timeline of
crimes, and identify the primary violent actors, gangs, and community
stakeholders in each location. n141 Police have begun tracking social media
posts of some of the targeted individuals. n142 This social media focus has
proven quite valuable in mapping out the social networks of gang activity in New
York. n143 Detectives and prosecutors can now visualize the social relationships
of gangs and communities in ways that explain and  [*725]  predict tension,
shootings, or other violence. n144 Threats on social media can help forecast the
next shooting. Prosecutors, in collaboration with the police, have begun using
traditional surveillance techniques (such as video cameras) to augment their
monitoring of predicted criminals. n145 Facial recognition software linked to
social media has led to the identification of suspects and witnesses. n146
Targets are not only mapped by their relationships, but actually tracked as they
go through the criminal justice system from arrest through post-parole release.
n147 Prosecutors, not just police, have gained access to traditionally
investigative, as opposed to adjudicatory. tools. n148

   The result is a new type of prosecutor-police relationship that blurs
traditional lines. n149 Prosecutors are focusing on future-oriented,
intelligence-driven prosecutions. n150 Police are following suit. As reported by
the New York Times, the CSU prosecutorial data system is intended to augment
joint police-prosecution investigations:



   As part of a template for relations between the two agencies, the district
attorney's office will provide the police with more  [*726]  than $ 20 million
from drug forfeiture cases to pay for new technology. That money will go for
security cameras, fiber-optic information systems and hand-held tablets that
will feed police officers data about suspects, Mr. Bratton said. The Police
Department, in turn, will provide the district attorney's Crime Strategies Unit
access to more of the data it collects not only on reported crimes but also on
suspects, Mr. Bratton said. He called the new approach "extreme collaboration"
and illustrated it by clasping his hands together. n151

 This process signifies a realignment to a more proactive method of prosecution
n152 and one that encourages what Commissioner Bratton called a "seamless web"
of information between prosecutors and the police. n153

   Before moving on to discuss the future of predictive prosecution, it must be
made clear that much of what is being proposed is not fundamentally all that
new. Police and prosecutors have long kept detailed dossiers on potential
suspects. n154 As Wayne Logan and I have written about, our current data-driven
criminal justice system has roots in 18th century innovations. n155 Data in the
form of arrest logs, arrest warrants, offender registries, biometrics, and a
host of court and community supervision records has long been available to
police. n156 Further, police have recognized the need to identify and target
potential "bad apples" since before there were police forces. n157 This
information has regularly been shared with prosecutors who have built similarly
extensive investigative files on potential offenders. n158 Predictive
prosecution is merely an innovative way to identify and predict likely targets
through the use of better data-sharing technologies.

    [*727]  Nevertheless, the impact of predictive analytics and social network
technology on law enforcement and prosecution is real and needs to be examined.
Predictive policing has gained a foothold in police administration. Predictive
prosecution is only a few years behind. And so, the promise and perils need to
be addressed as the technology and methodologies develop. The next section looks
at three big questions facing predictive prosecution.

   II. Preliminary Questions About Predictive Prosecution

 Predictive prosecution holds real promise for prosecutors' offices seeking to
focus resources on those individuals thought to present the greatest risk to
society. By prioritizing those identified to be most at risk, prosecutors - at
least in theory - can utilize existing discretionary power in a manner that is
more efficient, proactive, cheaper, and smarter. As this is a symposium devoted
to Implementing De-Incarceration Strategies: Policies and Practices to Reduce
Crime and Mass Incarceration, such an innovation deserves a serious look. At the
same time, hard questions must be asked of this new method of prosecution. What
are the impacts, distortions, or concerns?

   This section examines three big questions surrounding predictive prosecution.
First, how does predictive prosecution impact prosecutorial decision-making?
Second, how does predictive prosecution impact prosecutorial role? And third,
how will predictive prosecution impact crime suppression strategies? Due to the
constraints of the symposium-essay format, the ideas discussed are initial
impressions, not full explorations of complex and important topics.

   A. Predictive Prosecution and Prosecutorial Decision-making

 Predictive prosecution offers potential benefits in terms of prioritization,
efficiency, and more informed judgments. Prosecutors must make difficult
decisions every day, and more information might provide for better choices. In
today's legal system, prosecutors possess almost unlimited discretion. n159
Prosecutors  [*728]  decide whom to prosecute. n160 Prosecutors decide how to
charge and how to structure plea bargains. n161 And prosecutors decide
recommendations for sentences. n162 Adding information from sources such as the
predictive policing Heat List or organically developed intelligence does not
present any direct ethical or constitutional concerns. n163

   If used to identify and proactively target actual crime drivers in a
community, a predictive prosecution system could well provide an overall benefit
to society. If resources could be redirected toward incapacitating more serious
offenders (through bail, charging, and sentencing decisions), while
concomitantly incapacitating fewer, less serious offenders, such a process could
mean fewer overall people in jail. Such a system might also be more efficient,
redirecting scarce prosecution resources. Of course, the current system of mass
incarceration that has developed over the last several decades has not lacked
for efficiencies in prosecuting and convicting defendants. n164 Mandatory
minimums, harsh drug sentences, plea bargains, and other processing efficiencies
have created an overly efficient process for incarcerating millions of people.
n165 But, the web  [*729]  of people caught up in this system has been
overbroad, lacking a commitment to prioritize those most dangerous to society.
n166 Millions of nonviolent offenders, millions of misdemeanants, and millions
of low-level figures in the drug world are serving significant time in jail.
n167 Individually, those persons might not be the chosen targets of our criminal
justice resources, but systemically prosecutors have had few mechanisms to
evaluate or rank relative danger or risk to society. n168

   Predictive prosecution offers a potential smart-on-crime counterweight to the
tough-on-crime practices of over-incarceration. In fact, taken one step further,
if prosecutors only sought to target those predicted to be of high risk of
committing crime, then a huge majority of people would see reduced bail, better
pleas, and more lenient sentencing. Such prioritization might significantly
reduce pretrial detention costs, long term sentencing costs, and overall
criminal justice costs.

   The danger, of course, is that predictive prosecution might not reduce
prosecution levels, but might, in fact, bring more people into the criminal
justice system. Two obvious concerns arise within the Enforcer Model. First, in
the Enforcer Model individuals are being linked to criminal activity by proxies
for criminal activity. A gang member who has a friend who was shot may be added
to the system because, statistically, the associates of dead gang members are
more likely to themselves be involved in gun violence. n169 The "two degrees of
separation" analysis may both be accurate n170 and yet overbroad when it comes
to prosecutorial decisions. The particular individual might not have done
anything but be a victim of violence, or might remain a small time criminal
actor. Further, that particular individual might be summoned to a call-in by a
prosecutor and threatened that he may face harsher detention, charging, and
sentencing decisions should he get in trouble in the future. So, that individual
is in the first instance added to a prosecution list without  [*730]  criminal
activity of his own, and in the second instance faced with the potential for a
harsher criminal justice outcome because of that designation.

   Similarly, in the "Investigative Model," individuals are being targeted
because they have been identified as the primary targets for removal. n171 The
key, of course, is the process by which people are targeted. If limited to only
those individuals with multiple convictions for violence, this incapacitation
approach can be defended. Using minor crimes to incapacitate major criminal
actors is aggressive, but defensible. However, if other factors such as a lack
of cooperation with police, suspected but unproven violence, or low-level,
non-violent crimes become the justification for being a target, then
justification for aggressive incapacitation weakens. Using minor crimes to
incapacitate minor criminal actors undercuts the value of targeting only the
serious offenders.

   Put another way, because the targeting mechanism of identifying the primary
targets rests with the prosecution (in collaboration with police), and because
there is no system to challenge or correct a targeting error, a risk arises
about the data populating this system. Prosecutorial decision-making runs a real
risk of being infected by bad data in these systems. n172 Personal bias could
influence who becomes a target. Political or economic pressure could shape the
types of crimes addressed.

   Even more generally, any data-driven system runs into concerns with data
quality. Data can be inaccurate. n173 Data can be biased. n174 Data can reify
the existing socio-economic inequalities in  [*731]  the criminal justice
system. n175 Data can also be overwhelming, with little practical or
technological checks on quality or accuracy. n176 Yet, every day police and
prosecutors collect more data on individuals, and systems are being designed to
become more reliant on this data collection. n177 In prior articles, I have laid
out the concern of data error in the criminal justice system. n178 From big data
to small data - all data systems generate error. n179 Human error, collection
error, processing error, analytical error, application error, or sharing error
all exist and cannot be minimized when this same data is used to determine human
liberty. If prosecutors' discretionary power involving bail, charging, and
sentencing is informed by erroneous or merely poorly correlated data, then real
injustice could occur.

   The issue is not that prosecutors cannot rely on this data within their
existing professional and ethical mandate, but whether they should. Part III of
this Essay will address how prosecutors should minimize the real risk of using
bad or biased data.

   B. Predictive Prosecution and Prosecutorial Role

 Predictive prosecution may alter the prosecutor's role. A
predictive-prosecution focus redirects power away from a reactive model of
prosecution driven by police arrests to a more proactive model of prosecution.
As CSU Chief David O'Keefe stated, "It used to be we only went where the cases
took us. Now, we can build cases around specific crime problems that communities
are grappling with." n180 While many cities have experimented with community
[*732]  policing strategies for years, n181 and certain grand jury
investigations have been quite proactive, traditionally the majority of state
criminal cases come to prosecutors from police arrests and victim complaints.
n182 At least in one version of the prosecutorial role, prosecutors take the
facts and cases as they come to them.

   The Investigator Model of predictive prosecution potentially alters that
reality. By broadening the aperture of prosecutorial responsibility to focus on
predictive targeting, the role of the prosecutor shifts. As an example of how
traditional prosecution practice might change, New York City has a longstanding
problem of drugs and violence in certain apartment complexes. n183 For years,
patrol officers dutifully arrested drug sellers and buyers, and reactively
responded to violent incidents. n184 The arrests came from police observations
and investigation. n185 Over the last few decades, thousands of individual
criminal actors in those complexes have been arrested and prosecuted. n186 In
contrast, the Crime Strategies Unit decision to proactively target and indict
103 members of rival gangs all in one sweep presents a change in strategy and
role. n187 The case was driven and directed by the District Attorney's Office.
n188 It sent a message of prosecutorial involvement in rooting out crime, as
well a message of prosecutorial understanding of the structural nature of the
crime problem in local areas.

   In terms of the power to control criminal suppression in a city, the
predictive prosecution model shifts the identification of problem areas from the
street cops to the lawyers. Prosecutors get to decide - using all of their
discretion, data, and other tools - who to investigate before an actual
precipitating crime occurs. Prosecutors get to decide to target an individual
for incapacitation and use the tools of bail, charging, and sentencing to do it.
Police execute these decisions, but the power lies with the prosecutors' office
in the first  [*733]  instance. n189 While such large scale prosecutorial
investigations are not unusual in federal court or against large scale criminal
enterprises, n190 predictive prosecution of street crime might well shift the
balance of power away from police to prosecutors, and even to smaller units
within those prosecution offices.

   Beyond street crimes, a move to proactive prosecution might also shape the
types of crimes pursued by prosecutors. It is not accidental that most state
criminal courts are filled with lower-level crimes that police can personally
observe. n191 Drug sales, prostitution, theft, disorderly conduct, and assault
are all far more observable than domestic violence, white collar fraud, or
sexual assault. n192 As a result, prosecution resources are devoted toward
reactive policing, not proactive policing. n193 A shift toward predictive
prosecution might change that dynamic, with prosecutors taking the lead to
prioritize different types of criminal wrongdoing. Prosecutors can choose to
focus more attention on violence rather than drug possession, n194 or to target
human trafficking more than drug trafficking. n195

   At the same time, this new role threatens a longstanding source of
legitimacy. Prosecutors have traditionally been expected to be neutral arbiters
in the pursuit of justice. n196 As Professor Bruce Green and Fred Zacharias have
written, this neutrality "connotes independence from the police." n197
Prosecutors have remained independent from police investigations in order to
better evaluate  [*734]  the constitutionality, legality, and moral worth of the
prosecution. n198 Much of the judicial deference given to prosecutorial
discretion depends on this objective evaluation of whether the case should go
forward. n199 Prosecutors, after all, routinely refuse to go forward with cases
brought to them by police. n200

   The Investigator Model of predictive prosecution blurs this neutrality as
information sharing, strategy, and even execution of investigations becomes more
prosecutor-driven. While prosecutors can still be objective about the evidence
recovered, they may be less neutral in their role if they planned and
implemented the collection of that evidence. They might be tempted to engage in
the "competitive enterprise of ferreting out crime" n201 and thus lose a measure
of objectivity. Prosecutors might be tempted to bring weak cases simply to
incapacitate an individual identified as a primary target, even though in every
other situation that same case would not be prosecuted. Charges might be
ratcheted up from a misdemeanor to a felony, not because the facts warrant the
increase, but because the individual has been targeted for incapacitation.
Perhaps just as damaging, the image of prosecutor will be tarnished, even if
there is no actual difference in practice or outcome. n202 This is not to say
that prosecutors have not led significant, high-profile prosecutorial-driven
investigations for many years, but they would now have a different role for
low-level street crime involving repeated thefts, non-homicide shootings, and
drug dealing.

   The Enforcer Model of predictive policing presents a slightly different
distortion of role. As enforcers, prosecutors become more dependent on the
police data that created the predictive targets. If the algorithm that creates
the Heat List or the information that guides the gang audit is wrong, then the
accompanying prosecutorial judgments about whether to enforce the threats may
also be wrong. In some ways this reduces the role of prosecutors in the system
at the expense of the data collectors at the police  [*735]  department. One can
imagine that in high-volume jurisdictions with aggressive predictive policing
models, prosecutors will not be in a position to judge the accuracy or
reliability of the person-focused predictions. In an ideal world, prosecutors
would want to know who was attending the call-in meeting and the appropriateness
of their official threats to not violate the law. In practice, such knowledge
might be improbable to expect. Prosecutors already have too many cases and
responsibilities, n203 and adding additional responsibilities to understand why
certain people were summoned to a call-in meeting may not be feasible. As
"enforcers," prosecutors will likely simply defer to the police-driven
prediction and hope that the sorting mechanism is accurate.

   The blurring of lines also has an impact on the prosecutor's responsibility
to provide exculpatory information to defendants. The requirements of Brady
disclosure include information known to the prosecutor and the police. n204 In
ordinary cases, this would include information known to the prosecutor through
the prosecutor's investigation and the relevant police documents or witnesses.
n205 But, in a world of "extreme collaboration" and within a "seamless web" of
shared databases, those pieces of information become far more interconnected.
n206 Prosecutors arguably are responsible for every fact listed in the shared,
searchable database. Almost by definition, intelligence-driven policing
generates more scattered bits of intelligence about the players involved in
criminal activity (nicknames, gang affiliations, shared addresses, and
cooperators). With interlinked crimes, suspects, and witnesses, the
prosecution's data systems will likely have more information that could be
exculpatory to defendants.

   For example, notes within the arrest alert system could suggest other gangs
or gang members who might have a similar motive for a violent act, or could
include witness statements that discredit the prosecution's theory of the case.
The line prosecutor may not personally know any of this information, but the
information would be available in a searchable prosecution-controlled database.
Is the failure to reveal this searchable, available information a constitutional
violation? The danger of integrated databases is that all of that information
becomes collectively imputable to the prosecutor's office, which in turn means
that the prosecutor is responsible for providing it to the defense. Similar
questions exist with shared surveillance resources. Information not directly
under  [*736]  the control of the prosecutor's office could be plausibly denied
as not in the prosecutor's constructive or actual possession. A system of
extreme collaboration undercuts that argument. A prosecutor who has access to
more information because of more efficient data-sharing systems will be
responsible for disclosing more because of that collective knowledge.

   This leads to an even bigger change in role, in that prosecutors may have to
become quasi-intelligence analysts in this intelligence-driven system. In the
traditional criminal case, a prosecutor is given thousands of facts through
witnesses, police officers, documents, photographs, investigations, and other
sources. n207 The prosecutor knows what she is told by police, and what the
evidence shows, but there is no independent obligation or ability for a
prosecutor to vet the information. n208 The facts are usually collected after
the fact, by police not prosecutors, and with an eye toward what can be proven
in court. n209 Rumors and theories are useful as background, but prosecutors are
looking for facts they can prove in court. A natural screening process occurs
because the rules of evidence, burdens of proof, and realities of trial practice
all create an emphasis on credible and provable facts. n210

   With predictive prosecution technologies, the information assessment is
slightly different. At the investigation stage (as opposed to the arrest stage),
the information is more fragmented. Facts that could not be proven in court are
used to establish the primary targets. n211 Intelligence tips are not always
provable. In addition, they are not always accurate. Prosecutors thus need to
establish systems akin to intelligence analysts in the intelligence community to
vet the credibility and reliability of this raw data. In both the national
security context and the police context, "sources" lie, deceive, err, and, of
course, get things right. n212 And only by  [*737]  establishing a process to
evaluate the data can prosecutors trust the data. This change may require
modifications in how prosecutors' offices process, analyze, vet, and use data,
which will be discussed in Part III.

   C. Predictive Prosecution and Crime Suppression Priorities

 Prosecutors' offices do not just enforce criminal violations, but also
strategize about crime suppression. n213 Especially in jurisdictions with
elected prosecutors who must take responsibility for increased crime rates,
crime reduction is a top priority. n214 Prosecutorial control of criminal
justice priorities strengthens democratic accountability and connection. n215 If
a community has concerns about disproportionate minority arrests for drug
possession, the normal (and defensible) traditional prosecutorial response is
that prosecutors merely handle the cases the police bring them. While they have
the power to decline such prosecutions, they do not have the power to redirect
police efforts to make the arrests. n216 Predictive prosecution changes that
dynamic. Communities could well say to prosecutors that the focus should not be
on drug crimes, but instead gang crimes, or homicides or whatever the community
prioritized. Predictive prosecution thus gives more power (and therefore more
accountability) to prosecutors to align priorities with their communities.

   This reprioritization can also include a shift in how to reduce crime. While
predictive prosecution certainly maintains an emphasis on incapacitation and
threats of incarceration, it is also built upon a public health approach to
crime. Over the last decade, many policy makers have been pushing a public
health approach to violence, drug addiction, and criminal activity. n217
Person-based predictive policing explicitly adopted a public health model of
identifying risk factors. In the same way that certain environmental toxins
increase the risk of cancer, so too do certain environmental factors increase
the risk of violence for youth. n218 If predictive prosecution techniques are
used to identify the individual,  [*738]  human risks, as well as the casualties
of those risks, then certain public health-like interventions could be
implemented.

   These intervention strategies do not need to involve police or prosecutors or
the threat of incarceration. In fact, part of the predictive policing model in
Chicago and other cities expressly recognizes that social services and community
pressure may be more effective than law enforcement. n219 As just one example,
the Chicago VRS intervention system structured its call-in meetings to balance
any law enforcement discussion with equal parts community involvement and social
services. n220 The point was to emphasize that the solutions to criminal
activity could be found through available community and social services
resources. n221 The question, of course, is whether this same public health
intervention strategy can work without the "stick" of prosecutorial enforcement.
Analytically, the identification of risk and the remediating of risk are
separate problems. Neither has to be led by police or prosecutors. But, due to
practical, political, and financial reasons, they appear to be bound together
for the near future.

   Predictive prosecution, because it is a proactive approach, can also shift
priorities to look at underlying environmental drivers of crime, rather than
simply responding to criminal activity. Predictive analytics can isolate places
that attract criminal activities. n222 Environmental criminologists have long
written about problematic hot spots n223 and predictive policing techniques are
now policing some of those areas. n224 But, prosecutors might be able to
intervene at a more elevated political or policy level. Prosecutors might be
able to use political capital to alter the physical landscape in a community,
engage with community stakeholders, or even develop social services programs to
help individuals from the community. If, for example, a particular area is known
for car thefts, because the environment of abandoned buildings, dark streets,
and easy escape routes provides a tempting opportunity for criminal activity,
then prosecutors could work with communities and politicians to remedy the
environmental risks. Or prosecutors could, as the Manhattan District Attorney's
Office has done, n225  [*739]  partner with community groups to sponsor youth
sports and academic events in troubled areas.

   Finally, predictive prosecution encourages a shift in looking at crime
patterns from a network perspective. Traditional prosecution tends to focus on
individuals. We think of crime as a function of individual choice, not
environmental influences. n226 While many prosecutors' offices have targeted
large-scale crime networks, the majority of cases involve a limited number of
suspects targeted for particular completed crimes. n227 Predictive prosecution
has the potential to shift the focus of attention from individuals to networks
and from individual choices to social group influences. This shift is not a
wholesale shift. Clearly, predictive prosecution seeks to identify specific
individuals to be placed in databases of targeted suspects. These individuals
are placed there because of their choice to break the law. But, because of its
focus on gangs, neighborhoods, and social media networks, predictive prosecution
also allows for broader understanding of criminal relationships and patterns.
The "intelligence" of intelligence-driven policing is to see how the networks of
violent actors interact, and then do something to interrupt those cycles of
violence.

   As a hypothetical example, prosecutors may know that one hundred young men
live in a particular housing complex and ten of those men are actively involved
in social media posts that boast about violence, criminal activity, and
lawlessness. Seeing this group as a network, and not ten individuals, does
several helpful things. First, it allows for a study of the interrelation
between the ten men. Some may be instigators of violence, some might be
followers, and some might be silent, non-participants. This might allow
prosecutors to prioritize within the group about the more dangerous of the
group. In addition, it allows prosecutors to see how the network extends across
neighborhoods and generations. Prosecutors can see who else might be connected
to this group, and thus brought into its ambit. Most criminal networks are
bounded by geography and family, n228 so one could almost predict who might be
the next individual joining the group.

   Studying this group to figure out why certain individuals have not joined the
group might also be valuable. Is it friendship, finances, some triggering event
that links the ten together and doesn't include the other ninety? Is there a new
group that has arrived in an area? Are there correlations that can be drawn to
explain why certain people remain outside the network of potential criminality?
Predictive prosecution thus might allow a study of why  [*740]  certain networks
form, about connections arising from neighborhoods, schools, or environments.
While sociologists have been studying this phenomenon for a century, n229 and
most prosecutors and police officers could tell you about this reality from
experience, a network theory of criminal justice has not yet been
operationalized in practice in most prosecutors' offices.

   III. Principles for Predictive Prosecution

 Predictive technologies are not new to the criminal justice system. n230 Since
the 1920s the lure of predictive insights has led the criminal justice system to
try to forecast the future. n231 Predictors for recidivism, n232 pretrial
detention, n233 sex offenders, n234 juveniles, n235 and a host of actuarial
solutions have been proposed. n236 Predictive policing, and now predictive
prosecution, fit that pattern.

   For almost as long as their creation, the critiques of these predictive
technologies have identified the same concerns over and over again. Predictive
correlations become mistaken for causation, n237 validation studies fail to
validate, n238 analytical  [*741]  mistakes infect the legitimacy of the
conclusions, and error - small and systemic - pervades all data-driven systems.
n239

   The concept of predictive prosecution provides the same promise and potential
critique. Yet, because of the prosecutor's special role in the criminal justice
system, there may be some cause for optimism. If designed carefully, a
predictive prosecution system might provide an accountability mechanism to
police data error and moderate blind reliance on data-driven predictions.

   While a full descriptive framework is beyond the scope of this Essay, any
predictive prosecution system must be built on four related principles:
ownership, accuracy, transparency, and fairness. These principles are explained
below, with recognition that significant additional discussion and debate is
needed before the adoption of any predictive prosecution program.

   First, prosecutors must accept ownership of the data underlying predictive
prosecution systems. If bail determinations, charging decisions, or sentencing
is impacted at all by data correlations (being on the SSL list or being
identified as one of the primary targets in New York City), then that underlying
data must be trustworthy enough to withstand scrutiny of judges inquiring about
the bases of the lists or reasons for the decisions. Whether from a predictive
policing system or organically developed by prosecutors, once used in court,
prosecutors must take responsibility for the data. n240 Integrating police and
prosecutorial systems, even informally, means that prosecutors must take on a
data management duty that they previously did not have to accept.

   Second, and relatedly, prosecutors must ensure the accuracy of the data. In
adopting theories of intelligence collection to augment traditional prosecution
roles, prosecutors should also examine how intelligence agencies test and assess
the data collected. In the national security context, thousands of intelligence
analysts work for the United States government because of a healthy distrust of
the raw intelligence coming in from sources. n241 Intricate internal systems
exist to evaluate the reliability of data, n242 recognizing that actionable data
for targeting cannot be relied upon without critical analysis. So, too, with
intelligence-driven prosecution, prosecutors must establish systems to assess
the value of the data coming in through community sources, detectives, social
media, and other sources.

    [*742]  In addition, this push for accuracy means developing systems to
audit existing data-collection systems, including mechanisms for removal and
alteration of bad or outdated data. The danger of a high-volume data collection
enterprise is that it is much easier to simply collect everything, accurate or
not. n243 Going back to correct errors involves time, money, and technological
sophistication. n244 But, without such checks, the data becomes unworthy of use
in criminal courts. Direct connection to criminality, not mere correlation,
should be required when an individual's liberty is being decided. Processes must
be created to ensure that personal bias or corruption does not distort the
targeting. Further, the data collection and analysis must be scrutinized for
implicit or explicit bias. n245 Disproportionate minority contacts, high
incarceration rates, and harsh sentencing have been clearly demonstrated
throughout the criminal justice system. n246 Any data-driven system built on top
of that inequality will likely reify the inequality unless explicit steps are
taken to address the issue.

   Third, any data system must be transparent. n247 This involves a two-fold
transparency, both to the prosecutor using the data and the community
legitimizing the use of the data. Prosecutors are lawyers trained in law, not
technology. In large offices the data will be compiled by colleagues and
assistants. In systems of "extreme collaboration," data will also be compiled by
police. So, mechanisms must be created so that prosecutors can understand the
source of the data. Prosecutors need to be able to not only trust, but
understand and defend the data. Arguments cannot be along the lines of "judge, I
am asking for a no bond bail determination because the pre-printed form told me
to ask for it," but because of  [*743]  particularized, verifiable facts that
can be obtained through a data-driven system. Arguments cannot be "judge, the
defendant is on the SSL, so we ask that he be held," but based on the actual
underlying facts that might have led some individual to be on that list.
Prosecutorial transparency requires understanding why individuals have been
chosen to be marked by predictive technologies. This understanding may also
require knowledge of the provenance of the data, the currency of the data, and
the reliability of the data.

   The other aspect of transparency focuses on community acceptance of
predictive prosecution outcomes. The Orwellian nature of government lists of
predicted targets rightly causes suspicion. n248 Any predictive prosecution
system needs to be able to explain, in a relatively open and clear way, how
people are placed on predictive lists, and why the criteria is legitimate. This
presents a challenge in that most prosecution or police methods also need to be
relatively opaque in order to avoid undermining ongoing investigations. n249
This balance between transparency and operational secrecy presents real
tensions. But, as the creation of custom notification letters demonstrate,
prosecutors can develop a process to show and explain why someone is targeted.
Custom notification letters are "customized" and include the target's specific
criminal history and risk factors. n250 The reasons for the targeting are thus
particularized and individualized and open for inspection. n251 Similarly, in
call-ins, prosecutors can explain in specific detail why the particular targets
have been contacted. This process provides transparency and legitimacy to the
process (albeit after the fact).

   This type of customization also needs to be applied systemically. Prosecutors
need to be able to explain why certain communities have been targeted, and how
they have attempted to avoid class or race-based impacts. Using crime mapping,
visual displays of historic criminal activity, and other accessible media, the
argument can be made for why certain areas were chosen and not others.
Discriminatory impacts need to be monitored and studied. Communities may accept
a higher prevalence of prosecutorial interest in an area, but it must be
explained and defended in a transparent manner.

   Finally, predictive prosecution systems must build in mechanisms to ensure
fair process. An emphasis on fairness must address concerns that citizens might
hold in being targeted by predictive techniques. A process will need to be
developed to  [*744]  challenge a target designation on a police list. n252 A
method to account for possible racial or class discrimination will need to be
created. n253 Clear procedures to use and validate the predictive target list
needs to be developed. n254 And, a general emphasis on procedural justice must
continue. Due to the influence of some of the academics who provided the early
inspiration for the Chicago projects, procedural justice has been a key
organizing principle behind the intervention strategy, but such an emphasis must
continue to be prioritized. n255

   An emphasis on fairness must include a focus on other players in the criminal
justice system. Fairness includes procedures to address exculpatory information
available in the database and other discovery issues that will necessarily
arise. n256 In an interconnected system, owned and operated by the prosecutors'
offices, Brady material will be stored in the shared files. Disclosure of this
shared information will require a new system because traditional case
separations and information barriers will no longer exist. Finally, fairness
includes the ability to defend the data-collection system in a court when
challenged by defendants, judges, or internal accountability groups. These
fairness principles and concerns undergird most of the existing criminal justice
system, so the demand should be neither surprising nor objectionable.

   Conclusion

 Predictive prosecution exists in an experimental phase. This Essay seeks to
raise preliminary questions about an obviously nascent experiment. But, the
questions are real, and will need to be answered soon. The hope of this brief
Essay is to set forth the possible impacts, raise questions, and plan for the
future of predictive prosecution.

Legal Topics:

For related research and practice materials, see the following legal topics:
Criminal Law & ProcedureBailGeneral OverviewCriminal Law & ProcedureJury
InstructionsRequests to ChargeReal Property LawFixtures & ImprovementsFixture
Characteristics

FOOTNOTES:




n1.  See, e.g., Ellen Huet, Server and Protect, Forbes, Mar. 2, 2015, at 46, 46.





n2.  See, e.g., Guy Adams, The Sci-Fi Solution to Real Crime, Independent
(London), Jan. 11, 2012, at 32, 32; Erica Goode, Sending the Police Before
There's a Crime, N.Y. Times, Aug. 16, 2011, at A11; Leslie A. Gordon, A Byte Out
of Crime, A.B.A. J., Sept. 2013, at 18, 18; Predictive Policing: Don't Even
Think About It, Economist, July 20, 2013, at 24, 24, 26.





n3.  See, e.g., Darwin Bond-Graham & Ali Winston, Forget the NSA, the LAPD Spies
on Millions of Innocent Folks, L.A. Wkly. (Feb. 27, 2014, 4:00 AM),
http://www.laweekly.com/news/forget-the-nsa-the-lapd-spies-on-millions-of
-innocent-folks-4473467; John Buntin, Social Science: Facebook and Other Social
Media Networks are Upending the Way Chicago Fights Gang Violence, Governing,
Oct. 2013, at 26, 29; Reducing Murder Rates, Palantir Techs.,
https://www.palantir.com/philanthropy-engineering/annual-report/2015/murder
-reduction/ (last visited Sept. 16, 2016).





n4.  See infra Part I.





n5.  See infra Subpart I.C.





n6.  See infra Subpart II.A.





n7.  See Andrew Guthrie Ferguson, Big Data and Predictive Reasonable Suspicion,
163 U. Pa. L. Rev. 327, 329-30 (2015); Wayne A. Logan & Andrew Guthrie Ferguson,
Policing Criminal Justice Data, 101 Minn. L. Rev. (forthcoming 2017).





n8.  Ferguson, supra note 7, at 329-30.





n9.  Bruce A. Green, Why Should Prosecutors "Seek Justice"?, 26 Fordham Urb.
L.J. 607, 608 (1999).





n10.  See infra Part III.





n11.  See infra Subpart I.C.





n12.  See Monica Davey, Chicago Tactics Put Major Dent in Killing Trend, N.Y.
Times, June 11, 2013, at A1; see also Tracey Meares et al., Homicide and Gun
Violence in Chicago: Evaluation and Summary of the Project Safe Neighborhoods
Program 1 (2009) ("Data analysis immediately revealed that a very small number
of neighborhoods in Chicago are responsible for most of the city's violence
trends. The "city's' crime problem is in fact geographically and socially
concentrated in a few highly impoverished and socially isolated neighborhoods.
Data also revealed that most victims (and offenders) of gun violence in Chicago
tend to be young African American men who live in neighborhoods on the West or
South sides of the city."); Jeremey Gorner, The Heat List, Chi. Trib., Aug. 21,
2013, at 1; Mark Guarino, Can Math Stop Murder?, Christian Sci. Monitor (July
20, 2014), http://www.csmonitor.com /USA/2014/0720/Can-math-stop-murder-video
("Armed with a plethora of statistics on everything from gun violations to
individual parole and arrest histories, police here are trying to create a
national model that will help them predict where shootings might occur and who
might be involved - both victims and offenders."). See generally Andrew V.
Papachristos et al., Attention Felons: Evaluating Project Safe Neighborhoods in
Chicago, 4 J. Empirical Legal Stud. 223 (2007) (describing the impact of
Chicago's Project Safe Neighborhoods on crime rates using quasi-experimental
design).





n13.  See Gorner, supra note 12, at 6.





n14.  See infra Subpart I.C.





n15.  Aubrey Fox, David O'Keefe, Head of the Manhattan District Attorney's Crime
Strategies Unit, Ctr. for Court Innovation (May 29, 2013),
http://www.courtinnovation.org/research/david-okeefe-head-manhattan-district
-attorneys-crime-strategies-unit.





n16.  See infra Subpart I.C.2.





n17.  Chip Brown, The Data D.A., N.Y. Times Mag., Dec. 7, 2014, at 22, 24-25.





n18.  See infra Subpart I.C.2.





n19.  See Jurek v. Texas, 428 U.S. 262, 275 (1976) ("Prediction of future
criminal conduct is an essential element in many of the decisions rendered
throughout our criminal justice system.").





n20.  See generally Philip J. Cook, The Great American Gun War: Notes from Four
Decades in the Trenches, 42 Crime & Just. Am. 19, 52-53 (2013) (discussing
focused deterrence theory and gun violence).





n21.  See Brady v. Maryland, 373 U.S. 83, 87-88 (1963).





n22.  See infra Subpart I.C.





n23.  Beth Pearsall, Predictive Policing: The Future of Law Enforcement?, Nat'l
Inst. Just. J., June 2010, at 16, 16 ("Predictive policing, in essence, is
taking data from disparate sources, analyzing them and then using results to
anticipate, prevent and respond more effectively to future crime.").





n24.  Id. at 16-17.





n25.  See, e.g., Chicago Police Department Adopts Predictive Crime-Fighting
Model, Geography & Pub. Safety, Mar. 2011, at 14, 14 (2011) ("In April 2010, the
Chicago Police Department began piloting a crime prevention strategy called
predictive analytics."); Predictive Policing Helps Tennessee Officers Reduce
Violent and Property Crimes, Geography & Pub. Safety, Mar. 2011, at 15, 15
(2011) ("Use of a new policing strategy in Memphis, Tennessee, has helped lower
the rate of violent, property, and UCR Part I crimes by an average of 15.8
percent."); Nate Berg, Predicting Crime, LAPD-style, Guardian (June 25, 2014,
5:19 PM), http://www.theguardian.com/cities/2014/jun/25/predicting -crime-lapd-
los-angeles-police-data-analysis-algorithm-minority-report; Zen Vuong, Alhambra
Police Chief Says Predictive Policing Has Been Successful, Pasedena Star-News
(Feb. 11, 2014, 6:53 PM),
http://www.pasadenastarnews.com/government-and-politics/20140211
/alhambra-police-chief-says-predictive-policing-has-been-successful.





n26.  See Vince Beiser, Forecasting Felonies: Can Computers Predict Crimes of
the Future?, Miller-McCune, July-Aug. 2011, at 20, 20, https://psmag.com
/can-computers-predict-crimes-of-the-future-5dd5ecaab617#.o8gsmcvzt (discussing
the influence of National Institute of Justice ("NIJ") grants).





n27.  See, e.g., Rachael King, IBM Analytics Help Memphis Cops Get "Smart,'
Bloomberg (Dec. 5, 2011, 10:30 PM), http://www.bloomberg.com/news/articles
/2011-12-05/ibm-analytics-help-memphis-cops-get-smart; Juliana Reyes, Philly
Police Will Be First Big City Cops to Use Azavea's Crime Predicting Software,
Technical.ly (Nov. 7, 2013, 12:30 PM), http://technical.ly/philly/2013/11/07
/azavea-philly-police-crime-prediction-software.





n28.  See Ferguson, supra note 7, at 327; Andrew Guthrie Ferguson, Policing
Predictive Policing, 94 Wash. U. L. Rev. [hereinafter Policing Predictive
Policing] (forthcoming 2017) (manuscript at 11); Andrew Guthrie Ferguson,
Predictive Policing and Reasonable Suspicion, 62 Emory L.J. 259, 265 (2012).





n29.  Joel Rubin, Stopping Crime Before It Starts, L.A. Times, Aug. 21, 2010, at
A1 ("For patrol officers on the streets, mapping software on in-car computers
and hand-held devices would show continuous updates on the probability of
various crimes occurring in the vicinity, along with the addresses and
background information about paroled ex-convicts living in the area.").





n30.  See Charlie Beck & Colleen McCue, Predictive Policing: What Can We Learn
from Wal-Mart and Amazon about Fighting Crime in a Recession?, Police Chief
(Nov. 2009), http://www.policechiefmagazine.org/magazine
/index.cfm?fuseaction=display_arch&article_ id=1942&issue_id=112009.





n31.  Former LAPD Chief Predicts the Future of Policing (National Public Radio
broadcast Nov. 26, 2011), http://www.npr.org/2011/11/26/142795951
/former-lapd-chief-predicts-the-future-of-policing.





n32.  James J. Willis et al., Compstat in Practice: An In-depth Analysis of
Three Cities 1-2 (2003); John Douglass, Tactical Deployment: The Next Great
Paradigm Shift in Law Enforcement?, Geography & Pub. Safety, Jan. 2009, at 6, 7
n.1 (2009); Eli B. Silverman, With a Hunch and a Punch, 4 J.L. Econ. & Pol'y
133, 144-45 (2007).





n33.  See G. O. Mohler et al., Self-Exciting Point Process Modeling of Crime,
106 J. Am. Stat. Ass'n 100, 100-04 (2011); Martin B. Short et al., Dissipation
and Displacement of Hotspots in Reaction-Diffusion Models of Crime, 107 Proc.
Nat'l Acad. Sci. 3961, 3961-62 (2010).





n34.  Kate J. Bowers & Shane D. Johnson, Who Commits Near Repeats? A Test of the
Boost Explanation, W. Criminology Rev., Nov. 2004, at 12, 13 ("Research ...
suggests that the risk of victimisation is communicable, with the risk of
victimisation following an initial burglary not only affecting the burgled home
but, in a similar way to the spread of a communicable disease, also extending to
properties nearby.").





n35.  See Jerry H. Ratcliffe & George F. Rengert, Near-Repeat Patterns in
Philadelphia Shootings, 21 Security J. 58, 58 (2008) ("The near-repeat
phenomenon states that if a location is the target of a crime such as burglary,
the homes within a relatively short distance have an increased chance of being
burgled for a limited number of weeks.").





n36.  See Josh Koehn, Algorithmic Crimefighting, SanJose.com (Feb. 22,
2012),http://www.sanjose.com/2012/02/22/sheriffs_office _fights_property
_crimes_with_predictive_policing/.





n37.  Wim Bernasco, Them Again?: Same-Offender Involvement in Repeat and Near
Repeat Burglaries, 5 Eur. J. Criminology 411, 412 (2008); Bowers & Johnson,
supra note 34, at 21.





n38.  Shane D. Johnson, Repeat Burglary Victimisation: A Tale of Two Theories, 4
J. Experimental Criminology 215, 216 (2008).





n39.  Spencer Chainey et al., The Utility of Hotspot Mapping for Predicting
Spatial Patterns of Crime, 21 Security J. 4, 5 (2008) ("Crime also does not
occur randomly. It tends to concentrate at particular places for reasons that
can be explained in relation to victim and offender interaction and the
opportunities that exist to commit crime."); Shane D. Johnson et al., Space-Time
Patterns of Risk: A Cross National Assessment of Residential Burglary
Victimization, 23 J. Quantitative Criminology 201, 203-04 (2007).





n40.  Megan Yerxa, Evaluating the Temporal Parameters of RiskTerrain Modeling
with Residential Burglary, 5 Crime Mapping 7, 7, 10-11 (2013) (discussing
environmental criminology).





n41.  See Leslie W. Kennedy et al., Risk Clusters, Hotspots, and Spatial
Intelligence: Risk Terrain Modeling as an Algorithm for Police Resource
Allocation Strategies, 27 J. Quantitative Criminology 339, 358 (2011) ("Hotspots
policing relies on the identification, primarily through GIS analysis, of
distinct places experiencing crime concentrations.").





n42.  See Keith Harries, Nat'l Inst. of Justice, Mapping Crime: Principle and
Practice 92 (1999), https://www.ncjrs.gov/pdffiles1/nij/178919.pdf; Derek J.
Paulsen & Matthew B. Robinson, Crime Mapping and Spatial Aspects of Crime 154-55
(2d ed. 2009); Andrew Guthrie Ferguson, Crime Mapping and the Fourth Amendment:
Redrawing "High Crime Areas," 63 Hastings L.J. 179, 182-84 (2011).





n43.  See Beiser, supra note 26, at 20-21.





n44.  Kalee Thompson, The Santa Cruz Experiment, Popular Sci., Nov. 2011, at 38,
97. The above description uses the PredPol technology and strategy as a
representative example of place-based predictive policing. Other competing
technologies use different methods to forecast risk areas for crime.





n45.  Id. at 40.





n46.  Patrick Healy, Predictive Policing Forecasts Crime That Officers Then Try
to Deter, NBC (Jan. 8, 2013, 6:40 AM), http://www.nbclosangeles.com/news
/local/LAPD-Chief-Charlie-Beck-Predictive-Policing-Forecasts-Crime
-185970452.html.





n47.  See Mike Aldax, Richmond Police Chief Says Department Plans to Discontinue
"Predictive Policing' Software, Rich. Standard (June 24, 2015),
http://richmondstandard.com/2015/06/richmond-police-chief-says-department
-plans-to-discontinue-predictive-policing-software/ (quoting Richmond,
California police Chief Chris Magnus, "In Richmond crime went down, yes, but now
it's going back up ... . We're seeing double digit increases."); Ben Poston,
L.A. Sees a Broad Increase in Crime, L.A. Times, Dec. 31, 2015, at A1.





n48.  Darwin Bond-Graham & Ali Winston, All Tomorrow's Crimes, S.F. Wkly., Oct.
30-Nov. 5, 2013, at 11, 12-14.





n49.  See generally PredPol, http://www.predpol.com/ (last visited Aug. 27,
2016) (describing PredPol's services, technology, and results).





n50.  Tessa Stuart, Santa Cruz's Predictive Policing Experiment, SantaCruz.com
(Feb. 14, 2012), http://www.santacruz.com/news/santa_cruzs_ predictive_policing
_experiment.html; see also Koehn, supra note 36; Thompson, supra note 44, at 97.





n51.  Lev Grossman, The 50 Best Inventions of the Year, Time, Nov. 28, 2011, at
55, 82.





n52.  Timothy B. Clark, How Predictive Policing Is Using Algorithms to Deliver
Crime-Reduction Results for Cities, Route Fifty (Mar. 9, 2015),
http://www.routefifty.com/2015/03/predictive-policing-santa-cruz-predpol
/107013/; Will Frampton, With New Software, Norcross Police Practice Predictive
Policing, CBS Atlanta (Aug. 19, 2013), http://www.cbsatlanta.com
/story/23178208/with-new-software-norcross-police-utilize-predictive-policing.





n53.  Joel M. Caplan et al., Joint Utility of Event-Dependent and Environmental
Crime Analysis Techniques for Violent Crime Forecasting, 59 Crime & Delinq. 243,
243-45, 248 (2013).





n54.  Risk Terrain Modeling, http://www.riskterrainmodeling.com/ (last visited
Aug. 27, 2016).





n55.  Joel M. Caplan et al., Rutgers Ctr. on Pub. Sec., Integrating Spatial
Crime Analysis Techniques for Tactical and Strategic Actions 3
(2012),http://www.rutgerscps.org/uploads/2/7/3/7/27370595/jo intutility
_brief.pdf; Joel M. Caplan, Mapping the Spatial Influence of Crime Correlates: A
Comparison of Operationalization Schemes and Implications for Crime Analysis and
Criminal Justice Practice, 13 Cityscape, no. 3, 2011, at 57, 68; Kennedy et al.,
supra note 41, at 343.





n56.  See Leslie Kennedy et al., A Multi-jurisdictional Test of Risk Terrain
Modeling and a Place-Based Evaluation of Environmental Risk-Based Patrol
Deployment Strategies, Rutgers Ctr. on Pub. Security,
http://www.rutgerscps.org/uploads/2/7/3/7/27370595/nij6city_ resultsexecsum
_final.pdf (last visited Aug. 27, 2016). As a disclosure, I was an unpaid,
uninvolved consultant on one federal RTM grant. I had no role in developing or
testing the technology.





n57.  Laura Nahmias & Miranda Neubauer, NYPD Testing Crime-Forecast Software,
Politico (July 8, 2015, 5:52 AM), http://www.politico.com/states/new
-york/city-hall/story/2015/07/nypd-testing-crime-forecast-software-090820.





n58.  See Maurice Chammah, Policing the Future, Verge,
http://www.theverge.com/2016/2/3/10895804/st-louis-police-hunchlab-predictive
-policing-marshall-project (last visited Aug. 27, 2016); Huet, supra note 1, at
46; King, supra note 27.





n59.  See Chainey et al., supra note 39, at 4-5; Dan Turkel, "Predictive
Policing' Tries to Stop Violent Crime Before It Happens, Bus. Insider (Sept. 25,
2015, 8:20 PM), http://www.businessinsider.com/predictive-policing-tries-to
-stop-violent-crime-before-it-happens-2015-9.





n60.  Caplan et al., supra note 53, at 243-45, 248.





n61.  David Black, Here Comes Predictive Policing: The Next Wave of
Crimefighting Technology is Being Tested in New York City, N.Y. Daily News (Jan.
24, 2016, 5:00 AM), http://www.nydailynews.com/opinion/david-black -
predictive-policing-article-1.2506580.





n62.  Anthony A. Braga et al., Problem-Oriented Policing, Deterrence, and Youth
Violence: An Evaluation of Boston's Operation Ceasefire, 38 J. Res. Crime &
Delinq. 195, 195-200 (2001); David M. Kennedy et al., Youth Violence in Boston:
Gun Markets, Serious Youth Offenders, and a Use-Reduction Strategy, 59 L. &
Contemp. Probs. 147, 147-49, 156 (1996).





n63.  See David Kennedy, Don't Shoot: One Man, a Street Fellowship, and the End
of Violence in Inner-City America 269 (2011); Anthony A. Braga, Pulling Levers
Focused Deterrence Strategies and the Prevention of Gun Homicide, 36 J. Crim.
Just. 332, 332-34 (2008); Papachristos et al., supra note 12, at 239-42.





n64.  Davey, supra note 12, at A1; see also Guarino, supra note 12.





n65.  Andrew V. Papachristos et al., Why Do Criminals Obey the Law? The
Influence of Legitimacy and Social Networks on Active Gun Offenders,102 J. Crim.
L. & Criminology 397, 436 (2012).





n66.  See Heather Mac Donald, Opinion, A Smarter Way to Prosecute, L.A. Times,
Aug. 10, 2014, at A24.





n67.  David M. Kennedy, Pulling Levers: Chronic Offenders, High-Crime Settings,
and A Theory of Prevention, 31 Val. U. L. Rev. 449, 449-51 (1997); Kennedy et
al., supra note 62, at 147-49.





n68.  Andrew V. Papachristos et al., Social Networks and the Risk of Gunshot
Injury, 89 J. Urb. Health 992, 993 (2012).





n69.  Papachristos et al., supra note 12, at 224, 253, 266-67.





n70.  This is primarily the function of the mass media that has used the concept
of predictive policing and the fear of a Minority Report future as an attractive
news headline. See, e.g., Jack Smith IV, "Minority Report' is Real - and It's
Really Reporting Minorities, Mic (Nov. 9, 2015), http://mic.com/articles
/127739/minority-reports-predictive-policing-technology-is-really-reporting
-minorities#.zwXVV93jm.





n71.  Gorner, supra note 12, at 1.





n72.  Id.





n73.  See Chi. Police Dep't, Custom Notifications in Chicago, Special Order
S10-05, at III.C (Oct. 6, 2015), http://directives.chicagopolice.org
/directives/.





n74.  See id. at IV.B.





n75.  Id.





n76.  Gorner, supra note 12, at 1.





n77.  See Chi. Police Dep't, supra note 73, at IV.A, D.





n78.  Id. at V.C.





n79.  Id. at III.A, B.





n80.  Monica Davey, Chicago Police Predict Who May Shoot or Be Shot, N.Y. Times
(May 23, 2016), http://www.nytimes.com/2016/05/24/us/armed-with-data
-chicago-police-try-to-predict-who-may-shoot-or-be-shot.html?_r=0.





n81.  See, e.g., Anthony A. Braga et al., SMART Approaches to Reducing Gun
Violence, at ii-iii (2014), http://www.smartpolicinginitiative.com
/sites/all/files/SPI%20Gun%20Violence%20Spotlight%20FINAL.pd f;Jeffrey Goldberg,
A Matter of Black Lives, Atlantic, Sept. 2015, at 70, 73; Los Angeles Police
Using CIA Software to Track Criminals, Ex-cons, RT (Nov. 15, 2014, 3:30 AM),
http://rt.com/usa/205727-lapd-criminals-data-collection/; Reducing Murder Rates,
Palantir Techs., https://www.palantir.com/philanthropy-engineering
/annual-report/2015/murder-reduction/ (last visited Sept. 16, 2016).





n82.  Maya Rao, Police Tool Targets At-Risk Teens, Star Trib., Oct. 25, 2014, at
B3; Matt Stroud, Should Los Angeles County Predict Which Children Will Become
Criminals, Pac. Standard (Jan. 21, 2016), https://psmag.com/should -los-angeles
-county-predict-which-children-will-become-criminals-ad67f1d217de #.3tmnq7l2j.





n83.  For more information, see Policing Predictive Policing, supra note 28.





n84.  See generally id. (discussing the state of objective, peer-review testing
of the technologies).





n85.  Huet, supra note 1, at 46 ("It's impossible to know if PredPol prevents
crime, since crime rates fluctuate, or to know the details of the software's
black-box algorithm, but budget-strapped police chiefs don't care.").





n86.  See Mac Donald, supra note 66, at A24.





n87.  Telephone Interview with David O'Keefe & Kerry Chicon, Manhattan Dist.
Attorney's Office (Mar. 30, 2016).





n88.  The Manhattan District Attorney's Office and others have adopted the
terminology "intelligence-driven prosecution" as opposed to predictive
prosecution. See Fox, supra note 15.





n89.  See Chi. Police Dep't, supra note 73, at V.D.





n90.  Id.





n91.  Id.





n92.  Id. at IV.A.





n93.  Id. at IV.D (emphasis added).





n94.  See Heather Mac Donald, Prosecution Gets Smart, City J. (2014),
http://www.city-journal.org/2014/24_3_intelligence-driven- crime-fighting.html.





n95.  See Andrew V. Papachristos & David S. Kirk, Changing the Street Dynamic:
Evaluating Chicago's Group Violence Reduction Strategy, 14 Criminology & Pub.
Pol'y 525, 533 (2015) ("Focused deterrence posits that crime reduction is best
achieved by concentrating deterrence efforts on those groups or individuals
involved directly in the targeted type of crime.").





n96.  Id. at 533-34.





n97.  Chi. Police Dep't, Custom Notifications in Chicago, General Order G10-01,
at IV.A (Dec. 31, 2015), http://directives.chicagopolice.org/directives/ ("The
cornerstone of the Gang Violence Reduction Strategy is the Gang Audit.").





n98.  See id. at V.A, B (discussing The Gang Intervention Probation Program
("GIPP") and the Targeted Repeat Offender and Apprehension and Prosecution
("TRAP") Program).





n99.  See Papachristos & Kirk, supra note 95, at 536.





n100.  John Eligon & Timothy Williams, On Police Radar for Crimes They Might
Commit, N.Y. Times, Sept. 25, 2015, at A1 ("Call-ins are central to the program.
The authorities invite about 120 of the group leaders they have identified (25
to 40 usually show up) to hear from a range of officials, including the local
and federal prosecutors, the police chief and the mayor.").





n101.  See Papachristos & Kirk, supra note 95, at 536.





n102.  Eligon & Williams, supra note 100, at A17 ("Tammy Dickinson, the United
States Attorney for the Western District of Missouri, related the story of a man
in the program who was given a 15-year prison sentence for being caught with a
bullet in his pocket.").





n103.  To Stem Gun Crime, "Moneyball,' St. Louis Post-Dispatch, June 28, 2015,
at A20 (quoting Circuit Attorney Jennifer Joyce: ""Here are the rules. The first
group that commits a homicide, the first body that drops, we're coming after you
and your friends. The group that does the most violence, we're coming after
you.' Probation may be revoked, major and minor crimes will be prosecuted and so
will minor ordinance violations, building code violations and civil issues like
failure to pay child support.").





n104.  Maureen Fan, Steering Youth Straight Sound Counsel From Mentor Cops,
Prosecutors and Judges, N.Y. Daily News (May 18, 1997, 12:00 AM),
http://www.nydailynews.com/archives/boroughs/steering-youth-straight-sound
-counsel-mentor-cops-prosecutors-judges-article-1.760985.





n105.  U.S. Dep't of Justice, Office of the Attorney Gen., The Attorney
General's Report on Criminal History Background Checks 3 (2006),
http://www.bjs.gov/content/pub/pdf/ag_bgchecks_ report.pdf; Robert Faturechi &
Jack Leonard, ID Errors Put Hundreds in County Jail, L.A. Times, Dec. 25, 2011,
at A1 (stating that more than 1480 people have been mistakenly arrested over
five year period); Amanda Simon, Garbage In, Unnecessary Arrests Follow, Daily
Kos (Apr. 26, 2010, 12:20 PM), https://www.aclu.org/blog/speakeasy
/garbage-unnecessary-arrests-follow; see also Briana Duggan, The Rap-Sheet Trap:
One Man vs. a Multitude of Errors, City Limits (Mar. 3, 2015),
http://citylimits.org/2015/03/03/the-rap-sheet-trap-one-man-vs-a-multitude-of
-errors/#.





n106.  K. Babe Howell, Gang Policing: The Post-Stop-and-Frisk Justification for
Profile-Based Policing, 5 U. Denv. Crim. L. Rev. 1, 15-16 (2015); Joshua D.
Wright, The Constitutional Failure of Gang Databases, 2 Stan. J. C.R. & C.L.
115, 122-23 (2005).





n107.  Herring v. United States, 555 U.S. 135, 155 (2009) (Ginsburg, J.,
dissenting) ("Inaccuracies in expansive, interconnected collections of
electronic information raise grave concerns for individual liberty."); U.S.
Dep't of Justice, Review of Department of Justice's Implementation of the Sex
Offender Registration and Notification Act, at iii (2008),
https://oig.justice.gov /reports/plus/e0901/final.pdf (noting widespread
inaccuracies in state registry information); see, e.g., Fredrick Kunkle, Caught
in a Neighborhood Web: Innocent Man Mistaken for Registered Offender, Wash.
Post, May 13, 2006, at A1.





n108.  Gorner, supra note 12, at 1.





n109.  Id.





n110.  See Mac Donald, supra note 66, at A24.





n111.  Id. ("Prosecutors in Richmond, Va., and Rockland County, N.Y., as well as
San Francisco and Philadelphia, are building intelligence systems to drive crime
down."); New Baton Rouge Crime Strategies Unit Announced, U.S. Dep't of Just.,
http://www.justice.gov/usao-mdla/new-baton-rouge-crime-strategies
-unit-announced (last visited Aug. 27, 2016).





n112.  Brown, supra note 17, at 24; Mac Donald, supra note 66, at A24.





n113.  Brown, supra note 17, at 24.





n114.  Id. at 24-25.





n115.  Id. at 24; Mac Donald, supra note 66, at A24.





n116.  See Mac Donald, supra note 66, at A24.





n117.  See Brown, supra note 17, at 28-29.





n118.  Id. at 24-25.





n119.  See Mac Donald, supra note 66, at A24.





n120.  Id.





n121.  Brown, supra note 17, at 25; Mac Donald, supra note 66, at A24.





n122.  See Mac Donald, supra note 66, at A24; James C. McKinley, Jr., In Unusual
Collaboration, Police and Prosecutors Team Up to Reduce Crime, N.Y. Times, June
5, 2014, at A25.





n123.  Brown, supra note 17, at 24-25.





n124.  Mac Donald, supra note 94 ("Based on daily communication with local
police commanders and precinct field-intelligence officers, the Crime Strategies
Unit has compiled a database of Manhattan's most significant criminal players
and other persons of interest (such as elusive or uncooperative witnesses).").





n125.  See Brown, supra note 17, at 24 ("They asked police commanders to submit
a list of each precinct's 25 worst offenders - so-called crime drivers, whose
"incapacitation by the criminal-justice system would have a positive impact on
the community's safety. Seeded with these initial cases, the C.S.U. built a
searchable database that now includes more than 9,000 chronic offenders,
virtually all of whom have criminal records.'"); Mac Donald, supra note 94 ("In
2012, police arrested a leading gang member in East Harlem for running toward
people in a brawl brandishing a metal lock tied into a bandanna. The defendant
had been shot in the past and had also likely witnessed a homicide, without
cooperating with police after either crime. The attempted assault would
ordinarily have gone nowhere, had the CSU not closely tracked the assailant.
Instead, the prosecutor indicted him for criminal possession of a weapon in the
third degree - a felony charge. After the charges were read, the defendant
absconded while on bail. Arrested a second time on the open warrant, he was
eventually sentenced to two to four years in prison on the weapon charge and two
to four years on the bail-jump charge - outcomes that would have been
unthinkable but for the information that the CSU had developed.").





n126.  Fox, supra note 15.





n127.  Brown, supra note 17, at 24 ("When someone in the Arrest Alert System is
picked up, even on a minor charge or a parole violation, or is arrested in
another borough, any interested prosecutor is automatically pinged with a
detailed email."). While the final decision will be determined based on the
particular facts of the individual and the case, and would remain within the
broad grant of discretion given to prosecutors, the influence of the arrest
alert system is significant.





n128.  Mac Donald, supra note 66, at A24 ("The unit has compiled a database of
Manhattan's most significant criminal players - now numbering about 9,000 -
whose arrest anywhere in the city immediately triggers an alert to one of the
Crime Strategies Unit attorneys. The attorney will then contact the local
prosecutor who has been assigned the case - whether in Manhattan or another
borough - to make sure the defendant is prosecuted to the full extent of the law
rather than slipping through the cracks."); McKinley, Jr., supra note 122, at
A25 ("The unit assembled what amounts to a list of prioritized targets for
prosecution in each precinct. When people on the list are arrested, even for
minor crimes, prosecutors receive an electronic alert.").





n129.  See Mac Donald, supra note 66, at A24 ("The arrest alert system
recognizes that a defendant's official history of arrests and convictions may
fail to convey his position in the criminal food chain. A 16-year-old gang
member may be responsible for numerous shootings, as attested to by his and
others' Facebook pages, but never arrested for any of them because his victims
and witnesses refused to cooperate with the police. If he is nabbed for
shoplifting, the misdemeanor prosecutor will have a few minutes at most to
decide whether to pursue the case. Seeing simply a petty criminal, the charging
attorney might well let him walk free. But if that attorney is armed with
intelligence gathered on the suspect, he can seek the maximum charge and argue
to the judge for high bail."); Fox, supra note 15 ("It can help us prepare a
bail application in advance, or help us plan the strategy to enable an
arrest.").





n130.  See McKinley, Jr., supra note 122, at A25 ("Bail application letters
detailing the defendant's history of other crimes have been prepared in advance,
and at the arraignment, the prosecutor regularly pushes for higher bail and
sometimes brings a more serious charge, if it can be justified by the
evidence.").





n131.  See Mac Donald, supra note 94.





n132.  See McKinley, Jr., supra note 122, at A25 ("The office's strategy has
been to pursue people believed to be drivers of crime, using whatever felony
charge prosecutors can prove and seeking the maximum penalty.").





n133.  See Fox, supra note 15 ("This system has all sorts of useful
applications. It can help shape the plea offers made to the court.").





n134.  See Gorner, supra note 12, at 6.





n135.  See Fox, supra note 15 ("We also have a great relationship with parole.
It's all about using levers of influence. For example, if we have someone on our
target list who's about to come out of prison, we can go to parole and ask if
they're willing to put special conditions on the defendant.").





n136.  Id. ("It can also help us gain cooperation among crime victims, who are
often reluctant to testify. If that person is arrested on another offense, the
ADA will get a notification and it might become a factor in encouraging him or
her to agree to help out on the case.").





n137.  See id.





n138.  Brown, supra note 17, at 25.





n139.  See Fox, supra note 15 ("It can also help us gain cooperation among crime
victims, who are often reluctant to testify.").





n140.  See John Eligon, Top Prosecutor Creates a Unit on Crime Trends, N.Y.
Times, May 25, 2010, at A22 ("The Crime Strategies Unit will rely on a computer
database developed by the district attorney's office to allow prosecutors to
draw parallels among cases, unearth crime patterns in particular areas and make
more informed decisions on how to handle defendants ... ."); Mac Donald, supra
note 94 ("[DA Cyrus] Vance then created a new entity called the Crime Strategies
Unit, the sole purpose of which is to gather and deploy intelligence on
Manhattan's crime patterns and serious offenders.").





n141.  See Brown, supra note 17, at 25; Fox, supra note 15 ("We also identified
hot spots and the names of the people committing the most crimes in each
area.").





n142.  Mac Donald, supra note 94 ("The Crime Strategies Unit has been as quick
as the NYPD to spot the crime-fighting usefulness of social media. Crime
analysts in the unit constantly track the Internet footprints of suspects in the
arrest-alert database. The indictments in the 2013 East Harlem gang conspiracy
case, for instance, consist almost exclusively of the Facebook postings of the
defendants, as well as recordings of their phone calls whenever they were
confined at Rikers.").





n143.  Id.





n144.  See id. ("The prosecutors and police investigators had scanned more than
a million social media pages to map out the web of criminality among the
defendants ... .").





n145.  See id. ("The Crime Strategies Unit will gain access to more of the
police department's databases on suspects and to its network of security
cameras, while police detectives will receive the granular intelligence about
criminal conspiracies developed during trial preparation.").





n146.  See, e.g., Bernard Marr, Big Data: Using Smart Big Data Analytics and
Metrics to Make Better Decisions and Improve Performance 130 (2015) (concerning
the use of facial recognition software in the UK, "Video footage is now
routinely used to create a 3D faceprint of a suspect which is then used to
compare to images available on the Internet or social media sites.").





n147.  Eligon & Williams, supra note 100, at A17; Mac Donald, supra note 94.





n148.  McKinley, Jr., supra note 122, at A25 ("Prosecutors will have access, for
instance, to the network of security cameras on city streets the department uses
to solve crimes, as well as the mountains of data collected on police reports,
while detectives will receive the granular intelligence about criminal
conspiracies gathered by prosecutors as they prepare for trial.").





n149.  Mac Donald, supra note 94 ("Vital information about offender networks
gleaned in the course of preparing a case for trial usually remains on a
prosecutor's legal pad, rarely conveyed back to the police or shared with other
prosecutors.").





n150.  Brown, supra note 17, at 24 (quoting Cyrus Vance: "I wanted to develop
what I call intelligence-driven prosecution."); Conor Skelding, Cy Vance on
"21st Century Crime-Fighting', Politico (June 10, 2014, 11:45 AM),
http://www.capitalnewyork.com/article/city-hall/2014/06/8546853/cy-vance-21st
-century-crime-fighting (quoting Cyrus Vance Jr.: ""Like CompStat, the Crime
Strategies Unit identifies the crime-drivers and crime hotspots,' he said. "But
that's just the beginning. C.S.U. collects, connects, and analyzes that, and
other data, from seemingly unrelated cases. It makes sense of the enormous data
that comes into our office and creates actionable intelligence.'").





n151.  McKinley, Jr., supra note 122, at A25. This development has not yet
occurred, as prosecutors are not yet adding information to police hand-held
tablets or police databases.





n152.  See Fox, supra note 15 ("The Arrest Alert system has started to
revolutionize the way cases are handled; I call it the "central nervous system"
for intelligence-driven prosecution... . If a prosecutor has a case they're
working on, they can add names of persons of interest to the list and they will
get an alert in the form of an email if that person is arrested anywhere in New
York City. Before arrest alerts, prosecutors would likely have no idea if the
person they were prosecuting had been arrested again while the case was active,
particularly if the arrest happened outside of Manhattan. The arrest alert
system has allowed us to break out of a reactive approach to prosecution to one
that is focused on coordination and proactive measures.").





n153.  Mac Donald, supra note 94 ("Bratton wants a "seamless web" of information
between the prosecutors and the police, he told the New York Times in early
June.").





n154.  Wayne A. Logan, Policing Identity, 92 B.U. L. Rev. 1561, 1561 (2012).





n155.  Logan & Ferguson, supra note 7.





n156.  Id.





n157.  Logan, supra note 154, at 1564-66.





n158.  See generally id. (describing how, over time, governments sought more
systematic means of identification for community members and felons alike).





n159.  Ellen S. Podgor, Race-ing Prosecutors' Ethics Codes, 44 Harv. C.R.-C.L.
L. Rev. 461, 462 (2009) ("Prosecutorial discretion is an accepted component of
our criminal justice system."). See generally Angela J. Davis, Arbitrary
Justice: The Power of the American Prosecutor 148 (2007) ("As one former
prosecutor stated, "[a] prosecutor's power to damage or destroy anyone he
chooses to indict is virtually limitless.'"); Tracey L. Meares, Rewards for Good
Behavior: Influencing Prosecutorial Discretion and Conduct with Financial
Incentives, 64 Fordham L. Rev. 851, 900 (1995) (describing prosecutorial
misconduct because of the lack of discipline coming from regulatory entities);
Ellen S. Podgor, The Ethics and Professionalism of Prosecutors in Discretionary
Decisions, 68 Fordham L. Rev. 1511 (2000) (discussing the duties of prosecutors
in making discretionary decisions and the implications resulting from those
decisions).





n160.  Wayte v. United States, 470 U.S. 598, 607 (1985) ("In our criminal
justice system, the Government retains "broad discretion' as to whom to
prosecute."); see also United States v. Armstrong, 517 U.S. 456, 464 (1996);
United States v. Batchelder, 442 U.S. 114, 123-24 (1979); Bodenkircher v. Hayes,
434 U.S. 357, 364-65 (1978).





n161.  Russell D. Covey, Fixed Justice: Reforming Plea Bargaining With
Plea-Based Ceilings, 82 Tul. L. Rev. 1237, 1254-56 (2008); Harry Litman,
Pretextual Prosecution, 92 Geo. L.J. 1135, 1137 n.4 (2004); Podgor, supra note
159, at 463 ("The power of prosecutorial discretion can be seen when prosecutors
deliberately overcharge to obtain a desirable plea agreement. Likewise, there
are ample examples of "pretextual' prosecutions on extraneous charges when
prosecutors believe the accused individuals are inherently evil.").





n162.  Leslie C. Griffin, The Prudent Prosecutor, 14 Geo. J. Legal Ethics 259,
272-74 (2001) (discussing the ethics of prosecutorial sentencing).





n163.  Prosecutors are guided by ABA Ethics guidelines and other codes of
professional conduct. ABA Rule of Professional Conduct 3.8(a) prohibits charges
that are "not supported by probable cause." See Model Rules of Prof'l Conduct r.
3.8(a) (Am. Bar Ass'n 2012). American Bar Association Standards for Criminal
Justice Prosecution Function and Defense Function states prosecutors "should not
institute, cause to be instituted, or permit the continued pendency of criminal
charges in the absence of sufficient admissible evidence to support a
conviction." See Standards for Criminal Justice § 3-3.9(a) (Am. Bar Ass'n 1993).





n164.  Michelle Alexander, The New Jim Crow: Mass Incarceration in the Age of
Colorblindness 40-57 (2010). Intriguingly, for a symposium on mass
incarceration, New York State has seen both a huge drop in crime and a
significant drop in its prison population. See Inimai M. Chettiar, The Many
Causes of America's Decline in Crime, The Atlantic (Feb. 11, 2015),
http://www.theatlantic.com/politics/archive/2015/02/the-many-causes-of
-american-decline-in-crime/385364/.





n165.  Anne R. Traum, Mass Incarceration at Sentencing, 64 Hastings L.J. 423,
428-431 (2013).





n166.  John F. Pfaff, The Micro and Macro Causes of Prison Growth, 28 Ga. St. U.
L. Rev. 1239, 1242-55 (2012); Leon Neyfakh, Why Are So Many Americans in Prison?
A Provocative New Theory, Slate (Feb. 6, 2015, 6:30 PM),
http://www.slate.com/articles/news_and_politics/ crime/2015/02/mass
_incarceration_a_provocative_new _theory_for_why_so_many _americans_are.html.





n167.  Alexandra Natapoff, Misdemeanors, 85 S. Cal. L. Rev. 1313, 1320 (2012).





n168.  See, e.g., Neyfakh, supra note 166 (describing how policymakers have
influenced prosecutors' decisions relating to drug offenses, regardless of the
risk of danger the drug possessors pose to society).





n169.  See Papachristos & Kirk, supra note 95, at 528-29 (describing how
"research found that simply being in such networks exponentially increases the
likelihood that one becomes a victim of a gunshot injury; in the Chicago study,
for instance, being in a network with another gunshot victim increases the
probability of being a victim a staggering 900%."); Gorner, supra note 12, at 6.





n170.  See Papachristos & Kirk, supra note 95, at 528-29.





n171.  See supra Subpart I.C.2.





n172.  Herring v. United States, 555 U.S. 135, 155 (2009) (Ginsburg, J.,
dissenting) ("The risk of error stemming from these databases is not slim.
Herring's amici warn that law enforcement databases are insufficiently monitored
and often out of date. Government reports describe, for example, flaws in NCIC
databases, terrorist watchlist databases, and databases associated with the
Federal Government's employment eligibility verification system." (footnotes and
citation omitted)).





n173.  See, e.g., Mary De Ming Fan, Reforming the Criminal Rap Sheet: Federal
Timidity and the Traditional State Functions Doctrine, 33 Am. J. Crim. L. 31, 60
(2005) (describing errors in rap sheets); Shaudee Navid, They're Making a List
but Are They Checking It Twice?: How Erroneous Placement on Child Offender Lists
Offends Procedural Due Process, 44 U.C. Davis L. Rev. 1641, 1641 (2011); Daniel
J. Steinbock, Data Matching, Data Mining, and Due Process, 40 Ga. L. Rev. 1,
17-18 (2005) (describing pattern of erroneous "indications of criminality");
Christine M. Whalley, Extending the Exclusionary Rule: Enforcing Data Quality in
National Security Databases and Watch Lists, 27 J. Marshall J. Computer & Info.
L. 257, 259 (2009) (describing errors in terror lists).





n174.  Andrew E. Taslitz, Police Are People Too: Cognitive Obstacles to, and
Opportunities for, Police Getting the Individualized Suspicion Judgment Right, 8
Ohio St. J. Crim. L. 7, 38 (2010).





n175.  Bryan Llenas, Brave New World of "Predictive Policing' Raises Specter of
High-Tech Racial Profiling, Fox News Latino (Feb. 25, 2014),
http://latino.foxnews.com/latino/news/2014/02/24/brave-new-world-predictive
-policing-raises-specter-high-tech-racial-profiling/ (""It ends up being a
self-fulfilling prophecy,' said Hanni Fakhoury, staff attorney at the Electronic
Frontier Foundation, a nonprofit digital civil liberties organization. "The
algorithm is telling you exactly what you programmed it to tell you. "Young
black kids in the south side of Chicago are more likely to commit crimes," and
the algorithm lets the police launder this belief. It's not racism, they can
say. They are making the decision based on what the algorithm is, even though
the algorithm is going to spit back what you put into it. And if the data is
biased to begin with and based on human judgment, then the results the algorithm
is going to spit out will reflect those biases.'").





n176.  Eric J. Mitnick, Procedural Due Process and Reputational Harm: Liberty as
Self-Invention, 43 U.C. Davis L. Rev. 79, 126 (2009) (noting that while most
databases are supposed to be subject to quality control, "in reality ... the
evidence is overwhelming that the control measures currently in place regularly
fail, either due to lack of resources, skill, or because they are simply
neglected").





n177.  See id. at 125.





n178.  Ferguson, supra note 7, at 329-30; Logan & Ferguson, supra note 7.





n179.  See generally Ferguson, supra note 7 (noting that the risk of error
stemming from police databases is significant and that inaccuracies raise
concerns for individual liberty).





n180.  Fox, supra note 15.





n181.  Bruce A. Green & Alafair S. Burke, The Community Prosecutor: Questions of
Professional Discretion, 47 Wake Forest L. Rev. 285, 287 (2012); Kay L. Levine,
The New Prosecution, 40 Wake Forest L. Rev. 1125, 1157 (2005); Tracey L. Meares,
Praying for Community Policing, 90 Calif. L. Rev. 1593, 1593 (2002).





n182.  See Anthony C. Thompson, It Takes a Community to Prosecute, 77 Notre Dame
L. Rev. 321, 323 (2002).





n183.  See Michel Marriot, New York's Worst Drug Sites: Persistent Markets of
Death, N.Y. Times, June 1, 1989, at A1.





n184.  Id.





n185.  Id.





n186.  Id.





n187.  Mac Donald, supra note 94 ("In June 2014, Vance and New York police
commissioner William Bratton (back in New York on his second tour as police
commissioner) announced the largest-ever gang conspiracy indictment in New York
history. One hundred and three members of three West Harlem youth gangs based in
two housing projects were charged with conspiracy to commit murder and gun
possession, among other crimes.").





n188.  Id.





n189.  Standards for Criminal Justice 1 (Am. Bar Ass'n 2014); Margaret E.
McGhee, Preliminary Proceedings, Prosecutorial Discretion, 88 Geo. L.J. 1057,
1058-59 (2000).





n190.  Standards for Criminal Justice, supra note 189, at 1 ("Many prosecutors
participate in investigations involving organized crime, political corruption,
corporate and financial fraud, money laundering, environmental and other
regulatory crimes, and terrorism.").





n191.  See Thomas Cohen et al., Caseload Highlights: Examining the Work of State
Courts 2-3 (2000).





n192.  See, e.g., id.





n193.  Mac Donald, supra note 94.





n194.  Joseph Goldstein, Police Take on Family Violence to Avert Death, N.Y.
Times, July 25, 2013, at A1 ("The officers assigned to the domestic violence
unit make a total of 70,000 precautionary visits a year to households with past
episodes. Each precinct station house also maintains a "high propensity' list of
a dozen or so households that get special attention because they are believed to
be most at risk of further violence.").





n195.  Bernhard Warner, Google Turns to Big Data to Unmask Human Traffickers,
Bloomberg (Apr. 10, 2013, 1:46 PM), http://www.bloomberg.com
/news/articles/2013-04-10/google-turns-to-big-data-to-unmask-human -traffickers.





n196.  See Bruce A. Green & Fred C. Zacharias, Prosecutorial Neutrality, 2004
Wis. L. Rev. 837, 837-38 (2004).





n197.  Id. at 849 ("With respect to garden-variety investigations and
prosecutions, neutrality sometimes connotes independence from the police.").





n198.  Id. at 860-61 ("Commentators sometimes employ the term "neutrality' to
refer to prosecutorial independence from police investigators ... and other
interested parties.").





n199.  Id. at 837-38.





n200.  See id. at 881.





n201.  See Johnson v. United States, 333 U.S. 10, 14 (1948). The Supreme Court
used this language to describe the understandable danger of police being overly
aggressive in their pursuit of stopping crime, and thus the need to have a
strong Fourth Amendment warrant requirement.





n202.  While perhaps a contestable point that deserves more unpacking, there
exists a general perception about how the public views prosecutorial-driven
investigations, as opposed to ordinary police-driven investigations. Cases
involving insider trading, public corruption, and gangs might be viewed as "the
prosecutor v. the defendant," whereas a traditional case usually is better
conceived of as "the police v. the defendant." In that latter role, the
prosecutor is more likely to benefit from the neutrality principle and be
trusted more for his or her exercise of discretion and restraint.





n203.  K. Babe Howell, Prosecutorial Discretion and the Duty to Seek Justice in
an Overburdened Criminal Justice System, 27 Geo. J. Legal Ethics 285, 294
(2014).





n204.  Brady v. Maryland, 373 U.S. 83, 87-88 (1963).





n205.  See Joshua A.T. Fairfield & Erik Luna, Digital Innocence, 99 Cornell L.
Rev. 981, 1040 (2014).





n206.  Mac Donald, supra note 94; Skelding, supra note 150.





n207.  See Green & Zacharias, supra note 196, at 879 & n.149.





n208.  See generally Alafair S. Burke, Prosecutorial Agnosticism, 8 Ohio St. J.
Crim. L. 79, 84-86, 91-99 (2010) (discussing a prosecutor's obligation to "do
justice" based on the evidence presented to him or her); Bruce A. Green & Ellen
Yaroshefsky, Prosecutorial Discretion and Post-Conviction Evidence of Innocence,
6 Ohio St. J. Crim. L. 467, 497-501 (2009) ("The prosecutor should engage in the
tricky exercise of determining the credibility of prior evidence that is no
longer available. She should consider all the credible information, currently
available or not, and decide whether the evidence of guilt or innocence
satisfies whatever standard the prosecutor employs.").





n209.  See generally Green & Yaroshefsky, supra note 208, at 497 (discussing a
prosecutor's gatekeeping role in charging decisions, and how a prosecutor must
only have evidence that demonstrates "probable cause" at the time of commencing
charges).





n210.  Burke, supra note 208, at 91.





n211.  Litman, supra note 161, at 1135.





n212.  Myrna S. Raeder, See No Evil: Wrongful Convictions and the Prosecutorial
Ethics of Offering Testimony by Jailhouse Informants and Dishonest Experts, 76
Fordham L. Rev. 1413, 1413 (2007).





n213.  See Elizabeth Glazer, Thinking Strategically: How Federal Prosecutors Can
Reduce Violent Crime, 26 Fordham Urb. L.J. 573, 573-74 (1999); Charles J. Hynes,
The Evolving Prosecutor: Broadening the Vision, Expanding the Role, 24 Crim.
Just. 1, 41 (2009); Levine, supra note 181, at 1130.





n214.  See Andrew Novak, It's Too Dangerous to Elect Prosecutors, Daily Beast
(Aug. 24, 2015, 1:12 AM), http://www.thedailybeast.com/articles/2015/08
/24/it-s-too-dangerous-to-elect-prosecutors.html.





n215.  See id.





n216.  See What Does a Prosecutor Do?, Best Law. Guide,
http://www.thebestlawyersguide.com/what-does-a-prosecutor-do (last visited Aug.
28, 2016).





n217.  See supra notes 89-97.





n218.  See Papachristos & Kirk, supra note 95, at 528-29.





n219.  Id. at 533-34.





n220.  Id.





n221.  Id.





n222.  See supra notes 140-48, and accompanying text.





n223.  Michael D. Reisig, Community and Problem-Oriented Policing, 39 Crime &
Just. 1, 40 (2010) (discussing environmental criminology).





n224.  See supra notes 29-43.





n225.  Press Release, N.Y. Cty. Dist. Att'y's Office, D.A. Vance Announces
Funding for Innovative Crime Prevention Initiatives and Programs to Improve
Access to Services for Victims of Crime (June 23, 2016), http://manhattanda.org
/press-release/da-vance-announces-funding-innovative-crime-prevention
-initiatives-and-programs-improv.





N226.  Kenneth Padowitz, Rational Choice as a Theory of Crime, Psychol. L. &
Crim. Behav. Blog, http://www.psychology-criminalbehavior-law.com/2016
/04/rational-choice-as-a-theory-of-crime/ (last visited Aug. 28, 2016).





n227.  See Ferguson, supra note 7, at 380.





n228.  See supra notes 111-26 and accompanying text.





n229.  See Michael D. Lyman & Gary W. Potter, Organized Crime 59, 66 (4th ed.
2007), http://wps.pearsoncustom.com/wps/media/objects/6904/7070214
/CRJ455_Ch02.pdf.





n230.  Bernard E. Harcourt, Against Prediction: Profiling, Policing and
Punishing in an Actuarial Age 145 (2007); Bernard E. Harcourt, From the
Ne'er-Do-Well to the Criminal History Category: The Refinement of the Actuarial
Model in Criminal Law, 66 L. & Contemp. Probs. 99, 112 (2003).





n231.  Harcourt, supra note 230, at 112.





n232.  See, e.g., Melissa Hamilton, Adventures in Risk: Predicting Violent and
Sexual Recidivism in Sentencing Law, 47 Ariz. St. L.J. 1, 5 (2015); Dawinder S.
Sidhu, Moneyball Sentencing, 56 B.C. L. Rev. 671, 718 (2015).





n233.  Shima Baradaran & Frank L. McIntyre, Predicting Violence, 90 Tex. L. Rev.
497, 512-13 (2012); Jack F. Williams, Process and Prediction: A Return to a
Fuzzy Model of Pretrial Detention, 79 Minn. L. Rev. 325, 337-38 (1994).





n234.  Melissa Hamilton, Public Safety, Individual Liberty, and Suspect Science:
Future Dangerousness Assessments and Sex Offender Laws, 83 Temp. L. Rev. 697,
737 (2011); Eric S. Janus & Robert A. Prentky, Forensic Use of Actuarial Risk
Assessment with Sex Offenders: Accuracy, Admissibility and Accountability, 40
Am. Crim. L. Rev. 1443, 1454-55 (2003).





n235.  Jeffrey Fagan & Martin Guggenheim, Preventative Detention and the
Judicial Prediction of Dangerousness for Juveniles: A Natural Experiment, 86 J.
Crim. L. & Criminology 415, 429 (1996); Albert R. Roberts & Kimberly Bender,
Overcoming Sisyphus: Effective Prediction of Mental Health Disorders and
Recidivism Among Delinquents, 70 Fed. Prob. 19, 20 (2006).





n236.  See generally Policing Predictive Policing, supra note 28 (describing the
different types of risk assessments and predictive tools used throughout the
criminal justice system).





n237.  Barbara D. Underwood, Law and the Crystal Ball: Predicting Behavior with
Statistical Inference and Individual Judgment, 88 Yale L.J. 1408, 1446 (1979)
(discussing the differences between correlations and causation).





n238.  See, e.g., William M. Grove & Paul E. Meehl, Comparative Efficiency of
Informal (Subjective, Impressionistic) and Formal (Mechanical, Algorithmic)
Prediction Procedures: The Clinical-Statistical Controversy, 2 Psychol. Pub.
Pol'y & L. 293, 302 (1996); Bernard E. Harcourt, The Shaping of Chance:
Actuarial Models and Criminal Profiling at the Turn of the Twenty-First Century,
70 U. Chi. L. Rev. 105, 125-26 (2003).





n239.  See supra notes 173-79 and accompanying text.





n240.  See supra Part I.





n241.  U.S. Dep't of Justice, Today's FBI Facts & Figures 2013-2014, at 9
(2014), https://www.fbi.gov/file-repository/facts-and-figures-031413-2.pdf/view.





n242.  See id. at 72.





n243.  Kevin Lapp, Databasing Delinquency, 67 Hastings L.J. 195, 211-12 (2015)
("Even when [gang database] purging procedures are in place, they are rarely
carried out. That is because there is little incentive for law enforcement to
purge records from gang databases.").





n244.  J. Christopher Westland, The Cost of Errors in Software Development:
Evidence from Industry, 62 J. Sys. & Software 1, 1 (2002).





n245.  See Andrew E. Taslitz, Racial Blindsight: The Absurdity of Color-Blind
Criminal Justice, 5 Ohio St. J. Crim. L. 1, 3 (2007); Tracey G. Gove, Implicit
Bias and Law Enforcement, Police Chief, Oct. 2011, at 44, 50 ("Police officers
are human and, as the theory contends, may be affected by implicit biases just
as any other individual. In other words, well-intentioned officers who err may
do so not as a result of intentional discrimination, but because they have what
has been proffered as widespread human biases.").





n246.  Robin Walker Sterling, Raising Race, Champion, Apr. 2011, at 24, 24 ("The
criminal justice system has exploded outside of the prison walls, as well. As of
2009, the number of people under criminal justice supervision - including those
who are in jail, in prison, on probation, and on parole - totaled 7.2 million
people. In a dismaying parallel to incarceration rates, people of color are also
overrepresented among arrestees, probationers, and parolees.").





n247.  Tal Z. Zarsky, Transparent Predictions, 2013 U. Ill. L. Rev. 1503,
1533-34 (2013).





n248.  See generally George Orwell, Nineteen Eighty-Four (1949) (presenting a
novel about a nation living under omnipresent government surveillance).





n249.  Clearly, prosecutors do not want to reveal the targets of their
investigation. In addition, safety issues of officers must be taken into
account.





n250.  See supra notes 71-79 and accompanying text.





n251.  See id.





n252.  See, e.g., Margaret Hu, Big Data Blacklisting, 67 Fla. L. Rev. 1735, 1789
(2015) (discussing redress issues with data errors in no fly lists).





n253.  See Ifeoma Ajunwa et al., Hiring By Algorithm: Predicting and Preventing
Disparate Impact (Feb. 28, 2016) (unpublished manuscript) (on file with author).





n254.  The General Orders of the Chicago Police Department discussed in this
article are quite complete.





n255.  See, e.g., Tracey L. Meares, Norms, Legitimacy and Law Enforcement, 79
Or. L. Rev. 391, 400-03 (2000); Tom R. Tyler, Procedural Justice, Legitimacy,
and the Effective Rule of Law, 30 Crime & Just. 283, 284-86 (2003).





n256.  See, e.g., Fairfield & Luna, supra note 205, at 1039-40.


                               2 of 41 DOCUMENTS

          Copyright (c) 2016 Michigan State University College of Law
                           Michigan State Law Review

                                      2016

                           Michigan State Law Review

                           2016 Mich. St. L. Rev. 947

LENGTH: 10314 words

ARTICLE: QUANTIFYING CRIMINAL PROCEDURE: HOW TO UNLOCK THE POTENTIAL OF BIG DATA
IN OUR CRIMINAL JUSTICE SYSTEM

NAME: Ric Simmons *

BIO:



   * Chief Justice Thomas J. Moyer Professor for the Administration of Justice
and Rule of Law, Moritz College of Law, The Ohio State University. I would like
to thank Angela Lloyd, Andrew Selbst, Stephen Smith, Christopher Slobogin, David
Gray, Bryan Choi, Natalie Venatta, Mike Hintze, Dennis Hirsch, Kiel
Brennan-Marquez, Rebecca Lipman, and the participants in the 2016 Privacy Law
Scholars Conference. I also want to thank Paige Weinstein and Daniel Colston for
their research assistance.



HIGHLIGHT: Big data's predictive algorithms have the potential to revolutionize
the criminal justice system. They can make far more accurate determinations of
reasonable suspicion and probable cause, thus increasing both the efficiency and
the fairness of the system, since fewer innocent people will be stopped and
searched.
ABSTRACT

   However, three significant obstacles remain before the criminal justice
system can formally use predictive algorithms to help make these determinations.
First, we need to ensure that neither the algorithms nor the data used are based
on improper factors, such as the race of the suspect. Second, under Fourth
Amendment law, individualized suspicion is an essential element of reasonable
suspicion or probable cause. This means that either the predictive algorithms
must be designed to take individualized suspicion into account, or the
predictive algorithms can only be used as one factor in determining whether the
legal standard has been met, forcing police and judges to combine the
algorithms' results with individualized factors. And finally, the legal
standards themselves must be quantified so that police and judges can use the
numerical predictions of big data in their reasonable suspicion and probable
cause determinations.

   These obstacles are not insurmountable. And if the necessary changes are
made, the criminal justice system will become far more transparent, since the
factors the algorithms take into consideration will necessarily be reviewable by
judges and the general public alike. Furthermore, setting a quantified
likelihood for reasonable suspicion and probable cause will allow us to engage
in a healthy debate about what those numbers ought to be, and it will also
ensure conformity across different jurisdictions.

TEXT:
 [*948]  INTRODUCTION

   The criminal justice system has always been concerned with predictions.  n1
Police officers on patrol predict which suspects are  [*949]  engaged in
criminal activity in order to determine where to focus their investigative
efforts. Magistrates deciding whether to grant a search warrant predict the odds
that contraband will be found based on the facts presented in a warrant
application. Judges conducting bail hearings predict the chances that a
defendant will return to court for trial, and sentencing judges try to determine
whether a convicted defendant is likely to reoffend if he is given a
nonincarceration sentence.

   Since the inception of our criminal justice system, law enforcement officers
and judges have relied primarily on experience, training, intuition, and common
sense in making their predictions.  n2 In response, courts have crafted broad
standards to accommodate these subjective judgments and allow for flexibility in
application. For example, police officers may briefly detain an individual if
they reasonably believe that "criminal activity may be afoot,"  n3 while
magistrates should issue a warrant if "a man of prudence and caution [believes]
that the offense has been committed."  n4

   The broad, flexible nature of these standards is no accident: They have been
intentionally left imprecise by generations of courts. One reason is the nearly
infinite number of different facts that could arise in any criminal case, which
make hard and fast rules rather impractical.  n5 But the main reason these rules
have been kept  [*950]  ambiguous is that police and courts have historically
lacked the necessary tools to evaluate the accuracy of their predictions with
any precision. Thus, state actors have been forced to rely on their own
subjective beliefs and anecdotal evidence in making their predictions.  n6

   All of that is now changing. Modern methods of data collection and analysis
commonly known as "big data" are providing police and judges with tools that can
predict future behavior with greater precision than ever before.  n7 These tools
hold out the promise of increased fairness and greater objectivity at many of
the critical decision points in our criminal justice system. But despite the
potential of big data tools, three significant obstacles potentially bar their
effective incorporation into the criminal justice system.

   First, we need to ensure that the tools of big data are not hard-wired to
produce discriminatory results. If the predictive algorithms consider race or
religion as a factor, then using these algorithms to predict behavior is
unacceptable (and illegal) no matter how much they may increase accuracy.
Similarly, if the algorithms themselves were developed based on past
discriminatory practices, we need to develop new algorithms based on better
data.

   Second, Fourth Amendment law mandates that decisions to stop or search a
suspect be based at least in part on individualized suspicion. Because big data
involves processing large amounts of information, its algorithms frequently
generate predictions based on broad generalizations rather than specific
conduct. Thus, in their current form, these algorithms cannot on their own form
the basis for reasonable suspicion or probable cause.

   And finally, the current legal standards that govern police officers and
judges are imprecise and subjective. Courts have deliberately created them to be
imprecise and seem to have every intention of keeping them that way.
Unfortunately, these nebulous standards are a poor fit for big data's highly
precise and quantitative tools.

   These obstacles are not insurmountable barriers. Big data algorithms can be
structured so that they are truly race neutral and  [*951]  take into account
individualized conduct when making their calculations. But in order to ensure
that they meet these requirements, the factors they apply must be transparent to
judges. In other words, it is not sufficient for reviewing courts to know that
these algorithms are working; the courts must also understand exactly how the
methods work to ensure that those methods meet the appropriate legal standards.
n8 And although courts have historically been reluctant to attach specific
numbers to the relevant legal standards, there is no doctrinal barrier to doing
so. Courts may be more willing to take this step as they come to realize that
big data offers highly precise and quantitative tools that can create not only
better accuracy but also greater transparency in our criminal system.

   This Article seeks to harmonize the analytical world of big data with the
legal world of criminal justice. If those who design the big data tools can
ensure the transparency of their algorithms and databases, not only will these
tools become more palatable to the courts, but the transparency of these
calculations will simultaneously improve the transparency of the criminal
justice system. Moreover, if courts embrace the use of numerically quantifiable
data, not only will we achieve greater accuracy in the administration of
justice, but we will also achieve greater clarity of the process.

   Part I of this Article discusses the ways in which big data can increase the
accuracy of our criminal justice system.  n9 Part II addresses the challenges
involved in the use of big data.  n10 Part III explains how these challenges can
be overcome by requiring heightened transparency of big data's algorithms and
databases and by introducing quantifiable standards into our criminal justice
system.  n11 The Article concludes by positing that big data tools, if properly
designed and used, can dramatically improve both the accuracy and transparency
of our criminal justice system.

    [*952]  I. THE PROMISE OF BIG DATA: INCREASED ACCURACY

   "Big data" is the practice of accumulating extraordinarily large amounts of
information from a variety of different sources and then processing that
information using statistical analysis.  n12 The results of these analyses are
termed "mechanical predictions" in contrast with subjective "clinical
judgments," which are based on the individual decision-maker's past experience
and knowledge.  n13

   Private companies have been using big data for over a decade to predict
consumer behavior. Retailers use it to determine and change shopping habits.
n14 Insurance companies rely on big data to try to identify the safest drivers
and healthiest people in their customer pool.  n15 Banks and credit agencies use
big data to determine the likelihood that a potential borrower is a credit risk.
n16 And all sorts of companies buy and sell this data to each other, seeking to
mine it for information about their customers that they can use for economic
advantage.  n17

   In the criminal law context, mechanical predictions can be used to assist
decision-makers in making the judgment calls that are integral to the criminal
justice system. The extraordinary promise of applying big data to the criminal
justice system is based on two  [*953]  aspects of these mechanical predictions.
First, the underlying data is usually gathered from public sources, and
therefore, the use of such data does not constitute a "search" under the Fourth
Amendment.  n18 Thus, law enforcement officers have a significant amount of
freedom in acquiring this information, which means that they can obtain the
predictions from big data without needing to meet any legal standard such as
reasonable suspicion or probable cause. Essentially, big data algorithms can be
seen as a force multiplier, allowing police to generate more predictive power
from the same public information that has always been available to them.

   The second enticing aspect of big data's mechanical predictions is that they
are more accurate than clinical judgments. Studies have shown that big data's
mechanical predictions are, on average, 10% more accurate than clinical
predictions.  n19 Police officers and judges who have adopted these methods have
been seeing increased accuracy in many different contexts, ranging from
predicting where crime is likely to occur to determining which defendants are
most likely to succeed if released on parole.  n20 The increased accuracy
offered by big data will lead to both greater efficiency and fairness. The
system will be more efficient because police and courts will be able to focus
their resources more effectively. It will be fairer because innocent people will
be less likely to be stopped, frisked, searched, or arrested if big data can
successfully narrow the field of legitimate suspects.

   Big data's predictive algorithms could be used in a number of different ways
in the criminal justice system. First, law enforcement officers could use these
tools to determine where crime is likely to occur and to allocate their
resources accordingly; as we will see in Section I.A, police are already using
big data tools for this purpose,  [*954]  with notable success. Second, the
results from these predictive algorithms could informally influence police
officers when they make their clinical judgments about whether reasonable
suspicion or probable cause exists; as I argue in Section I.B, this is probably
already occurring. Third, police could formally cite the results from predictive
algorithms in court when justifying their stops or searches or when applying for
a search warrant. As we see in Section I.C, there is as yet no evidence that law
enforcement has done this, although this is likely to happen soon. Finally, the
results from big data's predictive algorithms could be outcome determinative,
meaning that a police officer or a judge would only consider the algorithm's
output and ignore all other evidence. We are a long way from this point in the
context of reasonable suspicion or probable cause, but Section I.D notes that
some courts are coming close to allowing mechanical predictions to be outcome
determinative for bail, sentencing, and parole decisions.  n21

A. Predictive Algorithms and Policing

   Police have a long history of using massive amounts of data to help decide
where to deploy resources.  n22 In the 1990s, law enforcement use of data
compilation gained national attention with the New York Police Department's
COMPSTAT program.  n23 Crime mapping algorithms quickly spread to other cities
and became a staple of big-city policing.  n24 Today, more advanced software has
[*955]  made crime-predicting software available in smaller jurisdictions, and
the National Institute of Justice is funding research into the efficacy of such
programs.  n25

   These crime prediction software systems vary considerably in their
sophistication. One program known as PredPol (short for "predictive policing")
only looks at past reports of criminal activity and then highlights areas of the
precinct in which crime has been most prevalent during specific time periods.
n26 The police department then assigns more officers to the high-crime areas in
order to detect or deter crime more effectively. Police officers using the
software in a suburb of Los Angeles saw their crime rate decrease by 13% over
the course of four months, while it rose by 0.4% in surrounding areas.  n27 A
more sophisticated program called HunchLab also uses reports of past criminal
activity, but adds in additional factors.  n28 Some of these extra factors, such
as the proximity to subway stations or bars, or the current weather conditions,
have an obvious correlation to particular types of criminal activity. Other
factors seem unrelated, such as the decrease in aggravated assaults on windy
days, or the increase in car thefts near schools.  n29

   The Fresno Police Department uses crime prediction software in a somewhat
different way, employing a software system called Beware to warn police officers
of the threat level for the location of a  [*956]  911 call.  n30 As law
enforcement officers are on their way to the location, workers in police
headquarters plug the address into the Beware program, which quickly analyzes
countless pieces of data, including "arrest reports, . . . commercial databases,
deep Web searches and . . . social media postings" that are associated with that
address.  n31 The program then offers a rating for the location: green for safe,
yellow for caution, and red for dangerous.  n32 Police officers who arrive at
the scene can take appropriate precautions based on that rating.

   Chicago takes this process one step further, using predictive software to
determine which individuals are most likely to be involved in a crime.  n33
Using a special algorithm designed by an engineer at the Illinois Institute of
Technology, the Chicago Police Department created a "heat list" of 400 people
who are "most likely to be involved in a shooting or homicide."  n34 Police will
then deploy resources to monitor these individuals more closely than other
individuals  n35 in an attempt to deter their criminal behavior by letting them
know they are under increased surveillance or to swiftly apprehend them if they
do commit crimes.  n36

    [*957]  Using predictive software to determine how to allocate scarce law
enforcement resources is not limited to investigations of street crime. The
Internal Revenue Service (IRS) uses a secret algorithm to determine which of the
over one hundred million tax returns should be audited each year. The IRS
algorithm scans through every tax return, looking for outlying levels of
deductions or other factors that indicate a higher chance of fraud, and then it
assigns a risk level to each return.  n37 Those returns with high risk factors
are then personally reviewed by IRS agents to see if an audit is appropriate.
n38

   Some critics of adapting big data to our criminal justice system argue that
it does not, in fact, make more accurate decisions. Professor Bernard Harcourt
has argued that predictive policing may actually reduce the efficiency of stops
and searches, because when police focus their resources on certain portions of
the population, they necessarily withdraw resources from other portions of the
population.  n39 According to his model, crime will decrease among those who are
targeted, but it will increase among those who are not targeted; thus, whether
the overall crime rate decreases actually depends on the comparative elasticity
of the crime rate in each of the two groups.  n40 This critique is persuasive if
the police are using a very basic predictive policing model that focuses on one
specific neighborhood or (as in Harcourt's example) one specific race. But the
critique becomes weaker if the police are using a multi-factor algorithm to
direct resources, and it becomes weaker still if it is merely used to determine
whether reasonable suspicion or probable cause exist. However, Harcourt's
objection does highlight the need to ensure that the data used by the predictive
algorithm remains current; that is, if there is a feedback effect that makes
certain factors less likely to indicate criminal activity, the algorithm should
be adjusted to ensure that those factors are given less weight or eliminated
entirely. It also highlights a legitimate concern about relying on data which
itself may be tainted by past discrimination or inaccurate decisions, a topic we
will address in Section III.A below.

 [*958]  B. Predictive Algorithms as Background Data

   PredPol, Hunchlab, Beware, Chicago's "heat list," and the IRS algorithm
represent what we could call the first stage of crime prediction
algorithms--algorithms used to help police decide where and how to deploy their
resources, but not used (at least formally) to make any specific legal
determination.  n41 But as the amount of data about individuals grows and
becomes more accessible, police will use big data at later stages of the
criminal justice system. It is likely that police already informally use these
tools as background information in making their determination as to whether
reasonable suspicion or probable cause exists.

   Assume a police officer observes marginally suspicious activity--say, a
suspect walking slowly down the street at night, peering into windows and
constantly looking over his shoulder. If the officer is using crime prediction
software, and the software informs her that she is currently in a low crime
neighborhood with few burglaries, she may simply assume that the suspect is
engaged in innocent conduct and merely observe the suspect for a few minutes
until he leaves the area. But if the software informs her that there are many
burglaries that occur in this neighborhood at this time of night, that extra
factor could be enough to change her response and lead her to conduct a Terry
stop of the suspect. Or consider a police officer who uses risk assessment
software and shows up at a home in response to a 911 call to find two
individuals engaged in a heated argument, one with a bruise on his cheek. The
injured individual refuses to tell the police officer whether he has been
assaulted. If the risk assessment software flashes a peaceful green, the
responding officer might simply give a warning to the two individuals or ask one
of them to take a walk to cool down. But if the software presented a red light,
indicating the presence of a violent individual at the location, the officer
might decide that she has probable cause to arrest the uninjured individual and
charge him with assault.

   The same calculus would occur--consciously or unconsciously--when an officer
is investigating a potential crime and a member of a heat list is a suspect, or
when an IRS agent is reviewing a return that has already been flagged by the
software. Other police officers have mobile applications that can display the
[*959]  location of individuals suspected of gang activity, registered sex
offenders, or those who have outstanding warrants, thus allowing a police
officer to quickly generate reasonable suspicion or probable cause.  n42 Indeed,
presence in a "high crime area" is a factor that is frequently cited by police
officers who are explaining why they believed that reasonable suspicion existed,
n43 and the fact that a suspect is a known violent felon could also be used by
an officer in deciding whether to make an arrest.  n44 Many law enforcement
agents (and many lay people) would say that it would be foolish to ignore these
signals when deciding on the appropriate course of action.

   Although police probably use these results as background information in
making their determination, so far no law enforcement agent or prosecutor has
formally used the results of crime prediction software in court as a factor to
support reasonable suspicion or probable cause.  n45 Instead, courts rely on the
testimony of the law enforcement officers to establish the necessary factors,
even in situations where big data could provide more accurate information.  n46

C. Predictive Algorithms as Formal Factors

   The increasing pervasiveness of predictive algorithms in policing means that
police officers will soon be using these predictions as part of their arguments
justifying reasonable suspicion or probable cause. Moreover, as police officers
use these factors  [*960]  more often, judges will begin to expect this kind of
hard data and may begin to reject the current subjective, experiential, or
anecdotal evidence that officers currently rely upon.  n47 This will almost
certainly result in more accurate determinations overall. To see why, we need to
take a closer look at the current system that is used to determine reasonable
suspicion or probable cause.

   For example, consider the "high-crime area" determination that is frequently
cited by police officers as a factor supporting reasonable suspicion or probable
cause. The opinion of a police officer about how much crime occurs in a certain
area is likely to be based on a small sample of cases; it may be based on an
outdated reputation of a neighborhood; and it is possibly tainted by many
different kinds of bias.  n48 Even if accurate, it is inappropriately
comparative. If the neighborhood in question has three times the number of drug
arrests per week than all of the surrounding neighborhoods, that fact in itself
is irrelevant to a reasonable suspicion argument.  n49 Instead, the police
officer and the judge should consider the absolute number of criminal
activity--does the neighborhood in question have two drug arrests per week, or
ten drug arrests per week, or fifty drug arrests per week?  n50

   Take another example: An officer is only allowed to frisk a suspect during a
Terry stop if the officer has a reason to believe the suspect is armed. Up until
now, that "reason to believe"--like the reasonable suspicion underlying the stop
itself--has been based on the opinion and past experience of the police officer
and evaluated based on the intuition of the reviewing court. Police officers
[*961]  routinely testify, for example, that individuals suspected of engaging
in narcotics transactions are more likely to have weapons on their person. In
practice, judges have credited this testimony, regularly approving Terry frisks
when the police officer had reasonable grounds to believe a suspect was engaged
in narcotics trafficking.  n51 But what is the actual link between selling
narcotics and weapons possession? If the former actually does make the latter
more likely, what is the degree of increase in probability? Is it the same for
every city, and every neighborhood of every city, and every type of narcotic?
Clinical judgments can answer none of these questions--nor can they answer these
questions for any other factor relied upon by police when justifying a Terry
frisk. Thus, the "reason to believe" standard has become a legal term of art,
defined not by actual probability but by years of precedents in which certain
fact patterns have been approved by courts based solely on the experience and
expertise of police officers.

   In fact, the Bureau of Justice review of over 200,000 criminals who were
convicted in state court shows that only 8.6% of those who were convicted of
drug dealing carried a firearm at the time of the offense, and only 7.8% of
those convicted of drug possession carried a firearm at the time of the offense.
n52 Does an 8.6% chance give officers a "reason to believe?" Judges have never
answered this question, preferring instead to rely on the self-reported
intuition and experience of the very police officers who are trying to justify
their own actions.

   Other used factors for clinical judgments also may comport with the intuition
of police officers (and with the intuition of the judges who review the police
officers' actions), but may be empirically false. For example, flight from
police has long been held to be a significant factor in determining reasonable
suspicion,  n53 but studies have shown that in "high-crime urban communities
where the  [*962]  population is disproportionately minority," there is a very
weak link between flight from police and criminal activity.  n54

   Courts have long been criticized for deferring to the various factors police
officers use in determining that they have the authority to make a Terry stop.
In his dissent in United States v. Sokolow, Justice Thurgood Marshall listed
dozens of cases in which different circuit courts had approved of contradictory
factors offered to show that a suspect fit a "drug courier profile" at an
airport: first to deplane; last to deplane, deplaned in the middle, one way
ticket, round-trip ticket, nonstop flight, changed planes, gym bag, new
suitcase, traveled alone, traveled with companion, acted nervously, acted too
calmly.  n55 As one pair of commentators noted, "Apparently almost any human
trait can be a basis for suspicion, and nearly everybody exhibits several
potentially suspicious . . . factors at any given time."  n56

   In the recent case of Floyd v. City of New York,  n57 a class action suit
challenging the stop-and-frisk policies of the New York Police Department, the
trial judge criticized the often used police factors such as "furtive
movements," "high crime area," and "suspicious bulge" as overly vague.  n58
During testimony in the case, two police  [*963]  officers testified as to what
they understood "furtive movements" to mean:


     One [officer] explained that "furtive movement is a very broad
     concept," and could include a person "changing direction," "walking in
     a certain way," "[a]cting a little suspicious," "making a movement
     that is not regular," being "very fidgety," "going in and out of his
     pocket," "going in and out of a location," "looking back and forth
     constantly," "looking over their shoulder," "adjusting their hip or
     their belt," "moving in and out of a car too quickly," "[t]urning a
     part of their body away from you," "[g]rabbing at a certain pocket or
     something at their waist," "getting a little nervous, maybe shaking,"
     and "stutter[ing]." Another officer explained that "usually" a furtive
     movement is someone "hanging out in front of [a] building, sitting on
     the benches or something like that" and then making a "quick
     movement," such as "bending down and quickly standing back up," "going
     inside the lobby . . . and then quickly coming back out," or "all of a
     sudden becom[ing] very nervous, very aware."  n59


In the statistics from the Floyd case, police officers cited "furtive movements"
as a factor in 42% of their stops.  n60

   Not only are many of the clinical judgment factors overly vague, their
supposed link to criminal activity is based on a very limited data set. Factors
offered by law enforcement officers are frequently supported only by the
officer's own prior experience, and in approving (or disapproving)  n61 of these
factors as probative of criminal activity, courts either cite the expertise of
the officers or use their own intuition to evaluate the probability that a crime
will occur.

   Unsurprisingly, the result of these vague standards and limited data sets is
a troublingly low hit rate for police officers conducting stop and frisks. The
recent expansion of Terry stops in New York  [*964]  City resulted in a regime
in which only 12% of all Terry stops in New York City resulted in an arrest or a
summons.  n62 During that same period, only 1.5% of the Terry frisks produced
evidence of a weapon.  n63 Thus, for that time period, the police officers'
standard for reasonable suspicion was in fact a 12% likelihood that criminal
activity was occurring, while their standard for a "reason to believe" that a
suspect was armed (thus justifying a frisk) was 1.5%. Although courts have been
unwilling to explicitly quantify the percentage chance for "reasonable
suspicion," it is probably more than 12% and certainly more than 1.5%.  n64

   Indeed, the district court in the Floyd case concluded that many of the stops
by the police officers during this time period were not supported by reasonable
suspicion.  n65 This implies that the 12% success rate over that time period was
insufficient to support reasonable suspicion, since it was the result of overly
aggressive police tactics and the use of improper factors. Similarly, a review
of police tactics in Philadelphia concluded that only 3% of the stops resulted
in recovery of contraband; the review also concluded that reasonable suspicion
was lacking for somewhere between 35% and 50% of these stops.  n66

   Thus, there is a growing dissonance between the objective, data-driven tools
used by police officers to guide their conduct, and the intuitive arguments and
subjective experience used by police officers to justify that conduct in court.
Given the success of the data-driven tools in everyday police work, it seems
inevitable that they will soon be formally used by police officers in assessing
whether reasonable suspicion or probable cause exists.

   Although these predictive algorithms have not yet been used in the context of
reasonable suspicion or probable cause, they are not  [*965]  completely foreign
to the criminal justice system. As we will see in the next Section, courts have
been using these predictive algorithms in other contexts, such as bail hearings
and parole hearings.

D. Predictive Algorithms Elsewhere in the Criminal Justice System

   The final step in the use of predictive algorithms is for the police officers
and judges to make their decisions based solely on the outputs of the algorithms
without exercising any of their own independent judgment. We may never get to
this stage for reasonable suspicion and probable cause determinations (and we
may not want to, as discussed below),  n67 but we have come close to such a
world in other contexts, such as bail determinations, sentencing decisions, and
parole judgments. For decades, judges used generalizations based on risk factors
in making these decisions, but in recent years, just as in the policing context,
big data has slowly been infiltrating these procedures, using vast quantities of
data to empirically test traditional factors and experiment with new factors.
n68

   One example of this shift in the bail context is the Public Safety Assessment
(PSA) designed by the Arnold Foundation, which has been adopted by about two
dozen jurisdictions over the past few years.  n69 The PSA, which is based on an
analysis of one and a half million criminal cases, uses up to ten different
objective factors to determine whether a defendant is a flight risk or likely to
commit a crime during pretrial release.  n70 The results of the PSA have been
nearly uniformly positive--after pilot projects, the city of Charlotte lowered
its pretrial detention by 20%, with no increase in crime or  [*966]  bench
warrants, while the state of Kentucky has saved significant money and increased
accuracy of its pretrial decisions.  n71

   The sentencing process is also undergoing a quiet revolution in the methods
that judges use to assess risk of reoffending. Some states now use formal "risk
assessment instruments" to determine the appropriate sentence after conviction.
n72 These risk assessment instruments are designed using an algorithm that takes
into account decades of prior cases.  n73 They typically use around ten
different inputs, such as age and history of alcohol abuse, and then assign
defendants a number on a scale, which translates to a percentage chance that the
defendant will reoffend within a certain period of time.  n74 For example,
Virginia developed a nine-factor risk assessment instrument based on past
evidence and uses the instrument to help determine whether to divert a defendant
away from a prison sentence.  n75 As of now, judges use these risk assessment
instruments as tools to help them make their decision, and judges still maintain
the discretion to depart from the recommendations made by the instrument,  n76
but the influence of these instruments on the actual sentencing decision is
growing.

   Predictive algorithms have also gained popularity in assessing the
appropriateness of parole. Mechanical predictions were used as far back as the
1920s, long before computers and large databases became available.  n77 The goal
of these early predictions was to assess an inmate's risk of recidivism. Due to
the vast number of individuals who were paroled, even in the early years there
was a large pool of subjects for a natural experiment. Sociologists and
psychologists utilized this pool to examine the characteristics of those who did
and did not succeed on parole.  n78 By 2004, over 70% of states that maintained
an active parole system employed some form of mechanical predictive instrument
in determining whether parole was  [*967]  appropriate.  n79 One common tool,
the Level of Services Inventory-Revised (LSI-R), takes into account fifty-four
separate factors ranging from criminal history and education level to alcohol
abuse and attitude towards sentencing.  n80 Courts, correctional facilities, and
parole boards routinely use these instruments in determining what level of
supervision an inmate needs in prison, whether he should be paroled, and what
conditions are necessary if parole is granted.  n81

   Like police officers, judges who make clinical judgments about bail,
sentencing, or parole may subconsciously or explicitly use stereotypes or
intuitions that are incorrect.  n82 In creating the PSA, the Arnold Foundation
determined that many traditional factors used in bail hearings, such as
defendant's employment status, community ties, or drug and alcohol abuse, were
poor predictors of flight risk.  n83 They also concluded that a face-to-face
interview--traditionally a staple of prearraignment assessment--was not a useful
tool.  n84 In the sentencing context, many judges had long believed that mental
illness was a strong indicator of recidivism; actual studies of mentally ill
criminals have shown that not to be the case.  n85

   There are two obvious differences between the predictive algorithms used by
police during their investigations and those used by courts in making decisions
about bail, sentencing, or parole. The first seems significant but in fact is
relatively trivial: The police officers are making predictions about past or
current behavior (i.e., whether the person they are about to stop is currently
engaged in criminal activity or whether the house they would like to search
currently contains drugs), while courts are making predictions about future
behavior (i.e., whether the defendant will return to court if released or
whether the defendant will commit more crimes if released on parole). In truth,
however, there is no material difference between these two types of
predictions--both involve a decision-maker in the criminal justice system trying
to use known facts to  [*968]  determine the odds that an unknown fact is true.
As noted by Professor Barbara Underwood in one of the first articles regarding
prediction and the law, "Some past or present facts are as elusive as any
prediction, and some predictions can be made with as much confidence as most
determinations of past fact."  n86

   The second, more significant distinction is in the amount of time available
to conduct the prediction. Police officers deciding whether to stop or arrest an
individual on the street are reacting to an ongoing and sometimes rapidly
changing situation, and therefore may not have the time to do anything but rely
on their clinical judgments. Even if an accurate, fast-processing algorithm is
available to the police, they may not have time to make the necessary
observations that are required for the algorithm to deliver an accurate
prediction. Judges who are reviewing these judgments at a later suppression
hearing, as well as judges who are making decisions about search warrants, bail,
sentencing, or parole, have the time to gather more data about the defendant and
his circumstances, and then make use of a predictive algorithm in making their
decision. In other words, predictive software may be less accurate when used by
law enforcement officers than when used by judges.

   Nevertheless, the success of these mechanical predictions in the context of
bail and parole hearings shows that courts may be receptive to applying these
tools on the front end of the criminal justice system--to justify stops,
arrests, and searches. Data-driven predictive algorithms represent an
opportunity to dramatically increase the accuracy of these decisions, thus
ensuring that fewer innocent citizens are detained or searched, and increasing
the efficiency of our law enforcement resources.  n87 However, a number of
obstacles remain--both in the design of the algorithms and in the legal
standards used by courts. We will discuss these obstacles in the next Part.

    [*969]  II. CHALLENGES TO USING PREDICTIVE ALGORITHMS

   As noted in Part I, crime prediction software could soon be used by police
officers on the street and by judges in criminal courts to prove reasonable
suspicion or probable cause. This development could potentially result in more
accurate and consistent determinations of whether these standards have indeed
been met--but only if certain obstacles can be overcome. First, there is a
concern that predictive algorithms would use factors that are illegal for courts
to consider, such as the race of the subject.  n88 Similarly, the underlying
data that the algorithms use may be in itself biased; thus, using these
algorithms would not actually increase accuracy but merely reinforce decades of
discriminatory policing. Also, the law requires police officers and judges to
act on facts that are specific to the case at hand; the general probability
factors used by big data may not be able to provide this specificity. And
finally, the hyper-quantified world of big data is currently an uncomfortable
fit with the flexible standards used by courts.

   All of these obstacles are surmountable, but only if the algorithms and
databases used by the big data analyses are made more transparent so that courts
can evaluate the underlying processes and the standards being used, and only if
courts are willing to accept the quantified world of predictive software.

A. Detecting the Racial Biases in the Predictive Algorithms

   To the extent that human beings have a hand in creating the algorithms and
compiling the data that the algorithms use, human biases will infect the
results. Although it is impossible to eliminate these biases altogether, there
are ways to minimize the problems they create.

    [*970]  1. Direct and Indirect Use of Forbidden Factors

   Mechanical predictions are not necessarily color-blind. If an individual's
race is a significant factor in determining whether a certain outcome is likely
to occur, then the individuals who are designing (and using) the algorithm may
be tempted to use race as one of the inputs in order to achieve more accurate
results. In some cases outside the context of criminal procedure, this may be
relatively harmless--for example, when companies use big data to decide where to
market certain products or when political campaigns use big data to decide which
voters to contact with a certain kind of outreach. In other cases, race-based
factors can be quite harmful (and illegal)--for example, in deciding which
customers are a good credit risk for a home loan  n89 or which job applicants
should be hired.  n90 In the context of criminal procedure, race-based factors
are especially problematic, both legally and morally.

   For the purposes of this discussion, let's assume that a private company has
developed an algorithm that can predict with great accuracy whether drugs will
be found inside a certain house. The algorithm requires the user to enter six
different inputs, such as the neighborhood where the house is located, the prior
criminal convictions of the house's owner, and observations made by police
officers about activity outside the house. One of these inputs is the race of
the owner of the home. Assume, further, that without using the race factor, the
algorithm can predict the presence of drugs with 40% accuracy, but with the race
factor, the algorithm can predict the presence of drugs with 55% accuracy.
Assume the police have purchased this algorithm and are using it in their
warrant application. Should they input the race factor in order to enhance the
algorithm's accuracy? In other words, would it be illegal for the state to use
race as a factor in determining probable cause or reasonable suspicion if it
could be definitively proven that using race made the prediction more accurate?

    [*971]  Surprisingly, Fourth Amendment jurisprudence has little to say about
whether race can be used as a factor in determining reasonable suspicion or
probable cause. Courts are unanimous in holding that race alone can never be the
basis for a stop or a search, for the obvious reason that a person's race alone
can never create probable cause or even reasonable suspicion that criminal
activity is occurring.  n91 However, some courts have approved cases in which
race was one of many factors in deciding whether reasonable suspicion or
probable cause existed--for example, when searching for illegal immigrants near
the Mexican border.  n92 Other courts have disagreed, arguing that a person's
race is "of such little probative value [in the reasonable suspicion analysis]
that it may not be considered as a relevant factor."  n93

   As these cases make clear, the only problem with using race under Fourth
Amendment jurisprudence is that in the vast majority of cases, the race of a
subject is not a relevant indicator as to whether the suspect is more or less
likely to engage in criminal activity.  n94 Therefore, any law enforcement
official who does consider race is almost certainly doing so because of an
irrational bias against that particular race. But this objection is not entirely
valid in every circumstance--as noted above, if the law enforcement officer is
looking for illegal immigrants near the Mexican border, for example, the
suspect's race could conceivably be one factor in trying to predict whether the
suspect was illegally in the country. Likewise, if a person seems "out of place"
due to her race (for example, a white person in a predominantly black
neighborhood), her race could be one factor that would lead to reasonable
suspicion that she was engaging in criminal activity.  n95

    [*972]  Given this jurisprudence, there is no valid Fourth Amendment
objection to using race as a factor in a mechanical prediction algorithm for
reasonable suspicion or probable cause. Assuming we have a properly designed
algorithm,  n96 race would only be used as a factor if it actually was a useful
predictor of individualized suspicion; in other words, there would be empirical
statistical proof that in the given context race did help determine whether or
not an individual was guilty of a crime.  n97 In our hypothetical case, in which
the use of race increased the accuracy of the prediction from 40% to 55%, using
the race-based factor would not be prohibited under the Fourth Amendment.

The Equal Protection Clause is another matter, however. Under the Equal
Protection Clause, race can only be used as a factor in state actions if the use
of race is necessary and if it is narrowly tailored to achieve a compelling
state interest.  n98 This is a difficult, if not impossible, burden for law
enforcement to meet in the stop-and-search context. Some courts have held that
the use of race as a factor does not require exclusion as long as there were
sufficient other factors to justify the stop or search,  n99 while others have
noted that law enforcement officers violate the Equal Protection Clause if they
incorporate race routinely as a factor in their drug courier profile.  n100
Neither of these principles bodes well for using race as a factor in mechanical
prediction algorithms, regardless of how accurate it might be. As further
evidence that racial factors are forbidden by the Equal Protection Clause,
nearly all the civil suits alleging racial  [*973]  profiling result in consent
decrees that forbid the use of race as a factor.  n101

   Outside the Fourth Amendment context, the seminal case on racial bias in the
criminal justice system is McCleskey v. Kemp, in which a black defendant argued
that the state of Georgia engaged in racial discrimination when administering
the death penalty.  n102 The defendant relied on a study that showed that
defendants who killed white victims were far more likely to be sentenced to
death than those who killed black victims.  n103 The study also showed that
black defendants were more likely to get the death penalty than white
defendants.  n104 The Supreme Court rejected the defendant's arguments, holding
that in order to prevail on an equal protection claim, the defendant had to
demonstrate that the decision-makers in the process acted with a "discriminatory
purpose."  n105 The Justices were concerned with interfering with the discretion
that is given to prosecutors, judges, and juries, and thus said it required
"exceptionally clear proof before [the Court] would infer that the discretion
has been abused."  n106

   Based on this jurisprudence, it is hard to see our hypothetical algorithm
passing constitutional muster. Even assuming that the interdiction of drugs is a
compelling state interest, law enforcement would be hard pressed to argue that
using the race-based factor was necessary and narrowly tailored to accomplish
that purpose. The use of the algorithm would probably be seen as nothing more
than a sophisticated method of racial profiling--an institutionalization of
using race as a factor in determining probable cause.

   The only plausible defense for the state would be to argue that although race
is clearly a factor in the decision made by the algorithm, the decision is not
made with a "discriminatory purpose" as forbidden by McCleskey. In other words,
those who design and use the algorithm are (arguably) not acting with racial
animus or out of any intent to treat the members of one race differently than
another. This narrower definition of "discriminatory purpose" is consistent with
McCleskey's language, which held that  [*974]  "'[d]iscriminatory purpose' . . .
implies more than intent as volition or intent as awareness of consequences. It
implies that the decisionmaker . . . selected or reaffirmed a particular course
of action at least in part 'because of,' not merely 'in spite of,' its adverse
effects upon an identifiable group."  n107 This does not really fit the state's
motivation in using the algorithm--the police are not choosing to use the
algorithm (or, more specifically, the race factor) "because of" its adverse
effects on a particular race; they are using it to increase the accuracy of
their predictions.

   However, the narrow definition of "discriminatory purpose" is not borne out
in other areas of criminal procedure. For example, in the context of jury
selection, the Court held that if a defendant established a pattern of racial
discrimination in peremptory jury challenges, the prosecutor could only prevail
if she could provide a racially neutral reason for making those challenges.
n108 The Court further noted that "the prosecutor may not rebut the defendant's
prima facie case of discrimination by stating merely that he challenged jurors
of the defendant's race on the assumption--or his intuitive judgment--that they
would be partial to the defendant because of their shared race."  n109 This
would be analogous to a prosecutor arguing that explicit discrimination should
be allowed in the probable cause algorithm because it increases the accuracy of
the prediction.

   Thus, our hypothetical algorithm could not legally use race as a factor,
however much that factor could be proven to increase accuracy. This legal
conclusion is consistent with most individuals' intuitive moral sense and
(relatedly) to the political feasibility of using predictive algorithms. In the
past, the media has harshly criticized racial profiling,  n110 and it is
unlikely that the public would support a system that regularly and explicitly
used race as a significant factor to determine whether to stop a person or
search his home.

   But explicit use of race is not the only potential problem in the context of
predictive algorithms, and this is where the need for  [*975]  transparency
becomes significant. It would be relatively easy for courts to enforce a rule
that prohibits the police from using the defendant's race directly as a factor
in predictive algorithms, but this may not prevent the algorithm from relying on
factors that are strongly correlated to race. Assume we change our hypothetical
algorithm and remove the race factor altogether, but still use the location of
the house as one of the factors. As has been established by decades of redlining
neighborhoods,  n111 location can be an effective proxy for race in the context
of providing insurance, banking services, health care, or many other types of
services.  n112 As we saw earlier, current software used by police to predict
crime patterns is highly location-specific, and it is certainly possible to
imagine a scenario in which higher-crime areas track the racial makeup of
specific neighborhoods.  n113 We can call this "indirect discrimination" as
opposed to the unconstitutional direct discrimination that occurs when race is
officially used as a factor.  n114 Nearly every predictive program that is
currently in use has given rise to concerns about indirect discrimination.  n115
Thus, before law enforcement agents and judges officially use these programs to
formally help them make their decisions, we need to determine whether it is
legally or ethically permissible to use these nonracial elements that are
correlated to race.

   One way of answering this question is to note that proxies for race are
already used in determinations of reasonable suspicion or  [*976]  probable
cause. Police officers routinely testify that they made their observations in a
"high crime area" as a factor that led to their reasonable suspicion or probable
cause.  n116 No doubt in many instances, higher-crime neighborhoods will tend to
be inner city neighborhoods with higher proportions of certain minority groups
n117 (or at least this will be the perspective of many police officers and
judges).  n118

   And this formal use of proxies for race under the current system is likely
only the tip of the iceberg. The unconscious (or conscious) racial biases of
police officers and magistrates permeate every aspect of the front end of the
criminal justice system.  n119 Under the current system, police officers
disproportionately stop and frisk black and Latino suspects, and they are more
likely to engage in violent and even lethal conduct when interacting with these
[*977]  suspects.  n120 The findings from the class action lawsuit challenging
the expanded police stop and frisks in New York City  n121 found that over an
eight-and-a-half-year period, 52% of all the citizens subjected to Terry stops
were black, even though black citizens made up only 23% of the population.  n122
Studies have shown similar numbers in Philadelphia,  n123 Los Angeles,  n124
Boston,  n125 and on the New Jersey turnpike.  n126 Unlike the formal factors
which can (at least in theory) be proven to be proxies for race, the use and
effect of these informal decisions are difficult to detect and even more
difficult to prove in court. These implicit biases on the part of police
officers are also difficult to cure, even in the long run, since they exist in
almost every individual, even those who harbor no conscious prejudices.  n127

   In other words, the current system relies on personal, subjective clinical
judgments that are based on some known factors (which are  [*978]  explicitly
described by the police officer or magistrate when requesting a warrant or
justifying their decision) and some unknown factors (such as unconscious
biases). Even for the explicitly listed known factors, the decision-makers do
not (and likely could not) quantify the degree to which they relied on each
individual factor.

   For example, assume a police officer is driving through a neighborhood and
notices a young black man standing on the street corner. The young man is
dressed in a way that is common to the neighborhood but that the police officer
identifies as consistent with gang affiliation. The man then looks over at the
officer, immediately places something in his pocket, and then walks briskly away
from the officer. Assume at this point the officer honestly believes that there
is a reasonable suspicion that the man is engaging in criminal activity (that
is, the officer is not out to hassle the young man and is not simply stopping
people indiscriminately in the hope of finding contraband). The officer then
gets out of her car and orders the man to stop.

   Later on, the officer is required to justify her stop by explaining why she
believed she had reasonable suspicion to believe criminal activity was afoot.
She lists the following factors:


     (1) The action took place in a high crime neighborhood;

     (2) The suspect hid an item after noticing a police officer;

     (3) The suspect attempted to leave the scene after noticing a police
     officer.

   The police officer does not list (and may not even be consciously aware of)
other factors that led her to believe the suspect may have been engaged in
criminal activity:


     (1) The suspect's race (the officer subconsciously believes that black
     men are more likely to possess guns or drugs than white men);

     (2) The suspect's age (the officer believes that men in their twenties
     are more likely to be engaged in criminal activity than children or
     men over forty);

     (3) The suspect's gender (the officer believes that men are more
     likely to be carrying drugs or weapons than women);

     (4) The suspect's clothing (which is actually common to the
     neighborhood but which the police officer subconsciously associates
     with criminals);

     (5) The way the suspect looked at the police officer, which the
     officer couldn't describe in testimony but which she associated with
     hostility to authority and to police specifically.

   Racial bias played a role in the officer's determination that the defendant
was likely engaged in criminal activity, but it is impossible  [*979]  to know
to what degree. Of the formal elements, the fact that the encounter took place
in a "high crime neighborhood" is likely correlated to race, but neither the
officer nor the magistrate reviewing her conduct are able to explain exactly how
important that factor was out of the three that were listed. And the fact that
the suspect's race led the officer to focus on this particular individual (as
opposed to the young white man she observed standing on a different street
corner two minutes before this interaction) may have played a significant role
in her decision or a very minor role. Likewise, the suspect's clothing (likely
another proxy for race) may have been a strong motivator for her to act, or it
may have been relatively insignificant. There is simply no way to measure, much
less prove, the degree to which race or proxies for race influenced her decision
to detain the suspect. Over the course of many years and tens of thousands of
stops, a clear pattern will probably emerge that shows that this police
department disproportionately stops people of color, but effective remedies at
that point are hard to come by.

   It is against this backdrop that we must evaluate any potential future use of
predictive software. In contrast to the use of clinical judgments, predictive
software will only base its results on the formal factors that are coded into
its system. Thus, there will be no unconscious or hidden human biases that
affect its decision. Furthermore, we can precisely quantify the degree to which
each of the formal factors affects the result, so a judge (or a policymaker) can
make an informed judgment as to whether certain factors that are proxies for
race are dominating the calculation. In other words, under the current system of
clinical judgments, the only way to infer indirect discrimination is by
reviewing the aggregate results after many months or years have passed. Under a
system of mechanical predictions, the level of indirect discrimination can be
assessed even before a stop or a search occurs by examining the algorithm the
police intend to use. Thus, the mechanical predictive algorithms can be designed
to ignore (or at least minimize) improper factors such as race--something that
may be impossible to do if we leave these determinations to the subjective
determinations of police officers.  n128

   All of this, however, depends on a high level of transparency in the
algorithm itself, so that judges and other policymakers (including the police
department that is considering adoption of the algorithm) can review the
factors, their correlation (if any) to race, and the strength of any specific
factor in reaching the result. We will  [*980]  examine the challenges of
achieving this level of transparency in Part III.

   2. Preexisting Biases in the Underlying Data

   A related concern about using mechanical predictions involves the underlying
data that is used by the predictive algorithms. Put simply, if the underlying
data is discriminatory, then the results that are based on that data will be
discriminatory, and the supposedly color-blind algorithms will be doing nothing
more than reinforcing the existing racial bias in the criminal justice system.
In the civil context, commentators are beginning to pay close attention to these
potential problems, noting that "[i]f a sample includes a disproportionate
representation of a particular class . . . the results of an analysis of that
sample may skew in favor of or against the overor underrepresented class."  n129

   As an example, assume that for the past twenty years a metropolitan police
department has been disproportionately stopping, searching, and arresting black
and Latino citizens. This disproportionate treatment does not stem from the fact
that citizens from these groups are more likely to commit crimes, but from
inherent racial biases in the criminal justice system, such as the tendency of
police to engage with minorities more than with whites and the increased level
of policing in minority neighborhoods.  n130 Assume also that these stops,
searches, and arrests result in conviction at a higher rate than stops,
searches, and arrests of white citizens--again, not because the police are
better at predicting crime for the minority citizens, but because of downstream
biases in the criminal justice system: Because black and Latino defendants tend
to be poorer,  n131 they are less likely to be able to afford private lawyers
[*981]  and less likely to be able to afford bail; and because of conscious or
subconscious prejudice on the part of prosecutors and judges, black and Latino
defendants are more likely to be overcharged  n132 (leading to higher rates of
plea bargaining) and more likely to be convicted by a jury if the case goes to
trial.  n133

   These discriminatory stops, searches, arrests, and convictions will become
the underlying data for the city's predictive algorithms, and they create two
distinct problems for mechanical predictions. The first is related to the
disproportionately high rate of encounters between the police and members of the
minority community--the so-called "hassle" rate.  n134 This will create large
amounts of data about certain individuals or areas of a city and
disproportionately small amounts of data about other individuals or areas. Thus,
when an algorithm determines whether a neighborhood is a "high crime area," it
will have a skewed interpretation of the frequency of crimes in different areas.
This in turn will lead to more frequent searches of individuals in the "high
crime areas," which will create a self-fulfilling prophecy as more individuals
are stopped, searched, arrested, and thus convicted in those areas. Likewise, if
an individual is determined to be at "high risk" for committing a crime, it
could merely be reflecting the prejudices of police officers who have had
previous encounters with the individual.  n135 Professor Bernard Harcourt refers
to this as the "ratchet" effect: If certain factors are already perceived as
leading to higher levels of criminal activity, a  [*982]  predictive algorithm
will lead police and judges to conduct and authorize more searches on suspects
who meet these factors, leading to more arrests that are linked to those
factors.  n136

   The second problem relates to the disproportionately high ratio of
convictions to arrests for minority populations--what is usually referred to as
the "hit" rate.  n137 The primary way to know whether a stop, search, or arrest
is successful (is a "hit") is by examining conviction rates. Thus, even if in
fact the police do find contraband at the same rate for every ethnic group that
is searched, if certain minority groups are convicted at a higher rate after the
contraband is discovered, the statistics will indicate a higher hit rate for
those minority groups than for others. In other words, because these citizens
are unfairly convicted at a higher rate, the stops and searches that are
conducted against them will appear to be more effective.  n138

   As with the decision-making process itself, this problem is not new to
mechanical predictions. The "data" that are used by police officers and judges
today--their own personal experiences--is similarly flawed.  n139 The danger in
moving towards a big data analysis in this context is not that a new problem
will be created, but that--despite big data's promise of being color-blind and
objective--the old problems will persist. Even worse, these old problems will
become institutionalized and thus be even harder to successfully challenge and
expose because they are presented as part of the "hard science" of big data.

   These problems with underlying data are not insoluble. The issue is common to
many uses of big data, and it arises when statistics that are kept for one
purpose are used for another.  n140 Stop-and-frisk statistics and criminal
conviction numbers are not recorded for the purposes of sophisticated
statistical study; thus, those who collect them generally make no effort to
correct for any biases inherent in the process.  n141 Part of the solution thus
involves correcting the data--that is, estimating the rate of
over-representation  [*983]  of minorities in the hassle rates and hit rates and
then adjusting the numbers accordingly.  n142 Another solution would be to use
data from different sources, not just from information that results from
police--citizen encounters. For example, algorithms could draw their underlying
data from the Bureau of Justice Statistics' National Crime Victimization Survey,
n143 which tracks crimes based on victim reports, as opposed to the more
traditional method of tracking crime through police reports.  n144

   Once again, these solutions require real transparency as to the data being
used. Courts and policymakers need to demand to see the source of the data used
by the predictive algorithms and need to be given the tools to evaluate whether
the data is representative of reality or the product of discriminatory decisions
or unfair processes from the past.

B. Ensuring the Computer Looks for Individualized Suspicion

   Individualized suspicion is a bedrock requirement of almost any police action
that implicates the Fourth Amendment.  n145 If police officers knew that
statistically speaking, 60% of everyone living in a certain building were guilty
of possessing drugs, they would not be allowed to arrest everyone in the
building, even though they would almost certainly have probable cause to believe
that each person is guilty.  n146 The Fourth Amendment demands a certain level
of  [*984]  particularity; that is, not merely a statistical likelihood that a
suspect is guilty based on his membership in a certain group, but a reference to
particular characteristics or actions by the suspect that shows that he
specifically is likely to be guilty.  n147

   One objection to using mechanical predictions is that they will dilute or
even eliminate the individualization requirement by focusing on broad categories
instead of the individual's particularized conduct.  n148 Even if big data's
mechanical predictions could lead to more accurate results, it would be legally
and morally wrong to punish a person based on membership in a specific group
(such as economic class or age) instead of focusing on the person's individual
actions.  n149

   In order to address this concern, we first have to define what we mean when
we say that suspicion must be individualized.  n150 In general, we mean that
police officers must look at the specific characteristics and actions of the
suspect himself, and not determine reasonable suspicion or probable cause merely
because the suspect is a member of a certain group. However, individualized
suspicion does not preclude inferring facts about an individual based on his
[*985]  membership in a certain group; it simply requires the presence of
additional factors that are specific to the suspect. Even in the analog world of
clinical judgments, police officers and judges routinely rely on assumptions
about an individual based in part on the characteristics of their group. For
example, police officers will give some weight to a suspect's known gang
affiliation, while magistrates making bail determinations will consider whether
a defendant is unemployed or has a criminal record.

   However, it would be inappropriate to stop, search, or arrest an individual
solely based on his membership in a specific group.  n151 This would essentially
be saying that the group characteristics of the individual are so suspicious
that at any given moment there is reason to believe that he is likely to be
engaging in criminal activity. In order to avoid this problem, courts have held
that the police officer must observe conduct that gives her some reason to
believe that the suspect is currently engaging in criminal activity.  n152 These
actions may be legal (but suspicious) conduct, such as running from the police,
exiting a location where drugs are known to be sold while sticking something in
a pocket, or wearing a heavy coat on a summer day. Or they may be legal and
innocuous conduct, such as purchasing a one-way ticket or traveling with no
luggage. But the reasonable suspicion or probable cause cannot be based only on
who the person is; it must also be based on what the person does.  n153

    [*986]  The Supreme Court has repeatedly reminded us of the need to consider
the specific actions of the individual being searched. In Ybarra v. Illinois,
law enforcement officers with a warrant to search a tavern decided to stop and
frisk every individual inside the tavern, under the theory that mere presence in
a tavern where drugs were being sold generated reasonable suspicion that a
person possessed drugs.  n154 The Supreme Court rejected this argument,
explaining that "the Terry exception does not permit a frisk for weapons on less
than reasonable belief or suspicion directed at the person to be frisked."  n155

   A mechanical prediction that is used to demonstrate reasonable suspicion or
probable cause must meet these same criteria.  n156 Law school hypotheticals
aside, it is hard to imagine a situation in the real world where group
characteristics alone rise to the level of reasonable suspicion, but it is
theoretically possible that a mechanical prediction would arrive at such a
result. Thus, any predictive software used to calculate whether reasonable
suspicion or probable cause exists must require the observing officer to input
the specific actions of the suspect as well as his general characteristics. The
software would thus use these specific actions as part of its analysis, and it
would be designed in such a way that it could not find reasonable suspicion or
probable cause--regardless of the percentage chance of criminal activity
occurring--unless the specific actions were a significant factor in the
determination.  n157

C. Changing the Legal Standards

   So far in evaluating the obstacles to adapting big data to criminal law, we
have looked at the potential problems with the underlying data or the methods
used to process that data. In other words, we have been concerned with shaping
the way that mechanical predictions are made in order to ensure that they are
consistent with the requirements of our criminal procedure jurisprudence. But
even if these problems are solved, we face a potentially even greater obstacle:
reshaping the criminal procedure jurisprudence so that it can use the
information provided by big data.

    [*987]  Simply stated, the quantitative results from mechanical predictions
are incompatible with the broad, flexible standards used by police and judges in
the world of criminal procedure.  n158 Reasonable suspicion and probable cause
are standards that have been intentionally kept vague by the courts. The Supreme
Court has long resisted setting specific probabilities for the flexible concepts
of reasonable suspicion or probable cause,  n159 explaining that it is a
"practical, nontechnical conception" which is "incapable of precise definition
or quantification into percentages."  n160 The Court explains to us that the
concepts are not "readily, or even usefully, reduced to a neat set of legal
rules"  n161 and then follows through on this promise by providing a multitude
of messy rules for police and lower courts to follow. Probable cause is defined
as evidence that would "warrant a man of prudence and caution in believing that
the offense has been committed" or as a "reasonable ground to believe that the
accused [is] guilty."  n162 Reasonable suspicion is defined as "obviously less
demanding than . . . probable cause,"  n163 requiring merely "some minimal level
of objective justification."  n164

   These definitions are rather unhelpful in providing guidance or clarity as to
when a stop or a search is appropriate. No lay person would possibly know what
these terms mean in the real world; police officers and law students must study
dozens of fact patterns from case law to get a sense of what kinds of factors
will create reasonable suspicion or probable cause. Forty-five years ago, one
law professor surveyed 166 federal judges to ask them to quantify the concept of
[*988]  probable cause, and the results ranged from ten percent to ninety
percent.  n165 The same group of judges was asked to quantify the concept of
reasonable suspicion, and most judges gave responses between ten percent and
sixty percent.  n166

   This imprecision has its costs: It creates inconsistency from jurisdiction to
jurisdiction and even from judge to judge and it makes it harder for police to
know whether their actions are legal at the time they take those actions.  n167
It also forces magistrates and judges to rely on the subjective descriptions and
personal judgments of the police officers, since these vague standards breed
vague descriptions to meet those standards, such as "high crime neighborhood,"
"acting nervous," and "suspicious hand movements." Police officers who testify
to these factors are usually not acting in bad faith; they are merely trying to
find ways to satisfy an ambiguous legal standard. Perhaps worst of all, the
imprecise standards make it difficult to evaluate the constitutionality of law
enforcement actions on a larger scale. Assume that a study of all
probable-cause-based automobile searches in a jurisdiction demonstrated that 32%
of the time, the police found contraband. Does this mean that the police in this
jurisdiction are following the law or that they are violating people's rights?
Without any quantification of the standard, it is impossible to tell.

   To some extent, the imprecision of these terms was a necessary evil. If the
Supreme Court had instructed police that they needed to be at least 20% certain
of an individual's guilt before conducting a  [*989]  Terry stop, the precise
quantification would not have helped individual officers in making their
on-the-spot decisions. It makes more sense for officers to be given some broad
guidelines (e.g., "more than a mere hunch" or "some level of objective
justification required") and then teach them through training and trial and
error what courts will approve and what they will not (e.g., observing a suspect
leave a known crack house and then run from a uniformed police officer
constitutes reasonable suspicion; observing a suspect leave a known crack house
with no other suspicious behavior does not). Similarly, telling a magistrate
that she should only issue the warrant if there is a 45% chance of finding
contraband would be unlikely to help her make the decision in a world of
clinical judgments. The magistrate must consider the myriad of subjective
factors from the police officer's affidavit: the credibility of an informant,
the reports of unusual but not blatantly illegal activity, and so on. Given the
messiness of the evidence confronted by police and judges, a messy standard
makes the most sense. Such a standard allows the decision-makers to follow their
intuition and make a subjective judgment about whether "something seems not
right about this situation" (reasonable suspicion) or "I believe there is a good
chance that a crime has been committed" (probable cause).  n168 Indeed, many
judges who were polled about percentages for probable cause and reasonable
suspicion in the 1981 survey refused to answer the questions, arguing that using
percentages would be "misleading because burdens of proof deal with qualitative
judgments rather than quantitative judgments."  n169

   Numerous scholars have also objected to creating specific quantifiable
standards. For example, Professor Orin Kerr argues that quantification of
probable cause would lead to less accurate probable cause determinations because
warrant applications only provide a limited amount of information, and under the
current system, judges are able to use their intuition to account for the
missing facts.  n170 Professor Kerr argues that when a judge gets a warrant
application,  [*990]  she only sees the selective facts that the police want her
to see: investigative techniques that successfully found evidence to build
towards probable cause.  n171 But the application will not describe any
investigative techniques that were used that failed to find evidence nor will it
describe any possible investigative techniques that could have been used that
were not used.  n172 In the current non-quantified world, Professor Kerr argues,
judges can use their intuition about what might be missing from the warrant
application, and judges will instinctively (and perhaps subconsciously) factor
that into their decision.  n173 If the probable cause standard became
quantified, at, say, 40%, judges would merely calculate the odds (incorrectly)
based on the selective facts in the affidavit and would suppress their natural
intuition to be suspicious about the facts that might not have been included.

   Although Professor Kerr claims his argument is based on the value of judicial
intuition, it is really about the need for particularized suspicion. He uses an
example of law enforcement who have a well-documented study that 60% of all
Harvard dorm rooms contain illegal drugs, and he posits that police officers
attempt to use that study to get a warrant to search a specific dorm room.  n174
A judge would rightfully be suspicious of this request, he argues, because the
judge's intuition would make her wonder why the police have chosen this room in
particular--thus leading to the conclusion that she is not getting the full
story from the police.  n175 But this is merely a restatement of the requirement
that suspicion be particularized--that the affidavit must contain some
information that links this specific suspect to the illicit activity. And as
noted above,  n176 this is an important consideration in designing big data's
algorithms for criminal law application--we need to either ensure that the
inputs contained some reference to the individual actions or behavior of the
suspect himself, or allow for police and judges to add in their own observations
of individual activity.  n177

    [*991]  A more troubling critique of using predictive algorithms is the
Supreme Court's requirement that the decision-maker use a "totality of the
circumstances" test in determining whether reasonable suspicion or probable
cause exist.  n178 Professor Michael Rich argues that a predictive algorithm can
never determine probable cause on its own because the algorithm is by definition
limited in the factors that it considers in making its determination.  n179 A
predictive algorithm might be programmed to consider only a handful of factors,
or it might be programmed to consider hundreds of factors, but it can never
consider every factor that could possibly be relevant to a probable cause
analysis.  n180 A human being at least has the potential to incorporate new
observations, but a predictive algorithm is limited by its previous programming.
n181

   One response to this critique is that it somewhat misrepresents what the
Court means by "totality of the circumstances." This requirement does not mean
that the decision-maker must consider every possible factor--that would be
impossible for a human being or a computer. Indeed, courts have noted that once
a police officer has established that probable cause exists, the officer is
under no further duty to investigate or gather exculpatory data.  n182 Instead,
"totality of the circumstances" means two things.

   First, courts should reject a formalistic checklist of factors (such as the
pre-Gates "two pronged" test)  n183 and be willing to consider many different
factors in deciding whether probable cause  [*992]  exists.  n184 Certainly a
predictive algorithm can be designed to consider hundreds of different factors,
far more than the average police officer observing the scene and far more than
are typically included in an affidavit in a warrant application.  n185 It is
true that no predictive algorithm will ever be able to consider every relevant
factor, whether inculpatory or exculpatory. But of course this is also true for
police officers and judges. In fact, predictive algorithms could conceivably
process thousands of different factors, many more than a human being could.

   It is easy to come up with examples of cases in which a police officer makes
an observation that is not programmed into the predictive algorithm and which
dramatically increases (or decreases) the level of suspicion in a situation, but
it is equally easy--if not easier--to think of examples in which a predictive
algorithm considers relevant factors that an average police officer would never
consider. Many of the factors that human police officers consider to be relevant
may in fact be irrelevant or may be given insufficient weight or too much
weight. And, as many commentators have pointed out, some of the "intuitions" of
police officers and even judges are grounded in implicit racial bias, making
their conclusions not just inaccurate but also discriminatory.  n186

   Second, the police and courts must also consider potential exculpatory
evidence as part of the totality of the circumstances, since certain
observations or background facts may lower the level of suspicion.  n187
Predictive algorithms can--and should--be programmed to consider possible
exculpatory evidence as well, and to weigh that evidence in reaching their
conclusions.

   In short, quantifying these standards will allow police and judges to use
predictive algorithms, bringing a number of benefits: the opportunity to reduce
discriminatory bias in the system; greater accountability for police actions;
and a higher level of accuracy (that is, fewer searches of those who are
innocent and more searches of  [*993]  those who are in fact engaged in criminal
activity). There is nothing inherent about these tests that would forbid courts
from adopting quantitative standards, but courts have been extremely reluctant
to do so.  n188 In the next Part, we will talk about the feasibility of such a
shift.

   III. MAKING BIG DATA WORK IN THE CRIMINAL JUSTICE SYSTEM

   Under current law, a police officer seeking a search warrant states that she
believes there is probable cause to believe that contraband will be found in the
suspect's house, and a judge appraises that assertion by reviewing and
evaluating the facts that the police officer places in her affidavit, including
the credibility of any informants (and of the police officer herself). The judge
then reaches her own conclusion about whether a person of reasonable caution
would believe that contraband is present at the location.

   In a world of predictive algorithms, the police officer will instead present
the magistrate with the output of a computer program which states that there is
a 40% chance that contraband will be found in the suspect's house. The judge
will then examine the algorithm that was used to ensure that it meets the
appropriate legal standards and will then make a ruling as to whether the 40%
prediction is sufficient to establish probable cause. Depending on the
circumstances, the judge may make a decision based solely on the output of the
algorithm (the "outcome determinative" model), or she may consider the output of
the algorithm as one factor to combine with other relevant facts (the "formal
factor" model).

   As we have seen in the previous Parts, in order to reach this world we must
overcome a number of obstacles. First, the judge needs to know that the computer
is not using discriminatory factors or data that merely reinforces past
discrimination. Second, the judge will need to confirm that at least some of the
factors used by the computer are specific to this particular suspect and that
the 40% figure is not merely derived from aggregate group probability figures.
If the algorithm has no factors that are based on individualized suspicion, a
judge needs to combine the 40% result with specific facts about this particular
suspect in order to arrive at her own prediction. And finally, we need to know
whether the 40% chance of finding contraband (or whatever number the judge
settles on after factoring in other information) is sufficient to convince a
[*994]  judge that a person of reasonable caution would believe that contraband
is present. In order to overcome this final problem, courts must overcome their
hostility to quantifying the legal standards that make up the backbone of
criminal procedure.

   Thus, in order to create a system where police officers and judges use
data-centric mechanical predictions in making their decisions, two major changes
must occur. First, the predictive algorithms must be sufficiently transparent to
allow judges to ensure that the algorithm is not relying upon unconstitutional
factors, either directly or indirectly, in reaching its conclusions.
Transparency is also required so that judges can ensure that at least some of
the factors leading to this number are specific to this particular suspect. And
as we will see, transparency is also necessary so that judges can add additional
factors to these algorithms in order to adjust their results to the facts of a
specific case. Second, courts must overcome their resistance to quantifying
these legal standards, so that the numerical results from mechanical predictions
can be applied to these legal determinations. As part of overcoming that
reluctance, in some cases judges must also become comfortable with manipulating
these probabilities and combining them with other factors in order to reach
their own independent conclusions.

A. Transparent Algorithms and Data Sets

   The first step is to convince companies who make these algorithms to share
the details of their operation--if not the source code, at least the factors
that their predictive models consider and the weight that the models assign to
each factor. The transparency requirement is necessary not only for the
algorithm itself but also for the underlying data sets, in order to avoid the
ratchet effect discussed earlier.  n189 Courts need to be able to examine the
underlying evidence being used by the algorithm to ensure that they are not
already tainted by race or by proxies for race--and if they are, the data sets
need to be adjusted in order to remove the taint. Greater transparency for the
data sets will also help with another growing problem with our increasing
reliance on big data: erroneous information in the government and private
databases upon which these algorithms rely.  n190 As we have seen earlier,
police are already relying on these predictive algorithms to direct resources
and place certain people  [*995]  under suspicion, so cleansing the algorithms
of discriminatory factors and purging inaccurate information is already long
overdue.

   Another reason to mandate transparency is to ensure that the individualized
suspicion requirement is met. As noted above,  n191 some predictive algorithms
may base their conclusions solely on group membership and external factors, thus
violating the legal requirement that reasonable suspicion or probable cause be
based on individualized suspicion. If the inputs used by the algorithm are open
for the judge to examine, then she can ensure that the conclusion is based on
the appropriate level of individual activity. And if there are no inputs based
on individualized suspicion, the judge must demand additional facts from the law
enforcement officer in order to establish individualized suspicion--that is, she
will be forced to switch from an "outcome determinative" use of predictive
algorithms to a "formal factor" model.

Unfortunately, up until now, companies have been extremely secretive about the
details of their predictive algorithms, presumably because they consider these
details to be valuable proprietary information.  n192 The company that provides
the Beware software to police departments does not even allow the police
departments to know the details of the algorithm.  n193 Recently, the American
Civil Liberties Union (ACLU) had to make a public records request to the Fresno
police, seeking information about the factors used by its predictive software;
the results still did not provide anything like the kind of transparency
necessary to evaluate the constitutionality of the program.  n194 This secrecy
is not limited to private corporations; even  [*996]  private individuals who
design these algorithms refuse to disclose exactly how they work.  n195

   Thus far, this secrecy has not posed significant legal problems, since
predictive algorithms are only being used to direct police resources. But this
is likely to change in the near future, regardless of whether police and courts
begin to use predictive algorithms to establish legal cause to stop or search.
There is growing concern that the use of mechanical predictions is merely a
sophisticated form of racial profiling,  n196 and if police want to continue to
use algorithms in any capacity, they will need to reveal (or require their
client companies to reveal) the details of these algorithms. This greater
transparency will not only reassure the public (and the courts) that the
determinative factors used by the algorithm are not related to race, but it will
also lay the groundwork for adopting these algorithms more formally into the
legal system. And, not incidentally, it may reveal that some algorithms are
relying on forbidden factors in reaching their conclusions, which of course
would require the algorithm to be redesigned with the offending factors removed.
The ACLU's recent public records request, for example, revealed that one of the
Fresno Police Department's predictive software algorithms used the social media
hashtag # BlackLivesMatter as a risk factor for "police hate crimes."  n197

   But requiring the software engineers and statisticians who design mechanical
predictions to reveal the factors being used and the weights assigned to each
factor is only the first step. Modern day predictive software is not static; the
more sophisticated algorithms will adjust the factors as they go, learning from
past experience. As  [*997]  the algorithm makes thousands or millions of
predictions, it will be told which of those predictions ended up being accurate,
and it will change the weight assigned to each of its factors accordingly to
improve its accuracy. This process, known as machine learning,  n198 ensures
that the algorithm's mechanical predictions improve with time, but it makes it
even more difficult for the courts to evaluate the degree to which each factor
is relevant to the machine's conclusions.  n199 As one scholar has noted,
"[F]orecasting becomes a distinct activity that differs from explanation. . . .
What matters most is forecasting accuracy. Combining explanation with
forecasting can compromise both."  n200 In other words, the most accurate
algorithms--those that use machine learning to sift through millions of
different data points--may be the least transparent.  n201

   However, as we have seen in other contexts in the criminal justice system, it
is possible to overcome these obstacles. A judge does not really need an
intricate understanding of the underlying code of the algorithm; she only needs
to know (1) the factors that the algorithm used and (2) the historical accuracy
of algorithm's results.  n202 Although the experts who design the algorithm need
to consider hundreds or thousands of data points in order to determine which
ones are the most predictive, for practical reasons the actual algorithm will
probably only use eight or nine factors, just like the sentencing risk
assessment tools.  n203 Thus, the first piece of  [*998]  information should be
easy for law enforcement to provide, since presumably it is law enforcement
officers who input the data. And the accuracy of the results should easily be
available, since an integral part of developing big data's algorithms is to
calculate (and then improve on) the accuracy of the predictions that are being
made.

   Once the judge obtains this information, she would then need to evaluate (1)
whether the specific inputs are proxies for a forbidden factor, such as race,
n204 and (2) whether they contain sufficient particularity to justify the stop,
search, or arrest.  n205 In other words, the judge does not need to know exactly
how the algorithm arrived at its results, only which factors it considered in
doing so. The judge would also have to determine whether the accuracy of the
algorithm is sufficient to meet the reasonable suspicion or probable cause
standard, a question we turn to in the next Section.

   And if a judge did want to understand the way the algorithm processed the
inputs, she would not have to personally decipher the meaning of the underlying
source code, much less understand the evolution of the data in a machine
learning environment. Just as judges hear from experts in a Daubert hearing when
they are called upon to determine the reliability of a new and complex
scientific process, a judge who is called upon to evaluate the methodology and
reliability of a predictive algorithm could also listen to experts testifying
from both sides.  n206

   This transparency requirement should be seen not as a weakness of adopting
mechanical predictions but as one of its strengths. Courts currently rely on a
combination of their own intuition (an internal, subjective algorithm) and
experience (an internal, limited database) when reviewing the decisions of a
police officer (decisions that are made based on a combination of the police
officer's intuition and experience). It has already been conclusively
demonstrated that these intuitions are subject to significant levels of racial
bias,  n207 but it is difficult for a magistrate to know if (or to what degree)
her own intuition may be suffering from this problem. Likewise, the magistrate's
personal experiences are likely based in part on problematic data. These hidden
biases are very difficult to  [*999]  remove from a person's decision-making
process.  n208 With the proper transparency requirements, however, these biases
can be easily detected in algorithms and data sets of mechanical predictions.

B. Quantifying the Legal Standards

   Lack of transparency is not only a problem for those who collect and process
the data, but also for those who use the data--that is, the judges who apply the
legal standards. If the quantified results from the world of big data are going
to be used effectively in the courts, judges will need to update the legal
standards that they use.

   1. Setting a Number

   Perhaps the most challenging aspect of adopting predictive algorithms is
determining the quantified percentage to match up with reasonable suspicion or
probable cause.  n209 The vagueness of the current rules obscures any attempt to
determine how much suspicion is actually necessary to reach these standards, and
courts have routinely stated that these standards should not or even cannot be
reduced to mere numerical probabilities.  n210 But if the criminal justice
system is going to benefit from the increased accuracy and potential reduction
of unfair bias that is offered by predictive algorithms, courts will need to
overcome their hostility to quantification.

   Quantifying these standards may lead to other benefits as well. One positive
side effect of greater quantification is the possibility of creating precise
standards for different situations--what Professor Christopher Slobogin refers
to as the proportionality principle.  n211 Courts (or legislatures) could craft
specific standards for the most intrusive searches (such as wiretaps or bodily
intrusions) and lower  [*1000]  standards on a sliding scale as searches become
less invasive (searches of homes, searches of cars, searches of offices, frisks,
flyovers, surveilling public spaces).  n212 Of course, courts and legislatures
already have created these different standards to some degree,  n213 but the
lack of quantification has made this process confusing and limited the number of
"tiers" that can realistically be created.

   Other commentators have argued that quantifying the probable cause standard
would enable courts to adopt a sliding scale based on the severity of the crime
being investigated.  n214 Courts have so far been reluctant to entertain this
idea, generally holding that one standard should apply across the board to every
criminal investigation.  n215 But as Professor Craig Lerner has pointed out,
courts have dropped some hints that the probable cause standard should be lower
for police investigating a mass shooting or a kidnapped child than they would be
for a low-level drug possession case.  n216 Judge Richard Posner, for example,
writing an en banc decision for the Seventh Circuit, held that probable cause
should be "a function of the gravity of the crime" in the context of exigent
circumstances.  n217  [*1001]  This type of sliding scale would be all but
impossible to administer with the current broad standards; only with greater
precision can courts make meaningful distinctions in different contexts.

   Professor Erica Goldberg also points out that the imprecise nature of the
current standards for probable cause tends to create a very low bar in practice
because of the good faith exception to the exclusionary rule.  n218 Under this
exception, even if a reviewing court finds that a warrant lacked probable cause,
the illegally obtained evidence will still be admissible as long as the officer
acted in good faith--that is, as long as the warrant was not "so lacking in . .
. probable cause as to render official belief in its existence entirely
unreasonable."  n219 A vague probable cause standard means that many warrants
that fall short of the probable cause standard will in practice result in
evidence that can be used in trial, as long as the lack of probable cause was
not obvious to the officer.  n220 If the probable cause standard were
quantified, it could also be enforced with more regularity against police
officers, who would be much less able to claim the good faith exception when a
warrant did not in fact meet the proper standard.

   There is a possibility that if we use actual data to run these analyses, we
will learn that our standards for stops, arrests, and warrants are
embarrassingly low. For example, we may learn that the standard hit rate for
Terry stops is 2% and the average hit rate for search warrants is 10%--that is,
that police officers conduct Terry stops on individuals with only a one in fifty
chance that the suspect is engaged in criminal activity; and judges are issuing
search warrants even though there is only a one in ten chance of finding
contraband at the named location. We may also learn that these rates vary wildly
depending on the jurisdiction,  n221 the suspected crime, and (as we have
already seen) the race of the suspect.  n222 This information will be yet
another fringe benefit of shifting to a quantitative model. If courts learn that
they are in fact using a 2% rate for reasonable suspicion, we can have a real
debate about whether this number is too low, and if so, what the number ought to
be. Such a debate is nearly  [*1002]  impossible to have now because the current
standards are shrouded in intentionally ambiguous legalese.

   Once we agree on a number, that number can be imposed consistently throughout
the country. No longer will individuals in the city be subjected to one standard
while individuals in the suburb receive a more deferential standard. Similar
standards will apply to those suspected of tax fraud as to those suspected of
possessing heroin. This type of equality is simply not feasible under our
current system.

   Yet another benefit to quantification will be greater transparency in the
factors that police and courts use to make these decisions.  n223 For example,
consider the case law surrounding Terry frisks, which shows courts struggling to
determine when there is reasonable suspicion to believe a suspect is armed. One
commonly cited factor is the type of crime the person is suspected of having
committed. Courts have consistently held that some crimes, such as robbery,
n224 narcotics trafficking,  n225 growing large amounts of marijuana,  n226
rape,  n227 or burglary,  n228 all involve a high risk of the suspect carrying a
weapon and are thus a legitimate factor in determining whether the suspect is
armed.  n229 But is the nature of the crime enough on its own to create
reasonable suspicion? Is it enough when combined with one other observation by
the police officer, such as a "furtive move" or a "suspicious bulge"?

   Generally, courts will find that if the officer reasonably believes that the
suspect is guilty of one of these "weapons likely"  [*1003]  crimes, then that
belief is sufficient to create reasonable suspicion that a suspect is armed.
n230 But surely the risk of a suspect carrying a weapon is not identical for all
five of those crimes--so in theory courts should require some corroboration in
the case of certain suspected crimes and less (or none) in the case of others.
This is not what happens: Courts merely state that the suspected crime is
"likely to involve the use of weapons"  n231 and then generally find that the
frisk was justified. Meanwhile, other suspected crimes, such as passing
counterfeit money  n232 or possession of illegal drugs,  n233 are held to not be
a legitimate factor--that is, an individual suspected of these crimes has
absolutely no greater likelihood than anyone else to be carrying a weapon. In
reaching these conclusions, courts generally rely on their intuition rather than
any actual evidence that indicates the prevalence (or dearth) of weapons on
suspects who commit these crimes. And in the absence of empirical evidence,
courts create a false binary categorization: Suspicion of certain crimes
generates reasonable suspicion on its own, while suspicion of other crimes does
not add to the probability of a weapon being present.

   Occasionally, courts do venture into the realm of data when deciding whether
reasonable suspicion or probable cause exist, with decidedly mixed results. In a
recent case, the Ninth Circuit attempted to determine if suspicion of domestic
violence was a legitimate factor in determining whether the individual was
armed.  n234 The majority held that suspicion of domestic violence did not
increase the likelihood of the suspect possessing a weapon. To support its
conclusion, the court cited studies that concluded that "domestic violence calls
for service account for a relatively small proportion of the overall rate of
police officers murders" and that 36.7% of domestic violence victims had at some
point in their lives been threatened or harmed by a weapon during a domestic
violence incident.  n235 The dissent cited FBI studies demonstrating that 33% of
assaults on police officers in a recent year were committed while police were
responding to "disturbance calls," which is "a category which includes domestic
violence calls," and that over a ten year period three times more police
officers were killed responding to  [*1004]  domestic violence calls than those
responding to burglary calls.  n236 None of these studies establish any
quantitative probability that perpetrators of domestic violence use or carry
weapons; they merely establish the undeniable fact that perpetrators of domestic
violence sometimes carry weapons and sometimes pose a risk to police officers.
n237

   The court did cite one seemingly useful study: a Bureau of Justice report
covering seven years, which concluded that 15% of domestic violence attacks
involved a weapon.  n238 But this statistic is almost certainly too crude to be
useful. Like "burglary" or "narcotics trafficking," the crime of domestic
violence encompasses many different kinds of behavior--some of them probably
linked to a high likelihood of weapons possession and some linked to a
relatively low likelihood.  n239 In order to effectively use statistics, courts
will need more sophisticated and detailed data, which can be applied to the
facts of the specific case--did the alleged domestic violence occur at home or
in a public place? What percentage of individuals living in the neighborhood
possess firearms? Are the police responding at night or during the daytime? This
type of detailed data needs to be developed so that it can be used by the
courts--without it, courts may identify these factors as relevant but then apply
their own flawed intuition as to how each factor affects the ultimate question
of reasonable suspicion.

    [*1005]  Of course, even if better data were available, the data would be
insufficient without a quantitative standard to judge it against. Assume that
the court had access to a database that stated that of all the domestic violence
calls in this neighborhood during this time of day in the past five years, 19.2%
of the suspects were armed when the police arrived. Would that constitute
reasonable suspicion? If not, how close is it--close enough that a suspicious
movement by the suspect is enough to put the risk across the line?  n240 Without
a quantified definition of reasonable suspicion, judges are unable to answer
these questions, and so instead they create an inaccurate binary distinction
among different types of crimes.

   Thus, we need to set a quantified percentage chance for reasonable suspicion
or probable cause. As we saw earlier, judges appear to have widely divergent
views as to this question, with survey results varying widely but averaging at
30.8% for reasonable suspicion and 44.5% for probable cause.  n241 The Supreme
Court has implied  n242--and lower courts have stated  n243--that the probable
cause standard does not mean "more probable than not," which places the probable
cause standard at less than 50%. Most commentators also agree that probable
cause is something close to but just less than 50%,  n244 while scattered
evidence from prosecutors and law enforcement point to numbers between 40% and
51%.  n245

    [*1006]  One way to derive a specific number for these standards is to
reverse engineer the stops and searches that have been approved under the
current law. In other words, we can measure the hit rates for stops and searches
that courts have approved using the traditional standards. This should provide
us with a number that is at least above the minimum level of suspicion that is
required. For example, if across the country, courts approve of 100,000 probable
cause searches and police find contraband in 45,000 of those searches, we can
know that generally a prediction which is 45% accurate is at least high enough
to satisfy the probable cause standard.

   Unfortunately, there are not many statistics available, but we do have some
actual data from the real world that can be used as a starting point. For
example, the district court in the Floyd case held that the Terry stops in New
York City in the early 2000s were often conducted without reasonable suspicion.
These stops had a 12% hit rate; thus, the Floyd judge apparently considers a 12%
rate to be too low.  n246 In contrast, we know that before the New York Police
Department began its aggressive stop-and-frisk policy, its hit rate for Terry
stops was a more respectable 21%.  n247

   Reviewing probable cause searches of automobiles provides some real-world
data as to the percentage chance necessary to establish probable cause. An
independent review of the San Antonio police showed that their probable cause
automobile searches resulted in a hit rate of 35.1%.  n248 As part of a
settlement of a federal civil  [*1007]  rights action in 1995, Maryland State
Troopers were required to report every stop and search of a car on their
highways,  n249 which showed a 52.5% hit rate for probable cause searches.  n250
And a review of the Florida State Police showed a 38.2% success rate for such
searches.  n251

   Another way to estimate the number is to look at cases involving alerts by
drug-sniffing dogs, which can constitute probable cause as long as the dog's
reliability has been established.  n252 Thus, when a court needs to determine
whether a positive alert by a drug dog is sufficient to establish probable
cause, the Supreme Court has instructed the reviewing judge to consider the
training and past performance of the drug dog in controlled testing
environments.  n253 Lower courts have already (albeit grudgingly) approved
specific numerical success rates for drug dogs as sufficient to establish that
the dog's positive alert creates probable cause, holding that accuracy rates of
50%,  n254 55%,  n255 58%,  n256 and 60%  n257 were all sufficient to satisfy
the probable cause standard.  n258

   On the other hand, Professor Max Minzner points out that the success rate for
search warrants, which allegedly use the same probable cause standard, are much
higher--somewhere between  [*1008]  84% and 97%.  n259 Although this dramatic
disparity between different applications of the probable cause standard makes it
more challenging to determine the "proper" number through reverse engineering,
it provides yet another compelling reason to quantify the standard. Are courts
being too lenient in reviewing probable cause for warrantless searches, or are
they requiring too high a showing for warrant applications? Or perhaps we want
two different standards, one for the on-the-spot decisions made by police
officers, and one for the greater legitimacy and presumed legality of search
warrants? None of these questions can be truly addressed until the probable
cause standard is quantified.

   From this brief review of the available data, we can see that hit rates for
stops and searches vary depending on the jurisdiction and even on the context in
which the standard is applied. Thus, if we want to reverse engineer percentages
for reasonable suspicion and probable cause from the existing standards, we will
need data from a much broader set of studies. However, even the small amount of
data that we have so far confirms the estimates of commentators and courts that
the number for probable cause is somewhere between 40% and 50%.  n260 There is
very little data on the success rate for stop and frisks that have been approved
by courts, but the Floyd case implies that 12% is too low,  n261 and we know
that the number has to be significantly less than the 40% to 50% range for
probable cause.

   In one sense, the use of predictive algorithms to establish reasonable
suspicion or probable cause is not so revolutionary. The Supreme Court has not
been averse to using statistical data in other Fourth Amendment contexts. For
example, when the Court was determining whether a drunk driving checkpoint was
"reasonable" under the special needs doctrine, it noted that the checkpoint
resulted  [*1009]  in a 1.6% hit rate for drunk drivers  n262 and also that
similar checkpoints around the country had a 1% hit rate.  n263 And as noted
above, lower courts already routinely evaluate the reliability of certain tools,
such as drug dogs, that are used to demonstrate probable cause.  n264 The need
for courts to use success rates to evaluate probable cause will only increase as
sophisticated investigative technologies such as facial recognition software or
gun detectors become more widely used. In a sense, predictive algorithms will be
doctrinally no different from these other tools that are already being used to
establish probable cause.

   2. Using the Number

   Once a number is set for reasonable suspicion and probable cause, the next
step is to decide whether the results from the predictive algorithms will be
determinative of the outcome or whether they will merely be one of a number of
factors used by officers and judges. As an example, take Professor Andrew
Ferguson's modern-day recreation of Detective McFadden observing John Terry on
the streets of Cleveland:


     [McFadden] observes John Terry and, using facial recognition
     technology, identifies him and begins to investigate using big data.
     Detective McFadden learns through a database search that Terry has a
     prior criminal record, including a couple of convictions and a number
     of arrests. McFadden learns, through pattern-matching links, that
     Terry is an associate (a "hanger on") of a notorious, violent local
     gangster--Billy Cox--who had been charged with several murders.
     McFadden also learns that Terry has a substance abuse problem and is
     addicted to drugs.  n265

   Now let us take the next step and assume that the detective plugs all of John
Terry's background information into a predictive algorithm, which tells him that
John Terry has a 1% chance of being involved in criminal activity at any given
time during the day. This result would certainly not be sufficient to create
reasonable suspicion. Then our modern Detective McFadden could do some more
quick research through the police database and add in some other factors; for
example, that Terry has multiple prior convictions for armed robbery of
commercial establishments, and license plate  [*1010]  data connects Terry to
prior commercial robberies in this area.  n266 This, combined with the earlier
information about Terry, tells the detective that Terry has a 5% chance of being
armed with an illegal weapon at any given time. We still do not have anything
like reasonable suspicion. Indeed, it is unlikely that mere background
information on a suspect could ever rise to the level of reasonable
suspicion--this is akin to saying there are certain people who are so suspicious
that there is always reasonable grounds to believe they are engaging in criminal
activity anytime they are seen in public.  n267

   Regardless of how high the prediction is based on the background information
alone, Detective McFadden cannot legally have reasonable suspicion at this point
because he has not yet considered any individualized conduct on the part of
Terry. So Detective McFadden must incorporate Terry's individualized conduct
into the calculus. As it turns out, the detective sees Terry pacing back and
forth outside a commercial establishment multiple times, looking in the window,
and then conferring with another individual.  n268 However, the modern-day
Detective McFadden has two options. He can take the 5% chance that Terry is
carrying an illegal weapon and then incorporate that into his own subjective
calculation, combining that factor with his own observations of Terry pacing,
looking, and conferring.  n269 Or he can simply input these observations into
the algorithm, which would then automatically combine these observations along
with other data in order to give a percentage chance that the suspect was in
fact involved in criminal activity. The first is an example of using the
predictive algorithm as a factor; the second is an example of the "outcome
determinative" model.

    [*1011]  From this basic example, we can see that the "outcome
determinative" option has a number of advantages. First, it will be simpler for
officers and judges to apply, since it will not require individual officers and
judges to process numerical probabilities; the algorithm will literally do all
the processing itself and give the decision-maker an exact number. The
predictive algorithm will (presumably) use statistics from thousands of previous
cases in order to establish whether the relevant facts create the level of
suspicion necessary to reach reasonable suspicion or probable cause. These
results (and thus the algorithm itself) can be periodically tested every few
months to ensure they are still reliable--and as part of that testing, the
algorithm can be adjusted to give different weights to different types of data
or even to add or remove certain types of data altogether. Second, the outcome
determinative model will minimize the potentially biased factors that human
decision-makers apply in making these determinations. Both reasonable suspicion
and probable cause require the officer to show specific, objective facts to
support their conclusion,  n270 and forcing police officers to input these
specific facts into the algorithm will make it harder for them to consciously or
subconsciously use factors based on race.

   The purely determinative model could even work in cases where the police
officers and judges need to evaluate an informant's reliability to make a
probable cause determination. For example, assume that a reliable algorithm is
created to predict the chance that drugs will be found at a certain location. It
requires five different variables in order to produce a result, and three of
these data points are particularized with respect to the suspect's observed
behavior. None of these data points are related, either directly or indirectly,
to race, religion, or any other protected class. Assume that a police officer
has personal knowledge of all of these factors and inputs them into the
software, which predicts a 75% chance that drugs will be found at the location.
Given these facts, a court will almost certainly find that probable cause exists
and a search warrant should be issued.

   How would the model work if the police officer does not have any personal
knowledge about the case, and instead her affidavit quotes an informant who
provides the information about all five  [*1012]  variables? Once again, all
five variables are entered into the software, and the algorithm predicts a 75%
chance that drugs will be found at the location, assuming that the information
is correct. How can the algorithm (and thus the judge) take into account the
inevitable reliability questions that accompany the use of informants? In order
to preserve the purely determinative model, the software must be designed so
that the credibility of the informant can be taken into account as part of the
algorithm. In many cases, this would be feasible. Generally, search warrant
applications only have a few different categories of informants: known
informants who have provided accurate information in the past, known informants
who have never provided information before, anonymous informants, etc. Thus,
these specific categories could be inputs into the software, so that after each
relevant factor is entered, the algorithm would ask about the source of the
fact--did it come from personal observation by the affiant police officer or
from an informant; and if from an informant, how much is known about the
informant and his prior track record?  n271 These categories would be at least
as specific as the descriptions currently used by police officers in search
warrant affidavits.

   Any outcome determinative model in this context will require a far more
sophisticated algorithm, with many more potential inputs for the different
behaviors that might be observed. And in designing these algorithms, the
programmers will need to stay away from the vague factors that currently cause
so much unreliability and are open to abuse, such as "furtive movements" or
"acting suspiciously."  n272 Other inputs, such as "suspicious bulge" or
"nervous behavior," which could conceivably refer to specific facts that
indicate the presence of criminal activity, may need to be defined with more
specific language. And the inputs need to include potentially exculpatory
information as well, in order to ensure that the algorithm complies with the
"totality of the circumstances" requirement of the probable cause determination.
n273

   Given these practical problems, it is unlikely that any predictive algorithm
could ever be designed that contains every possible type of specific behavior
that a police officer might use in making a reasonable suspicion or probable
cause determination. Some predictive algorithms could be designed in certain
basic, often-repeated  [*1013]  scenarios (observations made of individuals
exiting buildings where drugs are being sold, observations made during routine
traffic stops, etc.),  n274 but the potential range of observed activity is
simply too broad to conceive of a world in which every possible relevant factor
is accounted for in the computer programming. And in some cases the police
officer or judge may have her own opinion about the reliability of an informant
that is not accurately captured by the five or six traditional categories that
are part of the algorithm's inputs. Furthermore, it may be politically
unacceptable to take human beings completely out of the loop, since this would
require police officers and judges to ignore information (whether inculpatory or
exculpatory) that is highly probative to the reasonable suspicion/probable cause
determination.

   Thus, there will be some situations in which the predictive algorithm is
merely one of the factors that the judge considers. In these cases, the judge
will need to incorporate the conclusions of the predictive algorithm alongside
other factors. We will call these "independent" factors to indicate that they
are above and beyond the factors used by the algorithm. For example, assume that
the algorithm uses five different inputs and predicts a 25% likelihood that
drugs will be found at a given location. The judge also knows about three
independent factors that on their own do not quite rise to the level of probable
cause. The judge will be provided with the 25% prediction by the software. If
the predictive algorithm is meant to be one of the many factors that she
considers, she would then need to combine the 25% from the algorithm and the
unquantified "almost-but-not-quite" factors from her own judgment. How does she
balance the specific number from the algorithm with her own intuitive
conclusion? Does she have to quantify her "almost-but-not-quite" conclusion?
Assume she can do this (and presumably judges would get better at this task with
practice), and she quantifies her subjective conclusion at a 30% likelihood. How
much weight does she give to her 30% compared to the 25% from the algorithm?

   In order to accurately combine the results from the predictive algorithm with
other factors, we need to take two steps. First, in order to avoid double
counting, we need to separate the factors that have already been considered by
the algorithm from the factors that have not.  n275 The transparency that we
already require from these algorithms should make this task easier; the
decision-maker will be  [*1014]  able to review the factors that have already
been considered by the algorithm and then remove those from her own independent
analysis.

   Second, the decision-maker must use the predictive algorithm as the starting
point and then adjust the percentage chance up or down as she adds in the
independent factors. One method of doing this is to apply Bayes' theorem, which
is a process of combining known probabilities with new evidence in order to
create a new, updated probability.  n276 The predictive algorithm would provide
the decision-maker with a base rate or prior probability that criminal activity
is present, and then the decision-maker would apply the probability of criminal
activity based on the relevant evidence that was not considered by the
predictive algorithm (known as the "current probability").  n277 This extra
evidence could include personal observations on the part of the police officer
(assuming those observations were not taken into account by the algorithm
already) or extra information about the reliability of the informant that was
not accounted for by the algorithm.

   As an example, let's return to the modern-day version of Detective McFadden
and John Terry.  n278 We know from our algorithm (based only on background
information about John Terry) that there is a 5% chance that Terry is carrying
an illegal weapon at  [*1015]  any given time. Detective McFadden then observes
him pacing, looking, and conferring and realizes this is exactly the kind of
behavior that he would expect a potential robber to engage in before committing
the crime.  n279 Thus, Detective McFadden estimates that a person who is
planning a robbery is 90% likely to engage in the kind of behavior that Terry is
currently engaging in. And although the detective realizes that there are some
innocent explanations for this kind of behavior (perhaps Terry is window
shopping and then conferring with his friend about what to buy), the fact that
Terry has repeated this behavior multiple times means that the odds of him not
planning a robbery are only about 10%. Given these estimates, the detective can
complete a Bayesian calculation (or, more likely, input these estimates into a
simple calculator that will then conduct the Bayesian calculation) and determine
that the chances that Terry is engaged in criminal activity are 32.1%.  n280
Assuming that courts set the standard for reasonable suspicion at around 20% to
25%, this would be sufficient to establish reasonable suspicion.

   In contrast, assume that our modern Detective McFadden, like the real-life
Detective McFadden, did not have any information about John Terry's background.
Instead, he merely observed Terry's suspicious behavior. Under Bayes' theorem,
our base rate would be much lower. Perhaps we recognize that this is a high
crime neighborhood, so we know that 1% of the population is carrying an illegal
weapon at any given time. If Detective McFadden makes the same observations as
before and he calculates the same odds of criminal activity based on those
observations, the chances that Terry is engaged in criminal activity drops to
only 8.3%.  n281 In other words, the lower base rate from the lack of big data
makes the detective's prediction of criminal activity much less accurate.

   Thus, even if predictive algorithms are not outcome determinative, using a
more statistical approach to determine reasonable suspicion or probable cause
will allow police officers and judges to incorporate more reliable base rates
into their calculations. Predictive algorithms will also help these
decision-makers avoid a  [*1016]  common problem when making predictions:
ignoring or undervaluing the base rate. As can be seen from our above example, a
very low base rate or prior probability for potential criminal activity means
that even very suspicious independent factors might not result in a very high
resulting probability. Studies have shown that individuals who make predictions
frequently undervalue or even ignore base rates and give too much weight to the
independent factors that they are presented with.  n282 Forcing police officers
and judges to incorporate the base rate in making their calculations would be
another benefit of using a quantified system of criminal procedure.

   Of course, the more we allow the decision-makers to use independent factors,
the more we lose the benefits of predictive algorithms, such as the increased
accuracy and the mitigation of subjective and potentially biased human input.
For example, when Detective McFadden enters in his own probability estimates
into the Bayesian calculation, he may underestimate the chance that Terry has an
innocent explanation for his conduct because Terry is African-American, and the
detective has an irrational implicit bias against African-Americans. This would
result in a higher prediction of criminal activity for Terry than it would for a
white person with the same background engaging in the same activity. Thus, we
should design our algorithms to avoid the need for independent factors as much
as possible, since the biases in the algorithms can be detected and minimized.

   CONCLUSION

   Big data's predictive algorithms have the potential to revolutionize the way
police investigate crime and the way the courts regulate the police. For
centuries, courts have been crafting legal standards for police officers who
were making clinical judgments based on experience and intuition. The
imprecision and subjectivity of these legal standards were a necessary
evil--they were required given the subjective factors that were used by the
police, but their accuracy could not be tested, they made the system less
transparent, and they opened the door to vastly inconsistent and frequently
discriminatory results. With the rise of big data's predictive algorithms, we
have an opportunity to increase the accuracy and the transparency of the way we
apply the standards and of the standards  [*1017]  themselves, making the system
more efficient, more fair, and more open.

   In order to reap these benefits, we need to ensure that the predictive
algorithms are race neutral and that they take into account individual
suspicion. This may require new types of algorithms that are specifically
designed for determining reasonable suspicion and probable cause. It will
certainly require that the algorithms be transparent, so that reviewing courts
can understand what factors the algorithm is using. More controversially, we
need to update the definition of reasonable suspicion and probable cause to
include quantifiable standards. Although courts have shown a strong aversion
quantifying standards in the past, the benefits to such a change far outweigh
the costs. We have seen that some courts, recognizing this fact, have already
started to experiment with using quantified standards when evaluating some of
the factors put forward by law enforcement officers or when evaluating the tools
that these officers use in determining probable cause.

   To be sure, a system of mechanical predictive algorithms and quantified legal
standards will not be perfect. It will probably be impossible to scrub all
residue of racial discrimination from the existing databases, and police
officers and judges will almost certainly make mistakes when trying to use the
predictive algorithms as base rates and then adding their own independent
observations. And the predictive algorithms themselves will still make mistakes,
and thus will not always be as accurate as we would like. But the current system
includes the implicit and sometimes explicit biases of police officers and
judges; vague standards that can be manipulated by police officers, which are
more or less incomprehensible to lay people; and accuracy rates (when they can
be measured) that vary wildly from jurisdiction to jurisdiction. The time has
come for courts to embrace the enhanced precision and transparency that big data
has to offer.

FOOTNOTES:





n1  See BERNARD E. HARCOURT, AGAINST PREDICTION: PROFILING, POLICING, AND
PUNISHING IN AN ACTUARIAL AGE 17-18 (2007) ("The truth is, most criminal justice
determinations rest on probabilistic reasoning. The jury's verdict at trial, for
instance, is nothing more than a probabilistic determination of prior fact. So
is a police officer's determination whether there is sufficient cause to search
or arrest a suspect; a judge's decision whether a suspect was coerced to
confess; or even a forensic laboratory's conclusion regarding a DNA match--or
DNA exoneration."). Professor Harcourt goes on to draw a sharp distinction
between the necessary probabilistic decisions that are inherent in the criminal
justice system and what he calls the "actuarial" determinations that are derived
from "statistical correlations between group traits and group criminal offending
rates," which should be avoided if at all possible. Id. at 18.





n2  There were certainly scattered examples of statistical prediction
instruments before the big data era. Statistical prediction methods were
developed as early as 1935 to determine the likelihood of a prisoner's success
if paroled; by the late twentieth century similar statistical prediction
instruments were being used by dozens of states. Id. at 1, 7-9. Likewise, in the
1970s and 1980s federal Drug Enforcement Administration officers used "drug
courier profiles" to determine which passengers at airports to investigate. Id.
at 15-16. But the rise of big data, with its vast amounts of information and
vastly powerful methods of processing that data, brings the promise (or the
threat) of a true revolution in the sophistication and the proliferation of
these tools.





n3  Terry v. Ohio, 392 U.S. 1, 30 (1968).





n4  Carroll v. United States, 267 U.S. 132, 161 (1925). Occasionally specific,
recurring fact patterns lead to more specific applications of these rules: For
example, police officers know that if they observe a suspect fleeing from them
while in a high crime neighborhood, those two factors result in reasonable
suspicion that the suspect has committed a crime. Illinois v. Wardlow, 528 U.S.
119, 124-25 (2000).





n5  The Supreme Court has explained that "probable cause is a fluid
concept--turning on the assessment of probabilities in particular factual
contexts--not readily, or even usefully, reduced to a neat set of legal rules."
Illinois v. Gates, 462 U.S. 213, 232 (1983).





n6  For example, a magistrate might reasonably conclude that a defendant who
does not have a steady job seems less likely to come back to court on her own;
furthermore, last month the magistrate remembers releasing a defendant who did
not have a steady job and sure enough, she did not appear for her court date.





n7  See infra Part I.





n8  See Andrew Guthrie Ferguson, Predictive Policing and Reasonable Suspicion,
62 EMORY L.J. 259, 319-20 (2012). Unfortunately, as these algorithms become more
accurate, they also become more complicated, and the databases they use become
even larger and more detailed, making them less comprehensible to the average
police officer or judge. We will consider this problem in more detail in Section
III.A.





n9  See infra Part I.





n10  See infra Part II.





n11  See infra Part III.





n12  See Andrew Guthrie Ferguson, Big Data and Predictive Reasonable Suspicion,
163 U. PA. L. REV. 327, 352-53 (2015).





n13  See William M. Grove et al., Clinical Versus Mechanical Prediction: A
Meta-Analysis, 12 PSYCHOL. ASSESSMENT 19, 19 (2000).





n14  A famous Forbes story reported that Target had used big data from seemingly
random purchasing to determine that a minor customer was pregnant and then sent
the customer coupons for pregnancy and new baby items before the teenager had
notified her parents that she was pregnant. See Kashmir Hill, How Target Figured
Out a Teen Girl Was Pregnant Before Her Father Did, FORBES (Feb. 16, 2012, 11:02
AM),
http://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen
-girl-was-pregnant-before-her-father-did/#3363735834c6
[https://perma.cc/BA2Q-8HK4].





n15  See Brian Fung, The Big Data of Bad Driving, and How Insurers Plan to Track
Your Every Turn, WASH. POST (Jan. 4, 2016), https://www.washingtonpost.
com/news/the-switch/wp/2016/01/04/the-big-data-of-bad-driving-and-how-insurers-p
lan-to-track-your-every-turn/ [https://perma.cc/999Q-K9TZ].





n16  See EVA WOLKOWITZ & SARAH PARKER, BIG DATA, BIG POTENTIAL: HARNESSING DATA
TECHNOLOGY FOR THE UNDERSERVED MARKET 11 (2015),
http://www.morganstanley.com/sustainableinvesting/pdf/Big_Data_Big_Potential.pdf
[https://perma.cc/DY42-K2Q7].





n17  See Meta S. Brown, When and Where to Buy Consumer Data (and 12 Companies
Who Sell It), FORBES (Sept. 30, 2015, 9:49 AM),
http://www.forbes.com/sites/metabrown/2015/09/30/when-and-where-to-buy-consumer-
data-and-12-companies-who-sell-it/#c8b7ed1711bc [https://perma.cc/NJN9-57LE].





n18  Recently, there have been signs that the Fourth Amendment may be expanded
so that the gathering or processing of massive amounts of public data may be
considered a search. Although government surveillance of public places, or of
publicly available sources, does not implicate the Fourth Amendment, see, e.g.,
United States v. Knotts, 460 U.S. 276, 281-82 (1983), the Supreme Court has
hinted at the possibility that gathering and processing large amounts of
information from public sources to learn information about a suspect could
implicate the Fourth Amendment through the "mosaic" theory, United States v.
Jones, 132 S. Ct. 945, 954-55 (2012) (Sotomayor, J., concurring), but that
doctrine has not yet gained widespread acceptance in courts. For an overview and
a critique of the mosaic theory, see Orin S. Kerr, The Mosaic Theory of the
Fourth Amendment, 111 MICH. L. REV. 311 (2012).





n19  Grove et al., supra note 13, at 19.





n20  See infra notes 22-27, 69-71 and accompanying text.





n21  There is likely to be enormous resistance to adopting a system that is
outcome determinative in any of these contexts, though I will argue that such an
option is preferable in certain contexts. See infra Section III.B.





n22  For an excellent overview of the use of predictive algorithms by police
officers, see Andrew Guthrie Ferguson, Policing Predictive Policing, 94 WASH U.
L. REV. (forthcoming 2017).





n23  See Sewell Chan, Why Did Crime Fall in New York City?, N.Y. TIMES CITY ROOM
(Aug. 13, 2007, 2:10 PM),
http://cityroom.blogs.nytimes.com/2007/08/13/why-did-crime-fall-in-new-york-city
/?_r=2 [https://perma.cc/2HS9-E27E].





n24  In addition to New York, sophisticated crime-mapping software has been used
in Los Angeles, St. Louis, Philadelphia, San Francisco, Washington, D.C.,
Oakland, and many other cities. See Stuart Wolpert, Predictive Policing
Substantially Reduces Crime in Los Angeles During Months-Long Test, UCLA
NEWSROOM (Oct. 7, 2015), http://newsroom.ucla.edu/releases/predictive-policing
-substantially-reduces-crime-in-los-angeles-during-months-long-test
[https://perma.cc/3PTX-JXK6]; Maurice Chammah, Policing the Future, VERGE (Feb.
3, 2016), http://www.theverge.com/2016/2/3/10895804/st-louis-police-hunchlab-
predictive-policing-marshall-project [https://perma.cc/X7UZ-Y4XP]; Darwin
Bond-Graham & Ali Winston, All Tomorrow's Crimes: The Future of Policing Looks a
Lot Like Good Branding, SF WEEKLY (Oct. 30, 2013),
http://www.sfweekly.com/sanfrancisco/all-tomorrows-crimes-the-future-of-policing
-looks-a-lot-like-good-branding/Content? oid=2827968
[https://perma.cc/2ARE-MFS2]; Eugene K. Chow, Is Predictive Policing Making
Minority Report a Reality?, WEEK (Oct. 7, 2013),
http://theweek.com/articles/459396/predictive-policing
-making-minority-report-reality [https://perma.cc/3X7W-R3VG]; Darwin
Bond-Graham, Oakland Mayor Schaaf and Police Seek Unproven 'Predictive Policing'
Software, E. BAY EXPRESS (June 24, 2015),
http://www.eastbayexpress.com/oakland/oakland-mayor-schaaf-and-police-seek-unpro
ven-predictive-policing-software/Content?oid=4362343
[https://perma.cc/99HG-MYPA].





n25  See Chammah, supra note 24.





n26  Id.; see Cameron Albert-Deitch, Predictive Policing Crime Prevention
Software Successful for APD, ATLANTA MAGAZINE (Nov. 10, 2014), http://www.
atlantamagazine.com/news-culture-articles/predictive-policing
-crime-prevention-software-successful-for-apd/ [https://perma.cc/F8YY-2JRE].
PredPol is now being used by more than fifty different police agencies in the
United States and Britain. See Chammah, supra note 24.





n27  See Chammah, supra note 24. Other jurisdictions have seen similar
improvements in crime rates: Norcross, Georgia, saw a 20% decrease in crime
after adopting PredPol, which led the Atlanta police department to adopt it as
well. See Albert-Deitch, supra note 26.





n28  See Chammah, supra note 24.





n29  Id.





n30  Justin Jouvenal, The New Way Police Are Surveilling You: Calculating Your
Threat 'Score', WASH. POST (Jan. 10, 2016),
https://www.washingtonpost.com/local/public-safety/the-new-way-police-are-survei
lling-you-calculating-your-threat-score/2016/01/10/e42bccac-8e15-11e5-baf4-bdf37
355da0c_story.html [https://perma.cc/B5HT-PNT9].





n31  Id.





n32  Id.





n33  Matt Stroud, The Minority Report: Chicago's New Police Computer Predicts
Crimes, But Is It Racist?, VERGE (Feb. 19, 2014, 9:31 AM),
http://www.theverge.com/2014/2/19/5419854/the-minority-report-this-computer-pred
icts-crime-but-is-it-racist [https://perma.cc/J6VQ-Q64E].





n34  Id.; see also Robert L. Mitchell, Predictive Policing Gets Personal,
COMPUTERWORLD (Oct. 24, 2013, 7:00 AM),
http://www.computerworld.com/article/2486424/government-it/predictive-policing
-gets-personal.html [https://perma.cc/6SR9-4QGW] (describing a similar program
in North Carolina).





n35  Stroud, supra note 33.





n36  Id. Kansas City has been using a similar program, known as KC NoVA, which
targets individuals "at risk" of committing violent crimes. The program warns
these individuals that they are being watched and that "harsh penalties will be
imposed for even petty slights once warnings have been given," but it also
provides services such as housing and social services to help the individuals
stay out of trouble. See John Eligon & Timothy Williams, Police Program Aims to
Pinpoint Those Most Likely to Commit Crimes, N.Y. TIMES (Sept. 24, 2015),
http://www.nytimes.com/2015/09/25/us/police-program-aims-to-pinpoint-those-most-
likely-to-commit-crimes.html?_r=0 [https://perma.cc/7UYW-KFDM].





n37  See HARCOURT, supra note 1, at 10.





n38  Id.





n39  Id. ch. 4.





n40  Id. at 123.





n41  Another example of law enforcement using big data to try to detect criminal
activity is the National Security Agency's massive metadata collection program.
See ACLU v. Clapper, 785 F.3d 787, 792, 816-17 (2d Cir. 2015).





n42  See Ferguson, supra note 12, at 368-69.





n43  See, e.g., Illinois v. Wardlow, 528 U.S. 119, 124 (2000).





n44  See, e.g., State v. Carter, 697 N.W.2d 199, 205 (Minn. 2005).





n45  A recent comprehensive report from the RAND Corporation surveyed every
known use of predictive algorithms in law enforcement and showed no evidence of
such algorithms being used to determine reasonable suspicion or probable cause.
See WALTER L. PERRY ET AL., RAND CORP., PREDICTIVE POLICING: THE ROLE OF CRIME
FORECASTING IN LAW ENFORCEMENT OPERATIONS 107-08 (2013).





n46  For example, in the Wardlow case, the Court merely accepted the testimony
of the officer that the stop occurred in an "area known for heavy narcotics
trafficking." 528 U.S. at 119-23. In fact, the actual crime data from the
Chicago district where the stop occurred showed that the district ranked just at
the median for criminal activity of the twenty-five districts in the city. See
Amici Curiae Brief of the National Ass'n of Police Organizations et al. in
Support of Petitioner at 7, Wardlow, 528 U.S. 119 (No. 98-1036), 1999 WL 451226,
at *7. For an excellent discussion of how crime mapping has been used (or
ignored) by the Supreme Court, see Andrew Guthrie Ferguson, Crime Mapping and
the Fourth Amendment: Redrawing "High-Crime Areas", 63 HASTINGS L.J. 179 (2011).





n47  Ferguson, supra note 46, at 221-22 ("If the officer did not base his
decision on specific data about a specific crime problem in a specific area, or
if the data relied upon did not demonstrate a specific and relevant crime
problem, then reliance on this information should not be considered.").





n48  Id. at 224-25. Professor Ferguson notes that using actual data about
high-crime areas will probably be an improvement: "While not perfect, a more
data-driven approach is an improvement over the police 'war stories' that have
essentially served as the basis of prior designations of high-crime areas. In
fact, analysis of crime data has shown that subjective opinions about high-crime
areas are often erroneous." For a discussion of the possible inherent biases in
the data, see infra Subsection II.A.2.





n49  Ferguson, supra note 46, at 223.





n50  In fact, the best numbers to consider would not be based on arrest, but
rather on actual criminal activity. Using arrest numbers as a proxy for criminal
activity may lead to a number of inaccuracies, which I discuss in Section III.B,
infra. For a good discussion on the difficulty of determining whether a
neighborhood is a "high-crime area" in the absence of any evidence from big
data, see United States v. Wright, 485 F.3d 45, 49-50 (1st Cir. 2007).





n51  See, e.g., Wardlow, 528 U.S. at 122 ("[Officer Nolan] immediately conducted
a protective patdown search for weapons because in his experience it was common
for there to be weapons in the near vicinity of narcotics transactions.").





n52  CAROLINE WOLF HARLOW, BUREAU OF JUSTICE STATISTICS, FIREARM USE BY
OFFENDERS 3 (2001). The report also found that 2.9% of those who committed
sexual assault carried a firearm, while 4% of those who committed burglary
carried a firearm. Id. Of course, the Terry standard asks courts to consider the
likelihood that the suspect has a weapon, not merely a firearm, but this only
emphasizes the need to apply more accurate statistics to the analysis.





n53  Wardlow, 528 U.S. at 125; United States v. Dykes, 406 F.3d 717, 720 (D.C.
Cir. 2005) (suspect was stopped in an area "known for the sales of cocaine and
marijuana" and he fled upon seeing the officers exit their cars).





n54  Tracey L. Meares & Bernard E. Harcourt, Foreword: Transparent Adjudication
and Social Science Research in Constitutional Criminal Procedure, 90 J. CRIM. L.
& CRIMINOLOGY 733, 792 (2000).





n55  United States v. Sokolow, 490 U.S. 1, 13-14 (1989) (Marshall, J.,
dissenting). Illegal immigration profiles came under a similar attack in a
dissent in United States v. Zapata-Ibarra, 223 F.3d 281, 281-82 (5th Cir. 2000)
(Wiener, J., dissenting).





n56  Samuel R. Gross & Katherine Y. Barnes, Road Work: Racial Profiling and Drug
Interdiction on the Highway, 101 MICH. L. REV. 651, 740 (2002); see also Charles
L. Becton, The Drug Courier Profile: "All Seems Infected That Th' Infected Spy,
As All Looks Yellow to the Jaundic'd Eye", 65 N.C. L. REV. 417 (1987); United
States v. Broomfield, 417 F.3d 654, 655 (7th Cir. 2005) ("Whether you stand
still or move, drive above, below, or at the speed limit, you will be described
by the police as acting suspiciously should they wish to stop or arrest you.
Such subjective, promiscuous appeals to an ineffable intuition should not be
credited."); Utah v. Strieff, 136 S. Ct. 2056, 2069 (2016) (Sotomayor, J.,
dissenting) ("[An officer's] justification must provide specific reasons why the
officer suspected you were breaking the law, but it may factor in your
ethnicity, where you live, what you were wearing, and how you behaved. The
officer does not even need to know which law you might have broken so long as he
can later point to any possible infraction--even one that is minor, unrelated,
or ambiguous." (citations omitted)).





n57  959 F. Supp. 2d 540 (S.D.N.Y. 2013).





n58  Id. at 559-60. In the data from New York City reviewed by the court,
"furtive movements" was cited as a factor 42% of the time; "high crime area" 55%
of the time, and "suspicious bulge" 10% of the time. Id. at 559. Sometimes the
only factors cited by the officer were two of these three factors. Id.





n59  Id. at 561. The officers in New York are hardly unique in their use of
vague factors. In Philadelphia, police were engaging in overly aggressive Terry
stops using factors such as "loitering" or "acting suspiciously"; after the
police were sued over their tactics, they agreed in a consent decree to stop
using these factors. See Plaintiffs' Fifth Report to Court and Monitor on Stop
and Frisk Practices at 2-4, Bailey v. City of Philadelphia (E.D. Pa. 2013) (No.
10-5952).





n60  Floyd, 959 F. Supp. 2d at 559.





n61  In the Sokolow case itself, the Ninth Circuit held that there was no
reasonable suspicion because the factors used by the agents were "vague and
inchoate," "hazy in form, susceptible to great adaptations, and almost entirely
speculative," and that "[t]he obvious lack of substantiation [of the
government's conclusion] betrays its lack of merit." United States v. Sokolow,
831 F.2d 1413, 1423-24 (9th Cir. 1987). But seven Supreme Court Justices looked
at the same factors and concluded that probable cause did exist. United States
v. Sokolow, 490 U.S. 1, 9 (1989).





n62  Floyd, 959 F. Supp. 2d at 558.





n63  Id.





n64  See infra notes 241-250 and accompanying text for some estimates of where
courts might set this number if predictive algorithms force them to do so.





n65  For example, in 36% of the cases the police did not identify any suspected
crimes and approximately half the forms used "Furtive Movements" and "High Crime
Area" as factors, which the judge determined were "vague and subjective terms"
that cannot on their own "reliably demonstrate individualized reasonable
suspicion." Floyd, 959 F. Supp. 2d at 559-60.





n66  See Plaintiffs' Fifth Report, supra note 59, at 3-4. The police conceded
that the rate of stops without documented reasonable suspicion was around 35%,
but argued that this high number was due to "incomplete paperwork, improper
narratives used by police officers, and an overall lack of credibility in the
electronic data base." Id. at 4.





n67  See infra notes 265-282 and accompanying text.





n68  In particular, the empirical scholarship on this issue has grown to focus
on big data techniques such as machine learning or massive statistical analyses.
See, e.g., Richard A. Berk, Susan B. Sorenson & Geoffrey Barnes, Forecasting
Domestic Violence: A Machine Learning Approach to Help Inform Arraignment
Decisions, 13 J. EMPIRICAL LEGAL STUD. 94 (2016); Richard Berk & Jordan Hyatt,
Machine Learning Forecasts of Risk to Inform Sentencing Decisions, 27 FED.
SENT'G REP. 222 (2015); Richard A. Berk & Justin Bleich, Statistical Procedures
for Forecasting Criminal Behavior: A Comparative Assessment, 12 CRIMINOLOGY &
PUB. POL'Y 513 (2013).





n69  Shaila Dewan, Judges Replacing Conjecture with Formula for Bail, N.Y. TIMES
(June 26, 2015),
http://www.nytimes.com/2015/06/27/us/turning-the-granting-of-bail-into-a-science
.html?_r=0 [https://perma.cc/P8NE-LDUL].





n70  Id.





n71  Id.





n72  Christopher Slobogin, Risk Assessment, in THE OXFORD HANDBOOK OF SENTENCING
AND CORRECTIONS 196, 203-05 (Joan Petersilia & Kevin R. Reitz eds., 2012).





n73  Id. at 200.





n74  Id. at 204.





n75  Id. The risk assessment tool looks at type of offense, gender, age,
employment status, and four aspects of the defendant's criminal record. Id.





n76  Id. For example, in Virginia, 59% of defendants who were considered to be a
low risk by the algorithm were still sentenced to a prison term by the judge.
Id.





n77  See HARCOURT, supra note 1, at 48-51.





n78  Id. at 48.





n79  Id. at 78.





n80  Id. at 80-81.





n81  Id. at 82.





n82  Id. at 20-21.





n83  Id.; see Dewan, supra note 69.





n84  HARCOURT, supra note 1, at 82; see Dewan, supra note 69.





n85  Henry J. Steadman, Implications from the Baxstrom Experience, 1 J. AM.
ACAD. PSYCHIATRY L. 189, 190, 193 (1973). Studies of nearly 1,000 inmates at a
mental hospital for the criminally insane showed that over 97% of the
inmate--patients did not return after being released; even among those with the
highest risk factors (violent criminal history, juvenile record, numerous prior
conviction), less than 10% returned. Id.





n86  Barbara D. Underwood, Law and the Crystal Ball: Predicting Behavior with
Statistical Inference and Individualized Judgment, 88 YALE L.J. 1408, 1413
(1979). Professor Underwood gives an example that "past states of mind are
notoriously difficult to determine, and it is relatively easy to determine the
amount of interest that will be paid by a bank on a deposit." Id. at 1413 n.10.





n87  Bennett Capers, Policing, Technology, and Doctrinal Assists, FLA. L. REV.
(forthcoming 2016) (manuscript at 33-38),
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2760388
[https://perma.cc/NV47-URGD]; see also infra note 140-141 and accompanying text.





n88  Some scholars argue that many of the risk prediction factors currently in
use in sentencing decisions may be unconstitutional because they rely directly
or indirectly on race or other suspect classes. See, e.g., Sonja B. Starr,
Evidence-Based Sentencing and the Scientific Rationalization of Discrimination,
66 STAN. L. REV. 803, 819 (2014). But see Christopher Slobogin, Risk Assessment
and Risk Management in Juvenile Justice, 27 CRIM. JUST. 10, 13-15 (2013) (use of
gender and age in sentencing decisions is permissible because it survives
intermediate scrutiny); J.C. Oleson, Risk in Sentencing: Constitutionally
Suspect Variables and Evidence-Based Sentencing, 64 SMU L. REV. 1329, 1385-88
(2001) (sentencing factors survive a strict scrutiny analysis).





n89  See, e.g., Sarah Ludwig, Credit Scores in America Perpetuate Racial
Injustice. Here's How, GUARDIAN (Oct. 13, 2015, 10:14 AM),
https://www.theguardian.com/commentisfree/2015/oct/13/your-credit-score-is-racis
t-heres-why [https://perma.cc/4P6B-WM55]; 15 U.S.C. § 1691 (2012).





n90  See Lee Price, Racial Discrimination Continues to Play a Part in Hiring
Decisions, ECON. POL'Y INST. (Sept. 17, 2003),
http://www.epi.org/publication/webfeatures_snapshots_archive_09172003/
[https://perma.cc/465W-KRGM]; 42 U.S.C. § 2000e-2 (2012).





n91  See, e.g., United States v. Brignoni-Ponce, 422 U.S. 873, 886-87 (1975)
("[Mexican ancestry] alone . . . does not justify stopping all Mexican-Americans
to ask if they are aliens.").





n92  Id. ("The likelihood that any given person of Mexican ancestry is an alien
is high enough to make Mexican appearance a relevant factor . . . ."); see also
United States v. Martinez-Fuerte, 428 U.S. 543, 562-63 (1976).





n93  United States v. Montero-Camargo, 208 F.3d 1122, 1135 (9th Cir. 2000).





n94  See, e.g., State v. Kuhn, 517 A.2d 162, 165 (N.J. Super. Ct. App. Div.
1986) ("No rational inference may be drawn from the race of [a person] that he
may be engaged in criminal activities.").





n95  It is harder to come up with an example in the bail context where the
defendant's race was actually a relevant factor in determining flight risk or
danger to the community. Certain factors that are correlated to race (such as
income level or employment status) may be relevant, however.





n96  As we will see, one of the objections to using mechanical predictions is
that the underlying data may be tainted by preexisting biases in the criminal
justice system that overstate the criminal activity of certain ethnic
minorities. See infra Subsection II.A.2.





n97  See, e.g., Whren v. United States, 517 U.S. 806, 813 (1996) ("[T]he
constitutional basis for objecting to intentionally discriminatory application
of laws is the Equal Protection Clause, not the Fourth Amendment."). But see
Gross & Barnes, supra note 56, at 733-38 (surveying lower court decisions and
concluding that "American judges are ambivalent and divided about the use of
race as a basis for individualized suspicion under the Fourth Amendment. Lower
court cases go both ways, but increasingly the tone is negative").





n98  Adarand Constructors, Inc. v. Pena, 515 U.S. 200, 235 (1995).





n99  See, e.g., Lowery v. Commonwealth, 388 S.E.2d 265, 267 (Va. Ct. App. 1990).





n100  See, e.g., United States v. Taylor, 956 F.2d 572, 578-79 (6th Cir. 1992)
(en banc); see also Tracey Maclin, Race and the Fourth Amendment, 51 VAND. L.
REV. 333 (1998) (discussing the legality of racial profiling).





n101  See Gross & Barnes, supra note 56, at 743 (citing settlement agreements
with the Maryland State Police and various other Department of Justice racial
profiling consent decrees).





n102  481 U.S. 279, 291-92 (1987).





n103  Id. at 293-99 & n.11.





n104  Id.





n105  Id. at 292-93.





n106  Id. at 297.





n107  Id. at 298 (quoting Pers. Adm'r of Mass. v. Feeney, 442 U.S. 256, 279
(1979)).





n108  Batson v. Kentucky, 476 U.S. 79, 97-98 (1986).





n109  Id. at 97.





n110  See, e.g., Conor Friedersdorf, The NYPD Officers Who See Racial Bias in
the NYPD, ATLANTIC (Jan. 7, 2015),
http://www.theatlantic.com/national/archive/2015/01/the-nypd-officers-who-see-ra
cial-bias-in-the-nypd/384106/ [https://perma.cc/3VS2-2X6F].





n111  The term "redlining" came from "residential security maps" that were used
by the Federal Home Loan Bank Board ("FHLBB") in the 1930s to describe the
quality of real estate investments in different parts of the city. Certain
areas, known as "Type D" neighborhoods, were outlined in red on the map to
indicate the riskiest areas for mortgages. See BRUCE SCHNEIER, DATA AND GOLIATH:
THE HIDDEN BATTLES TO COLLECT YOUR DATA AND CONTROL YOUR WORLD 109 (2015).





n112  See id.





n113  See supra Section I.A.





n114  The problem of indirect discrimination is related to a more sinister
problem--that of intentional "masking." Masking occurs when a decision-maker
truly wishes to discriminate, but knows that doing so explicitly is forbidden.
The decision-maker then intentionally chooses factors that are close statistical
proxies for race and then uses them as factors. See, e.g., Solon Barocas &
Andrew D. Selbst, Big Data's Disparate Impact, 104 CAL. L. REV. 671, 692-93
(2016). Masking can occur when a decision-maker uses traditional clinical
judgments as well when she uses mechanical predictions, but could be easier to
achieve with big data methods. Id.





n115  See, e.g., Stroud, supra note 33; Julia Angwin et al., Machine Bias,
PROPUBLICA (May 23, 2016),
https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sen
tencing [https://perma.cc/W6K7-XKME].





n116  See, e.g., Illinois v. Wardlow, 528 U.S. 119, 124 (2000).





n117  See ELIZABETH KNEEBONE & STEVEN RAPHAEL, METRO. POLICY PROGRAM AT
BROOKINGS, CITY AND SUBURBAN CRIME TRENDS IN METROPOLITAN AMERICA 2-3 (May
2011), https://gspp.berkeley.edu/assets/uploads/research/pdf/p66.pdf
[https://perma.cc/EW7Z-UDMT].





n118  Proxies for race are also used at other stages of the criminal justice
system. At bail hearings, for example, magistrates will routinely consider the
prior criminal history of the defendant in deciding whether the defendant is a
flight risk or a danger to others. See DAVID N. ADAIR, JR., FED. JUDICIAL CTR.,
THE BAIL REFORM ACT OF 1984, at 6 (3d ed. 2006),
http://www.fjc.gov/public/pdf.nsf/lookup/bailact3. pdf/$ file/bailact3.pdf
[https://perma.cc/N3TL-79JA]. Criminal history is linked to race because certain
ethnic groups have higher rates of conviction than others. See George Gao, Chart
of the Week: The Black-White Gap in Incarceration Rates, PEW RES. CTR. (July 18,
2014),
http://www.pewresearch.org/fact-tank/2014/07/18/chart-of-the-week-the-black-whit
e-gap-in-incarceration-rates/ [https://perma.cc/E45N-L6XQ]. Other factors that
magistrates use, such as employment or home ownership, are strongly correlated
to poverty, which is correlated to race. ADAIR, supra, at 6.





n119  Of course, these biases permeate the rest of the criminal justice system
as well, as evidenced by the statistics cited in McCleskey v. Kemp, 481 U.S.
227, 293-99 (1987), and other studies showing biases in prosecutorial charging
decisions, jury verdicts, and sentencing. See, e.g., Robert J. Smith & Justin D.
Levinson, The Impact of Implicit Racial Bias on the Exercise of Prosecutorial
Discretion, 35 SEATTLE U. L. REV. 795, 805-22 (2012) (bias in charging
decisions); Robert Barnes, Supreme Court to Hear Case of Alleged Racial Bias by
Juror, WASH. POST (Apr. 4, 2016),
https://www.washingtonpost.com/politics/courts_law/supreme-court-to-hear-case-of
-alleged-racial-bias-by-juror/2016/04/04/c9256e9c-fa92-11e5-9140-e61d062438bb_st
ory.html [https://perma.cc/9Q2M-CW3T] (bias by jurors); Edward Helmore, Racial
Bias Evident in South Carolina Criminal Sentences, Study Reveals, GUARDIAN (Feb.
29, 2016, 12:01 AM),
https://www.theguardian.com/us-news/2016/feb/29/racial-bias-criminal-sentencing-
south-carolina [https://perma.cc/2UFC-BLC2] (bias in sentencing). These biases,
and ways in which to overcome them, are beyond the scope of this Article.





n120  John Cassidy, The Statistical Debate Behind the Stop-and-Frisk Verdict,
NEW YORKER (Aug. 13, 2013),
http://www.newyorker.com/news/john-cassidy/the-statistical-debate-behind-the-sto
p-and-frisk-verdict [https://perma.cc/FT7P-QZTZ].





n121  Floyd v. City of New York, 959 F. Supp. 2d 540, 556, 573-75 (2013).





n122  Id. at 574. This disproportionality cannot be explained by a higher rate
of criminal activity by black citizens, since the "hit rate" for stopping black
citizens was actually lower than that for white citizens--1.0% of the frisks of
black citizens resulted in a weapon and 1.8% resulted in contraband, while 1.4%
of the frisks of whites resulted in a weapon and 2.3% resulted in contraband.
Id.





n123  See Plaintiffs' Third Report to Court and Monitor on Stop and Frisk
Practices, Bailey v. City of Philadelphia (E.D. Pa. 2013) (No. 10-5952).





n124  See IAN AYRES & JONATHAN BOROWSKY, A STUDY OF RACIALLY DISPARATE OUTCOMES
IN THE LOS ANGELES POLICE DEPARTMENT (Oct. 2008),
https://www.aclusocal.org/wp-content/uploads/2015/09/11837125-LAPD-Racial-Profil
ing-Report-ACLU.pdf [https://perma.cc/P9YV-9H2Y]. The report shows that black
residents are three times as likely to be the subject of a Terry stop as white
residents, but that black residents are less likely to receive a citation after
the stop, demonstrating that "African Americans are more often subject to stops
without justification where no ticket could be issued." ACLU OF S. CAL., RACIAL
PROFILING AND THE LAPD: A SUMMARY OF PROFESSOR IAN AYERS' REPORT ON RACIALLY
DISPARATE OUTCOMES IN THE LOS ANGELES POLICE DEPARTMENT,
https://www.aclusocal.org/wp-content/uploads/2015/09/99227648-Racial-Profiling-t
he-LAPD.pdf [https://perma.cc/FHV5-4EQP].





n125  See ACLU FOUND. OF MASS., BLACK, BROWN AND TARGETED: A REPORT ON BOSTON
POLICE DEPARTMENT STREET ENCOUNTERS FROM 2007-2010 (Oct. 2014),
http://www.bostonherald.com/sites/default/files/media/2014/10/08/black_brown_and
_targeted_online.pdf [https://perma.cc/7VHB-Z5RH].





n126  See John Lamberth, Driving While Black: A Statistician Proves That
Prejudice Still Rules the Road, in RACE, ETHNICITY, AND POLICING: NEW AND
ESSENTIAL READINGS 32, 33 (Stephen K. Rice & Michael D. White eds., 2010).





n127  See, e.g., Jerry Kang, Trojan Horses of Race, 118 HARV. L. REV. 1489,
1491-528 (2005).





n128  See infra Section III.A and accompanying text.





n129  See Barocas & Selbst, supra note 114, at 686.





n130  This is, of course, not really a hypothetical case. Studies have shown,
for example, that black citizens are nearly four times as likely to be arrested
on charges of marijuana possession as white citizens, even though both blacks
and whites use the drug at similar rates. In some states, black citizens were
eight times as likely to be arrested. Ian Urbina, Blacks Are Singled Out for
Marijuana Arrests, Federal Data Suggests, N.Y. TIMES (June 3, 2013),
http://nyti.ms/18KaQO5 [https://perma.cc/K5XQ-VMJ6]. One of the reasons for this
disparity is that "police departments, partly driven by a desire to increase
their drug arrest statistics, can concentrate on minority or poorer
neighborhoods to meet numerical goals." Id.





n131  See, e.g., Suzanne Macartney, Alemayehu Bishaw, and Kayla Fontenot,
POVERTY RATES FOR SELECTED DETAILED RACE AND HISPANIC GROUPS BY STATE AND PLACE:
2007-2011 at 1, American Community Survey Survey Briefs, United States Census
Bureau (February 2013) (showing black and Latino poverty rates at twice those
for white Americans), http://www.census.gov/prod/2013pubs/acsbr11-17.pdf
[https://perma.cc/X3YX-VJ6Y].





n132  Id. at 10-12; see also RAM SUBRAMANIAN ET AL., VERA INST. OF JUSTICE,
INCARCERATION'S FRONT DOOR: THE MISUSE OF JAILS IN AMERICA 15 (Feb. 2015),
http://www.safetyandjusticechallenge.org/wp-content/uploads/2015/01/incarceratio
ns-front-door-report.pdf [https://perma.cc/GRV7-NFRG].





n133  SENTENCING PROJECT, REPORT OF THE SENTENCING PROJECT TO THE UNITED NATIONS
HUMAN RIGHTS COMMITTEE: REGARDING RACIAL DISPARITIES IN THE UNITED STATES
CRIMINAL JUSTICE SYSTEM 10-12 (Aug. 2013),
http://sentencingproject.org/wp-content/uploads/2015/12/Race-and-Justice-Shadow-
Report-ICCPR.pdf [https://perma.cc/NR9M-3ZDJ].





n134  See Jane Bambauer, Hassle, 113 MICH. L. REV. 461, 464-65 (2015) (arguing
that the "hassle rate"--the rate at which individuals are stopped by the
police--is at least as important as the "hit rate"--the rate at which these
encounters uncover criminal activity--because a low hassle rate will ensure that
the police have particularized suspicion when they conduct their stops). We will
discuss the problem of particularized suspicion in Subsection III.B.2, infra.





n135  See generally Wayne A. Logan & Andrew Guthrie Ferguson, Policing Criminal
Justice Data, 101 MINN. L. REV. 541 (2016).





n136  See HARCOURT, supra note 1, at 145-71.





n137  Id. at 112.





n138  See Stroud, supra note 33 (discussing Chicago's "heat list" and noting
that "[f]rom what the CPD is willing to share, most of the collected information
for the heat list is focused on rap sheets--arrest and conviction records. So
rather than collecting information on everyone, they're collecting and using
information on people who have had interactions with the police").





n139  See Bambauer, supra note 134, at 473-74.





n140  See Barocas & Selbst, supra note 114, at 686 ("Data gathered for routine
business purposes tend to lack the rigor of social scientific data
collection.").





n141  See id. at 674.





n142  Id. at 727.





n143  See Data Collection: National Crime Victimization Survey, BUREAU JUST.
STAT., https://www.bjs.gov/index.cfm?ty=dcdetail&iid=245
[https://perma.cc/2DRN-VM9W] (last visited Nov. 19, 2016).





n144  See, e.g., Uniform Crime Reporting, FBI,
https://www.fbi.gov/about-us/cjis/ucr/ucr#cius [https://perma.cc/46T7-XPCE]
(last visited Nov. 19, 2016).






n145  See, e.g., Ybarra v. Illinois, 444 U.S. 85, 91 (1979); Maryland v.
Pringle, 540 U.S. 366, 371 (2003); United States v. Cortez, 449 U.S. 411, 418
(1981). The only exception involves special needs searches, when police officers
are (at least in theory) acting for a purpose other than crime control and are
therefore permitted to conduct reasonable searches on defined groups of people
(such as airline travelers, drivers, or students) in order to further that
purpose. See, e.g., Mich. Dep't of State Police v. Sitz, 496 U.S. 444, 449-50
(1990).





n146  For a detailed discussion of the individualization requirement, see
Bambauer, supra note 134, at 490-94. Bambauer begins with a variation on this
hypothetical, in which the police obtain results of a study that shows that 60%
of all Harvard dorm rooms contain illegal drugs. Id. at 462. This is adopted
from a hypothetical proposed by Professor Orin Kerr. See Orin Kerr, Why Courts
Should Not Quantify Probable Cause, in THE POLITICAL HEART OF CRIMINAL PROCEDURE
135-37 (Michael Klarman, David Skeel & Carol Steiker eds., 2012).





n147  See Arnold H. Loewy, Rethinking Search and Seizure in a Post-9/11 World,
80 MISS. L.J. 1507, 1518 (2011) (arguing that "demographic probabilities" are
insufficient to create probable cause or reasonable suspicion; the police must
also notice something "specific to the defendant to create the probability as to
him").





n148  See, e.g., Underwood, supra note 86, at 1425-29; Michael L. Rich, Machine
Learning, Automated Suspicion Algorithms, and the Fourth Amendment, 164 U. PA.
L. REV. 871, 896-901 (2016). In fact, many of the objections to using
statistical information in the criminal investigation process focus only on the
requirement for individualized suspicion. See Erica Goldberg, Getting Beyond
Intuition in the Probable Cause Inquiry, 17 LEWIS & CLARK L. REV. 789, 806-07
(2013).





n149  See, e.g., HARCOURT, supra note 1, at 173-92.





n150  See Bambauer, supra note 134, at 469. Professor Bambauer examines (and
rejects) four different conceptions of individualized suspicion: the need for
case-by-case assessment, the need to engage in human intuition, the need to
focus on conduct under the control of the suspect, and tracing suspicion from a
crime to a suspect instead of from an individual to a crime. Id. at 469-82. She
then proposes her own definition of individualization, which focuses on the
"hassle rate"--that is, the proportion of the innocent population who were
searched. Id. at 482-94. Using big data algorithms to determine reasonable
suspicion or probable cause is not compatible with all of these definitions--for
example, it downplays or eliminates the use of human intuition and will
frequently start with an analysis of a suspect rather than with a crime. But
these algorithms will be particularly useful if one adopts Professor Bambauer's
concept of hassle rates, since they focus on specific hit rates and miss rates
that can easily be quantified and included in a crime prediction algorithm.





n151  That is, it would be inappropriate to do so outside the context of a
special needs search. See supra note 145.





n152  See Terry v. Ohio, 392 U.S. 1, 30 (1968).





n153  See Ferguson, supra note 12, at 388. Big Data Professor Ferguson further
argues that there needs to be a link between the suspect's suspicious background
information and his current actions: "Courts analyzing big data suspicion should
thus be careful to require a direct link between the past data about a suspect
and the observed suspicion." Id. Otherwise, Professor Ferguson argues that the
background information is irrelevant to the reasonable suspicion analysis. Id.
It is not clear how "direct" the link would have to be; however, many different
types of criminal activity may be linked together in an officer's mind (such as
prior convictions of illegal weapons possession combined with a current
observation indicating possible drug dealing). Id. The linkage could be even
more indirect--and yet statistically significant--when big data is used. For
example, assume that a statistical analysis of thousands of burglars shows that
individuals who have prior convictions for child abuse are 35% more likely to
commit burglary than those without such a conviction. Even though there is no
logical link between the two crimes, this fact could be considered as one factor
(among many others) by an algorithm determining whether probable cause exists to
believe a specific suspect is guilty of burglary.





n154  444 U.S. 85, 87-89 (1979).





n155  Id. at 94; see also United States v. Cortez, 449 U.S. 411, 418 (1981)
("[T]he process . . . must raise a suspicion that the particular individual
being stopped is engaged in wrongdoing.").





n156  See Ferguson, supra note 12, at 387-88.





n157  If the software does not consider individualized suspicion, then police
and judges must use it only as a factor in their analysis. See infra notes
276-282.





n158  See, e.g., Illinois v. Gates, 462 U.S. 213, 232 (1983) (describing
probable cause as a "fluid concept . . . not readily, or even usefully, reduced
to a neat set of legal rules").





n159  See, e.g., United States v. Sokolow, 490 U.S. 1, 7-8 (1989) ("We think the
Court of Appeals' effort to refine and elaborate the requirements of 'reasonable
suspicion' in this case creates unnecessary difficulty in dealing with one of
the relatively simple concepts embodied in the Fourth Amendment. In evaluating
the validity of a stop such as this, we must consider 'the totality of the
circumstances--the whole picture.'" (quoting Cortez, 449 U.S. at 417)); Gates,
462 U.S. at 232 (describing probable cause as a "fluid concept").





n160  Maryland v. Pringle, 540 U.S. 366, 370-71 (2003).





n161  Sokolow, 490 U.S. at 7.





n162  Carroll v. United States, 267 U.S. 132, 161 (1925). In another case, the
Court noted that probable cause "deal[s] with probabilities. These are not
technical; they are the factual and practical considerations of everyday life on
which reasonable and prudent men, not legal technicians, act." Brinegar v.
United States, 338 U.S. 160, 175 (1949).





n163  Sokolow, 490 U.S. at 7.





n164  INS v. Delgado, 466 U.S. 210, 217 (1984).





n165  C.M.A. McCauliff, Burdens of Proof: Degrees of Belief, Quanta of Evidence,
or Constitutional Guarantees?, 35 VAND. L. REV. 1293, 1327 (1982). The vast
majority of the judges were between the 30% and 60% range--16% answered 30%, 27%
answered 40%, 31% answered 50%, and 15% answered 60%--still indicating a wide
range of disagreements. Id.





n166  Id. at 1327-28. Although a few outlying judges (somewhat inexplicably)
answered 0% or 100%, the vast majority of judges were within the 10% to 60%
range: 15% answered 10%, 20% answered 20%, 30% answered 30%, 13% answered 40%,
14% answered 50%, and 5% answered 60%. Id. The study also shows that the
definition of probable cause is not just vague but also likely misleading: It
purports to require evidence sufficient to support a belief that an offense has
been committed, which would seem to mean that it is more likely than not that an
offense has been committed. Id. at 1327. However, the average probability from
the judges was 44.5%--below the "more likely than not" standard. Id. at 1332.
The First Circuit agreed with this formulation, holding that probable cause was
a lower standard than preponderance of the evidence. United States v. Melvin,
596 F.2d 492, 495 (1st Cir. 1979). In other words, "probable cause" does not
actually mean "probable"; it means something that is close to probable. See
infra notes 242-245 and accompanying text.





n167  See infra notes 219-222 and accompanying text.





n168  Judges seem to reject quantitative standards as well. Rita James Simon,
Judges' Translations of Burdens of Proof into Statements of Probability, in THE
TRIAL LAWYER'S GUIDE 113 (John J. Kennelly, James P. Chapman & William J. Harte
eds., 1969). In the survey of 400 trial court judges from the late 1960s, judges
were asked whether they would approve of using specific percentages or
probabilities in determining standards of proof, and "[t]he judges were almost
unanimous in their rejection of the proposal for both criminal and civil
trials." Id.





n169  McCauliff, supra note 165, at 1332.





n170  Kerr, supra note 146, at 132.





n171  Id. at 133-34.





n172  Id.





n173  Id. at 137-39.





n174  Id. at 135-37.





n175  Id. at 138-39.





n176  See supra Section II.B.





n177  Professor Kerr's objection to quantification also focuses on the inability
of judges to use specific numerical probabilities in their decision-making
process and the cognitive biases that would prevent them from using probability
numbers appropriately. For example, Professor Kerr discusses the representative
heuristic and anchoring effects, both of which tend to make individuals misjudge
numerical probabilities, sometimes quite dramatically. This argument has broader
implications for adopting big data's mechanical predictions, which will be
discussed in Section III.B, infra.





n178  See Illinois v. Gates, 462 U.S. 213, 230-31 (1983).





n179  See Rich, supra note 148, at 897-98.





n180  Id. at 897.





n181  Id. Professor Rich gives an example of a predictive algorithm that
considers location, time of day, facial recognition technology, prior criminal
activity and other background information, and then adds in the specific
behavior that a certain suspect is approaching multiple people on the street and
briefly engaging in a hand-to-hand transaction with each of them. Id. at 898.
The algorithm predicts a strong possibility of drug dealing. Id. A police
officer who investigates notices that (1) the suspect does not change his
behavior when he sees the police officer; and (2) a person who just engaged in a
hand-to-hand transaction with the subject drops a church flyer on the ground
immediately after the encounter. Id. The predictive algorithm did not account
for these extra observations, which almost certainly obliterate the probable
cause conclusion, but any human being would be able to process this new data
appropriately. Id.





n182  See Ahlers v. Schebil, 188 F.3d 365, 371 (6th Cir. 1999).





n183  See, e.g., Aguilar v. Texas, 378 U.S. 106, 114 (1964).





n184  Illinois v. Gates, 462 U.S. 213, 230-33, 238-39 (1983). The Supreme Court
noted that a magistrate's job in reviewing a warrant application was "simply to
make a practical, commonsense decision whether, given all the circumstances set
forth in the affidavit before him, including the 'veracity' and 'basis of
knowledge' of persons supplying hearsay information, there is a fair probability
that contraband or evidence of a crime will be found in a particular place." Id.
at 238.





n185  See Rich, supra note 148, at 895-901.





n186  See id. at 897-900; L. Song Richardson, Police Efficiency and the Fourth
Amendment, 87 IND. L.J. 1143 (2012); see also supra notes 121-126 and
accompanying text.





n187  See, e.g., Gardenhire v. Schubert, 205 F.3d 303, 318 (6th Cir. 2000).





n188  See supra notes 159-161 and accompanying text.





n189  See supra notes 134-136 and accompanying text.





n190  See Logan & Ferguson, supra note 135, at 13-14.





n191  See supra notes 145-155 and accompanying text.





n192  Jouvenal, supra note 30.





n193  George Hostetter, In Wake of Paris, Fresno P.D. Rolls out Big Data to
Fight Crime, CVOBSERVER (Nov. 16, 2015),
http://www.cvobserver.com/crime/in-wake-of-paris-fresno-p-d-rolls-out-big-data-t
o-fight-crime/4/ [https://perma.cc/7MNX-ZB8B]. For example, the police were
asked at a city council meeting whether a misdemeanor conviction alone would be
enough for the program to conclude that the suspect was "red," the highest level
of danger. Id.





n194  Matt Cagle, This Surveillance Software Is Probably Spying on #
BlackLivesMatter, ACLU S. CAL. (Dec. 15, 2015),
https://www.aclusocal.org/mediasonar/ [https://perma.cc/58YX-LATJ]. The result
of the public records request was eighty-eight pages of emails that included
lists of "high frequency social media terms" that could be indicative of
criminal activity. Id. (follow "88 pages of documents" hyperlink; then see
E-mail from Media Sonar to Angeline MacIvor (Jan. 27, 2015, 10:43 AM),
http://www.aclunc.org/docs/201512-social_media_monitoring_softare_pra_response.p
df [https://perma.cc/93NK-YC3V]).





n195  Stroud, supra note 33. In fact, the Chicago Police Department refused to
even reveal the names of the people on their "heat list," because they argue
such disclosure could endanger the safety of law enforcement officers or the
general population. Id. They have revealed some of the factors that they use,
such as criminal records, social circles, gang connections, and whether the
suspect has been a victim of an assault or a shooting. See Eligon & Williams,
supra note 36. Unfortunately, a partial release of certain factors does little
to address the transparency concerns discussed in this Article.





n196  See Alexis C. Madrigal, The Future of Crime-Fighting or the Future of
Racial Profiling?: Inside the Effects of Predictive Policing, HUFFINGTON POST
(Mar. 28, 2016, 7:54 AM), http://www.huffingtonpost.com/entry/
predictive-policing-video_us_56f898c9e4b0a372181a42ef
[https://perma.cc/BK5D-V9JM].





n197  Cagle, supra note 194 (follow "88 pages of documents" hyperlink; then see
E-mail from Media Sonar to Angeline MacIvor (Jan. 27, 2015, 10:43 AM),
http://www.aclunc.org/docs/201512-social_media_monitoring_softare_pra_response.p
df [https://perma.cc/93NK-YC3V]).





n198  Machine learning is defined as the following process: "A computer program
is said to learn from experience E with respect to some class of tasks T and
performance measure P, if its performance at tasks in T, as measured by P,
improves with experience E." TOM M. MITCHELL, MACHINE LEARNING 2 (1997).





n199  See RICHARD BERK, CRIMINAL JUSTICE FORECASTS OF RISK: A MACHINE LEARNING
APPROACH 110-11 (2012).





n200  Id. at 111.





n201  See Rich, supra note 148, at 886 ("Absent an intentional decision to the
contrary, machine learning tends to create models that are so complex that they
become 'black boxes,' where even the original programmers of the algorithm have
little idea exactly how or why the generated model creates accurate predictions.
On the other hand, when an algorithm is interpretable, an outside observer can
understand what factors the algorithm relies on to make its predictions and how
much weight it gives to each factor. Interpretability comes at a cost, however,
as an interpretable model is necessarily simpler--and thus often less
accurate--than a black box model.").





n202  Some would argue that the judge would also need to know the weights that
the algorithm assigned to each factor, so that the judge would be better able to
accurately add in other factors if she was using a "formal factor" model. If so,
the program could be designed to provide explicit percentages for each factor
every time it produces a result.





n203  See supra notes 72-76 and accompanying text.





n204  See supra Subsection II.A.1.





n205  See supra Section II.B.





n206  Daubert v. Merrell Dow Pharm., 509 U.S. 579, 597 (1993).





n207  See supra notes 119-120 and accompanying text.





n208  See Sendhil Mullainathan, Racial Bias, Even When We Have Good Intentions,
N.Y. TIMES (Jan. 3, 2015),
http://www.nytimes.com/2015/01/04/upshot/the-measuring-sticks-of-racial-bias-.ht
ml?abt=0002&abg=1 [https://perma.cc/6QBT-6BJA].





n209  As the use of predictive algorithms becomes more widespread, other legal
standards, such as "flight risk" in the bail context, may also need to be
quantified. See supra Section I.D.





n210  See supra notes 159-164 and accompanying text.





n211  Christopher Slobogin, Let's Not Bury Terry: A Call for Rejuvenation of the
Proportionality Principle, 72 ST. JOHN'S L. REV. 1053, 1081-85 (1998)
[hereinafter Slobogin, Proportionality Principle]; see also CHRISTOPHER
SLOBOGIN, PRIVACY AT RISK: THE NEW GOVERNMENT SURVEILLANCE AND THE FOURTH
AMENDMENT 31-41 (2007).





n212  Slobogin, Proportionality Principle, supra note 211. Professor Slobogin
would also require a greater showing for the most intrusive searches, such as
wiretaps or bodily intrusions; not just a 75% likelihood but also "clear and
convincing proof that the evidence thereby sought is crucial to the state's case
and that the search will be conducted in the least intrusive manner possible."
Id. at 1082-83.





n213  See Ric Simmons, The New Reality of Search Analysis: Four Trends Created
by New Surveillance Technologies, 81 MISS. L.J. 991, 999-1004 (2012).





n214  See, e.g., Craig S. Lerner, The Reasonableness of Probable Cause, 81 TEX.
L. REV. 951, 1014-22 (2003); Joseph D. Grano, Probable Cause and Common Sense: A
Reply to the Critics of Illinois v. Gates, 17 U. MICH. J.L. REFORM 465, 504-05
(1984); Albert W. Alschuler, Bright Line Fever and the Fourth Amendment, 45 U.
PITT. L. REV. 227, 229-31 (1984).





n215  See, e.g., Dunaway v. New York, 442 U.S. 200, 208 (1979).





n216  Lerner, supra note 214, at 1015-17. Professor Lerner ultimately proposes a
formula for determining probable cause, similar to the Learned Hand formula for
negligence claims, which takes into account the severity of the crime and the
intrusiveness of the search. Id. at 1019-22.





n217  Llaguno v. Mingey, 763 F.2d 1560, 1566 (7th Cir. 1985) (en banc). Other
Justices and judges have also hinted at the need for a sliding scale, though the
hints are usually made in dissents. See, e.g., Brinegar v. United States, 338
U.S. 160, 183 (1949) (Jackson, J., dissenting) (arguing that the societal
interest in searching a car trunk for a kidnapped child was greater than the
societal interest in searching a car trunk for bootlegged alcohol, and thus he
would be tempted to make an "exception" to the Fourth Amendment in the former
case); United States v. Soyka, 394 F.2d 443, 452 (2d Cir. 1968) (en banc)
(Friendly, J., dissenting) ("[T]he gravity of the suspected crime and the
utility of the police action [should be] factors bearing on the validity of the
search or arrest decision.").





n218  See Goldberg, supra note 148, at 802-05.





n219  United States v. Leon, 468 U.S. 897, 923 (1984).





n220  See Goldberg, supra note 148, at 804-05.





n221  See id. at 802-03.





n222  See supra note 120 and accompanying text.





n223  See, e.g., Barry Jeffrey Stern, Warrants Without Probable Cause, 59 BROOK.
L. REV. 1385, 1436-37 n.172 (1994) (noting that the Supreme Court "has not
defined [the probable cause] standard in a manner that is particularly
illuminating to those charged with enforcing and interpreting the criminal
law"); Goldberg, supra note 148, at 833 (noting that even in the absence of
quantitative evidence, "assigning a numerical value to probable cause can still
assist judges in making probable cause determinations, so long as they
appreciate that this number serves only as a reference").





n224  See, e.g., Terry v. Ohio, 392 U.S. 1, 28 (1968).





n225  See, e.g., United States v. $ 109,179 in U.S. Currency, 228 F.3d 1080,
1086-87 (9th Cir. 2000).





n226  See, e.g., United States v. Davis, 530 F.3d 1069, 1082-84 (9th Cir. 2008).





n227  See, e.g., People v. Shackelford, 546 P.2d 964, 966-67 (Colo. App. 1976).





n228  See, e.g., United States v. Mattarolo, 209 F.3d 1153, 1158 (9th Cir.
2000).





n229  As it turns out, the court's assumptions about which crimes carry a high
chance of weapons being present is sometimes correct and sometimes not. The
Bureau of Justice study revealed that a person committing a robbery does have a
high probability of carrying a weapon (34.5%), but that burglary (4%), sexual
assault (2.9%) and narcotics trafficking (7.8%) do not. HARLOW, supra note 52,
at 3.





n230  Terry, 392 U.S. at 28.





n231  Id.





n232  See, e.g., United States v. Thomas, 863 F.2d 622, 629 (9th Cir. 1988).





n233  See, e.g., Ramirez v. City of Buena Park, 560 F.3d 1012, 1022 (9th Cir.
2009).





n234  Thomas v. Dillard, 818 F.3d 864, 878 (9th Cir. 2016).





n235  Id. at 880-81.





n236  Id. at 898 (Bea, J., concurring in part and dissenting in part).





n237  The regular inability of courts to effectively and accurately use
statistics has led some commentators to argue against quantifying legal
standards such as probable cause because judges are not generally skilled at
mathematics and statistical analysis. See, e.g., Max Minzner, Putting
Probability Back into Probable Cause, 87 TEX. L. REV. 913, 951 (2009); Kerr,
supra note 146, at 132. However, as noted below, courts already use statistical
evidence to some extent in evaluating reliability of different tools used by law
enforcement officers. See infra notes 238 and accompanying text. Courts also use
statistical evidence in evaluating and applying expert testimony. See Daubert v.
Merrell Dow Pharm., 509 U.S. 579, 597 (1993). Furthermore, since judges are
"repeat players" in reviewing reasonable suspicion and probable cause
determinations, they will develop an expertise with statistics in the probable
cause context as the results of predictive algorithms become more widespread.
See Minzner, supra note 237, at 954-55.





n238  Dillard, 818 F.3d at 896-97 (Bea, J., concurring in part and dissenting in
part) (citing CALLIE MARIE RENNISON, BUREAU OF JUSTICE STATISTICS, INTIMATE
PARTNER VIOLENCE AND AGE OF VICTIM, 1993-99 7 (Oct. 2001),
http://www.bjs.gov/content/pub/pdf/ipva99.pdf [https://perma.cc/UH2V-UQ4G]).





n239  The Ninth Circuit acknowledged this in its opinion, noting that "domestic
violence calls vary widely in the actual threats they pose to officers and
others." Dillard, 818 F.3d at 881 (majority opinion).





n240  Here is an example of where Bayesian analysis would be useful--courts
would start with a 15% baseline and then add in other factors to increase or
decrease the likelihood. See infra notes 276-277 and accompanying text.





n241  See supra notes 165-166 and accompanying text. The median numbers were 30%
for reasonable suspicion and 50% for probable cause.





n242  Illinois v. Gates, 462 U.S. 213, 235 (1983) (stating that the "[f]inely
tuned standards such as proof beyond a reasonable doubt or by a preponderance of
the evidence . . . have no place" in determining whether probable cause exists).
The Supreme Court also stated that probable cause represents only "a fair
probability" that contraband or evidence of a crime will be found, which implies
something less than 50%. Id. at 246. A plurality of the Supreme Court has stated
that probable cause does not require that the fact being asserted be "more
likely true than false." Texas v. Brown, 460 U.S. 730, 742 (1983).





n243  See, e.g., United States v. Garcia, 179 F.3d 265, 269 (5th Cir. 1999);
United States v. Travisano, 724 F.2d 341, 346 (2d Cir. 1983).





n244  See Goldberg, supra note 148, at 801 n.62 (listing numerous commentators,
most of whom agree that the probable cause standard is less than
more-probable-than-not); Ronald J. Bacigal, Making the Right Gamble: The Odds on
Probable Cause, 74 MISS. L.J. 279, 338-39 (2004) (setting probable cause at a
range of 40-49% but warning against too much precision); Daniel A. Crane,
Rethinking Merger Efficiencies, 110 MICH. L. REV. 347, 356 (2011) (noting that
practitioners and commentators estimate probable cause to be "in the 40-45
percent range"). But see Slobogin, Proportionality Principle, supra note 211, at
1082-83 (placing the current probable cause level at 50% and the reasonable
suspicion level at 30%). Many commentators agree with the courts and say that
probable cause should not be quantified. See, e.g., Bruce A. Antkowiak, Saving
Probable Cause, 40 SUFFOLK U. L. REV. 569, 586 (2007) (arguing that "we should
fear any attempt to co-opt mathematical concepts to solve the probable cause
riddle"); Grano, supra note 214, at 469 (arguing for a "commonsense approach,"
not a mathematical approach, to probable cause).





n245  See, e.g., Lawrence Rosenthal, The Crime Drop and the Fourth Amendment:
Toward an Empirical Jurisprudence of Search and Seizure, 29 N.Y.U. REV. L. &
SOC. CHANGE 641, 680 (2005) (quoting a senior Assistant United States Attorney
who estimated the number at 40%); Daniel Richman, Prosecutors and Their Agents,
Agents and Their Prosecutors, 103 COLUM. L. REV. 749, 783 (2003) (quoting an FBI
attorney who set the number at 51%).





n246  Floyd v. City of New York, 959 F. Supp. 2d 540, 558-59 (S.D.N.Y. 2013).





n247  Jeffrey Goldberg, The Color of Suspicion, N.Y. TIMES (June 20, 1999),
http://www.nytimes.com/1999/06/20/magazine/the-color-of-suspicion.html?pagewante
d= all [https://perma.cc/L75B-A7AR].





n248  See JOHN C. LAMBERTH, RACIAL PROFILING DATA ANALYSIS STUDY: FINAL REPORT
FOR THE SAN ANTONIO POLICE DEPARTMENT 48 tbl.8 (Dec. 2003),
http://www.mass.gov/eopss/docs/eops/faip/san-antonio-report.pdf
[https://perma.cc/WDV7-HS2G].





n249  See Gross & Barnes, supra note 56, at 658.





n250  Id. at 674 tbl.9.





n251  See Minzner, supra note 237, at 925.





n252  Florida v. Harris, 133 S. Ct. 1050, 1057 (2013). Of course, the Harris
Court repeated the admonition that the probable cause inquiry in the drug dog
context should be a totality of the circumstances test, including not just the
drug dog's reliability but also whether the handler gave inappropriate cues or
whether the dog was working under unfamiliar conditions. Id. at 1057-58. Below
we discuss the method for courts to combine the specific quantified numbers from
tools (such as drug dogs or predictive algorithms) with other factors. See infra
Section III.B.2.





n253  Harris, 133 S. Ct. at 1057-58.





n254  United States v. Donnelly, 475 F.3d 946, 955 (8th Cir. 2007).





n255  United States v. Anderson, 367 F. App'x 30, 33 (11th Cir. 2010).





n256  United States v. Ludwig, 641 F.3d 1243, 1252 (10th Cir. 2011).





n257  United States v. Koon Chung Wu, 217 F. App'x 240, 246 (4th Cir. 2007).





n258  See also United States v. Sanchez-Tamayo, No. 1:10-CR-0532-JOFJFK, 2011 WL
7767740, at *14 (N.D. Ga. Nov. 28, 2011) (noting that courts have approved a
drug dog reliability rate of "approximately 50%-60%" as sufficient to establish
probable cause). But see United States v. Huerta, 247 F. Supp. 2d 902, 910 (S.D.
Ohio 2002) (rejecting probable cause finding even though the drug dog had a 65%
success rate).





n259  Minzner, supra note 237, at 922-23. These rates may be inflated somewhat
because some of the jurisdictions that were studied involved police officers who
did not return their warrants after the search, presumably because nothing was
received. Id. at 923 n.38. Even taking into account this possibility, warrant
success rates still ranged between 46% and 93%. Id. This higher number does not
necessarily mean that courts are setting a higher bar for probable cause in
warrant applications; it could be that probable cause is always set at, say, 40%
for any kind of search, and that most warrant applications achieve a much higher
level of success because law enforcement officers want to ensure they get
approved when they take the time and expend the resources to apply for a
warrant. Id. at 922.





n260  See supra Subsection III.B.1.





n261  Floyd v. City of New York, 959 F. Supp. 2d 540, 582-83 (S.D.N.Y. 2013).





n262  Mich. Dep't of State Police v. Sitz, 496 U.S. 444, 454-55 (1990).





n263  Id. at 455.





n264  See supra note 252 and accompanying text (referencing Florida v. Harris,
133 S. Ct. 1050, 1057-58 (2013)); Goldberg, supra note 148, at 828.





n265  Ferguson, supra note 12, at 377.





n266  Id. at 378.





n267  See id. Of course, once predictive algorithms become more sophisticated,
we will have a better idea about how high this percentage could be based on only
background information. However, because of the particularized suspicion
requirement, even if background information alone took us to the required
threshold, reasonable suspicion would still not exist.





n268  The actual Detective McFadden used these observations alone to arrive at
reasonable suspicion. Terry v. Ohio, 392 U.S. 1, 6 (1968).





n269  This is the method suggested by Professor Ferguson, who notes that a
modern-day Detective McFadden can add the personal observations to the
information he gathered from the various police databases to make his finding of
reasonable suspicion "easier and, likely, more reliable." Ferguson, supra note
12, at 377-78. As explained below, infra notes 277-280 and accompanying text,
this will require Detective McFadden to engage in a Bayesian analysis, using 5%
as a prior probability and then adding in his observations to adjust that
probability upwards.





n270  Reasonable suspicion requires "specific and articulable facts." Terry, 392
U.S. at 21. Probable cause requires "facts and circumstances within their [the
arresting officers'] knowledge." Draper v. United States, 358 U.S. 307, 313
(1959) (quoting Carroll v. United States, 267 U.S. 132, 162 (1925)).





n271  See Goldberg, supra note 148, at 800.





n272  See supra notes 58-59 and accompanying text.





n273  See Ferguson, supra note 12, at 392.





n274  Id. at 406.





n275  See Goldberg, supra note 148, at 833.





n276  For an example of Bayes's theorem being applied in a legal context, see
Jonathan J. Koehler & Daniel N. Shaviro, Veridical Verdicts: Increasing Verdict
Accuracy Through the Use of Overtly Probabilistic Evidence and Methods, 75
CORNELL L. REV. 247, 255-56 (1990).





n277  Bayes' theorem can be expressed mathematically as: P = xy/[xy +z(1-x)].
Id. P is the number we are trying to calculate, known as the "posterior
probability"--that is, the updated probability that a certain fact is true; in
this case, it is the odds that criminal activity is occurring or that contraband
will be found if the search is conducted. x is the "prior probability"--the
probability that a certain fact is true before the extra information is added;
in this case, the odds of criminal activity or contraband that are calculated by
the predictive algorithm based on all the factors that it takes into
consideration. y is the probability that if the fact is true, then the extra
information will be present; in this case, the odds that the independent pieces
of information not considered by the algorithm exist because the defendant is
engaged in criminal activity or contraband is present. And z is the probability
that the fact is not true given the extra information; in this case, the chance
that given that all the independent pieces of information are true, there is no
criminal activity or contraband (i.e., there is a perfectly innocent explanation
for all of the independent pieces of information). Obviously the decision-maker
will have to estimate y and z, but this is not too different from what police
officers and judges already do--only in this case they will have a much more
accurate base rate to start from.





n278  See supra note 265 and accompanying text; Ferguson, supra note 12, at
377-79.





n279  Some robbers might simply barge in without investigating the location
first, but most robbers would want to take a good look at the location, looking
to see how many people are present, where the cash register or other valuables
are kept, and (in the modern age) whether there are any security cameras inside.
See Ferguson, supra note 12, at 378.





n280  Applying Bayes' theorem: P = .05*.9/[.05*.9 + .1*(1-.05)] = .321.





n281  Again, applying Bayes' theorem: P = .01*.9/[.01*.9 + .1*(1-.01)] = .043.





n282  Koehler & Shaviro, supra note 276, at 256.


                               3 of 41 DOCUMENTS

            Copyright © 2016 University of California Regents.  All
                                Rights Reserved.
                           UCLA Law Review Discourse

                                      2016

                           UCLA Law Review Discourse

                           64 UCLA L. Rev. Disc. 516

LENGTH: 10522 words

PULSE SYMPOSIUM: Imagining the Legal Landscape: Technology and the Law in 2030:
Policing Police Robots

NAME: Elizabeth E. Joh

BIO: Professor of Law, U. C. Davis School of Law. Thanks to the participants of
the Program on Understanding Law, Science, and Evidence (PULSE) "Imagining the
Legal Landscape: Technology and the Law in 2030," Ryan Calo, and Michael
Froomkin for their helpful comments.

HIGHLIGHT: ABSTRACT

Just as they will change healthcare, manufacturing, and the military, robots
have the potential to produce big changes in policing. We can expect that at
least some robots used by the police in the future will be artificially
intelligent machines capable of using legitimate coercive force against human
beings. Police robots may decrease dangers to police officers by removing them
from potentially volatile situations. Those suspected of crimes may also risk
less injury if robots can assist the police in conducting safer detentions,
arrests, and searches. At the same time, however, the use of robots introduces
new questions about how the law and democratic norms should guide policing
decisions--questions which have yet to be addressed in any systematic way. How
we design, regulate, or even prohibit some uses of police robots requires a
regulatory agenda now to address foreseeable problems of the future.

TEXT:
 [*518]  INTRODUCTION

   In July 2016, Dallas police chief David Brown decided to end a violent
standoff  n1 with Micah Johnson,  n2 who had fatally shot five officers and
wounded several more, in an unusual way.  n3 As a makeshift solution, the police
attached a pound of the plastic explosive C4 to a Remotec F-5,  n4 a robot
designed for bomb disposal.  n5 The intentional detonation of the explosive
killed Johnson, and was the first deliberate use by American police of a robot
armed with deadly force.  n6

   Keep in mind that this improvised solution was a remotely controlled robot.
The robot was not designed to harm people, and it lacked any ability to make
independent decisions.  n7 Nevertheless, the use of the robot in Dallas comes at
a time when many people are predicting that sophisticated police robots will one
day become "useful, cheap, and ubiquitous."  n8 Hundreds of robots--most  [*519]
of them made for bomb disposal--are already in the possession of local police
departments.  n9 Many such robots will soon employ artificial intelligence and
will be expected to operate with a degree of independence.  n10 The near certain
use of these robots by the police  n11 raises questions about what sorts of
limits and regulations should be imposed on their use.  n12

   Consider a future in which robots could supplement or replace some basic
police functions. An autonomous police vehicle patrols a neighborhood and
briefly detains a person deemed suspicious so that an officer miles away can
subject him to questioning.  n13 During the detention, the vehicle dispatches a
micro drone to obtain a DNA identification sample.  n14 Or consider the
possibility of thousands of autonomous police drones the size of insects flying
through a city without detection to conduct surveillance and carrying
nano-chemicals to disable dangerous suspects.  n15 Or imagine social patrol
robots that dispense advice to the lost, record surveillance data, and call in
other robots to assist in unexpectedly hostile situations.

   Rapid changes in technology have significantly shifted how police perform
their jobs. The squad car and the two-way radio provided the police with a
geographic range and communication ability far superior to traditional foot
patrol.  n16 Robots represent the next leap. Robot staff have already attended
to  [*520]  guests at the Henn-na Hotel in Japan.  n17 Hotel robots deliver
towels and coffee to guests, while other robot bartenders serve drinks and still
others deliver pizza.  n18 Robot journalists create online content for Thomson
Reuters and Yahoo.  n19 A novel co-written with an artificial intelligence (AI)
n20 program advanced to the first stage of a Japanese literary contest.  n21
Semiautonomous Reaper unmanned drones carry Hellfire missiles.  n22 In the near
future, robots will probably serve as our delivery drivers and our garbage
collectors.  n23 Robots like the Japanese Robear will probably provide eldercare
to seniors.  n24  [*521]  Pepper the robot will be an anthropomorphic companion
that will provide us with emotional care.  n25

   As for policing, Dubai plans to introduce patrol robots with artificial
intelligence to its streets by 2020.  n26 The Chinese AnBot can independently
patrol, and upon a remote operator's command, use its mechanical arm to grab
people as well as deploy its "electrically charged riot control tool."  n27
Equipped with infrared cameras, microphones, and license plate readers, the
American Knightscope security robot can patrol independently, for $ 7.00 an
hour.  n28 Machines endowed with artificial intelligence and the capacity for
independent action will have profound impacts on policing. To be sure, advances
in technology have always given police new powers. Robots, however, may be
different in kind. Like the internet, robots raise new issues and challenges to
the regulation of policing.  n29

   Police robots raise special questions because of the powers we entrust to the
police. If the development of military robots provides any guidance, then we can
expect some police robots to be artificially intelligent machines capable of
using legitimate coercive force against human beings.  n30 Military robots will
also possess these powers, with an important difference: We will not expect
police robots to exercise deadly force against a hostile enemy. More
importantly, constitutional law and democratic norms constrain the police. How
we design, regulate, or even  [*522]  prohibit some uses of police robots
requires a regulatory agenda now to address foreseeable problems of the future.

   Sophisticated and inexpensive robotics will be attractive to the police just
as they have been to the military.  n31 The federal government is already
spending significant amounts of money and attention on robotics research.  n32
Those robotic applications will make their way to policing, and federal monies
for robotics will become available to local law enforcement agencies just as
they have in the case of recent technologies like body cameras, biometrics, and
big data analysis.  n33 What is more, police departments will likely raise the
argument that they must be prepared for a robotics arms race, such as against
criminals and terrorists who could 3D print an army of weaponized micro-drones.
n34

   This Article considers the law and policy implications of a future where
police robots are sophisticated, cheap, and widespread. In particular, I focus
on questions raised by the use of robots able to use coercive force, as opposed
to robots with surveillance or other support functions. Drawing upon the rapidly
developing body of robotics law scholarship, as well as upon technological
advances in military robotics--from which policing will surely borrow--we can
anticipate the kinds of regulatory challenges we will face with the future of
police robots.

    [*523]  I. PUTTING POLICE ROBOTS IN CONTEXT

A. What Is a Robot?

   The definition of a police robot depends on the definition of the term robot
itself. Popular depictions of robots going back to the 1920s suggest robots are
machines in humanoid form; think of the Maschinemensch in Fritz Lang's 1927 film
Metropolis,  n35 or Rosie the maid robot in the jetsons.  n36 Yet robots neither
have to look like people nor behave in any specific way. Robots can look like
humans, animals, or insects; they can provide information, fire upon an enemy,
or engage in financial trades. Indeed, there is no single definition of a
"robot."  n37

   An emerging consensus has suggested, however, that a robot be defined as any
machine that can collect information, process it, and use it to act upon the
world.  n38 These qualities vary widely from one robot to another. This
sense-think-act model might describe anything from a "bot" that makes
independent online purchases  n39 to an eldercare robot that provides emotional
comfort or assists with lifting objects.  n40 In appearance, robots could take
any form. Some military robots, for instance, may assume the shape of four
legged centaurs to enhance stability.  n41 Thus, if a robot processes
information it senses and acts upon it, a police robot does so in order to
perform a task traditionally assumed by human police officers.

    [*524]  That robots might look alive and act in unpredictable ways also
distinguishes them from other technologies. Those special attributes of robots
might counsel robot-specific policies. Robotics law scholar Ryan Calo has
identified these qualities as "embodiment, emergence, and social valence."  n42

   First, the physicality of robots enables them to translate their data
analysis into action. Robots act upon the world: They can lift objects,
transport people, create art, and engage in commerce. And unlike other robots
that may cause real-world harm through accident,  n43 police robots--at least
some of them--will be designed with the capacity to exercise deliberate coercive
force. That physicality creates new operational possibilities for the police,
but it also raises new types of concerns when autonomous machines may be able to
harm people by design.

   Second, robots with artificial intelligence will behave in ways that are not
necessarily predictable to their human creators.  n44 Some robots may just
replace human labor in jobs that are repetitive and dull, but others will be
capable of adapting to their environment, learning from mistakes, and become
increasingly skilled in their assigned tasks. At one end of the spectrum, a
robot may be a glorified vacuum cleaner, designed to address the drudgery of
housecleaning. At the other end, a robot's artificial intelligence may be
designed not only to act upon processed information, but also to improve its
performance over time by learning from past mistakes.  n45 Not all of this
learning will be welcome. Microsoft quickly disabled its social chatbot Tay
after it incorporated online responses and began spouting racist speech and
called for genocide online.  n46 Since artificial intelligence would drive the
behavior of robots, robots may behave in ways that we cannot predict, or even
explain afterwards.  n47

    [*525]  Artificial intelligence by itself is not unique to robotics. We can
already feel the impact of big data--applying complex computer algorithms to
massive sets of digitized data--in fields like finance, healthcare, and even
policing. A number of police departments already use artificial intelligence in
software that tries to identify future geographic locations where crime will
occur, to predict which individuals may be at highest risk for violent crime
commission or victimization, and to identify which among the billions of daily
Internet posts amount to suspicious behavior.  n48 The police employ these big
data tools, however, as guidance for human decisionmaking. Robots with
artificial intelligence are distinct because they would be able to translate
their analysis of data into physical action.

   Third, robots are different from other technologies because they are in
appearance somewhere between inanimate objects and humans.  n49 No robot today
will fool a person into believing that it is alive, but many robots do not seem
completely inert, either. Research suggests that we tend to approach robots as
if they had human characteristics.  n50 Exploiting the human-like nature of some
robots could be useful. We could deliberately design caretaking robots to be
physically cute (such as rounded shapes, humanoid faces) to maximize their
benefits, whether for children or the elderly.

   The ambivalence we feel toward robots might also counsel new legal
characterizations particular to them. We may think that a person smashing his
lawn mower merely has an ill temper, but that a person abusing a social robot is
cruel.  n51 If robots are designed to serve as pets, caregivers or friends,
could robots be the victims of criminal assault, abuse, or even rape and murder?
n52 In this way, the law may need to extend some legal protections to robots,
for some of the same reasons we criminalize animal cruelty.  n53 We prohibit the
infliction of needless  [*526]  violence against some animals because such
behavior reflects something depraved about the perpetrator. Though we may not
mistake robots for humans yet, we may soon reach a point where machines endowed
with artificial intelligence may need protection from human abuse.

B. Military Robots

   The future of robotic policing can now be found in developments within the
military.  n54 The military has used remote controlled robots for more than a
decade.  n55 The Department of Defense is preparing for a future in which nearly
autonomous robots will play a central role in warfare.  n56 Consequently, the
military is spending the most money and attention on robotics.  n57 Peter W.
Singer has chronicled these changes in great detail, and argues that military
robots will change not just the tools we use to fight wars, but the very nature
of war itself.

   Robots are in use in active conflicts around the world. Predators, Global
Hawks, and Ravens have flown over Afghanistan, and MARCBOTs have aided soldiers
on the ground in Iraq.  n58 A clear advantage of robots is their ability to act
as "force multipliers."  n59 Future armies may assemble attachments that include
as few as 150 human soldiers and as many as 2000 robots.  n60 More importantly,
however, autonomous machines capable of deadly force are also likely to change
military tactics and strategy.

   Unlike people, robots can go places without compromising the safety of
soldiers. A "sensor"--shorthand for a drone's human operator--can direct the
launch of a Predator's Hellfire missile in Afghanistan without leaving his seat
in  [*527]  Las Vegas.  n61 Robots can look for land mines and protect the lives
of soldiers who would have had to assume minesweeping responsibilities
themselves. Unmanned submarines can launch smaller autonomous robots to look for
hostile ships while drawing less attention to themselves than human-operated
subs.  n62 Medbots-robotic ambulances--of the future may find wounded soldiers,
retrieve them, and autonomously diagnose and treat them while retreating from
the battlefield.  n63

   Robots can also behave in ways that humans cannot easily mimic. Scientists
are always looking to enhance solider stamina. In the 1940s, a solution was
amphetamines; today, it is Adderall.  n64 But robots never lose their accuracy
because of fatigue, boredom, or stress. Robots do not harbor revenge or rage.
Robotics researchers are working on autonomous vehicles for the air, ocean, and
land that can operate for days and weeks on end.

   That relentless attention to task may have other strategic benefits as well,
although how exactly remains unclear. How will human combatants facing tireless
robotic soldiers feel? Enemy forces may buckle in the face of robotic soldiers
that cannot die and do not retreat.  n65 Or, the opposite may come true; the
presence of robotic soldiers may galvanize enemy forces in a "war against the
machines."  n66 Alternatively, enemy forces may simply fight back with their own
robots.

   The unique characteristics of robots will also shape fundamental military
tactics. One application of robotics imagines "swarms" of small robots that move
in the same way birds and insects do: in unison, though without a defined
leader.  n67 In nature, individual bees or birds do not rely on high degrees of
intelligence to avoid crashing into each other; rather, each member follows
simple rules. Robotic swarms can work this way, without sophisticated
programming. In a swarm, robots could assemble together rapidly as a unit, and
then just as quickly disperse to continue with surveillance missions.

    [*528]  What develops first in the military often finds its way to domestic
policing. There has long been a close relationship between both the culture and
institutions of the military and law enforcement. The bureaucratic hierarchy in
policing--adopting titles like sergeant, lieutenant, and captain--reflects the
military's influence.  n68 Not only are many rank and file officers former
members of the military, many police departments actively recruit from their
ranks as well.  n69 We even use war metaphors to describe our domestic policing
strategies.  n70

   This military influence extends to specific tactics and technologies used by
the police. While the federal Posse Comitatus law  n71 forbids the use of the
military for civilian policing, military equipment and training has trickled
down to police departments through other means. For instance, the so-called
"1033 Program," part of the National Defense Authorization Security Act of 1997,
n72 is the federal initiative that has transferred surplus military equipment
such as MRAPs (Mine-Resistant, Ambush-Protected vehicles), grenade launchers,
and amphibious tanks to local police departments.  n73 VVhile the public may
have been shocked at images of police officers wearing combat fatigues and
carrying M16s during protests in Ferguson, Missouri in 2014,  n74 these police
officers were little  [*529]  different from the hundreds of other police
departments who had been recipients of military equipment transfers under the
1033 program.  n75 Similarly, police SWAT teams, now common in police
departments around the country, were created as specialized paramilitary groups.
Former LAPD chief Daryl Gates, credited with establishing the first SWAT teams,
brought in ex-Marines to help train these small groups of officers to act and
dress like soldiers in volatile situations.  n76

II. THE CHALLENGES POSED BY POLICE ROBOTS

   Imagine police robots that could surround a suspicious person or even halt a
speeding car.  n77 This might take the form of a swarm of small robots, each
less than a pound, designed to incapacitate a person by surrounding him and by
using nonlethal force. Consider further that such a swarm would be capable of
using some form of coercive force to prevent an unwillingly detained person from
flight. A "Multi-Robot Pursuit System" that guides packs of robots to  [*530]
"search for and detect a non-cooperative human"--part of a Pentagon request for
contractors--would surely be useful to the police.  n78

   Even if this use of robots is still just a concept, we can anticipate the
kinds of legal and policy challenges that might arise. First, how much should
humans remain "in the loop"--maintain some degree of involvement, in other
words--in the use of robot police?  n79 Second, how much coercive force should
we permit police robots to exercise? Third, how might the use of police robots
affect legal determinations like reasonable force? Fourth, will police robot use
further reinforce the social inequities in policing? Finally, how can we develop
a uniform approach to policing police robots?

A. How Much Control Should Humans Have Over Police Robots?

   How much should police delegate decisions about force and coercion to their
own robots?  n80 Take a look at the robotics currently on the market--the idea
that we might lose control over them seems almost laughable. No consumer today
fears their housekeeping Roomba, and even the most advanced private security
robot available now could be disabled by a swift kick. But technology changes
fast.  n81 The Pentagon's Autonomous Research Pilot Initiative funds research
for algorithms that will "increase a system's level of autonomy."  n82
Artificial intelligence experts hint that we might see humanlike artificial
intelligence within a few decades, not a century.  n83 Within our lifetime,
robots might not only seem "human" in their basic intelligence, but emotional,
perhaps even "superhuman."  n84

    [*531]  Not every robot will display such capabilities. Today, some machines
the military deems "robots"--like the widely used Talon--are controlled
completely by remote human operators.  n85 Other robots use artificial
intelligence to operate independently for limited tasks; the remote operator of
a Global Hawk, for instance, "just clicks" a computer mouse to tell the robot to
taxi and take off.  n86 A fully autonomous robot would need no human input at
all once someone has defined the robot's mission.  n87

   Greater degrees of autonomy in military robotics seem inevitable. One of the
efficiencies gained by military robots is that large numbers of them will be
capable of independent action with one human actor's oversight. Imagine a
phalanx of military robots controlled by one human operator, perhaps thousands
of miles away. As a result, fewer human lives are placed at risk. Such robots
would not increase efficiency if each required an independent human operator.
n88

   On the battlefield, some decisions must be made within fractions of a second.
Waiting for human approval or veto may be critical time wasted, particularly if
a robot must calculate how and whether to launch a counterattack.  n89 Not only
might there be insufficient time to oversee a single robotic decision, but there
may be little opportunity for a human operator to closely supervise the split
second decisions of the dozens of robots over which he has control. Human
involvement in such a case might take the form of a veto power, if at all.

   Current military research already supports the development of robots with
greater degrees of autonomy. One research goal of the Pentagon is to establish
linked autonomous systems so that robots can communicate to one another in a
rapidly changing environment. In the military, autonomous drones could scan a
combat area and communicate with ground robots to find suspicious places or
people.  n90

   The possibility that some robots capable of hurting or killing people will be
capable of complex, independent action raises concerns, however. In the near
future, robots could make decisions in ways that we cannot easily control or
understand. The question of human involvement is itself complicated, because
[*532]  artificial intelligence itself is becoming more complicated. Assume we
require that a human must assess a robot's determination to use coercive force.
Deciding whether a machine with artificial intelligence has made a good decision
may not be easy, since the algorithm's processes may not be totally intelligible
to a human operator. Even if we have access to an algorithm's source code, we
still might not know how or why it reached its decision.  n91 Engineers at
Google, for instance, recently conceded that they do not fully understand how
Google's successful Rank Brain AI works, only that it works well.  n92 Requiring
a human "in the loop" may mean little if how the robot came to its conclusion
remains opaque to the human being in charge.

   Armed robots with some degree of autonomy are also likely to be vulnerable to
criminal interference (hacking) as well as malfunction. Our current experience
with the security of electronic devices provides little assurance otherwise.
Security researchers have discovered vulnerabilities that make possible the
hacking of "smart" cars, insulin monitors, thermometers, refrigerators, and
locks.  n93

   For now, armed and independent military robots are not a reality in the
military, but they are a concern. Current military policy requires human
involvement in any potentially lethal action. As Deputy Defense Secretary Robert
O. Work commented in March 2016, the military "will not delegate lethal
authority to a machine to make a decision."  n94 Retaining some human
involvement in armed military robots remains a "line in the sand."  n95 But this
is a policy restraint, not a technological one. That restraint may give way
easily if another hostile nation or terrorist group decides to use lethal
autonomous robots against American soldiers.  n96

   Translating these developments in military robotics to domestic policing
requires little effort. The companies developing and producing robots can
[*533]  (and do) adapt them for military or law enforcement uses. Robots used
for surveillance, investigation, and coercive force in Iraq and Afghanistan
could easily be adapted to New York, Chicago, and Los Angeles.

   Should a Taser or firearm-enabled police robot require human input before
using force against a suspect? While a vice president at iRobot, which partnered
with Taser, once stated, there is "no way [we are] giving the robot the
capability to use force on its own,"  n97 that decision, like the Pentagon's, is
dictated by policy, not technology. Instead, we should ask whether a robot
capable of assessing a dangerous situation and enabled to use a Taser or other
weapon should be able to decide to do so without human input. As with the
military, a ban on such police robots makes sense until policies are developed
to address matters of control, security, and accountability.

B. How Much Force Should Be Used by Police Robots?

   Not only do we need to decide how much human beings should be involved in
police robot decisionmaking, we also need to decide how heavily robots should be
armed. From their beginnings in the nineteenth century, American police have
acquired ever more sophisticated tools: first truncheons, then firearms, and now
stun guns, pepper balls, tear gas, and long range acoustic device (LRAD) sound
cannons.  n98 Police injure and sometimes kill people during their stops,
arrests, and pursuits. When the circumstances warrant it, these are legally
justifiable uses of force. If police authority rests in part on the authority to
use coercive force, how much should coercive, even lethal force, should a police
robot possess?

   Should a robot be able to exercise the same deadly force as a police officer
does now? In 2007, iRobot announced a "strategic alliance" with Taser
International, to develop a Taser-equipped version of its popular Packbot.  n99
Electric stun guns, capable of transmitting a shock of up to 50,000 volts, can
temporarily  [*534]  disable suspects deemed dangerous and noncompliant.  n100
Tasers are considered less-than-lethal substitutes for guns. Indeed, police
departments often view Taser adoption as a measure of reform.  n101

   If police robots can carry Tasers, can they also carry firearms or other
lethal weapons? Any proposal to adopt the regular use of lethally armed
robots--whether semiautonomous or remotely controlled--is likely to meet initial
public resistance. There is already a public campaign against "killer robots" in
the military,  n102 and the discomfort many people feel about lethal robotic
soldiers will probably be more pronounced in local policing. Uncertainty about
partially or fully autonomous lethal robots will likely be more pronounced if
that possibility is introduced for police within the United States.

   There are at least two reasons to be skeptical that a prohibition against
lethal police robots would persist. First, the line between lethal and nonlethal
arms is not always clear. Even a Taser-enabled robot is one capable of lethal
force. While relatively uncommon, people have died in incidents in which police
use Tasers: at least forty-eight people in 2015.  n103 Some cases involve
improper Taser use, others involve unknown physical vulnerabilities of the
victims. Once we authorize police robots to use some degree of coercive force,
we implicitly acknowledge some uses of even less-than-lethal force will be
lethal in practice.

   A second reason to be skeptical about any prohibition on the regular use of
lethally armed police robots is the future role of robots more generally. In the
future, we will be surrounded by robots of all kinds at work (as coworkers), at
home (as caregivers), and in leisure (as social or sexual companions). That
world will also include robots involved in crime. Just as robots in the military
reduce the need for soldiers to put themselves at risk, robots can provide the
same safety and  [*535]  anonymity for someone interested in committing crime.
An armed robot drug dealer could act as an autonomous vending machine able to
defend itself against attack and destroy evidence in the event of discovery.
n104

   Once the first crimes are committed by robots armed with lethal force, police
in the United States will almost certainly balk at any prohibitions on lethally
armed police robots.  n105 Such prohibitions may find police support in
countries like New Zealand and Britain, where most police are unarmed, as are
most civilians.  n106 In the United States, however, lethally armed robots may
become just another point in the development of weapons that the police will
want to use.

C. What Is Robotic "Reasonable Force"?

   The kinds of weapons police robots might adopt are matters of technology and
policy, but the circumstances in which robots could use force against human
suspects are legal ones. Imagine that a suspect temporarily detained by a police
robot decides to start shooting at the robot. If the robot shoots back--and
injures or kills the suspect--would that be legally defensible?  n107

   The answer will depend in part on how we classify robots under the law. Human
police may legally resort to force, even deadly force, in the appropriate
circumstances. Claims of excessive force against the police, whether in the
context of an arrest, stop, or other detention, are judged by a standard of
[*536]  "objective reasonableness" under the Fourth Amendment.  n108 Deadly
force may be used in situations where a suspect "poses a threat of serious
physical harm, either to the officer or to others."  n109

   Distinguishing between legally permissible and impermissible uses of force by
the police is not always easy. The U.S. Supreme Court has avoided requiring any
exclusive list of factors in assessing reasonableness. Rather, the Court has
emphasized that the use of force analysis requires courts to "slosh" through the
"factbound morass of 'reasonableness.'"  n110 Moreover, considerable deference
is accorded to the police, as the "calculus of reasonableness must embody
allowance for the fact that police officers are often forced to make
split-second judgments--in circumstances that are tense, uncertain, and rapidly
evolving."  n111 That reasonableness "must be judged from the perspective of a
reasonable officer on the scene, rather than with the 20/20 vision of
hindsight."  n112 Finally, that assessment asks "whether the officers' actions
are 'objectively reasonable' in light of the facts and circumstances confronting
them, without regard to their underlying intent or motivation."  n113 The result
is a "notoriously opaque and fact-dependent" doctrine that has become difficult
for courts to articulate and police to incorporate into their training.  n114

   Even if the Fourth Amendment's use of force doctrine were clearer, it still
would not translate easily to the world of robotics. First, the high degree of
deference given to police in the use of force context takes into account the
fallible nature of human judgment in volatile situations with high degrees of
stress and emotion. As a result, police decisions to use force, even deadly
force, do not have to be correct, only objectively reasonable. Artificially
intelligent machines capable of coercive force do not feel fear, disgust, anger,
or take offense. In this respect, robots might be more reliable than human
beings in making split second decisions about whether to draw a weapon or use a
stun gun. Does that mean we should expect a narrower set of circumstances for
robotic reasonableness than we do for humans?

    [*537]  Second, and perhaps more importantly, the usual legal standards
governing the use of force by the police assume the perspective of officers who
fear for their lives or safety. Too little deference to the police may inhibit
their decisions and result in more injuries to the police; too much deference,
and the police may injure or kill people when such deaths could be avoided.
n115 In practice, courts have given considerable deference to officers' stated
beliefs that they felt their lives were in danger, even if those fears turn out
to be mistaken after deadly force has been used.  n116

   What do these legal standards mean when a police robot confronts a person who
appears to intend it harm? The law values life over property, yet robots might
occupy a legal category that is neither purely property nor human. How we think
of robots in these situations may depend on whatever analogies courts will adopt
to characterize them: Are robots like wild animals, slaves,  n117 children, or
something else?

   If robots are treated merely as property, then police robots should not be
permitted to defend themselves against human attack, even when acting in a
policing role.  n118 But that conclusion is not obvious. An animated debate
already exists as to whether cruelty to robots might be criminalized in the same
way we criminalize cruelty to animals.  n119 The dismemberment of the
hitchhiking "Hitchbot" in 2015 prompted new concerns about a future of unchecked
robot  [*538]  abuse.  n120 While we might have many reasons to criminalize
animal abuse, one reason may be to promote social values and to deter antisocial
violence. We disavow deliberate unjustified violence to animals in part because
to do otherwise would condone the human infliction of pain and suffering against
other beings.

   But permitting a robot to launch a counterpunch against an armed human poses
its own tricky questions. Perhaps a robot could exert proportional nonlethal
force to defend itself from destruction. Let us further assume that a human must
authorize such a use of force. In an optimal case, the suspect posing a threat
might be temporarily disabled by nonlethal force until in handcuffs (or their
future equivalent).

   Consider too, that one day, police robots might be sent to confront criminal
robots. What amount of force is permissible then? Can a police robot "kill"
another robot? Because the robot's actions would be attributable to the
government, the permanent disabling of a threatening civilian robot would be a
Fourth Amendment "seizure." But what would a "reasonable" robotic seizure of
another robot look like?

   To be sure, police robots might remove some of the problems raised in
confrontations between the police and the public. The use of robots in these
situations may reduce the risk of harm to the police, if they can safely subdue
a dangerous suspect at a distance. And if police lives are not at immediate
risk, it may be that detentions and arrests could be conducted with less risk to
individuals.

   Robots have the potential to make policing safer. That possibility, however,
must be balanced against the mistakes, hacks, and malfunctions that will
inevitably occur. Who will bear the responsibility for these mistakes, either
because the threat was misjudged, or the force disproportionate? Should we blame
the robot, the manufacturer, the software engineer, or the human operator
(assuming there is one)?

D. Will Robotic Police Reinforce Social Inequality?

   Whether or not police robots use coercive force and do so with some degree of
autonomy, the manner of their deployment raises a separate policy question.
Robots may decrease dangers for the police and those detained by the police, but
will they increase perceptions of policing unfairness? If arming robots is
already becoming an active topic of debate, an equally important but less
visible one is  [*539]  whether police robots will worsen ties to communities
where relationships with the police are already strained.

   We can see these questions of technology and policing already being put to
the test with predictive policing software. Defined broadly, predictive policing
applies artificial intelligence to data in order to detect patterns of crime.
n121 Using the vast amount of digitized information today, predictive policing
programs try to predict criminal risks in individuals or in geographic
locations. In the case of locational prediction, predictive policing
programs--using historical crime data and other factors--identify geographic
locations where crime is more likely to occur in the future.  n122 Police
departments can use that information to redistribute patrol resources. Cities
including Los Angeles, New York, and Seattle have purchased predictive software
programs of this type.  n123 In the future, predictive policing programs may
further guide the allocation of police resources and hiring.

   These predictive policing programs may appear neutral but in fact hide
biases. Consider the data used by predictive policing algorithms. If arrests are
a significant factor, then we cannot discount the fact that many arrests are the
product of highly discretionary decisions by police officers.  n124 If high
arrest rates influence the algorithm to direct the geographic focus of police,
then we should not be surprised if more arrests occur in those places as a
result. Similarly, if reported crimes constitute another factor taken into
account by a predictive policing algorithm, then crimes not usually reported or
not always reported will be omitted from the decision about where to direct
police attention.  n125 Robbery will make the cut, but domestic violence and
financial crime may not.  n126 These  [*540]  hidden sources of bias have
prompted concerns that predictive policing programs will justify a heavy police
presence in poor minority communities that have historically been targets of
over-policing.  n127

   Predictive policing programs only provide guidance, not action. What would
happen, though, if patrol robots use this predictive analysis? If predictive
policing programs fail to address issues of human bias, some communities would
be flooded with police robots, while others would not be. Imagine further that
police robots would be afforded less enforcement discretion than human officers.
We worry about human police discretion because it is difficult if not impossible
to know if impermissible factors influence enforcement. But would we live in a
better world if police patrol robots enforced minor offenses much more
frequently than human officers would in neighborhoods accustomed to aggressive
policing because they were directed to do so by their own artificial
intelligence?

The future may be one in which robots of all kinds are so ubiquitous that even
the heavy presence of police robots in some places would be unnoticeable. That
seems unlikely. Instead, it seems plausible that the introduction of an
all-seeing, interconnected, and tireless army of police robots into a
neighborhood could feel like an occupation or virtual imprisonment.

E. Who Will Decide These Questions?

   The regulation of police robots will prove to be especially difficult because
robots will likely be adopted and regulated much like other recent police
technologies: in an ad hoc and decentralized manner. Most of this can be
attributed to the structure of policing in the United States, which is largely a
matter for state and local agencies.

   Consider the immense interest in body camera adoption after a string of
highly publicized and controversial deaths of African Americans in police
custody, beginning with the 2014 fatal shooting of Michael Brown in Ferguson.
Before 2014, body cameras had been adopted by a handful of police departments.
Today, it seems all but inevitable that body cameras will become a standard
patrol tool. The federal government has encouraged that adoption. In its
discussion of new police technologies, the President's Task Force on 21st
Century Policing acknowledged in its 2015 report that body cameras could "build
community trust and legitimacy" with appropriate regulations.  n128 That same
[*541]  year, the Department of Justice made more than $ 20 million available to
local police departments to purchase body cameras.  n129

   Eager to present them as tools of accountability, police departments around
the country have embraced the adoption of body cameras. Yet many police
departments have adopted body cameras without detailed policies on their use,
public access, and data storage. Those body camera policies that do exist can
vary considerably:  n130 Seattle posted all of its pilot project body camera
footage on YouTube,  n131 while other departments have declined to release
footage unless required by court order.  n132

   The story of police body camera adoption thus far has been: use first,
regulate later. Without planning, the use of police robots will develop in the
same way, with more serious consequences. Should the arming of police robots,
for example, be left to local departments? Should the type of artificial
intelligence used by police robots depend on the access of private vendors to
police departments? Machines that may be equipped with artificial intelligence
and capable of coercive force are poor candidates for highly variable local
control.

   Instead, uniform national policies should dictate the regulation of robotic
policing. Even if robots of the sort described here have yet to arrive, we can
anticipate the sorts of questions that robotics will bring to policing. The
degree of human involvement in robotic decisionmaking, whether and how to arm
police robots, and how to evaluate the legal responsibility of a police robot:
These are all normative judgments about law and policy. In the absence of
uniform policies, we are likely to address these questions in a piecemeal
fashion: a mix of unenforceable internal policies, hesitant state legislatures,
possibly conflicting federal  [*542]  agency decisions, and court cases in which
judges cannot agree as to the appropriate characterization of robots.  n133

   We could begin with a national body to develop robotics expertise that could
advise federal, state, and local lawmakers. A "federal robotics commission," for
instance, could identify important legal and policy questions raised by robotics
in a variety of areas--including policing--with specific substantive
recommendations.  n134

   More concretely, the federal government can wield its considerable resources
to influence how local police departments use robots. While the federal
government cannot force state and local police to adopt particular policies,
n135 the Department of Justice can and has influenced the adoption of new
strategies and technologies through the use of federal funding. For example, the
widespread interest in and adoption of body-worn cameras by local police
departments in 2015 has been prompted in part by the availability of federal
funding for body camera purchases. Likewise, the Department of Justice offers
funding to local police departments in order to purchase predictive policing
systems.  n136

   The federal government could condition the receipt of federal funds upon the
adoption of regulations by grantees.  n137 Police departments could receive
funding for robots so long as they, for instance, did not enable the robots to
use deadly force without specific guidelines already in place. No police
department would be forced to accept a robot under these conditions, but every
department that sought federal funding would be obliged to follow these
conditions. A top-down form of strong encouragement by the federal government
could be effective in setting uniform policies for police robots.

    [*543]  CONCLUSION

   The future introduction of artificially intelligent robots capable of
conducting human-like tasks is likely to change policing in the same way it will
change other fields. Assuming even some of the traditional tasks of policing by
robots, however, will pose special problems. We will have to address how much
coercive force police robots should possess, and to what degree they should be
permitted to operate independently. In some cases, the use of police robots may
increase the safety of policing, for both officers and the public. In other
cases, however, the use of police robots to detain or subdue a suspect may raise
challenges to the conventional ways in which we have regulated the police. While
we cannot anticipate every issue that this technology raises, we can address
many of them now, well before these hypotheticals find their way to our streets.

Legal Topics:

For related research and practice materials, see the following legal topics:
Computer & Internet LawCopyright ProtectionCivil Infringement ActionsOwner
RightsAdaptationComputer & Internet LawCriminal OffensesData Crimes &
FraudGovernmentsLocal GovernmentsPolice Power

FOOTNOTES:





n1  Andrea Peterson, In an Apparent First, Dallas Police Used a Robot to Deliver
Bomb That Killed Shooting Suspect, WASH. POST (July 8, 2016),
https://www.washingtonpost.com/news/the-switch/wp/2016/07/08/dallas-police-used-
a-robot-to-deliver-bomb-that-killed-shooting-suspect
[https://perma.cc/EE7K-ADUH] (quoting Brown as stating police "saw no other
option but to use our bomb robot and place a device on its extension for it to
detonate where the subject was").





n2  Joel Achenbach et al., Five Dallas Police Officers Were Killed by a Lone
Attacker, Authorities Say, WASH. POST (July 8, 2016),
https://www.washingtonpost.com/news/moming-mix/wp/2016/07/08/like-a-little-war-s
nipers-shoot-11-police-officers-during-dallas-protest-march-killing-five
[https://perma.cc/3UVS-FAJF].





n3  W.J. Hennigan & Brian Bennett, Dallas Police Used a Robot to Kill a Gunman,
a New Tactic That Raises Ethical Questions, L.A. TIMES (July 8, 2016, 2:22 PM),
http://www.latimes.com/nation/la-na-dallas-robot-20160708-snap-story.html
[https://perma.cc/93GC-2YS5] (quoting Ryan Calo as stating robot use is "a
creative solution to a very challenging problem").





n4  Dpdpio, Investigative Update Regarding the Deadly Attack on Police Officers,
DPD BEAT,
https://dpdbeat.com/2016/07/08/investigative-update-regarding-the-deadly-attack-
on-police-officers [https://perma.cc/MG7W-M77K] (last updated July 10, 2016).





n5  Jon Swaine, Dallas Police Reveal Details of Bomb-Carrying Robots It Used as
a Last Resort', GUARDIAN (July 10, 2016, 3:12 PM),
https://www.theguardian.com/us-news/2016/jul/10/dallas-police-reveal-details-of-
bomb-carrying-robot-it-used-as-last-resort [https://perma.cc/PAQ8SQPB].





n6  Jack Nicas, Dallas Police Believed to Be First to Use Robot Lethally, WALL
STREET J. (July 8, 2016, 6:34 PM),
http://www.wsj.com/articles/dallas-police-believed-to-be-first-to-use-robot-leth
ally-1468001810 [https://perma.cc/3MJ9-BPHB]; Sam Thielman, Use of Police Robots
to Kill Dallas Shooting Suspect Believed to Be First in U.S. History, GUARDIAN
(July 8, 2016, 12:31 PM),
https://www.theguardian.com/technology/2016/jul/08/police-bomb-robot-explosive-k
illed-suspect-dallas [https://perma.cc/CU68-JSNC].





n7  See Peterson, supra note 1 ("But bomb disposal robots typically work like
advanced remote-controlled vehicles, featuring camera feeds that are transmitted
back to operators so that they can direct the units in potentially dangerous
situations from afar.").





n8  Patrick Tucker, Militaiy Robotics Makers See a Future for Armed Police
Robots, DEF. ONE (July 11, 2016),
http://www.defenseone.com/technology/2016/07/military-robotics-makers-see-future
-armed-police-robots/129769 [https://perma.cc/ZCF2-GH9M].





n9  DAN GETTINGER & ARTHUR HOLLAND MICHEL, CTR. FOR THE STUDY OF THE DRONE, LAW
ENFORCEMENT ROBOTS DATASHEET (2016),
http://dronecenter.bard.edu/files/2016/07/LEO-Robots-CSD-7-16-1.pdf
[https://perma.cc/3BPW-NNUF] (using public records to document the hundreds of
robots acquired by law enforcement agencies).





n10  Like "robots," the definition of "artificial intelligence" has been subject
to some debate, but generally the term refers to "a set of technologies that try
to imitate or augment human intelligence." See Om Malik, The Hype--and Hope--of
Artificial Intelligence, NEW YORKER (Aug. 26, 2016),
http://www.newyorker.com/business/currency/the-hype-and-hope-of-artificial-intel
ligence [https://perma.cc/Y69E-Y4QE].





n11  For instance, the Rand Corporation reported that in a workshop attended by
law enforcement officials and academics, participants "envisioned the emergence
of automated or robotic policing." RICHARD SILBERGLITT ET AL., VISIONS OF LAW
ENFORCEMENT TECHNOLOGY IN THE PERIOD 2024-2034, at 24 (2015).





n12  Editorial Board, When Police Use Lethal Robots, N.Y. TIMES: OPINION
PAGES(July 12, 2016), http://nyti.ms/29DSUyA ("[T]his seems an ideal time to
define the limits on armed robots . . . .").





n13  In 2003, the Spartan Scout, a robotic boat mounted with a loudspeaker and
microphone, inspected civilian boats in the Persian Gulf without anyone onboard.
James Dunnigan, Robotic Ship Talks to Startled Sailors, STRATEGYPAGE (June 14,
2005), https://www.strategypage.com/dls/articles2005/200561415554.asp
[https://perma.cc/27GE-U8GR].





n14  On the possibility of DNA "Terry" stops, see Elizabeth E. Joh, Maryland v.
King: Policing and Genetic Privacy, 11 OHIO ST. J. CRIM. L. 281,291-93 (2013).





n15  Such bug drones are being developed for use in the military. See, e.g.,
John Horgan, Unmanned Flight, NAT'L GEOGRAPHIC (Mar. 2013),
http://ngm.nationalgeographic.com/2013/03/unmanned-flight/horgan-text
[https://perma.cc/2LGL-4VVEB].





n16  Albert J. Reiss, Jr., Police Organization in the Twentieth Centwy, in 15
CRIME & JUSTICE 51, 51-52 (1992).





n17  Monisha Rajesh, Inside Japan's First Robot-Steed Hotel, GUARDIAN (Aug. 14,
2015, 2:00 PM),
http://www.theguardian.com/trave1/2015/aug/14/japan-henn-na-hotel-staffed-by-rob
ots [https://perma.cc/6RU6-KUCP].





n18  Hugo Martin, Robots Deliver Fun With Hotel Room Service Orders, and They
Don't Expect a Tip, L.A. TIMES (Feb. 7, 2016, 3:00 PM),
http://www.latimes.com/business/la-fi-hotel-robots-20160207-story.html
[https://perma.cc/4REP-QPKD].





n19  Jonathan Holmes, AI Is Already Making Inroads Into Journalism but Could It
Win a Pulitzer?, GUARDIAN (Apr. 3, 2016, 1:13 PM),
http://www.theguardian.com/media/2016/apr/03/artificla-intelligence-robot-report
er-pulitzer-prize?CMP=edit_2221 [https://perma.cc/W6EJ-VTW8].





n20  See P.W. SINGER, WIRED FOR WAR: THE ROBOTICS REVOLUTION AND CONFLICT IN THE
TWENTY-FIRST CENTURY 77 (2009) (quoting Sebastian Thrun, director of the
Artificial Intelligence Laboratory at Stanford University, in defining
artificial intelligence as "the ability of a machine to 'perceive something
complex and make appropriate decisions'").





n21  Michael Schaub, Is the Future Award-Winning Novelist a Writing Robot?, L.A.
TIMES (Mar. 22, 2016, 10:30 AM),
http://www.latimes.com/books/jacketcopy/la-et-jc-novel-computer-writing-japan-20
160322-story.html [https://perma.cc/VFS5-ZRAX].





n22  See, e.g., Peter Finn, A Future For Drones: Automated Killing, WASH. POST
(Sept. 19, 2011),
https://www.washingtonpost.com/national/national-security/a-future-for-drones-au
tomated-killing/2011/09/15/gIQAVy9mgE_story.html [https://perma.cc/BMB8-PAVY]
(noting that when military drones "are directly linked to human operators, these
machines are producing so much data that processors are sifting the material to
suggest targets, or at least objects of interest"); The Changing Shapes of Air
Power, N.Y. TIMES (June 19, 2011),
http://www.nytimes.com/interactive/2011/06/19/world/drone-graphic.html
[https://perma.cd3Y84-D22F] (describing Reaper as "hunter-killer" aircraft armed
with Hellfire surface-to-air missiles).





n23  Aarian Marshall, The Robot Garbage Collectors Are Coming, ATLANTIC: CITYLAB
(Mar. 1, 2016),
http://www.citylab.com/tech/2016/03/the-robot-garbage-collectors-are-coming/4714
29 [https://perma.cc/F222-KAV5] (describing self-driving, garbage-collecting
prototype developed by Volvo); Cat Zakrzeweski, Autonomous Delively Vehicle
Company Dispatch Drives $ 2M in Seed Funding, WALL STREET J. (Apr. 6, 2016, 9:23
AM),
http://blogs.wsj.com/venturecapita1/2016/04/06/autonomous-delivery-vehicle-compa
ny-dispatch-drives-2m-in-seed-funding [https://perma.cc/P2LU-FKEP] (announcing
funding for on-demand autonomous delivery robots).





n24  Sam Byford, This Cuddly Japanese Robot Bear Could Be the Future of Elderly
Care, VERGE (Apr. 28, 2015, 10:24 A1 4),
http://www.theverge.com/2015/4/28/8507049/robear-robot-bear-japanelderly
[https://perma.cc/UM89-MM46]; Will Knight, Your Retirement May Include a Robot
Helper, MIT TECH. REV. (Oct. 27, 2014),
https://www.technologyreview.com/s/531941/your-retirement-may-include-a-robot-he
lper [https://perma.cc/4R94-497X].





n25  Rebecca Linke, Meet Pepper, the Dancing Robot, COMPUTERWORLD: EMERGING
TECH. (Mar. 18, 2016, 7:37 AM),
http://www.computerwor1d.com/artic1e/3045642/emergingtechnology/meet-pepper-the-
dancing-robot.html [https://perma.cc/A74N-297W].





n26  See Joseph George, 'Robot Cop' May Be on Patrol by 2020, EMIRATES24/7 (June
1, 2016),
http://www.emirates247.com/news/robot-cop-may-be-on-patrol-by-2020-2016-06-01-1.
631688 [https://perma.cc/8WQG-2499]; Real Robocops of Dubai: UAE to Introduce
Police Robots Within Two Years,' RT (Apr. 27, 2015, 8:36 PM),
https://www.rt.com/news/253529-police-robot-dubai-robocop
[https://perma.cc/YV3A-CHDW].





n27  Liang Jun, China's First Intelligent Security Robot Debuts in Chongqing,
PEOPLE'S DAILY ONLINE (Apr. 26, 2016, 7:27 AM),
http://en.people.cn/n3/2016/0426/c90000-9049431.html
[https://perma.cc/WNY3-HMS6]; see also Stephen Chen, Meet China's RoboCop: The
Robot Police Officer Who Doesn't Tire--or Second-Guess Commands, S. CHINA
MORNING POST (May 5, 2016, 11:20 AM),
http://www.scmp.com/news/china/policies-politics/article/1941394/meet-chinas-rob
ocop-robot-police-officer-who-doesnt [https://perma.cc/HY26-SM6X].





n28  Nicky Woolf, RoboCop Is Real--and Could Be Patrolling a Mall Near You,
GUARDIAN (May 20, 2016, 6:30 PM),
https://www.theguardian.com/us-news/2016/may/20/robocop-robot-mall-security-guar
d-palo-alto-califomia [https://perma.cc/R8VL-HLG3] ("They are completely
autonomous, navigating like self-driving cars.").





n29  The emerging scholarship on the regulation of robots has already suggested
that robotics law could learn from the mistakes and successes of early cyberlaw
scholarship. See, e.g., Ryan Cab, Robotics and the Lessons of Cyberlaw, 103
CALIF. L. REV. 513, 514-516 (2015) (observing similarities between two bodies of
scholarship).





n30  I assume that capability would be no different than human officers who are
entitled to use coercive force, even lethal force, when the circumstances
warrant such use.





n31  See Tucker, supra note 8 (quoting Endeavor Robotics CEO Sean Bielat as
saying: "We aren't the ones who are going to think of these end use cases. It's
going to be the end users as they get closer to the technology, as it gets more
capable and less expensive. It's going to be the end user who says, 'wow, this
additional capability would really make a difference and would really make my
job safer if it had some level of armament on it.'").





n32  See, e.g., SINGER, supra note 2067, 423 (observing that "much of the
funding for robotics research comes from the military").





n33  See, e.g., Andrew Guthrie Ferguson, Predictive Policing and Reasonable
Suspicion, 62 EMORY L. REV. 259, 269 (2012) (noting local police department
adoption of predictive policing programs purchased federal funding from the
Department of Justice); Justice Department Awards Over $ 23 Million in Funding
for Body Worn Camera Pilot Program to Support Law Enforcement Agencies in 32
States, U.S. DEP'T JUST. (Sept. 21, 2015),
https://www.justice.gov/opa/pr/justice-department-awards-over-23-million-funding
-body-worn-camera-pilot-program-support-law [https://perma.cc/83WS-Q69N].





n34  See Zoltan Istvan, The Second Amendment Isn't Prepared for a 3D-Printed
Drone Army, MOTHERBOARD (Mar. 25, 2016, 8:00 AM),
http://motherboard.vice.com/read/the-second-amendment-isnt-prepared-for-a-3d-pri
nted-drone-army?utm_source=mbtwitter [https://perma.cc/9RAJ-SUL2].





n35  See, e.g., Robert Shrimsley, Are We Ready to Live With Robots?, FIN. TIMES
(May 6, 2016),
http://www.ft.com/cms/s/2/51d964c6-11dd-11e6-91da-096d89bd2173.html#axzz4FAV3fTB
U [https://perma.cc/7LRP-GMVW] (referring to Lang's "machine-human").





n36  Louise Chan, Not Quite 'The Jetsons' Rosie but Researchers Are Working on
Building Robot Maids of the Future, TECH TIMES (Jan. 16, 2016, 10:11 AM),
http://www.techtimes.com/articles/124943/20160116/not-quite-the-jetsons-rosie-bu
t-researchers-are-working-oxxpn-building-robot-maids-of-the-future.htm
[https://perma.cc/HB2A-SUTV].





n37  See, e.g., Michael Froomkin, Introduction to ROBOT LAW x, xi (Ryan Calo et
al. eds., 2016) ("There is not yet a consensus regarding what should count as a
robot.").





n38  See SINGER, supra note 20, at 67 (offering this definition); Cab, supra
note 29, at 529-32 (same); see also Neil M. Richards & William D. Smart, How
Should the Law Think About Robots?, in ROBOT LAW, supra note 37, at 3, 6 ("A
robot is a constructed system that displays both physical and mental agency, but
is not alive in the biological sense."). But see Adrienne Lafrance, What Is a
Robot?, ATLANTIC (Mar. 22, 2016),
http://www.theatlantic.com/technology/archive/2016/03/what-is-a-human/473166
[https://perma.cc/237A-6L3L] (observing that there is no clear consensus on
defining a robot).





n39  See, e.g., Cyrus Farivar, Dark Web Drug-Buying Bot Returned to Swiss
Artists After Police Seizure, ARSTECHNICA (Apr. 15, 2015, 12:50 PM),
http://arstechnica.com/tech-policy/2015/04/dark-web-drug-buying-bot-retumed-to-s
wiss-artists-after-police-seizure [https://perma.cc/TKH6-SYMF].





n40  See, e.g., Knight, supra note 24.





n41  SINGER, supra note 20, at 92.





n42  Calo, supra note 29, at 532.





n43  See, e.g., Chris Bryant & Richard Waters, Worker at Volkswagen Plant Killed
in Robot Accident, FINANCIAL TIMES (July 1, 2015),
http://www.ft.com/cms/s/0/0c8034a6-200f-11e5-aa5a-398b2169cf79.html#axzz4LUmfb9p
(describing technician killed by industrial robot in Germany).





n44  Ryan Calo describes this kind of action as "emergence," meaning
"unpredictably useful behavior." Calo, supra note 29, at 532.





n45  See SINGER, supra note 20, at 74.





n46  Abby Ohlheiser, Trolls Turned Tay, Microsoft's Fun Millennial AI Bot, Into
a Genocidal Maniac, WASH. POST (Mar. 25, 2016),
https://www.washingtonpost.com/news/the-intersect/wp/2016/03/24/the-internet-tur
ned-tay-microsofts-fun-millennial-ai-bot-into-a-genocidal-maniac/
[https://perma.cc/5J3G-2JEK].





n47  A related but distinct issue in big data analytics is that artificial
intelligence is becoming so sophisticated that while we may understand the
results achieved by algorithms, we may not understand the "whyness" of the
process leading to the result. See, e.g., Ahmed Ghappour, Machine Generated
Culpability (unpublished manuscript) (summarized at HTNM Lecture--Ahmed
Ghappour--"Machine Generated Culpability, BERKELEY CTR. FOR NEW MEDIA (Nov. 9,
2016),
http://bcnm.berkeley.edu/events/event/htnm-lecture-ahmed-ghappour-machine-genera
ted-culpability/http://bcnm.berkeley.edu/events/event/htnm-lecture-ahmed-ghappou
r-machine-generated-culpability) (explaining how "the use of machine-generated
culpability add the issue of 'whyness'").





n48  See, e.g., Elizabeth E. Joh, Policing by Numbers: Big Data and the Fourth
Amendment, 89 WASH. L. REV. 35, 42-48 (2014).





n49  Ryan Calo describes this as the "social valence" of robots. Calo, supra
note 29, at 545-46.





n50  See, e.g., Tim Radford, Touching Robots Can Arouse Humans, Study Finds,
WASH. POST (Apr. 5, 2016. 5:00 EDT),
https://www.theguardian.com/technology/2016/apr/05/touching-robots-can-arouse-hu
mans-study-finds [https://perma.cc/Y6YV-2VYL] (experiment demonstrates "a touch
where the robot's buttocks or genitals would be produced a measurable response
of arousal in the volunteer human").





n51  Kate Darling suggests that we may want to prevent the abuse of "social"
robots because doing so would protect social values. Kate Darling, Extending
Legal Protection to Social Robots, in ROBOT LAW, supra note 37, at 213, 223-24.





n52  See, e.g., James Temperton, Campaign Calls for Ban on Sex Robots, WIRED
(Sept. 15, 2015),
http://www.wired.co.uk/news/archive/2015-09/15/campaign-against-sex-robots
[https://perma.cc/3Q7K-DGVA4].





n53  See Cab, supra note 29, at 549.





n54  See SINGER, supra note 20, at 78 (observing that the "military sets the
agenda in AI").





n55  Emma Cott, Navy Robots Test the Limits of Autonomy, N.Y. TIMES (May 6,
2015), http://nyti.ms/1AFU53d.





n56  In 1999, the Army introduced an ambitious multiyear and multibillion dollar
program called Future Combat Systems (FCS), which was intended to revolutionize
warfare by developing new manned and unmanned systems linked by modernized
communications networks. See ANDREW FEICKERT, CONG. RESEARCH SERV., THE ARMY'S
FUTURE COMBAT SYSTEM (FCS): BACKGROUND AND ISSUES FOR CONGRESS 1-2 (2009),
https://www.fas.org/sgp/crs/weapons/RL32888.pdf. The FCS was effectively shut
down in 2009 by Secretary of Defense Gates, yet robotics still remain a part of
the Army's planning, albeit not in its original form. Id. at 3.





n57  Cf.. SINGER, supra note 20, at 78 (observing that "the U.S. military finds
as much as 80 percent of all AI research in the United States").





n58  Id. at 32-38.





n59  See, e.g., Ian Kerr & Katie Szilagyi, Asleep at the Switch? How Killer
Robots Become a Force Multiplier of Militaly Necessity, in ROBOT LAW, supra note
37, at 333, 362 n.139 (noting that the term refers "to a factor that
significantly enhances the effectiveness or strategic advantage of a particular
force").





n60  SINGER, supra note 20, at 133.





n61  Matthew Power, Confessions of a Drone Warrior, GQ (Oct. 22, 2013, 8:00 PM),
http://www.gq.com/stoty/drone-uav-pilot-assassination
[https://perma.cc/N4KW-LG4P].





n62  See, e.g., Kelsey D. Atherton, Robot Submarine Launches Drone at Command of
Autonomous Navy Ship, POPULAR SCI. (Sept. 28, 2016),
http://www.popsci.com/underwater-robot-launches-drone-at-command-other-robot-shi
p [https://perma.cd5KJE-C9NE] (describing robot-to-robot command as part of Navy
technology exercise).





n63  SINGER, supra note 20, at 112.





n64  See, e.g., Richard A. Friedman, Why Are We Drugging Our Soldiers?, N.Y.
TIMES (Apr. 21, 2012), http://nyti.ms/1DyTRLA [https://perma.cc/DA7R-8JD7]
(discussing "significant increase in the use of stimulant medication" for
soldiers).





n65  SINGER, supra note 20, at 298 (discussing psychological effects of robot
soldiers on opposing forces).





n66  Id. at 308-09 (discussing possible counterintuitive psychological effects
of robot soldiers on opposing forces).





n67  Id. at 230-34 (describing how robot swarms work).





n68  Albert J. Reiss, Jr., Police Organization in the Twentieth Century, 15
CRIME & JUSTICE 51, 80 (1992) (noting late nineteenth century adoption of "the
basic hierarchical rank organization of the military to insure internal
discipline and control").





n69  See, e.g., Robert Salonga, San Jose Police Accepting Militaly Service in
Place of College in Attempt to Boost Anemic Recruiting, MERCURY NEWS (Mar. 21,
2016, 11:17 AM),
http://www.mercurynews.com/crime-courts/ci_29666424/san-jose-police-accepting-mi
litary-service-place-college [https://perma.cc/7TYH-ZTBR].





n70  See, e.g., Ed Vulliamy, Nixon's "War on Drugs" Began 40 Years Ago, and the
Battle Is Still Raging, GUARDIAN (July 23, 2011),
https://www.theguardian.com/society/2011/ju/24/war-on-drugs-40-years
[https://perma.cc/X6RR-7FF3] (noting that President Nixon in a speech before
Congress on July 17, 1971 ushered in "war on drugs" era).





n71  18 U.S.C. § 1385 (2012) (prohibiting the unauthorized use of the Army or
Air Force as a posse comitatus).





n72  National Defense Authorization Act for Fiscal Year 1997 § 1033, 10 U.S.C. §
2576(a) (2012) ("The Secretary of Defense, under regulations prescribed by him,
may sell to State and local law enforcement, firefighting, homeland security,
and emergency management agencies, at fair market value, pistols, revolvers,
shotguns, rifles of a caliber not exceeding .30, ammunition for such firearms,
gas masks, personal protective equipment, and other appropriate equipment which.
. . have been determined to be surplus property . . . .").





n73  See, e.g., Benjamin Preston, Police Are Getting the Military's Leftover
Armored Trucks, N.Y. TIMES: WHEELS (Oct. 11, 2013, 6:00 AM),
http://wheels.blogs.nytimes.com/2013/10/11/police-are-getting-the-militarys-left
over-armored-trucks/?_r=0 [https://perma.cc/VP3B-JXWZ]. The Law Enforcement
Support Office, responsible for coordinating the 1033 program, states on its
website that more than 8000 law enforcement agencies have enrolled. See Law
Enforcement Support Office, DEF. LOGISTICS AGENCY,
http://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement.aspx
[https://perma.cc/UX,X9-TJY6].





n74  A Congressional Research Service report noted that the St. Louis county
police received twelve M16 rifles under the 1033 program as of July 2013. See
VALERIE BAILEY GRASSO, CONG. RESEARCH SERV., DEFENSE SURPLUS EQUIPMENT DISPOSAL,
INCLUDING THE LAW ENFORCEMENT 1033 PROGRAM 6(2014).





n75  See, e.g., Taylor Wofford, How America's Police Became an Army: The 1033
Program, NEWSWEEK (Aug. 13, 2014, 10:47 PM),
http://www.newsweek.com/how-americas-police-became-army-1033-program-264537
[https://perma.cc/GN4J-QMVP]. In 2015, the Obama administration announced that
it would ban transfers of certain types of equipment under the 1033 program
because of concerns about the increasing militarization of local police forces.
See David Nakamura & Wesley Lowery, Obama Administration Bans Some
Militiny-Style Assault Gear From Local Police Departments, WASH. POST (May 18,
2015),
haps://www.washingtonpost.com/news/postpolitics/wp/2015/05/18/obama-to-visit-cam
den-n-j-to-tout-community-policing-reforms [https://perma.cc/3EQ7-BQKM]; see
also LAW ENFORCEMENT EQUIPMENT WORKING GROUP, RECOMMENDATIONS PURSUANT TO
EXECUTIVE ORDER 13688: FEDERAL SUPPORT FOR LOCAL LAW ENFORCEMENT EQUIPMENT
ACQUISITION (2015),
https://www.whitehouse.gov/sites/default/files/docs/le_equipment_wg_final_report
_final.pdf [https://perma.cc/T9YQ3KPQ]. In July 2016, however, the White House
agreed to review each banned item from the program. See Julia Edwards,
Exclusive: White House to Review Ban on Military Gear for Police-Police Leaders,
REUTERS (July 21, 2016), http://www.reuters.
com/article/us-usa-police-gear-exclusive-idUSKCN1012KW
[https://perma.cc/L43M-BNT3].





n76  See, e.g., RADLEY BALKO, CATO INSTITUTE, OVERKILL: THE RISE OF PARAMILITARY
POLICE RAIDS IN AMERICA 6 (2006),
http://object.cato.org/sites/cato.org/files/pubs/pdf/balko_whitepaper_2006.pdf
[https://perma.cc/J463-CB3H] (attributing creation of SWAT teams to LAPD Chief
Daryl Gates in 1966).





n77  Such robots may not be as necessary in a future of self-driving cars. Law
enforcement agencies may in those situations have direct access to a vehicle's
computer in order to forcibly stop it. See generally JOHN S. HOLLYWOOD ET AL.,
USING FUTURE INTERNET TECHNOLOGIES TO STRENGTHEN CRIMINAL JUSTICE (2015),
http://www.rand.org/content/dam/rand/pubs/research_reports/RR900/RR928/RAND_RR92
8.pdf [https://perma.cc/F9UX-2QZS] (describing one future consideration by panel
of criminal justice experts for self-driving cars--though considered a low
priority--as "an interface for officers to directly take control of unmanned
vehicles").





n78  Paul Marks, Packs of Robots Will Hunt Down Uncooperative Humans, NEW
SCIENTIST (Oct. 22, 2008, 6:00 PM),
https://www.newscientist.corn/blogs/shortsharpscience/2008/10/packs-of-robots-wi
ll-hunt-down.html [https://perma.cc/W6Y3-EMBG].





n79  See, e.g., E.B. Boyd, Is Police Use of Force About to Get Worse--With
Robots?, POLITICO MAG. (Sept. 22, 2016),
http://www.politico.corn/magazine/stoiy/2016/09/police-robots-ethics-debate-2142
73 [https://perma.cc/H3NY-WSD4] (discussing current "man in the loop" limits).





n80  A distinct but equally important question is the degree to which the police
will be able to control citizen's robots without consent. Thanks to Ryan Calo
for this observation.





n81  As computer science professor David Gelertner points out, superhuman
artificial intelligence is likely to happen not because today's AI is so
advanced--it is not--but because such a technological leap requires a
"breakthrough," which, as Gelertner argues, is not hard to imagine. See David
Gelernter, Machines That Will Think and Feel, WALL STREET J. (Mar. 18, 2016,
10:36 AM), http://www.wsj.com/articles/when-machines-think-and-feel-1458311760.





n82  Kris Osborn, Pentagon Project Seeks to Build Autonomous Robots, DEF. TECH
(June 13, 2013),
http://www.defensetech.org/2013/06/13/pentagon-launches-pilot-to-build-autonomou
s-robots [https://perma.cc/Z2PJ-LGCR]. Peter Singer notes that the U.S. military
funds as much as 80 percent of all AI research in the United States. See SINGER,
supra note 20, at 78.





n83  See Gelernter, supra note 81.





n84  Id.





n85  See SINGER, supra note 20, at 30 ("Unlike the PackBot, the [armed Talon]
SWORDS . . . is remote-controlled from afar by either radio or a spooled-out
fiber optic wire.").





n86  Id. at 36.





n87  Id. at 128 ("So, despite what one article called 'all the lip service paid
to keeping a human in the loop,' autonomous armed robots are coming to war.").





n88  Id. at 75 ("If robots don't get higher on the autonomy scale, they don't
yield any cost or manpower savings.").





n89  Id. at 127 ("The very best human fighter pilot needs at least .3 seconds to
respond to any simple stimulus and twice as long to make a choice between
several possible consequences. A robotic pilot needs less than a millionth of a
second.").





n90  See Osborn, supra note 82.





n91  Ghappour, supra note 47.





n92  Kavita Iyer, Engineers Unable to Understand the Workings of Google's Search
AI, TECHWORM (Mar. 10, 2016),
http://www.techworm.net/2016/03/engineers-unable-understand-working-googles-sear
ch-ai.html [https://perma.cc/GUC4-33SE].





n93  See, e.g., Andy Greenberg, The Jeep Hackers Are Back to Prove Car Hacking
Can Get Much Worse, WIRED (Aug. 1, 2016, 3:30 PM),
https://www.wired.com/2016/08/jeep-hackers-return-highs-peed-steering-accelerati
on-hacks [https://perma.cc/7Q29-BMS6]; Alexandra Ossola, Hacked Medical Devices
May Be the Biggest Cyber Security Threat in 2016, POPULAR SCI. (Nov. 23, 2015),
http://www.popsd.corn/hackers-could-soon-hold-your-Hfe-ransom-by-hijacking-your-
medicaldevices [https://perma.cc/SR8Q;HYZM].





n94  Dan Lamothe, The Killer Robot Threat: Pentagon Examining How Enemy Nations
Could Empower Machines, WASH. POST (Mar. 30, 2016),
https://www.washingtonpost.com/news/checkpoint/wp/2016/03/30/the-killer-robot-th
reat-pentagon-examining-how-enemy-nations-could-empower-machines
[https://perma.cc/NXX5-K25B].





n95  See SINGER, supra note 20, at 124.





n96  See id. (reporting the Pentagon's concern on this issue).





n97  Mark Jewell, Taser, iRobot Team up to Arm Robots, WASH. POST (June 28,
2007, 11:04 PM),
http://wvvw.washingtonpostxom/wp-dyrn/content/artide/2007/06/28/AR2007062801338.
html [https://perma.cc/7KWK-UVZG].





n98  See, e.g., Roberto Baldwin, What Is the LRAD Sound Cannon?, GlZMODO (Aug.
14, 2014, 11:40 AM), http://gizmodo.com/what-is-the-lrad-sound-cannon-5860592
[https://perma.cc/W6VF-F74L] (describing LRAD as a device intended to "broadcast
messages and pain-inducing 'deterrent' tones over long distances").





n99  iRobot and Taser Team to Deliver New Robot Capabilities for Military, Law
Enforcement, IROBOT (June 28, 2007),
http://investor.irobot.com/phoenix.zhtml?c=193096&p=irol-newsArticle&ID=1334071
[https://perma.cc/MSJ5-SGXT].





n100  USA: Excessive and Lethal Force? Amnesty International's Concerns About
Deaths and Ill-Treatment Involving Police Use of Tasers, AMNESTY INT'L USA (Nov.
29, 2004), http://www.amnestyusa.org/node/55449 [https://perma.cc/BW9C-XWAW].





n101  See, e.g., Laura Crimaldi & Jan Ransom, Civil Rights Groups Express
Concern Over State Police Turning to Tasers, BOS. GLOBE (Mar. 31, 2016),
https://www.bostonglobe.com/metro/2016/03/31/state-police-troopers-outfitted-wit
h-tasers/uY2RvuJfMYiZOWxDgjAGCN/story.html [https://perma.cc/92GQ-QJLW]
(discussing adoption of Tasers by Massachusetts State Police as "part of a
larger effort to equip troopers to ratchet down potentially violent
confrontations"); Vivian Ho, SFs Next Police Chief Faces Mountain of Challenges,
S.F. CHRONICLE (May 23, 2016, 7:00 AM),
http://www.sfchronicle.com/crime/article/SF-s-next-police-chief-faces-mountain-o
f-7938997.php [https://perma.cc/PJ2H-HELJ] (discussing SFPD consideration of
adopting Tasers as part of departmental changes).





n102  See CAMPAIGN TO STOP KILLER ROBOTS, https://www.stopkillerrobots.org
[https://perma.cc/U4U7-95ZN].





n103  Cheryl W. Thompson &Mark Berman, Improper Techniques, Increased Risks,
WASH. POST (Nov. 26, 2015),
http://www.washingtonpost.com/sf/investigative/2015/11/26/improper-techniques-in
creased-risks [https://perma.cc/G6KN-9859].





n104  Noel Sharkey et al, The Coming Robot Crime Wave, 43 COMPUTER 116, 114
(2010) (describing such a robot).





n105  Cf. James B. Jacobs, Exceptions to a General Prohibition on Handgun
Possession: Do They Swallow Up the Rule?, 49 L. & CONTEMP. PROBS. 5, 20 (1986)
("Like the international arms race, there seems to be an inexorable drive to
accumulate more powerful weaponry.").





n106  Rick Noack, 5 Countries Where Most Police Officers Do Not Carry
Firearms--and It Works Well, WASH. POST July 8, 2015),
https://www.washingtonpost.com/news/worldviews/wp/2015/02/18/5-countries-where-p
olice-ofEcers-do-not-carry-firearms-and-it-works-well
[https://perma.cc/VY65-YCV8] (noting that police on patrol are unarmed in
Britain, Ireland, Norway, Iceland, and New Zealand).





n107  I assume here that a robot shooting would constitute a Fourth Amendment
"seizure," although robotic Fourth Amendment seizures may not always be obvious.
If a robot that is entirely remotely controlled detains a person, that action
may constitute "a governmental termination of freedom of movement through means
intentionally applied." See Brower v. County of Inyo, 489 U.S. 593, 596-97
(1989). On the other hand, is an autonomous robot's "accidental" infliction of
injury or death a Fourth Amendment seizure? See generally Jason Green, Report:
Security Robot at Stanford Shopping Center Runs Over Toddler, MERCURY NEWS (July
12, 2016, 8:25 AM),
http://www.mercurynews.com/ci_30118119/report-security-robot-at-stanford-shoppin
g-mall-injures [https://perma.cc/L888-P88R] (discussing incident in which
autonomous 300 pound Knightscope private security robot reportedly ran over
toddler); Woolf, supra note 28 (noting Knightscope robots are "completely
autonomous, navigating like self-driving cars").





n108  The Fourth Amendment guarantees "the right of the people to be secure in
their persons, houses, papers, and effects, from unreasonable searches and
seizures." U.S. CONST, amend. IV.





n109  Tennessee v. Gamer, 471 U.S. 1,11-12(1985).





n110  Scott v. Harris, 550 U.S. 372, 383 (2007).





n111  Graham v. Connor, 490 U.S. 386, 396-97 (1989).





n112  Id. at 396.





n113  Id. at 397.





n114  For an insightful critique of the existing Fourth Amendment use of force
doctrine, see generally Brandon Garrett & Seth Stoughton, A Tactical Fourth
Amendment, 102 VA. L. REV. (forthcoming 2017) (manuscript at 4),
http://papers.ssm.com/sol3/papers.cfm?abstract_id=2754759.





n115  Cf. Graham, 490 U.S. at 396-97 ("The calculus of reasonableness must
embody allowance for the fact that police officers are often forced to make
split-second judgments--in circumstances that are tense, uncertain, and rapidly
evolving--about the amount of force that is necessary in a particular
situation.").





n116  See, e.g., Kathryn R. Urbonya, Dangerous Mispercetions: Protecting Police
Officers, Society, and the Fourth Amendment Right to Personal Security, 22
HASTINGS CONST. L.Q. 623, 654 (1995) (noting courts perceive "scrutiny as [an]
impermissible second-guessing of split-second judgments made by police
officers"); cf. Seth W. Stoughton, Policing Facts, 88 TULANE L. REV. 847, 852
(2014) ("With regard to uses of force, the [U.S. Supreme] Court believes that
officers use violence in an environment that demands 'split second judgments,'
justifying significant deference to an officer's decision of whether to use
force and what force to use. However, only a very small percentage of
use-of-force incidents resemble the Court's intuitions, suggesting that the
standard used to review police violence may not often fit the circumstances of
the incident itself.").





n117  Nolan Bushnell, the founder of Atari, stated in 1984 that the ultimate
role of robots would be "slaves." Iver Peterson, World's Most Expensive Pet
Seeks a Rolein Life, N.Y. TIMES (Apr. 17, 1984),
http://www.nytimes.com/1984/04/17/us/world-s-most-expensive-pet-seeks-a-role-in-
life.html [https://perma.cc/T7PQ-HHK3].





n118  They would be entitled, presumably, to protect the lives of others from
harm. See Graham, 490 U.S. at 396 (noting the factor of "whether the suspect
poses an immediate threat to the safety of the officers or others").





n119  See Richard Fisher, Is It OK to Torture or Murder a Robot?, BBC (Nov. 27,
2013), http://www.bbc.com/future/stoiy/20131127-would-you-murder-a-robot
[https://perma.cc/69J4-5TX7].





n120  Daniela Hernandez, Hitchbot "Murder" Has Researchers Worry About Robot
Cruelty, FUSION (Aug. 3, 2015, 5:17 PM),
http://fusion.net/story/176834/hitchbot-murder-robot-cruelty
[https://perma.cc/4K8P-JRKM].





n121  See, e.g., Andrew Guthrie Ferguson, Predictive Policing and Reasonable
Suspicion, 62 EMORY LJ. 259, 265 (2015). As Ferguson notes, "predictive policing
" can sometimes be used to describe any crime fighting approach involving
analysis of a large set of data, but here I use the term to refer specifically
to the use of predictive analytics.





n122  See, e.g., Predictive Policing, NAT'L INST. JUST.,
http://www.nij.gov/topics/law-enforcement/strategies/predictive-policing/
Pages/welcome.aspx [https://perma.cc/525K-ZGMX] (last updated June 9, 2014).





n123  Nate Berg, Predicting Crime, LAPD-Style, GUARDIAN June 25, 2014, 5:19 AM),
https://www.theguardian.com/cities/2014/jun/25/predicting-crime-lapd-los-angeles
-police-data-analysis-algorithm-minority-report [https://perma.cc/2FEC-4TCS];
Somini Sengupta, In Hot Pursuit of Numbers to Ward Off Crime, N.Y. TIMES: BITS
June 19, 2013, 10:48 PM),
http://bits.blogs.nytimes.com/2013/06/19/in-hot-pursuit-of-numbers-to-ward-off-c
rime [https://perma.cc/7HAU-BVF7].





n124  See, e.g., Peter Moskos, The Better Part of Valor: Court-Overtime Pay as
the Main Determinant for Police Discretionary Arrests, 8 LAW ENFORCEMENT
EXECUTIVE F. 77, 81 (2008) ("Overall, the literature establishes that police
exercise considerable discretion in their day-to-day arrest decisions.").





n125  See, e.g., Ferguson, supra note 121, at 317 (noting that "not all crime is
reported, not all crime is recorded, and thus, not all crime is included in
crime databases to be used for predictions").





n126  See, e.g., id. at 317.





n127  127. See, e.g., id. at 322 (observing that data-driven law enforcement can
have a disproportionate effect on certain communities that perceive it as
discriminatory").





n128  128. President's Task Force on 21st Century Policing, Final Report of the
President's Task Force on 21st Century Policing, COMMUNITY ORIENTED POLICING
SERVS. 31-32 (May 2015),
http://www.cops.usdoj.gov/pdf7taskforce/taskforce_finakeport.pdf
[https://perma.cc/4KQE-4HWL].





n129  See Justice Department Awards Over $ 23 Million in Funding for Body Worn
Camera Pilot Program to Support Law Enforcement Agencies in 32 States, U.S.
DEP'T JUST. (Sept. 21, 2015),
https://www.justice.gov/opa/pr/justice-department-awards-over-23-million-funding
-body-worn-camera-pilot-program-support-law [https://perma.cc/T2FA-FBV5].





n130  See, e.g., Elizabeth E. Joh, Beyond Surveillance: Data Control and Body
Cameras, 14 SURVEILLANCE & SOCY 133 (2016),
http://ojs.library.queensu.ca/index.php/surveillance-and-society/article/view/cd
ebate4/bc4.





n131  Wylie Wong & Phil Goldstein, Seattle Shares Body-Cam Footage on YouTube,
STATETECH (Jan. 21, 2016),
http://www.statetechmagazine.com/article/2016/01/seattle-shares-body-cam-footage
-youtube [https://perma.cc/SWN3-3KUL].





n132  See, e.g., Police Body Camera Policies: Retention and Release, BRENNAN
CTR. FOR JUST. (Aug. 3, 2016),
https://www.brennancenter.org/analysis/police-body-camera-policies-retention-and
release [https://perma.cc/X3AU-V8H9] (collecting available policies).





n133  See, e.g., Ryan Calo, Robots in American Law (Univ. of Wash. Sch. of Law
Legal Studies Research Paper, Paper No. 2016-04, 2016),
http://papers.ssm.com/sol3/papers.cfmPabstract_ict2737598 (discussing history of
robot characterization in American law).





n134  RYAN CALO, BROOKINGS, THE CASE FOR A FEDERAL ROBOTICS COMMISSION (2014),
https://www.brookings.edu/wp-content/uploads/2014/09/RoboticsCommissionR2_Calo.p
df [https://perma.cc/87LX-3667].





n135  New York v. United States, 505 U.S. 144, 188 (1992) ("The Federal
Government may not compel the States to enact or administer a federal regulatory
program.").





n136  See, e.g., John Eligon & Timothy Williams, Police Program Aims to Pinpoint
Those Most Likely to Commit Crimes, N.Y. TIMES (Sept. 24, 2015),
http://www.nytimes.com/2015/09/25/us/police-program-aims-to-pinpoint-those-most-
likely-to-commit-crimes.html (noting predictive policing models typically are
"financed by the federal government").





n137  South Dakota v. Dole, 483 U.S. 203, 206 (1987) ("Congress may attach
conditions on the receipt of federal funds, and has repeatedly employed the
power 'to further broad policy objectives by conditioning receipt of federal
moneys upon compliance by the recipient with federal statutory and
administrative directives.'" (quoting Fullilove v. Klutznick, 448 U.S. 448, 474
(1980))).


                               4 of 41 DOCUMENTS

           Copyright (c) 2016 The Ohio State Journal of Criminal Law
                     The Ohio State Journal of Criminal Law

                                   Fall, 2016

                       Ohio State Journal of Criminal Law

                           14 Ohio St. J. Crim. L. 67

LENGTH: 10565 words

ARTICLE: Evaluating Section 14141: An Empirical Review of Pattern or Practice
Police Misconduct Reform

NAME: Joshua Chanin *

BIO:



   * Assistant Professor in the School of Public Affairs, San Diego State
University. This paper draws heavily from two earlier studies: Joshua M. Chanin,
Negotiated Justice? The Legal, Administrative, and Policy Implications of
'Pattern or Practice' Police Misconduct Reform (July 6, 2011) (unpublished Ph.D.
dissertation, American University),
https://www.ncjrs.gov/pdffiles1/nij/grants/237957.pdf, and Joshua M. Chanin,
Examining the Sustainability of Pattern or Practice Police Misconduct Reform, 18
POLICE Q. 163 (2015).

HIGHLIGHT:


     Section 14141 of the Violent Crime Act of 1994 fundamentally
     restructures the regulation of police behavior in the United States.
     Since the law's passage, dozens of police departments have undergone
     lengthy and complex reforms designed to eliminate a pattern or
     practice of misconduct. Despite the program's wide application,
     neither scholars nor practitioners know much about the efficacy or
     sustainability of these reforms. This paper draws on longitudinal data
     across several outcome metrics, including citizen complaints, use of
     force incidence, and civil litigation, and a series of interviews with
     key stakeholders to examine pattern or practice initiatives in
     Pittsburgh, Pennsylvania, Washington, D.C., Cincinnati, Ohio, Prince
     George's County, Maryland, and Los Angeles, California. Findings
     suggest that the reform process has the ability to minimize unwanted
     police misconduct and generate desirable policy outcomes, particularly
     during the period of Department of Justice (DOJ) oversight. Sustaining
     these reforms after the settlement agreement is dissolved, however,
     has proved a challenge.

     "We don't tend to evaluate . . . after we have left." - Vanita Gupta
     n1


 TEXT:
 [*67]  I. INTRODUCTION

   On May 26, 2015, Vanita Gupta, Head of the Department of Justice's (DOJ)
Special Litigation Section (SPL), announced an agreement between the DOJ and the
City of Cleveland, Ohio. Seven months earlier, Tamir Rice, an unarmed
twelve-year-old Black boy was shot and killed by the Cleveland Division of
Police (CDP) in an incident that quickly came to symbolize the tension between
the CDP  [*68]  and its community.  n2 The settlement was not designed to
address the actions taken by officers involved in the Rice killing, but to
address the wider problem of excessive force within the CDP.  n3 Gupta assured
the people of Cleveland that the agreement would "transform this police agency
into a model of community-oriented policing that will make both police officers
and the people they serve safer."  n4

   The investigation of the CDP occurred pursuant to § 14141 of the Violent
Crime Control and Law Enforcement Act of 1994, which vests the DOJ with
authority to initiate legal action against law enforcement agencies found in
systematic violation of constitutional or statutory law.  n5

   This provision has been instrumental in identifying unlawful behavior in many
of the country's most prominent police departments, and has generated settlement
agreements that articulate deep reforms to the offending department's
organizational model and accountability systems. The initiative continues to
serve as the primary means of addressing systemic police misconduct in the
United States. In fact, in the last eighteen months, the DOJ has used its
pattern or practice authority to investigate allegations of systemic misconduct
in several cities experiencing recent police-involved violence, including
Ferguson, Missouri,  n6 Baltimore, Maryland,  n7 and Chicago, Illinois,  n8
among others.

   Though perhaps this recent wave of litigation is unprecedented in its speed
and aggression, the use of federal power to address police misconduct is nothing
new. Since 1994, the DOJ has investigated allegations in some sixty-eight
jurisdictions, taking formal legal action against thirty-eight departments found
to  [*69]  have engaged in a pattern or practice of misconduct.  n9 Rather than
litigate these claims, most jurisdictions opt for settlement.  n10 The resultant
agreements, which are enforceable in federal court, typically require the
affected department to update relevant policy, revamp training requirements, and
develop an infrastructure designed to promote internal and external officer
accountability.  n11

   In many cases, including those reviewed here, an independent monitor is hired
to oversee implementation and establish the terms of compliance. These
agreements remain in place until the police are determined to have been in
"substantial compliance" with the terms of the agreement--typically defined as
95 percent compliant--for at least two full years.  n12 The emerging department
is  [*70]  stamped with the imprimatur of lawfulness and designated as a model
for other departments in terms of lawfulness, accountability, and transparency.
n13

   The pattern or practice initiative, as it has become known, has been a useful
tool for police chiefs and elected officials seeking change,  n14 as well as
reform minded community members.  n15 Anecdotal evidence suggests that many
affected department leaders have found the process worthwhile as well.  n16 The
response has not all been positive, however. Some have claimed that the DOJ's
enforcement of § 14141 is overly political,  n17 with decisions on which
jurisdictions to investigate made for partisan rather than policy reasons.  n18
Others have argued that the process is anti-democratic and unnecessarily
exclusive of perspectives brought to bear by citizen groups and labor
organizations.  n19 Some have also questioned whether this process, which often
lasts for several years and costs cities tens of millions of dollars,  n20 is
capable of producing meaningful, durable organizational change.  n21

    [*71]  The record of police department efforts to achieve and sustain
organizational reform is at best mixed.  n22 Many of policing's most promising
innovations, including high-profile efforts like community policing and
problem-oriented policing, have not lived up to their initial promise.  n23
Despite this pattern, those who study the police have largely overlooked the
issue. In general, scholars know relatively little about the bureaucratic
response to reform and thus remain somewhat ignorant about how and why
innovations in policing continue to erode.  n24

   This is not entirely surprising given the complexity of the issue.
Comprehensive reform efforts resist the kinds of clear, simple terms that
facilitate ex post evaluation. The process is defined by multiple goals, varying
perspectives, and competing political, administrative, and legal motivations,
all conspiring to form "a confusing and contradictory picture of change."  n25
The complexity of the process is only magnified by the intensity of the current
political and social context and the contentiousness with which police officers
confront changes to the organizational status quo.  n26

   Opposition among front line officers to pattern or practice reform is one of
several reasons to study the process. The significance of the initiative, the
issue that precipitates it, and the vehemence of arguments on both sides is
belied by how little we actually know about the effectiveness and sustainability
of these reforms. Despite its relevance to legal, administrative, and policy
scholarship, to date there has been relatively little social science research on
the reform process, with a particularly glaring lack of empirical analysis.

   This paper is a step toward filling in this gap. Part II reviews the existing
research that addresses efforts to institutionalize changes to organizational
structures, policies, and procedures in other contexts. Part III explains the
selection of departments for case studies, the available data, and the data's
limitations. Part IV draws on longitudinal data across several metrics,
including violent and property crime, citizen complaints, use of force
incidence, and civil litigation to examine the sustainability of reform in
various jurisdictions, including Pittsburgh, Pennsylvania; Washington, D.C.;
Prince George's County, Maryland; Cincinnati, Ohio; and Los Angeles, California.
Part V assesses what we can learn about the sustainability of reform from these
examples.

    [*72]  II. EXISTING LITERATURE ON INSTITUTIONAL REFORM LITIGATION

A. The Sustainability of Court-Mandated Organizational Change

   The need for closer attention to this issue is highlighted by the impermanent
nature of reforms brought about in other policy contexts through similar means.
Much like pattern or practice settlements, judicially enforced remedial orders
attempt to structure detailed reform of public bureaucracies found in systematic
violation of the law.  n27 This process has been used to facilitate the
desegregation of school districts,  n28 remedy unconstitutionally abusive prison
systems,  n29 and assert the rights of patients held unlawfully by state-run
mental hospitals,  n30 among others.

   Again, as with pattern or practice reform, formal oversight is terminated
upon a determination (typically made by the presiding judge) that the underlying
constitutional violation has been redressed. As a result, many see the process
as inherently fragile. At the heart of these arguments is the contention that
the sustainability of reform is undermined by the use of a transitory policy
solution--external oversight--to remedy what in many cases is a chronic
organizational problem.  n31 In the absence of persistent external oversight and
accountability, the argument goes, the affected bureaucracy can, and perhaps
must, revert to ex ante operating procedures.

   Two examples illustrate the point. Despite the significant gains made
following the Brown decision,  n32 over the last twenty years or so, scholars
have documented the increased segregation of primary and secondary school
children along racial, economic, and linguistic lines.  n33 Some contend that
resegregation has occurred as a direct result of limitations placed on the
ability of federal district  [*73]  court judges to continue to manage local
school districts.  n34 Rights-based reforms achieved through litigation against
state prison systems have eroded under similar circumstances. A recent
examination of the Arizona Department of Juvenile Corrections, which operated
under federal control between 2004 and 2007, documented post-termination
slippage in two areas critical to the initial reform effort: suicide prevention
and inmate education.  n35 In each case, the absence of external pressure to
adhere to new operational protocols corresponded with a reversion to
pre-intervention practices.

B. Evaluating Organizational Reform

   The term institutionalization is used to define the process of converting a
reform effort into an established part of the organization's normal functioning
n36 and "a way of regularly conducting . . . business."  n37 According to
Oliver,  n38 once organizational activities are institutionalized, they are
assumed to become relatively stable, enduring, reproducible, and sustainable
over long periods of time without continuing justification. In this sense,
"institutionalized" reforms are synonymous with "sustainable," "enduring," and
"lasting" changes.  n39

   Identifying the point in time when a reform implementation effort ends and
institutionalization begins is a complex task. This determination is
particularly difficult in part as a result of the fact that the complex and
perpetual nature of many implementation efforts makes a fixed end point
difficult to identify. It is similarly difficult to identify the point at which
assessment of a program's sustainability should begin. Here too the nature of
the analysis resists a definitive, dichotomous answer, and what little research
does exist provides conflicting  [*74]  guidance. Some scholars believe that
analysis should begin after one year;  n40 others say institutionalization takes
somewhere between five and ten years to manifest.  n41

   Previous scholarship has employed various approaches to examine the
institutionalization of organizational reform, beginning with an assessment of
staff response. This can be accomplished by measuring both the extent to which
organizational actors are aware of and understand changes to policy and agency
priorities brought on by the reform,  n42 as well as "the degree to which
intervention behaviors are actually performed."  n43

   Staff willingness to adopt new operational protocols is often couched in
terms of organizational culture. Policing scholars have consistently found
cultural change--measured in terms of individual officer preferences, norms, and
values--predictive of institutionalized reform.  n44 The sustainability of
pattern or practice reform is at least in part likely to be a function of the
degree to which street and mid-level officers, as well as department leadership,
have come to view both the letter and the spirit of the settlement as central to
the department's mission and reflective of the department's broader approach to
policing.

   Yet organizational reform is rarely pursued for these ends. Cultural and/or
behavioral change is typically instrumental, sought as a means to improving
certain measurable outcomes.  n45 Since the early 1990s, public management
scholars have advocated the use of outcomes to measure the performance of public
agencies and individual bureaucrats, rather than intangibles like attitudes or
culture.  n46 The notion of "measuring what matters" is a strong current in
policing research as well.  n47 Police practitioners are also heavily dependent
on these data--arrest rates, use of force statistics, demographic and geographic
data, etc.--to drive officer behavior and evaluate policy change. The Compstat
movement is one such example; predictive policing and crime mapping are others.

   Part of the challenge in evaluating the durability of organizational reform
is identifying performance measures that accurately identify sustainable change.
[*75]  Two types of outcome measures are relevant, beginning with systematic
metrics that establish broad, agency-wide performance. First, in terms of
pattern or practice reform, several such indicators are relevant, including
frequency of officer use of force incidents, citizen complaints, and civil suits
filed against the department. In fact, nearly every key stakeholder interviewed
as a part of this research stated that trend data is the most useful way to
gauge the effectiveness of a reform effort and a department's progress toward
institutionalization.

   Second, an organization's ability to sustain change can also be evaluated in
terms of its ability to avoid large-scale "performance crises." These events can
take the form of isolated, high profile incidents, like a police shooting or a
particularly vicious use of force caught on tape. Think Rodney King. Even one
such episode can shake the public's confidence in the agency, negatively affect
employee morale, and weaken organizational support for departmental leadership.
To illustrate the magnitude of such a crisis, Oliver argues that the Space
Shuttle Challenger disaster undercut the agency's reputation and "provoked
serious doubts within the organization about a range of long-standing practices
and procedures."  n48 Along the same lines, Cincinnati City Manager Milt Dohoney
acknowledged,


     [T]he only thing that could undo the good that's been done is for [the
     Cincinnati Police Department] to have a number of questionable
     situations at the street level where a citizen gets either seriously
     injured or is the recipient of a use of deadly force . . . . [T]hat
     can bring all of that past baggage back up. You can have one incident
     that really gets the community on edge.  n49

   The perception of systematic and protracted corruption--LAPD's Rampart
scandal, for instance--would no doubt have a similar destabilizing effect in a
postreform jurisdiction.

   To summarize, scholars have examined the sustainability of organizational
reform using four interrelated metrics: (1) staff knowledge of and compliance
with new protocols; (2) the extent to which staff culture reflects reform
values; (3) trend-based outcome data; and (4) the presence or absence of
performance crises. This research will track pattern or practice
institutionalization by examining metrics 3 and 4. What follows is a discussion
of the data and method used.

    [*76]  III. CASE SELECTION, DATA, AND METHOD

   Thirteen of the twenty-four jurisdictions facing federal oversight between
1994 and 2010 reached substantial compliance with the terms of their settlement
agreement. Of those, only Pittsburgh, Washington, D.C., Cincinnati, Prince
George's County, and Los Angeles were willing (or able) to share relevant
outcome data.  n50 These data, including use of force incidence, citizen-based
allegations of misconduct, officer disciplinary decisions, and civil litigation
related to police misconduct, were drawn from agency annual reports, independent
monitor reports, and the FBI's Uniform Crime Report database. Where data was not
available publicly, Freedom of Information Act requests were filed with affected
police departments and other relevant city agencies.
                           Washington,  Prince George's
              Pittsburgh   D.C.         County
Use of force  PBP          MPD          NA
              (2004-2014)  (2001-2015)
Civil         NA           City of DC   NA
litigation                 (2000-2010)
Citizen       CPRB         OPC          CCOP
complaints    (1998-2014)  (2001-2015)  (2006-2014)
Crime         UCR          UCR          UCR
              (1985-2012)  (1985-2012)  (1985-2012)


              Los Angeles  Cincinnati
Use of force  LAPD         CPD
              (2001-2015)  (1995-2012)
Civil         City of LA   NA
litigation    (2000-2010)
Citizen       NA           CCA
complaints                 (2005-2012)
Crime         UCR          UCR
              (1985-2012)  (1985-2012)

Note: PBP = Pittsburgh Bureau of Police; MPD = Metropolitan Police Department;
CPD = Cincinnati Police Department; CPRB = Citizen Police Review Board; OPC =
Office of Police Complaints; CCA = Citizen Complaint Authority; CCOP = Citizen
Complain Oversight Panel; UCR = Uniform Crime Report.

   As is clear from Table 1, both the sources and availability of these data
vary greatly from jurisdiction to jurisdiction. In many cases, data were simply
not available for the pre-reform period. Thus, establishing performance level
benchmarks was all but impossible. In Cincinnati, the Citizen Complaint
Authority, which was created as a result of the reform effort, began collecting
data in 2005, some three years after the initiation of federal reform. In other
instances, the analysis was complicated by changes in the way agencies captured
and presented relevant information. For example, between 1998 and 2005,
Washington, D.C. Metropolitan Police Department (MPD) shifted how they  [*77]
defined and categorized officer use of force incidents, rendering a consistent
prepost analysis all but impossible.

   As a result of these deficiencies, the analysis presented falls short of a
formal program evaluation and as such no causal conclusions are offered. There
are, however, sufficient data to analyze the bureaucratic response to external
reform mandates. Changes observed across each metric over time are evaluated as
separate, but interrelated, markers of the effects of reform and the
sustainability of such changes. Insights from several stakeholders, including
independent monitors, police department leadership, and relevant political and
community leaders were gathered from several in-depth interviews and are used to
supplement the quantitative analysis.  n51 Newspaper reports and other secondary
sources were helpful in establishing context and tracking the incidence of
performance crises.

   IV. FINDINGS

   Before presenting the results of this analysis, it should be noted that in
most cases, neither the effects of reform nor institutionalization should be
measured dichotomously.  n52 Organizational change is something that proceeds
incrementally and thus is most effectively measured in degrees. With that in
mind, the analysis proceeds chronologically, beginning with Pittsburgh.

A. Pittsburgh, Pennsylvania

   In April, 1997 the city of Pittsburgh agreed to settle DOJ claims that the
Bureau of Police (PBP) had engaged in a pattern or practice of unlawful
activity, including the use of excessive force and a failure to discipline
officers adequately.  n53 The consent decree was in place until September 2002.
n54

   Shortly after the decree was lifted, the Vera Institute of Justice attempted
to gauge the degree to which "local officials can maintain [consent decree]
reforms  [*78]  after the federal government and its monitor withdraw."  n55
Drawing on survey data and interviews with PBP officers and leaders from key
civil society groups gathered between March, 2003 and March, 2004, Vera
evaluated the sustainability of changes to police behavior, officer morale, and
public opinion brought on by federal oversight.  n56

   Three themes emerge from this research. First, PBP officers seemed to
understand and respect the goals of the reform, but were strongly resentful of
the process.  n57 In fact, only a tiny percentage of those surveyed felt the
reforms had improved performance or produced more professional encounters with
citizens.  n58 Second, despite this opposition, the first year or so after
federal oversight was lifted, PBP maintained operation of various reform
initiatives, including their early intervention system, new officer training
protocols, and regular oversight inspections.  n59 Third, a majority of
community leaders and members of the public saw the PBP as effective in stopping
crime, helping victims of crime, and working together with city residents to
solve local problems.  n60 Based on these findings, the authors conclude that
"the implementation of the consent decree requirements in Pittsburgh
dramatically changed the culture of the Bureau of Police" and that key
departmental changes "survive[d] the life of the decree intact."  n61

   Much has happened in Pittsburgh since the study was published, including
three mayoral transitions, the installation of four new police chiefs, and a
protracted budget crisis. Recent data suggest that advances in officer
accountability and community trust have eroded considerably over the last
several years.

    [*79]   Figure 1. Citizen Complaints of Police Misconduct in Pittsburgh
(1998-2014)

   Source: Pittsburgh Citizen Police Review Board

   Figure 1. Citizen Complaints of Police Misconduct in Pittsburgh (1998-2014)
Source: Pittsburgh Citizen Police Review Board Figure 1 charts the citizen-based
complaints filed against Pittsburgh Bureau of Police officers between 1998 and
2014. The figure shows a steady increase in total allegations until 2008, with a
significant uptick occurring following consent decree (CD) termination. On
average, there were 556 allegations made annually against PBP officers during
the implementation period. In the six years immediately following termination,
the mean annual total jumped to 822, an increase of 48 percent. Complaints have
fallen precipitously in recent years, with the 499 recorded in 2014, the second
lowest annual total since the CPRB came into existence. The percentage of
complaints alleging unlawful use of force has also dropped fairly steadily since
the DOJ terminated their oversight. That this occurred, even as annual complaint
totals spiked, should be seen as circumstantial evidence of PBP's success in
mitigating such incidents.

   Citizen allegations of misconduct are important ways of assessing PBP
officers' use of discretionary authority, their willingness to comply with law
and Bureau policy, as well as their general attitudes toward city residents  n62
--the very behavior targeted by the consent decree, either directly or
indirectly.

    [*80]  These data also provide a window into the operation of management and
accountability systems created as a product of the reform effort.  n63 Officer
training, accountability infrastructure, and chain-of-command oversight all
exist to either prevent or mitigate the kind of behavior that generates citizen
complaints. What is more, citizen complaints help to define the Bureau's
culture.  n64 A culture that values the rule of law, citizen rights, and
accountability would surely have relatively fewer such complaints than a
department that either overlooked or treated with impunity violations along the
lines of the categories measured below. According to former Washington, D.C.
Metropolitan Police Department (MPD) chief Charles Ramsey,  n65 citizen
complaints are an important metric for tracking officer behavior and the
sustainability of those systems, cultural norms, and values developed during the
CD process: "Citizen complaints . . . [must be] review[ed] very carefully . . .
to make sure that not just with use of force in terms of physical force, but
even verbal abuse and complaints, things of that nature. . . . [A]ll those
things . . . we want to monitor."

 Figure 2. PBP Officer Use of Force, Disciplinary Actions (2004-2014)

   Sources: Pittsburgh Citizen Police Review Board; Pittsburgh Bureau of Police

    [*81]  Given the several factors that may influence citizen complaint data,
including the ease of filing complaints and trust in the complaint investigation
process, and the ambiguous relationship between complaints and police behavior,
n66 it is helpful to view these kinds of data together with other indicators of
officer performance. Figure 2 tracks both use of force reports filed by PBP
officers and the disciplinary actions taken by PBP leadership. Though the
relationship between the two variables is unknown, that use of force has
increased since 2004 just as disciplinary actions have declined suggests a
curious and potentially troubling finding.

   There are several possible explanations. The rise in use of force incidence
could be a reflection of a department-wide emphasis on more accurate reporting,
with officers mandated to document all use of force regardless of its nature or
perceived insignificance. The decline in use of force-related citizen complaints
is in line with the idea that documentation, not actual use of force, has
increased. It is possible too that the reduction in disciplinary actions is
consistent with this narrative. It is also quite possible that the combination
of these trends is evidence of a department whose officers have become more
violent and less accountable.

   Though certainly not definitive, the broader context, including a recent
history of political and departmental corruption and several high-profile
incidents of police use of force, lends some credibility to the latter
interpretation.

   Robert McNeilly was hired in April 1996 and served as Chief in Pittsburgh
until January 2006. McNeilly remains an outspoken proponent of DOJ-led reform
and believes that the consent decree process helped to transform the PBP.  n67
Despite his reputation as a "micromanager" and a "disciplinarian," many believe
the PBP was more accountable, more lawful, and more community-friendly during
McNeilly's tenure than it was before his hiring.  n68

   The same is not said of the PBP today,  n69 and a concerted effort to move
away from McNeilly's leadership may be partly to blame. According to McNeilly,
his longtime political battles with Mayor-elect Bob O'Connor precluded a
cooperative transition. "I knew (O'Connor) wouldn't keep me on for good, but I
offered to stay there until [new chief] Costa settled in . . . to smooth the
transition," McNeilly  [*82]  said.  n70 O'Connor never responded to McNeilly's
request to have a "frank discussion" about the consent decree, and through his
spokesperson issued an icy dismissal: "[McNeilly] offered to share what he'd
done to comply with the consent decree, but it's a matter of public record what
was done, and Chief Costa is more than qualified to continue those programs."
n71

   Luke Ravenstahl took over as acting mayor in September 2006. Nathan Harper, a
career PBP officer and Ravenstahl nominee, took control of the department
shortly thereafter. Harper, like McNeilly before him, was seen as an extension
of the mayor's office and the city's Director of Public Safety. In McNeilly's
day, however, as the consent decree was being developed and implemented, the
city's executive branch largely supported reform, whereas today there appears to
be other priorities driving city administration.  n72 Whether or not changes in
PBP's leadership can be causally connected to recent backsliding, it is hard to
ignore the fact that many of PBP's biggest problems have occurred since
McNeilly's firing.

   To wit, between 2003 and 2005, PBP officers averaged 1,033 use of force
incidents per year. Between 2006 and 2012, that number jumped to 1,427, an
increase of 38 percent. Similarly, the average number of assaults committed
against PBP officers in the years after McNeilly was fired was 408, some 49
percent higher than the average committed during McNeilly's tenure. This
occurred as both property and violent crime trended down.

    [*83]   Figure 3. Crime in Pittsburgh (1985-2012)

   Source: FBI Uniform Crime Report

   Several recent high-profile incidents contribute to the notion that changes
made pursuant to the consent decree may have begun to erode with the replacement
of Robert McNeilly. In September 2009, Pittsburgh hosted the G-20 summit. A
cause célèbre for anti-globalization and anti-corporate activists, significant
protests tend to accompany the annual G-20 meetings. 2009 was no exception.
Several hundred protesters were arrested as the city sustained an estimated $
50,000 in property damage.  n73

   A September 2010 suit filed by the ACLU on behalf of a class of protesters
claims the PBP surrounded them, "refused to allow them to leave, ordered them to
lie on the ground and placed them in handcuffs" in violation of their First
Amendment right to assembly. The protesters also allege that the police "falsely
charged them with failure to disperse and disorderly conduct."  n74

   The aftermath of the G-20 protests exacerbated an already contentious
relationship between Pittsburgh's independent Citizen Police Review Board  [*84]
(CPRB) and the city's executive branch.  n75 After receiving scores of
G-20-related complaints, the CPRB moved to open a general investigation of PBP's
actions during the protest. The mayor's office successfully litigated to prevent
the CPRB from accessing G-20 documents.  n76 After losing an initial round in
the legal fight, Mayor Luke Ravenstahl replaced five of the Board's seven
members, a move one city councilmember believes was an attempt to "circumvent"
or "destroy" the CPRB.  n77 Beyond its reflection of alleged police abuse, the
city's response to the G-20 investigations suggests a political class, led by
the Mayor, which is reflexively defensive of the police and the politically
powerful officer union, and skeptical of transparency and accountability.

   Less than five months out from the G-20 meetings and just over seven years
after the consent decree was lifted, the Pittsburgh Bureau of Police suffered a
second major performance crisis. Three undercover Pittsburgh Bureau of Police
officers attempted to stop Jordan Miles, a classical musician and a high school
honor student, near his residence in Homewood, a largely African-American
neighborhood on Pittsburgh's east side.  n78 Miles believed he was about to be
robbed and attempted to flee the scene.  n79 After he fell, the officers
allegedly delivered several blows to Miles's head and back, ultimately sending
him to the hospital. Miles was arrested for aggravated assault and resisting
arrest, though the charges were later dismissed.  n80 On March 31, 2014, after
several years in court, a jury found in Miles' favor on his claim of false
arrest, but denied the excessive force charge; he was awarded $ 119,000 in
damages.  n81

   In March 2013, former PBP chief Nathan Harper was indicted on federal
corruption and tax evasion charges stemming from an alleged scheme to divert
city  [*85]  funds for personal use.  n82 Harper was sentenced in February 2014
to an eighteen-month prison sentence;  n83 he was released from federal custody
in May 2015.  n84

   Of course, these events do not alone signal PBP's failure to sustain pattern
or practice reforms. Longstanding and unaddressed tension between the police and
minorities, as well as shifts in economic and other social conditions, may help
explain incidents like the G-20 protest and the alleged beating of Jordan Miles.
Taken together, the incidents do seem to suggest an erosion of the
accountability infrastructure developed during the reform period. Regardless of
their cause, such incidents have had a dramatic effect on police-community
relations in the city and continue to negatively affect public perceptions of
the Bureau.

   With all of that said, the current state of police-community relations in
Pittsburgh may be as strong as it has been since 2002, when the consent decree
was dissolved. Former Madison, Wisconsin captain Cameron McLay was hired in
September 2014 and immediately set about attempting to reform a department he
saw as lacking accountability and community trust.  n85 Citizens Police Review
Board Executive Director Beth Pittenger, who has a long history of tension with
PBP leadership,  n86 has seen enough to call McLay's first year on the job
"extraordinary."  n87 Pittenger went on: "In terms of reorganization, creating a
new identity in the public perspective and keeping everyone safe, cops as well
as the  [*86]  community, all of these things in the short time of a year are
truly remarkable."  n88 While it is still in its early days, at least some of
McLay's rhetoric on accountability and transparency are supported by evidence.
According to a recent analysis of 350 police websites, PBP was the second-most
transparent department among those sampled.  n89

B. Washington, D.C.

   In June 2001, the District of Columbia and the Washington, D.C. Metropolitan
Police Department (MPD) entered into a Memorandum of Agreement (MOA) designed
eliminate a pattern or practice of excessive force.  n90 The Department reached
substantial compliance in June 2008, an occasion for former monitor Michael
Bromwich to laud the Department and the process:


     MPD has become a much more sophisticated police agency. . . . We
     believe that the City's and MPD's success in implementing the MOA's
     reforms, which are now embedded in the Department's internal policies
     and practices, stands as a model for municipalities and police
     departments across the country.  n91

   MPD Chief Cathy Lanier paints a similar picture. Not only does she credit the
MOA with significant improvements to the Department's accountability
infrastructure, but with catalyzing a shift in MPD's officer culture. Changes
made under the MOA are "the status quo now. It's part of our daily operations.
It's what we do."  n92 Despite their remarks, the evidence suggests a more
complex picture of the institutionalization process.

    [*87]   Figure 4. Citizen Complaints Filed against MPD Officers (2001-2015)

   Source: Washington D.C. Office of Police Complaints

   The total number of misconduct complaints levied against MPD officers
increased steadily as the MPD implemented the terms of MOA. From 2001 through
2007, annual totals hovered around a mean of 347 complaints, reaching a high of
440 in 2007, 42 percent higher than the 310 filed in 2001. In 2008 (the MOA
terminated in June of that year), however, total allegations increased to 600,
an additional 27 percent jump. Between 2009 and 2012, residents filed an average
of 566 complaints against MPD officers, well above the volume seen during
implementation. As is clear in Figure 4, as complaint totals have been somewhat
volatile since 2005, the rate of dismissal has been relatively stable over that
period, with investigators determining that well over half of complaints filed
were without merit.

   Interpreting these results is tricky, particularly in the absence of a larger
sample of data. The upward trend may simply indicate a steady increase in
unlawful police activity. It may also signal that reform-based changes,
including those designed to make the process of filing a complaint easier, were
having the desired effect. But even if a simplified complaint process can
account for the upward trend while the new policies were being implemented, it
is unlikely that the effect of such changes would stretch beyond the first four
or five years of reform. In other words, these policy changes do not seem to
explain the observed post-reform spike. Six years' worth of data is not nearly
enough to justify the conclusion that reform gains in D.C. have eroded.

    [*88]   Figure 5. MPD Officer Use of Deadly Force, by Incident Type
(2001-2015)

   Sources: Washington D.C. Metropolitan Police Department

   Figure 5 documents MPD use of deadly force between 2001 and 2015 broken down
by incident type. Between 2001 and 2008, when the CD was terminated, MPD
officers averaged 23.4 deadly force incidents per year, 44 percent higher than
the 13.1 they have averaged since. Given the small sample and the lack of
pre-MOA data from which to base comparisons, it is difficult to draw anything
other than superficial conclusions. The absence of an immediate post-MOA spike
is worth noting, particularly in light of the dramatic reporting by the
Washington Post on MPD use of deadly force,  n93 which is widely believed to
have set in motion the DOJ pattern or practice investigation.  n94 It is also
worth noting that neither the MOA nor its dissolution appears to have affected
the decades-long decline in the District's rate of violent or property crime, as
is shown in Figure 6.

    [*89]   Figure 6. Crime in Washington, D.C. (1985-2012)

   Sources: FBI Uniform Crime Report

 Figure 7. Civil Litigation Alleging Police Misconduct in Washington D.C.
(1999-2010)

    [*90]  Figure 7 charts the total number of civil suits resulting in either a
settlement or judgment in favor of plaintiffs filing use of force-related claims
against the MPD. The significant spike that occurred between 2001 and 2004 is
the result of litigation stemming from police action taken during the 2000
inauguration of George W. Bush  n95 and the mass arrest in Pershing Park during
a 2002 anti-globalization protest.  n96 Combined, Washington, D.C. faced at
least fifty-seven different suits and paid out a total $ 34,420,295 in damages
as a result of these events.  n97 Non-protest litigation trended downward
throughout the reform and has remained steady since the MOA was dissolved in
2008.

 Figure 8. Pro-Plaintiff Awards in Litigation Alleging Police Misconduct in
Washington D.C. (1999-2010)

   Figure 8 tracks the total dollar amounts paid out by the District as a result
of force-related settlement/disposition awards for suits filed during that same
period of time. The data show that non-protest payouts were flat during the
[*91]  implementation period and have continued to decline in the post-reform
years.  n98 On balance, both the rate and cost of litigation stemming from
force-related misconduct was fairly stable during the implementation period and
has continued to trend downward in the years following MOA termination.

   Finally, while MPD has not faced the kind of major event or scandal that has
plagued Pittsburgh in recent years, over ninety MPD officers were arrested
between 2009, the first full year after the MOA was terminated, and 2012.  n99
Police accountability expert Sam Walker argues that, in light of the fact that
MPD's early intervention system is designed to identify and correct such
problematic behavior, this pattern "raises very serious questions about whether
the accountability procedures instituted by the MOA are functioning at all."
n100

C. Cincinnati, Ohio

   In April 2001, a white Cincinnati police officer shot and killed Timothy
Thomas, an unarmed black teenager, setting off riots throughout the city.  n101
In response to a pattern of excessive force, the Department of Justice oversaw
police reform in Cincinnati from April 2002 through April 2007. During this
five-year period, in addition to the reforms required by the MOA, the Cincinnati
Police Department (CPD) also implemented the terms of a privately negotiated
settlement with several community groups and the local chapter of the Fraternal
Order of Police. As a result of this unique arrangement, the CPD was not only
required to reform its approach to police use of force and officer
accountability, but also to develop and implement new crime control, order
maintenance, and community relations strategies. The changes required of
Cincinnati were broader and deeper than in any of the several other
jurisdictions affected by the DOJ's pattern or practice initiative.

   Six years removed from DOJ and monitor oversight, the CPB has experienced
little or no discernable backsliding, a finding supported by consistent
reductions in undesirable outcomes, including use of force incidence and
allegations of abusive or unlawful behavior. In short, the reform effort in
Cincinnati appears to have transformed the CPD.

    [*92]   Figure 9. Police Use of Force in Cincinnati (1995-2012)

   Source: Cincinnati Police Department

 Figure 10. Crime in Cincinnati (1985-2012)

   Source: FBI Uniform Crime Report. Note: data from 1997 and 1998 are missing.

    [*93]  Longitudinal data show significant and lasting change within the CPD.
As documented in Figure 9, police use of force in Cincinnati was fairly volatile
during the MOA implementation period but has dropped by an average of 11 percent
per year since 2005. In fact, between 2002 and 2014, as crime rates have
remained relatively stable, use of force has declined by 46 percent.

 Figure 11. Citizen Complaints of Misconduct against CPD Officers (2005-2014)

   Source: Cincinnati Citizen Complaint Authority

   Data from Cincinnati's Citizen Complaint Authority (CCA) shows a similar
downward trend. According to annual reports filed by the CCA between 2005 and
2014, complaints against CPD officers continued to decline even after the
department was released from formal oversight. As is documented in Figure 11,
the sixty-five allegations of excessive force investigated by the CCA in 2012
represent a 26 percent drop in the number of similar allegations made in 2006,
the last full year that CPD was under federal control. Further, the percentage
of complaints against CPD officers found by the CCA to have some merit (i.e.,
sustained) continued to fall in the years following MOA termination.

   The data are more impressive in light of the changes made to the complaint
process as a result of the MOA. Prior to the reform, complainants had to appear
at CPD stations in person. Today, one can file a complaint by phone or by email,
directly to CPD or CCA, and may even do so anonymously. In short, the MOA made
it easier for people to complain, and far fewer people have. According to  [*94]
ACLU attorney Scott Greenwood, "overall satisfaction is better. People--the
community--trusts the integrity of the review process now."  n102

   CCA Director Kenneth Glenn has sensed a change not just in the data, but in
how complainants view the CPD. Anecdotally, even though complainants are upset
about the incident, they are attempting to address, their overall attitude and
orientation towards the police is more positive. To Glenn, trust in the CPD has
continued to grow as a result of the MOA: "[A]s we go out into the community and
talk with young people in the community . . . the tone is a lot better than it
was in 2002."  n103 That the CPD has been able to avoid a destabilizing,
high-profile performance failure in recent years contributes to the growth of
the Department's legitimacy in the eyes of the community.

Cincinnati's City Manager Milt Dohoney's view of the Department does well to
summarize CPD's progress since 2002:


     The changes that were made have resulted in . . . a significant
     drop-off in the number of instances where citizens are injured as
     they're being taken into custody. There's a lot fewer injuries to
     police officers as they're trying to make an arrest. The allegations
     of excessive force have plummeted. The incidents where the use of
     deadly force is even an issue has plummeted. . . . [The DOJ] agreement
     helped make all that happen.  n104

   Cincinnati residents, like those in every other major metropolitan area in
the country, have experienced their share of violent encounters with the police.
In June 2014, CPD officers shot and killed Donyale Rowe following a routine
traffic stop.  n105 Police Chief Jeffrey Blackwell immediately released recorded
footage of the incident and was credited with helping to avoid the kind of wider
conflict that followed the death of Timothy Thomas.  n106 Mike Bricker, policy
director at the ACLU of Ohio, credited the reform effort with this progress:
"Even where there is a strong intervention and things have changed
significantly, I think it's unrealistic to say that there is never going to be
another police problem or another issue that  [*95]  crops up . . . . But I
think what has changed is that there are much fewer of them."  n107 And when
such incidents do occur, Bricker believes CPD officers "have the tools and the
training and the mutual understanding of how to talk about these issues" to
reduce the likelihood of wider unrest.  n108

D. Prince George's County, Maryland

   On January 22, 2004, Prince George's County, the Prince George's County
Police Department (PGPD), and the U.S. Justice Department signed a Memorandum of
Agreement (MOA) designed to remedy a pattern or practice of excessive force.
n109

   The PGPD MOA adopts a structure and content very similar to those settlement
agreements established in Pittsburgh, Washington, D.C., and Cincinnati. The
terms of the MOA require changes to PGPD use of force policy and reporting
protocols,  n110 "evaluation, documentation, and review of uses of force,"  n111
officer training,  n112 "receipt, investigation, and review of misconduct
allegations,"  n113 and the development of further officer accountability
systems, including an improved "early identification" system and a protocol for
conducting internal "integrity audits" of the department.  n114

   On January 15, 2009, some five years after the MOA was instituted, the
independent monitor team filed its final report, documenting PGPD's substantial
compliance with all but one of the sixty-nine substantive provisions of the
agreement.  n115

   In announcing the MOA's formal termination, two years after the scheduled
three-year deadline, County Executive Jack B. Johnson claimed victory: "We have
rebuilt a police department that was once and now is considered a model for law
[*96]  enforcement. . . . I want everyone to know that our commitment to
improvement that we have made while under DOJ oversight will not wane simply
because the department is no longer watching."  n116

   Relative to the other three jurisdictions under review, little is known about
PGPD's experience since termination. There have been no independent reports
published, and requests to speak with PGPD leadership, County administrative,
and political officials, as well as members of local civil rights organizations,
have been denied. Further, requests for data on police use of force and civil
litigation outcomes were either denied or fulfilled with unusable data.

 Figure 12. Crime in Prince George's County (1985-2012)

   Source: FBI Uniform Crime Report

   Like much of the rest of the county, crime in Prince George's County is down
precipitously. On February 4, 2009, shortly after the MOA was terminated, the
Washington Post published an editorial lauding what it calls a "remarkable
turnaround," and attributing some of this success to enhanced PGPD officer
training requirements and other MOA-driven reforms.  n117 These trends have
continued since termination and add further support to the notion that pattern
or  [*97]  practice intervention does not correlate with increased incidence of
either violent or property crime.

   A review of what few outcome-based data points that do exist leaves the
impression that the pattern or practice reform process has not had the same
kinds of effects in Prince George's County as it has in other jurisdictions.

 See Figure 13. Citizen Complaints of Misconduct against PGPD Officers
(2001-2014)

   Source: Prince George's County, Maryland Citizen Complaint Oversight Panel

   Data from Prince George's County's Citizen Complaint Oversight Panel (CCOP)
indicate that allegations of PGPD officer misconduct increased steadily over the
lifetime of the five-year agreement. Figure 13 shows an average annual increase
of sixty-nine allegations per year between 2004 and 2008. Total allegations of
misconduct rose from 472 in 2004 to 650 in 2008, the last full year of the
implementation process, an increase of 33 percent. On average, Prince George's
County residents filed 641 allegations per year during the MOA implementation,
some 12 percent less than the yearly average during the 2009 to 2014
post-implementation period.

    [*98]   See Figure 14. Citizen Complaints against PGPD Officers, by Type
(2006-2014)

   Source: Prince George's County, Maryland Citizen Complaint Oversight Panel

   Interestingly, CCOP data shows that between 2006 and 2014, nearly 25 percent
of all allegations made against PGPD officers involved the use of excessive
force, second most common behind the catchall category, "Conduct." As Figure 14
documents, the rate of excessive force complaints has steadily declined since
2008, when some 30.6% involved allegations of excessive force. Without a closer
examination of the department's accountability systems, its officer culture, or
the context offered by a broader set of systematic trend indicators, it is
difficult to extract much meaning from these data. Perhaps it is enough to say
that neither the reform process nor the termination of DOJ oversight has had a
significant effect on the volume or nature of complaints submitted to the CCOP.

   According to a recent story in the Washington Post, PGPD reported 303
use-of-force incidents in 2010, the first full year after the DOJ terminated
oversight.  n118 In 2014, the Department logged 555 such incidents, an 83
percent increase. PGPD Chief Mark Magaw denied that this trend was at all
worrisome, instead pointing to the county's increased population size and a
newly expanded definition of use of  [*99]  force: "The way I read these numbers
is we're doing a better job, we're holding our officers more accountable and
we're being more transparent."  n119

   Magaw's sentiment is belied by several media reports of excessive force and
corruption involving PGPG officers. In March 2010, several Prince George's
County police officers were videotaped beating a University of Maryland student
during a wild celebration of a victory by the school's basketball team.
According to the Washington Post, PGPD officers falsely accused the victims of
aggressive behavior in an attempt to justify the use of force: "Police charging
documents initially alleged that [two students] jointly assaulted police
officers and their horses. The video contradicted that, and the charges against
the students were dropped."  n120 The incident, which cost county taxpayers a
total of $ 3.6 million in legal fees,  n121 led the Washington Post editorial
board to conclude that if no video had surfaced of Mr. McKenna's beating, that
too would have been swept under the rug of police impunity and official
indifference. This cannot be allowed to stand. It sends a terrible message to
the Prince George's police, who now know that consequences for their misconduct,
if any, will be slight.  n122

   The post-MOA list of other incidents involving excessive force is long. In
October 2010, five PGPD officers moonlighting as security guards were involved
in the alleged beating of a student attending a local fraternity party.
Allegations of lying and cover-up were attached to this incident as well.  n123
In September 2012, Stephen Merritt, a 23-year veteran of the Washington, D.C.
Metropolitan Police Department, filed civil charges against the county, claiming
he was unnecessarily beaten by PGPD officers outside a nightclub.  n124 The
criminal charges filed against Merritt in connection with the incident were
subsequently dropped.  n125 In October 2014, two PGPD officers were indicted on
charges stemming from separate  [*100]  incidents, "one involving a school
resource officer at Suitland High School charged with assaulting a student, the
other involving the reported assault of a handcuffed suspect in a jail cell."
n126 In December 2015, PGPD Officer Jenchesky Santiago was convicted on
first-degree assault charges stemming from an incident where he held a gun to a
man's head, apparently to impress his friends.  n127

   In addition to these allegations of unlawful use of force and cover-up, the
PGPD in 2010 became embroiled in a wide-ranging federal investigation into
illegal and corrupt practices within the department. According to the Washington
Post, "at least 46 Prince George's officers are either suspended or assigned to
administrative duties for misconduct or violations. In at least 19 of those
cases, investigators have reason to think the officers committed a crime."  n128

   In late 2010, a separate federal investigation into allegations of corruption
among Prince George's County government officials led to the arrest of
then-Prince George's County Executive Jack Johnson, under suspicion of bribery
and corruption.  n129 The conspiracy, alleged to have started in 2003, is
thought to have involved a "pay-for-play" scheme wherein Johnson is accused of
accepting among other things, cash, trips, and tickets in exchange for official
favors.  n130 In December 2011, Johnson was sentenced to seven years in prison.
n131

   At least four PGPD officers were swept up in the investigation that led to
Johnson's arrest. Two county officers were indicted in federal court on charges
related to their alleged participation in an illegal cigarette and alcohol
distribution ring, while a third was accused of dealing drugs.  n132 The fourth
officer, a narcotics detective, "accused of taking guns he had seized from
criminals and reselling them  [*101]  on the streets[,] was indicted . . . on 13
counts of misconduct in office and theft, according to law enforcement officials
and online court records."  n133

   In 2010, PGPD was also marred by allegations of cheating on police academy
exams. The cheating scandal, which implicated approximately 30 cadets and at
least one instructor, was not only highly embarrassing for the department, but
threatened several ongoing criminal investigations. The County's State's
Attorney Glenn Ivey admitted that his office was forced to review all cases
involving the alleged cheaters: "We assembled a team of prosecutors in the
office to start finding out which cases they were on and make a case by case
determination whether these cases should stand or not."  n134 An audit conducted
by the State of Maryland in 2011 determined (without examining the allegations
of cheating) that the affected officers did not "need to be removed from the
streets because there were no 'substantive issues' with their training."  n135

   Despite this pattern of unlawful and corrupt behavior among PGPD officers and
a continued absence of respect for the rule of law among certain county
officials, it is hard to draw any definitive conclusions about the effectiveness
or long-term viability of the reform effort. There is simply not enough known
about the department to make a legitimate assessment of efforts to change the
department's approach to the use of force and external accountability.

   Further, the lack of available information on the PGPD reform effort seems to
support the notion that the Prince George's County government is either
unwilling or unable to make police accountability and department transparency a
priority, despite claims to the contrary.  n136 The widespread unwillingness
among stakeholders to speak with me (either on or off the record) about the
process adds weight to this conclusion. These impressions become stronger still
after even the most cursory examination of incidents involving the County and
its police department since 2010, the first full year after the MOA was
terminated.

   Taken together, the existing quantitative and qualitative information seems
to suggest a wide gulf between where Prince George's County appears to be and
where the Justice Department would have wanted them to be seven years after the
MOA was signed.

 [*102]  E. Los Angeles, California

   On July 15, 2001 the City of Los Angeles and the DOJ formalized what remains
arguably the most comprehensive, pervasive reform instrument authorized under §
14141. Like the agreements discussed above, the LAPD consent decree (CD)
addressed a pattern or practice of excessive force and the absence of requisite
officer accountability and inadequate oversight.  n137 The DOJ also sought to
address unlawful search and arrest protocols, treatment of mentally ill
suspects, and racial inequities in the administration of both traffic and
pedestrian stops, in order to remedy problems with both the receipt and
investigation of complaints filed against LAPD officers, as well as the
management of confidential informants and department gang units.  n138

   The CD relied heavily on increased officer training and the institution of
several mechanisms designed to strengthen both internal and external
accountability. In addition to the development of an early warning system
designed to predict officer misconduct, the LAPD agreed to conduct regular
audits of CD-related performance and to accept enhanced oversight from the
City's Inspector General and the Police Commission,  n139 a civilian body
instituted in the 1920s to oversee the Department.  n140

   Former prosecutor Michael Cherkasky served as independent monitor, charged
with overseeing implementation.  n141 On July 17, 2009, Federal District Court
Judge Gary Feess signed an order approving termination of all but a few
provisions of the original CD.  n142 The consent decree was formally terminated
on May 15, 2013.  n143

   Much of the response to the reform effort has been positive. Attorney Merrick
Bobb, who is currently the Independent Monitor of the § 14141 process in Seattle
and longtime Los Angeles resident, saw the LAPD go from "an occupying  [*103]
army to being a community partner."  n144 Critics of the Department also have
recognized a change. "I'm not particularly fond of the police," said Clarence
Heard, a minister in South Los Angeles, "but, to be honest with you, I think
L.A. is much better since the feds took over the LAPD. You know, I think they
work harder at trying to defuse a situation as opposed to escalating a
situation."  n145 According to the executive director of the ACLU of Southern
California, the consent decree process resulted in "serious culture changes" to
the Department.  n146

   In 2009, Harvard University published a comprehensive analysis of the LAPD,
with a particular focus on the effects of the consent decree on officer morale
and performance, police-community relations, and the accountability
infrastructure inside the Department.  n147 After reviewing available
administrative data, including figures on use of force, citizen complaints, and
traffic and pedestrian stops, as well as survey and interview data gathered from
citizens and LAPD staff, the authors conclude that the "LAPD of today is a
changed organization."  n148 The available empirical evidence largely supports
these observations,  n149 beginning with the absence of any visible increases in
jurisdiction crime rates. Figure 15 makes clear that pattern or practice reform
in Los Angeles had no adverse effect on the City's violent or property crime.

    [*104]   Figure 15. Crime in Los Angeles, CA (1985-2012)

   Source: FBI Uniform Crime Report

 Figure 16. Use of Force by LAPD Officers (2001-2015)

   Source: LAPD. Note: Data on non-categorical use of force missing for 2003.

   Between 2001, when the CD was instituted, and 2009, when the Transition
Agreement went into effect, the LAPD averaged just over seventy officer-involved
shootings per year. In the six years since, the yearly average fell to 47.8, a
drop of  [*105]  22.4 percent. Incidence of non-categorical (non-deadly) use of
force spiked in 2004, but has remained relatively constant since, as is shown in
Figure 16. During the CD, LAPD officers used non-categorical force 1,894 times
per year on average, compared to 1,759 such incidents between 2010 and 2015. As
no pre-CD data is available, it is impossible to know how these reform and
post-reform data compare to pre-CD use of force levels. But that incidence of
both deadly and non-deadly force trend down at least suggests that there has not
been considerable backsliding in the absence of DOJ oversight.

    [*105]   Figure 17. Use of Force-Related Civil Litigation in Los Angeles
(1996-2012)

   Source: City of Los Angeles

   Data on use of force-related litigation, charted in Figure 17, is consistent
with these conclusions. Between 1996 and 2001, when the CD was enacted, citizens
filed an average of 240 civil suits alleging excessive force by LAPD officers.
During that period, plaintiffs won an average of 36 percent of the time. Between
2002 and 2009, average annual litigation fell to 150, with plaintiff remaining
flat at 35 percent. Between 2010, the first full year after the transition
agreement was signed, and 2012, plaintiffs won on 27 percent of the 119 suits
filed on an average annual basis.

    [*106]   See Figure 18. Financial Awards for Use of Force-Related Civil
Litigation in Los Angeles (1996-2012)

   Source: City of Los Angeles

   That the volume of civil litigation related to officer use of force and the
odds of a plaintiff victory each declined fairly steadily during the CD period
and continued to decline as the Department transitioned from federal oversight
is a solid indication that out-of-policy force events have become less common,
which reflects positively on the reform effort. Data on force-related payouts
complicates the story a bit. As is clear in Figure 18, which documents the total
annual cost of force-related civil litigation and the average payout of each
plaintiff victory between 1996 and 2012, the cost of police abuse is more
variable than case filings.

   Though the trend lines for each variable appear to slope downward, there are
three clear spikes: 1999/2000, 2007, and 2010. In 2007 and 2010, these payout
spikes occurred without significant corresponding spikes in either the volume of
cases filed or recorded use of force events, which suggests that they can
reasonably be attributed to a particularly severe incident or series of
incidents, like the May 1, 2007 confrontation between immigration protestors and
LAPD officers in MacArthur Park.  n150 Uses of force incidents such as these are
unavoidable in a city as large and as diverse as Los Angeles. That two such high
profile and significant  [*107]  events occurred in a three-year period is most
likely an indication of this inevitability, though something that should be
monitored fairly closely.

   Tellingly, the CD process has been credited with minimizing the effects of
these types of violent incidents: "Los Angeles has had its fair share of
officer-involved shootings recently, and they still generate protests. But
things haven't really gotten out of hand. Police reform groups and many LAPD
officials say this is a testament to all the work that's been done to repair
relations with communities over the year."  n151

   The Harvard report concludes with a note about the sustainability of the
changes found: "It is not that policing in Los Angeles is all that it can ever
be, but the balance of local leadership and local oversight is healthy enough to
carry the process of continuous improvement forward" in the absence of DOJ
oversight.  n152

   The strongest argument to be made along these lines will surely include
discussion of the relatively strong external accountability mechanisms in Los
Angeles. Pre-existing institutions like the Police Commission and the City's
Inspector General's Office were empowered by the consent decree and appear as of
this writing to remain active in their oversight of the LAPD.  n153 Moreover,
the city has a strong network of civil rights organizations to buttress these
formal institutions, as well as an active local media. One manifestation of this
external oversight is the extent to which the Department has committed to
sharing performance data and other information with the public. According to a
recent analysis of 350 police department websites, the LAPD ranked third in
terms of web based transparency.  n154

   To some, including author and attorney Tom Hayden, the current regulatory
infrastructure is insufficient: "[W]ithout the oversight of a federal judge and
a consent decree road map, the system of police reform in Los Angeles will
remain ad hoc, ineffective and even broken. . . . Beneath the layers of reform
added to the department over three decades, it remains the fact that the police
predominate in  [*108]  policing the police."  n155 This skepticism is surely a
function of the Department's long history of violence, racial injustice, and
impunity. The view of Earl Ofari Hutchinson, president of the Los Angeles Urban
Policy Roundtable, is instructive:


     There are still some of the old troubling signs . . . . Officers that
     overuse deadly force or commit acts of misconduct must be punished.
     Without it, it reinforces the notion that officers can administer
     street corner justice. This is the practice that got the LAPD into so
     much hot water in years past.  n156

   V. ANALYSIS

A. Variations in Outcomes

   Organizational response to the termination of pattern or practice reform
varied considerably between police departments in Pittsburgh, Cincinnati,
Washington, D.C., Prince George's County, and Los Angeles. The PBP was not able
to sustain organizational changes made under federal oversight. Key outcomes
that remained flat during implementation, including use of force incidence and
allegations of misconduct, now trend upward. Though there is new leadership in
place, the PBP is less than two years removed from the corruption scandal and
several high profile force-related incidents that prompted Pittsburgh Mayor Bill
Peduto to declare the department "on the verge of another consent decree."  n157

   By contrast, the process seems to have had a sustained, positive effect in
both Cincinnati and Washington, D.C. Numbers of post-reform citizen complaints
against CPD officers continue to decline, as does use of force incidence, and
the number of injuries sustained by CPD officers. Such progress has contributed
to strengthening the relationship between the Department and minority community
members  n158 and a sterling national reputation.  n159 In Washington, D.C.,
declines in  [*109]  both deadly force incidence and force-based civil
litigation suggest that the consent decree brought with it significant
improvements in department use of force policy, training, and oversight.
Inconsistencies in citizen complaint volume complicate the picture somewhat, as
does the startling number of officers that have faced criminal charges in the
post-reform years, though on balance the department appears to have made and
sustained considerable progress. Similar positive trends are evident in Los
Angeles, though there has been less time to evaluate post-reform progress there.

   Objective evaluation of Prince George's County is rather difficult, given the
limited amount of data made available. But it seems apparent that the department
continues to struggle with officer misconduct and has quite a ways to go to
reach the kind of accountability infrastructure developed in other
jurisdictions.

   Even in light of certain methodological limitations, these findings highlight
the challenge jurisdictions face in working to institutionalize pattern or
practice reform. They also demonstrate how little we actually know about the
effectiveness and sustainability of pattern or practice reform.

B. The Need for More Consistent Data

   Owing largely to the absence of consistent outcome data and a lack of
cooperation among potential subject jurisdictions, it is rather difficult to
generalize beyond the included cities. Further, without the data needed to
properly establish benchmarks, formal consideration of causal hypotheses was all
but impossible. In the absence of a deeper quantitative analysis, there remains
the possibility that some of the trends discussed occurred as a result of
factors other than reform implementation or termination.

   The need to evaluate the effectiveness and long-term sustainability of these
initiatives is clear, yet we lack the basic data needed to do so. This need not
be the case. In some jurisdictions, including Los Angeles, the DOJ has insisted
on the capture and publication of relevant outcome measures.  n160 Mandating the
dissemination of use of force statistics, officer disciplinary decisions, and
civil litigation results would be a solid step toward facilitating evaluation of
future settlement agreements, as would requiring independent monitors to set and
report on outcome-related goals, rather than continuing to perform what amounts
to an exclusively process-driven assessment.

C. The Need for More Thorough, Nuanced Analysis

   The field would also benefit from future research that moves beyond the use
of outcome data to evaluate sustainability, beginning with an assessment of
officer  [*110]  attitudes and organizational culture more broadly. In addition
to contributing to more thorough descriptive knowledge, examining the
relationship between outcomes, officer behavior, and department culture, would
help to broaden understanding of those factors that explain institutionalization
success and failure. To what extent do these elements show a consistent picture
of agency efforts to pursue and institutionalize reform? Can a department
achieve and sustain desirable levels of key outcomes, for example, in spite of a
culture that may not reflect core reform values?

   A closer look at the inner-workings of affected departments would allow for a
much more nuanced assessment of change. By necessity, the current research
framed pattern or practice reform as a monolithic initiative, rather than as a
series of individual components. In fact, development and implementation of each
component, from new policies and training to community outreach efforts, are
unique, distinguishable efforts, each worthy of a separate evaluation. As it
stands today, it is all but impossible to tease out the value of specific
components, either in terms of their effectiveness or sustainability. Does a
department's use of an early intervention system actually lead to fewer
incidents of misconduct and lower civil litigation costs? To what extent does
the system's effectiveness change over time? Is there an interaction between
system usage and officer training, in terms of both short- and long-term
outcomes? Answers to these and other similar questions would improve the
efficiency of future settlement agreements and aid departments in
institutionalizing change.

   Finally, future research should continue to monitor these and other pattern
or practice jurisdictions, paying particular attention to identifying those
factors that distinguish reforms that endure from those that erode. Explaining
the success in Cincinnati would be a useful point of departure. To what extent
did support for reform among city leaders and community residents contribute to
the durability of that Department's turn-around? The strength of officer
accountability mechanisms, both internal to the CPD and in agencies like the
Citizen Complaint Authority? Strategic efforts to coopt potentially hostile
groups like the officers' union? Was support from middle management as critical
in Cincinnati as it was to sustaining problem-oriented policing strategies in
Charlotte, North Carolina?  n161 Perhaps sustainability is a function of robust
efforts to educate officers to "nature, goals, and benefits" of such reforms, as
some contend.  n162

    [*111]  VI. CONCLUSION

   The best evidence on the DOJ's pattern or practice initiative suggests that
after implementing mandated reforms, affected departments will likely possess a
stronger, more capable accountability infrastructure, more robust training, and
a set of policies that reflect national best practices.  n163 These changes
occur as a result of the agreements' substantive requirements and the close,
external oversight that tends to accompany their implementation.

   But as the current research shows, the reform process is more complex than
the pursuit of substantial compliance with settlement terms. The resultant
organizational changes are not self-sustaining; implementation does not in and
of itself guarantee meaningful, institutionalized change. In fact, the
assumption that it does may undermine efforts to promote lasting reform. The
typical settlement agreement binds affected departments to a five-year period of
federal oversight. Upon a declaration of substantial compliance, which usually
occurs on or around the end of the contractual term, the DOJ announces that
department has been reformed, promptly terminates the agreement, and moves on to
other initiatives.  n164 This abrupt stoppage signals to the department that
sufficient change has been made and that no further attention to the reform is
necessary. Given how tenuous these reforms appear to be and how unpopular they
remain among the rank-and-file, the goals of the initiative would likely be
better served by ongoing external oversight of the affected department. Periodic
external check-ups designed to promote independent post-termination oversight,
whether conducted by DOJ attorneys or a public agency similar to the one created
by the State of New Jersey,  n165 would be a worthwhile investment.

   The absence of sufficient monitoring and oversight can be tragic. The City of
Cleveland knows this well. In August 2000, the DOJ opened a pattern or practice
investigation into claims of excessive force by Cleveland Division of Police
(CDP) officers.  n166

   In July 2002, the year Tamir Rice was born and twelve years before his fatal
encounter with the Cleveland Police Department, DOJ attorneys recommended that
[*112]  the CDP "clarify its use of deadly force policy,"  n167 while raising
questions about "the competency, thoroughness, and impartiality of [CDP] use of
force investigations"  n168--nearly identical to language drawn from the
Investigative Findings Letter sent to Cleveland Mayor Frank Jackson in December
2014.  n169

   Though the case of police reform in Cleveland is certainly unique, the
overarching point remains: organizational change is a long and fragile process.
Effectiveness is not guaranteed and early gains do not necessarily equate to
institutionalized change. This lesson is a critical one, for DOJ staff and
stakeholders in jurisdictions currently under federal oversight, for police
leaders and other public actors contemplating reform, and for policing scholars
and other students of the administrative process. The sooner it takes hold, the
more likely it is that changes brought about through the pattern or practice
initiative will not suffer the fate of other recent reform efforts.

Legal Topics:

For related research and practice materials, see the following legal topics:
Civil Rights LawPrisoner RightsSegregationContracts LawTypes of
ContractsSettlement AgreementsGovernmentsLocal GovernmentsPolice Power

FOOTNOTES:





n1  Kimbriell Kelly, Sarah Childress & Steven Rich, What Happens When the Police
Are Forced to Reform?, PBS FRONTLINE (Nov. 13, 2015),
http://stories.frontline.org/what-happens-when-police-are-forced-to-reform.





n2  Shaila Dewan & Richard A. Oppel, Jr., In Tamir Rice Case, Many Errors by
Cleveland Police, Then a Fatal One, N.Y. TIMES (Jan. 22, 2015),
http://www.nytimes.com/2015/01/23/us/in-tamir-rice-shooting-in-cleveland-many-er
rors-by-police-then-a-fatal-one.html.





n3  Settlement Agreement, United States v. City of Cleveland, 1:15-cv-01046-SO
(N.D. Ohio May 26, 2015),
https://www.justice.gov/sites/default/files/crt/legacy/2015/05/27/cleveland_agre
ement_5-26-15.pdf.





n4  Head of Civil Rights Division Vanita Gupta Delivers Remarks Announcing a
Settlement Agreement with the City of Cleveland Over the Pattern or Practice
Investigation into the Cleveland Division of Police, U.S. DEP'T OF JUSTICE (May
26, 2015),
https://www.justice.gov/opa/speech/head-civil-rights-division-vanita-gupta-deliv
ers-remarks-announcing-settlement-agreement.





n5  42 U.S.C. § 14141 (1994).





n6  Mark Berman, Sari Horwitz & Wesley Lowery, Justice Dept. Sues the City of
Ferguson to Force Policing Reform, WASH. POST (Feb. 11, 2016),
https://www.washingtonpost.com/news/postnation/wp/2016/02/10/ferguson-demands-ch
anges-to-agreement-reforming-police-tactics-justice-dept-criticizes-unnecessary-
delay/.





n7  Press Release, U.S. Dep't of Justice, Justice Department Opens Pattern or
Practice Investigation into the Baltimore Police Department (May 8, 2015),
http://www.justice.gov/opa/pr/justice-department-opens-pattern-or-practice-inves
tigation-baltimore-police-department.





n8  Press Release, U.S. Dep't of Justice, Justice Department Opens Pattern or
Practice Investigation into the Chicago Police Department (Dec. 7, 2015),
https://www.justice.gov/opa/pr/justice-department-opens-pattern-or-practice-inve
stigation-chicago-police-department.





n9  Sara Childress, Fixing the Force, PBS FRONTLINE (Dec. 14, 2015),
http://www.pbs.org/wgbh/frontline/article/fixing-the-force/.





n10  Stephen Rushin, Federal Enforcement of Police Reform, 82 FORDHAM L. REV.
3189, 3207-15 (2014); Press Release, U.S. Dep't of Justice, Justice Department
Reaches Agreement with City of Newark, New Jersey, to Address Unconstitutional
Policing in Newark Police Department (July 22, 2014),
https://www.justice.gov/opa/pr/justice-department-reaches-agreement-city-newark-
newjersey-address-unconstitutional-policing; Press Release, U.S. Dep't of
Justice, Justice Department and City of Ferguson, Missouri, Resolve Lawsuit with
Agreement to Reform Ferguson Police Department and Municipal Court to Ensure
Constitutional Policing (Mar. 17, 2016),
https://www.justice.gov/opa/pr/justice-department-and-city-ferguson-missouri-res
olve-lawsuit-agreement-reform-ferguson. There are exceptions. See Simone
Weichselbaum, A Rural Sheriff Stares Down the Justice Department, THE MARSHALL
PROJECT (Oct. 6, 2015),
https://www.themarshallproject.org/2015/10/06/a-rural-sheriff-stares-down-the-ju
stice-department#. xJ9SSzY94 (U.S. lost at trial against Alamance, N.C. Sherriff
Terry S. Johnson); Press Release, U.S. Dep't of Justice, Justice Department Wins
Religious Discrimination Lawsuit Against Colorado City, Arizona, and Hildale,
Utah (Mar. 7, 2016),
https://www.justice.gov/opa/pr/justice-department-wins-religious-discrimination-
lawsuit-against-colorado-city-arizona-and (Colorado City, AZ lost advisory jury
verdict on § 14141 claims).





n11  Joshua M. Chanin, Negotiated Justice? The Legal, Administrative, and Policy
Implications of "Pattern or Practice" Police Misconduct Reform 335 (July 6,
2011) (unpublished Ph.D. dissertation, American University),
https://www.ncjrs.gov/pdffiles1/nij/grants/237957.pdf; Stephen Rushin, Federal
Enforcement of Police Reform, 82 FORDHAM L. REV. 3189, 3207-15 (2014); Debra
Livingston, Police Reform and The Department of Justice: An Essay on
Accountability, 2 BUFF. CRIM. L. REV. 817 (1999).





n12  Despite some variation in their data collection and oversight method, each
monitor team applied the 95 percent substantial compliance threshold very
similarly, regardless of the substantive nature of the provision under review.
For example, when considering Pittsburgh's Office of Municipal Investigation's
ability to issue final reports on all investigations, the monitor determined
that "[a] failure rate of 15 of 55 completed cases constitutes 27 percent, far
in excess of the allowable five percent." PUB. MGMT. RES., AUDITOR'S NINETEENTH
QUARTERLY REPORT 53 (2002),
http://www.clearinghouse.net/chDocs/public/PN-PA-0003-0020.pdf. Similarly,
"MPD's demonstration of a sustained UFIR completion rate between 86% and 91% . .
. [was] quite high, even if below the 95% threshold." MICHAEL R. BROMWICH,
OFFICE OF THE INDEP. MONITOR, FINAL REPORT OF THE INDEPENDENT MONITOR FOR THE
METROPOLITAN POLICE DEPARTMENT 2 (2008),
http://www.policemonitor.org/MPD/reports/080613reportv2.pdf.





n13  JANET RENO, U.S. DEP'T OF JUSTICE, PRINCIPLES FOR PROMOTING POLICE
INTEGRITY: EXAMPLES OF PROMISING POLICE PRACTICES AND POLICIES (2001),
http://www.ncjrs.gov/pdffiles1/ojp/186189.pdf.





n14  E.g., Sari Horwitz & Jeff Leen, District Asks U.S. to Review Shootings,
WASH. POST (Jan. 7, 1999),
http://www.washingtonpost.com/wp-srv/local/longterm/dcpolice/deadlyforce/police7
.htm; David McCabe, Baltimore Mayor Asks DOJ to Investigate Police, THE HILL
(May 6, 2015),
http://thehill.com/blogs/blog-briefing-room/news/241180-baltimore-mayor-asks-doj
-to-investigatepolice-department.





n15  E.g., AM. CIVIL LIBERTIES UNION OF SAN DIEGO & IMPERIAL CTYS, ACLU
STATEMENT ON REPORT ASSESSING SDPD'S MISCONDUCT POLICIES (2015),
https://www.aclusandiego.org/aclustatement-on-report-assessing-sdpds-misconduct-
policies/.





n16  E.g., POLICE EXEC. RESEARCH FORUM, CIVIL RIGHTS INVESTIGATIONS OF LOCAL
POLICE: LESSONS LEARNED (2013),
http://www.policeforum.org/assets/docs/Critical_Issues_Series/civil%20investigat
ions%20of%20loca l%20police%20-%20lessons%20learned%202013.pdf.





n17  Heather Mac Donald, Targeting the Police, WEEKLY STANDARD (Jan. 31, 2011),
http://www.weeklystandard.com/targeting-the-police/article/536863; Brandon
Darby, Left Media Just Can't Stop Trashing Sheriff Joe Arpaio--For Doing His Job
, BREITBART (Oct. 3, 2015),
http://www.breitbart.com/big-government/2015/10/03/left-media-just-cant-stop-tra
shing-sheriff-joe-arpaio-for-doing-his-job/.





n18  Matthew J. Hickman, Opinion, Department of Justice Owes the Seattle Police
Department an Apology, SEATTLE TIMES (Feb. 8, 2012),
http://www.seattletimes.com/opinion/department-ofjustice-owes-the-seattle-police
-department-an-apology/.





n19  Maxine Bernstein, Portland Police Union Seeks to Intervene in Federal Court
Review of DOJ's Negotiated Settlement on Police Reforms, OREGONIAN: OREGONLIVE
(Dec. 19, 2012),
http://www.oregonlive.com/portland/index.ssf/2012/12/portland_police_union_files
_mo.html; Levi Bruce, Consent Decree Brings 500 Reforms, Controversy in NOPD,
NOLA DEFENDER (Aug. 2012),
http://www.noladefender.com/content/consent-decree-brings-500-reforms-controv99e
rsy-no5pd-0.





n20  Aamer Madhani, Ferguson: DOJ Consent Decree Could Cost City Nearly $ 10M,
USA TODAY (Feb. 8, 2016),
http://www.usatoday.com/story/news/2016/02/08/feguson-doj-consent-decreecould-co
st-city-nearly-10m/80031828/; Charles Maldonado, Paying for the Consent Decree,
GAMBIT (Aug. 14, 2012),
http://www.bestofneworleans.com/gambit/reform-at-a-cost/Content?oid=2057022.





n21  Kristen Gwynne, Can Obama's Justice Department Actually Curb Police
Brutality?, VICE (Dec. 9, 2014),
http://www.vice.com/read/can-obama-justice-department-do-anything-to-stop-police
-brutality-129.





n22  Wesley G. Skogan, Why Reforms Fail, 18 POLICING & SOC'Y 23 (2008).





n23  Samuel E. Walker, Institutionalizing Police Accountability Reforms: The
Problem of Making Police Reforms Endure, 32 ST. LOUIS U. PUB. L. REV. 57 (2012).





n24  Id. at 60.





n25  CANADIAN CTR. FOR MGMT. DEV., TAKING STOCK: ASSESSING PUBLIC SECTOR REFORMS
6 (Guy Peters & Donald J. Savoie eds., 1998).





n26  Evan MacDonald, Cleveland Police Union Says Justice Department Reforms
Would Endanger Police, CLEVELAND.COM (May 28, 2015),
http://www.cleveland.com/metro/index.ssf/2015/05/union_head_says_aspects_of_cle.
html.





n27  PHILLIP J. COOPER, HARD JUDICIAL CHOICES: FEDERAL DISTRICT COURT JUDGES AND
STATE AND LOCAL OFFICIALS (1988).





n28  See, e.g., MICHAEL J. KLARMAN, FROM JIM CROW TO CIVIL RIGHTS: THE SUPREME
COURT AND THE STRUGGLE FOR RACIAL EQUALITY (2004).





n29  Vincent M. Nathan, Have the Courts Made a Difference in the Quality of
Prison Conditions? What Have We Accomplished to Date?, 24 PACE L. REV. 419
(2004).





n30  Jonathan Brant, Pennhurst, Romeo, and Rogers: The Burger Court and Mental
Health Law Reform Litigation, 4 J. LEGAL MED. 323 (1983).





n31  Michele Deitch, The Need for Independent Prison Oversight in a Post-PLRA
World, 24 FED. SENT'G REP. 236 (2012).





n32  CHARLES T. CLOTFELTER, AFTER BROWN: THE RISE AND RETREAT OF SCHOOL
DESEGREGATION 48 (2004).





n33  See, e.g., Erwin Chemerinsky, The Segregation and Resegregation of American
Public Education: The Court's Role, 81 N.C. L. REV. 1597 (2003); Sean F. Reardon
et al., Brown Fades: The End of Court-Ordered School Desegregation and the
Resegregation of American Public Schools, 31 J. POL'Y ANALYSIS &MGMT. 876
(2012).





n34  GARY ORFIELD, SCHOOLS MORE SEPARATE: CONSEQUENCES OF A DECADE OF
RESEGREGATION 2 (2001),
https://civilrightsproject.ucla.edu/research/k-12-education/integration-and-dive
rsity/
schools-more-separate-consequences-of-a-decade-of-resegregation/orfield-schools-
moreseparate-2011.pdf; Chemerinsky, supra note 33.





n35  Melanie Ann Taylor, A Case Study of the Civil Rights of Institutionalized
Persons Act: Reforming the Arizona Department of Juvenile Corrections (May 2013)
(unpublished Ph.D. dissertation, Arizona State University),
http://repository.asu.edu/attachments/110593/content/Taylor_asu_0010E_13015.pdf.





n36  THOMAS G. CUMMINGS & CHRISTOPHER G. WORLEY, ORGANIZATION DEVELOPMENT AND
CHANGE 189 (8th ed. 2005).





n37  TRENT IKERD & SAMUEL WALKER, U.S. DEP'T OF JUSTICE, MAKING POLICE REFORMS
ENDURE: THE KEYS FOR SUCCESS 5 (2010),
http://ric-zai-inc.com/Publications/cops-p176-pub.pdf.





n38  Christine Oliver, The Antecedents of Deinstitutionalization, 13 ORG. STUD.
563 (1992).





n39  Id. at 581.





n40  NHS MODERNISATION AGENCY, IMPROVEMENT LEADER'S GUIDE TO SUSTAINABILITY AND
SPREAD (2002).





n41  John P. Kotter, Leading Change: Why Transformation Efforts Fail, 73 HARV.
BUS. REV., Mar.-Apr. 1995.





n42  Trent E. Ikerd, Beyond "Flavor of the Month": Institutionalizing
Problem-Oriented Policing (POP) in the CMPD, 33 POLICING: AN INT'L J. OF POLICE
STRATEGIES &MGMT. 179 (2010).





n43  CUMMINGS &WORLEY, supra note 36, at 196.





n44  See, e.g., WESLEY G. SKOGAN & SUSAN M. HARTNETT, COMMUNITY POLICING:
CHICAGO STYLE (1997); IKERD &WALKER, supra note 37.





n45  Kathryn E. Newcomer, Using Performance Measurement to Improve Public and
Nonprofit Programs, 75 NEW DIRECTIONS FOR EVALUATION 5 (1997).





n46  Robert D. Behn, Why Measure Performance? Different Purposes Require
Different Measures, 63 PUB. ADMIN. REV. 586 (2003).





n47  NAT'L INST. OF JUSTICE, MEASURING WHAT MATTERS: PROCEEDINGS FROM THE
POLICING RESEARCH INSTITUTE MEETINGS 151 (Robert H. Langworthy ed., 1999).





n48  Oliver, supra note 38, at 568.





n49  Joshua M. Chanin, Negotiated Justice? The Legal, Administrative, and Policy
Implications of "Pattern or Practice" Police Misconduct Reform 228 (July 6,
2011) (unpublished Ph.D. dissertation, American University),
https://www.ncjrs.gov/pdffiles1/nij/grants/237957.pdf.





n50  The remaining eight jurisdictions include: the State of New Jersey;
Steubenville, OH; Montgomery County, MD; Highland Park, IL; Buffalo, NY; Mount
Prospect, IL; Villa Rica, GA; and Cleveland, OH.





n51  The research that preceded this paper received Institutional Review Board
approval. All but one interviewee agreed to speak on the record. A subject list
and interview transcripts are on file with the author.





n52  It is worth noting that not all reform efforts proceed incrementally, and
some fail to take hold at all. See Samuel Walker, Does Anyone Remember Team
Policing? Lessons of the Team Policing Experience for Community Policing, 12 AM.
J. POLICE 33, 34-35 (1993) (describing the failure of the team policing reform
effort); see also LAWRENCE W. SHERMAN, SCANDAL AND REFORM: CONTROLLING POLICE
CORRUPTION (1978) (describing the failure of the effort to require officers to
obtain a college degree).





n53  Consent Decree, United States v. City of Pittsburgh, 2:97-cv-00354-RJC
(W.D. Pa. Feb. 26, 1997),
https://www.justice.gov/crt/united-states-district-court-western-district-pennsy
lvania-united-states-america-plaintiff-v-0.





n54  Stipulated Order, United States v. City of Pittsburgh, No. 97-0354 (W.D.
Pa. Sept. 30, 2002),
https://www.justice.gov/crt/united-states-district-court-western-district-pennsy
lvania.





n55  ROBERT DAVIS, NICOLE HENDERSON & CHRISTOPHER ORTIZ, CAN FEDERAL
INTERVENTION BRING LASTING IMPROVEMENT IN LOCAL POLICING?: THE PITTSBURGH
CONSENT DECREE 2 (2005),
http://www.vera.org/sites/default/files/resources/downloads/277_530.pdf. Because
the Office of Municipal Investigations (OMI) remained under the consent decree
during the period when Vera examined the sustainability of reform at PBP, their
2005 report does not address efforts to institutionalize changes at OMI.





n56  Id.





n57  Id. at 21.





n58  Id. at 19-20.





n59  Id. at 7-14.





n60  Id. at 39.





n61  Id. at 40-41.





n62  Kim M. Lersch, Police Misconduct and Malpractice: A Critical Analysis of
Citizens' Complaints, 21 POLICING: AN INT'L J. POLICE STRATEGIES & MGMT. 80
(1998); Jeff Rojek & Scott H. Decker, Examining Racial Disparity in the Police
Discipline Process, 12 POLICE Q. 388 (2009); SAMUEL E. WALKER & CAROL A.
ARCHBOLD, THE NEW WORLD OF POLICE ACCOUNTABILITY (2d ed. 2013).





n63  CARL B. KLOCKARS ET AL., ENHANCING POLICE INTEGRITY (2006).





n64  John D. McCluskey & William Terrill, Departmental and Citizen Complaints as
Predictors of Police Coercion, 28 POLICING: AN INT'L J. OF POLICE STRATEGIES
&MGMT. 513 (2005).





n65  Interview with Charles Ramsey, former Washington, D.C. Metropolitan Dep't
Police Chief (May 20, 2010).





n66  Compare Kim M. Lersch & Tom Mieczkowski, Who are the Problem-Prone
Officers? An Analysis of Citizen Complaints, 15 AM. J. POLICE 3, 23-24 (1996),
with McCluskey & Terrill, supra note 64.





n67  Interview with Robert McNeilly, Police Chief, Elizabeth Twp. Police, in
Pittsburgh, Pa. (Mar. 1, 2010).





n68  Michael A. Fuoco, Police Chief McNeilly's Tenure Saw Wrenching Changes,
PITTSBURGH POST-GAZETTE (Jan. 9, 2006),
http://www.post-gazette.com/stories/local/neighborhoods-city/police-chief-mcneil
lys-tenure-saw-wrenching-changes-416443/.





n69  Paula R. Ward, Justice Dept.'s Decision in Jordan Miles Case Increases
Distrust, PITTSBURGH POST-GAZETTE (May 8, 2011),
http://www.post-gazette.com/stories/local/neighborhoodscity/justice-depts-decisi
on-in-jordan-miles-case-increases-distrust-296751/.





n70  Jill King Greenwood, Ex-Police Chief Says Mayor Snubbed Him, PITTSBURGH
TRIBUNE-REVIEW (Mar. 6, 2006),
http://triblive.com/x/archive/1416632-74/archive-story.





n71  Id.





n72  Joe Smydo, Mayor Moves to Replace Some Members of Police Review Board,
PITTSBURGH POST-GAZETTE (June 19, 2010),
http://www.post-gazette.com/stories/local/neighborhoods-city/mayor-moves-to-repl
ace-some-members-of-police-review-board-251953/.





n73  Associated Press, 83 Arrested at G-20 in Pittsburg, $ 50,000 in Damage,
PENNLIVE (Sept. 25, 2009),
http://www.pennlive.com/midstate/index.ssf/2009/09/83_arrested_at_g-20_in_pittsb
u.html.





n74  Interview with Robert McNeilly, Police Chief, Elizabeth Twp. Police, in
Pittsburg, Pa. (Mar. 1, 2010). In fairness to the police, crowd control and
protest management were not specific areas of focus under the pattern or
practice reform initiative. The police contend that their behavior in response
to the G-20 protests was entirely lawful and well-within department protocol.
Alexandra Frean & David Byers, Police Embroiled in Violent Battles with G20
Protesters, TIMES (Sept. 24, 2009),
http://www.thetimes.co.uk/tto/news/world/americas/article2001320.ece.





n75  Sadie Gurman, Chief Ordered to Give Police Review Board G-20 Reports,
PITTSBURGH POST-GAZETTE (Mar. 19, 2010),
http://www.post-gazette.com/local/city/2010/03/19/Chief-ordered-to-give-police-r
eview-board-G-20-reports/stories/201003190154.





n76  Court Rules for Pittsburgh on G20 Arrests, UNITED PRESS INT'L (Dec. 29,
2011),
http://www.upi.com/Top_News/US/2011/12/29/Court-rules-for-Pittsburgh-on-G20-arre
sts/UPI-57881325188557/.





n77  Joe Smydo & Moriah Balingit, Controversy Addressed Over Police Review Board
Changes in City, PITTSBURGH POST-GAZETTE (June 23, 2010),
http://www.post-gazette.com/local/city/2010/06/23/Controversy-addressed-over-pol
ice-review-board-changes-in-city/stories/201006230185.





n78  Between 93 and 95 percent, according to the 2010 U.S. Census. UNIV. CTR.
FOR SOCIAL & URBAN RESEARCH, UNIV. OF PITTSBURGH, CITY OF PITTSBURGH
NEIGHBORHOOD PROFILES, CENSUS 2010 SUMMARY FILE 1 (SF1) DATA 47-49 (2011),
http://ucsur.pitt.edu/wp-content/uploads/2014/11/UCSUR_SF1_NeighborhoodProfiles_
July2011.pdf.





n79  Paula R. Ward, Judge Dismisses Charges against CAPA Student, PITTSBURGH
POSTGAZETTE (Mar. 5, 2010),
http://www.post-gazette.com/stories/local/neighborhoods-city/judge-dismisses-cha
rges-against-capa-student-236378/.





n80  Id.





n81  Rich Lord & Liz Navratil, Jordan Miles Jury Reaches Split Verdict,
PITTSBURGH POSTGAZETTE (Mar. 31, 2014),
http://www.post-gazette.com/local/city/2014/03/31/Jury-reaches-verdict-in-Jordan
-Miles-civil-trial/stories/201403310142.





n82  Jonathan D. Silver et al., Attorney: Ex-Pittsburgh Police Chief Nate Harper
to Plead Guilty, PITTSBURGH POST-GAZETTE (Mar. 22, 2013),
http://www.post-gazette.
com/stories/local/region/federal-grand-jury-meeting-suspended-police-finance-man
ager-on-hand-680415/.





n83  Rich Lord, Former Pittsburgh Chief Harper Gets 18-Month Prison Sentence,
PITTSBURGH POST-GAZETTE (Feb. 25, 2014),
http://www.post-gazette.com/local/city/2014/02/25/Former-Pittsburgh-police-chief
-Nathan-Harper-sentenced/stories/201402250123.





n84  Luke Nozicka, Former Pittsburgh Police Chief Nate Harper Released from
Prison, PITTSBURGH POST-GAZETTE (May 30, 2015), http://www.postgazette.
com/local/city/2015/05/30/Former-Pittsburgh-police-chief-Nate-Harper-released-fr
om-prison/stories/201505300157.





n85  Dale Shoemaker, Chief on Duty: Pittsburgh Police Chief Cameron McLay Wants
to Change His Force, and He Knows Just How He's Going To Do It, THE PITT NEWS
(Sept. 18, 2015),
http://pittnews.com/article/63046/news/chief-on-duty-pittsburgh-police-chief-cam
eron-mclay-wants-to-change-his-force-and-he-knows-just-how-hes-going-to-do-it.





n86  Jonathan D. Silver, City's Citizen Police Review Board Still a Subject for
Debate, PITTSBURGH POST-GAZETTE (May 3, 2005),
http://www.post-gazette.com/local/city/2005/05/03/City-s-Citizen-Police-Review-B
oard-still-a-subject-for-debate/stories/200505030245; Christian Morrow,
Citizen's Police Review Board: Fire Pittsburgh Cop for Teacher Arrest,
PITTSBURGH COURIER (Mar. 26, 2014),
http://newpittsburghcourieronline.com/2014/03/26/citizen-police-review-board-fir
e-pittsburgh-cop-for-teacher-arrest/.





n87  Rebecca Nuttall, Cameron McLay Getting High Marks after First Year as
Pittsburgh Police Chief, PITTSBURGH CITY PAPER (Sept. 23, 2015),
http://www.pghcitypaper.com/pittsburgh/cameron-mclay-getting-high-marks-after-fi
rst-year-as-pittsburgh-police-chief/Content?oid=1855889.





n88  Id.





n89  On file with author.





n90  Memorandum of Agreement Between the United States Department of Justice and
the District of Columbia and the District of Columbia Metropolitan Police
Department, U.S. DEP'T OF JUSTICE (June 13, 2001),
https://www.justice.gov/crt/memorandum-agreement-united-states-department-justic
e-and-district-columbia-and-dc-metropolitan.





n91  BROMWICH, supra note 12, at 3-4.





n92  Chanin, supra note 49, at 257.





n93  See, e.g., Jeff Leen et al., District Police Lead Nation in Shootings: Lack
of Training, Supervision Implicated as Key Factors, WASH. POST, Nov. 15, 1998,
at A1.





n94  See BROMWICH, supra note 12, at app. D.





n95  Associated Press, Protesters Scuffle with Police along Inaugural Route, USA
TODAY (Jan. 20, 2001),
http://usatoday30.usatoday.com/news/politics/inaug/2001-01-20-approtests.htm.





n96  Julie Zauzmer, Arrested Protesters Ask for Sanctions on District Officials,
WASH. POST (July 3, 2013),
http://articles.washingtonpost.com/2013-07-03/local/40349777_1_plaintiffs-court-
filing-attorney-general.





n97  These data are of limited value as a part of a broad review of MPD's
efforts to sustain reform-related changes, as the settlement agreement did not
address in any capacity policy related to mass protest. What is more, the
incident occurred less than a year in to the implementation process.





n98  A total of 68 force-related suits filed between 2003 and 2010 remain
unresolved and have the potential to increase Washington, D.C.'s total annual
payouts. Yet, even if one projects plaintiffs to win every outstanding case and
receive the average non-protest payout awarded between 2000 and 2010 ($ 57,096),
the effect on annual totals would be marginal.





n99  Aubrey Whelan, 90-Plus Arrests of D.C. Cops in Under 4 Years, WASH.
EXAMINER (Sept. 9, 2012),
http://www.washingtonexaminer.com/90-plus-arrests-of-d.c.-cops-in-under-4
years/article/2507386.





n100  Walker, supra note 23, at 64.





n101  Francis X. Clines, Appeals for Peace in Ohio After Two Days of Protests,
N.Y. TIMES (Apr. 11, 2011),
http://www.nytimes.com/2001/04/12/us/appeals-for-peace-in-ohio-after-two-days-of
-protests.html.





n102  Chanin, supra note 49, at 272-73.





n103  Id. at 273.





n104  Id. at 273-74.





n105  Jennifer E. Baker, Chief: Police-Involved Shooting 'a Fight for Survival,'
CINCINNATI.COM (Aug. 5, 2014),
http://www.cincinnati.com/story/news/2014/08/05/cincinnati-police-officer-shoots
-man-killed-traffic-stop/13611479.





n106  Susan Vela, Officer Shoots, Kills Suspect, CINCINNATI ENQUIRER (Apr. 8,
2001), http://enquirer.com/editions/2001/04/08/loc_officer_shoots_kills.html;
Marc Fisher, Cincinnati Still Healing from its Riots, and Has Lessons to Share
with Ferguson, WASH. POST (Sept. 5, 2014),
https://www.washingtonpost.com/politics/cincinnati-still-healing-from-its-riots-
and-has-lessons-to-share-with-ferguson/2014/09/05/2ff8b944-34a1-11e4-9e92-0899b3
06bbea_story.html.





n107  Nicole Flatow, What Has Changed About Police Brutality in America, from
Rodney King to Michael Brown, THINKPROGRESS (Sept. 11, 2014),
http://thinkprogress.org/justice/2014/09/11/3477520/whats-changed-and-what-hasnt
-in-policing-the-police/.





n108  Id.





n109  U.S. DEP'T OF JUSTICE, MEMORANDUM OF AGREEMENT BETWEEN THE UNITED STATES
DEPARTMENT OF JUSTICE AND PRINCE GEORGE'S COUNTY POLICE DEPARTMENT 1 (2004),
https://www.justice.gov/sites/default/files/crt/legacy/2010/12/15/pg_memo_agree.
pdf.





n110  Id. at 6-8.





n111  Id. at 8-11.





n112  Id. at 11-14.





n113  Id. at 14-18.





n114  Id. at 18-24.





n115  At the end of the five-year implementation process, PGPD was still unable
to meet the 90-day requirement for completing misconduct investigations.
ALEXANDRIA GROUP OF MPRI, REPORT OF THE INDEPENDENT MONITOR EIGHTEENTH QUARTERLY
REPORT 47-48 (2009),
http://web.archive.org/web/20110419215549/http://www.princegeorgescountymd.gov/G
overnment/PublicSafety/Police/pdfs/Final%20Eighteenth%20Quarterly%20Report%2001-
15-09.pdf.





n116  Aaron C. Davis, Justice Closes Pr. George's Police Review, WASH. POST
(Feb. 11, 2009),
http://www.washingtonpost.com/wp-dyn/content/article/2009/02/10/AR2009021002067.
html?tid=a_inl.





n117  Opinion, Crime Drops in Prince George's County, WASH. POST (Feb. 4, 2009),
http://www.washingtonpost.com/wp-dyn/content/article/2009/02/03/AR2009020302969.
html.





n118  Kimbriell Kelly et al., Forced Reforms, Mixed Results, WASH. POST (Nov.
13, 2015),
http://www.washingtonpost.com/sf/investigative/2015/11/13/forced-reforms-mixed-r
esults/.





n119  Id.





n120  Matt Zapotosky & Ruben Castaneda, Feds Now Lead Probe of Police Beating,
WASH. POST (Dec. 4, 2010),
http://www.washingtonpost.com/wp-dyn/content/article/2010/12/03/AR2010120306980.
html.





n121  Officer Receives Suspended Sentence in UMD Beating Case, NBC 4 WASH. (Dec.
14, 2012),
http://www.nbcwashington.com/news/local/Officer-Sentenced-UMD-Beating-James-Harr
ison-James-McKenna.html.





n122  Opinion, A Judge Wrongly Throws Out an Officer's Assault Verdict in Prince
George's County, WASH. POST, Sept. 20, 2014, at A22.





n123  Ruben Castaneda & Matt Zapotosky, Four More Prince George's Officers
Suspended in Alleged Moonlighting Misconduct, WASH. POST (Nov. 8, 2010),
http://www.washingtonpost.com/wp-dyn/content/article/2010/11/08/AR2010110805432.
html.





n124  Matt Zapotosky, D.C. Police Officer Sues Two Prince George's Officers,
Saying He Was Beaten, WASH. POST (Oct. 3, 2012),
https://www.washingtonpost.com/local/crime/dc-police-officer-sues-two-pr-georges
-officers-claiming-he-was-beaten/2012/10/03/66c249b0-0d73-11e2-a310-2363842b7057
_story.html.





n125  Matt Zapotosky, Charges Dropped Against D.C. Police Officer, WASH. POST
(Feb. 28, 2013),
https://www.washingtonpost.com/blogs/crime-scene/post/charges-dropped-against-dc
-police-officer/2013/02/28/8dec0f7c-81e4-11e2-8074-b26a871b165a_blog.html.





n126  Lynh Bui, 2 Pr. George's Officers are Indicted on Assault Charges, WASH.
POST, Oct. 31, 2014, at B6.





n127  Julie Zauzmer, Officer Convicted of Assault for Pointing Gun at Civilian's
Face, WASH. POST (Dec. 2, 2015),
https://www.washingtonpost.com/local/public-safety/officer-convicted-of-assault-
for-pointing-gun-at-civilians-face/2015/12/02/f8d3ec04-992b-11e5-94f0-9eeaff906e
f3_story.html.





n128  Matt Zapotosky, Pr. George's Police Woes Wider than U.S. Probe, WASH. POST
(Nov. 29, 2010),
http://www.washingtonpost.com/wp-dyn/content/article/2010/11/28/AR2010112804028.
html.





n129  Paul Schwartzman et al., Jack Johnson, Prince George's County Executive,
and His Wife, Leslie, Arrested, WASH. POST (Nov. 13, 2010),
http://www.washingtonpost.com/wp-dyn/content/article/2010/11/12/AR2010111204001.
html.





n130  Maria Glod & Ovetta Wiggins, Johnson, Former Prince George's County
Executive, Charged with Taking $ 200,000 in Bribes, WASH. POST (Feb. 14, 2011),
http://www.washingtonpost.com/wp-dyn/content/article/2011/02/14/AR2011021406579.
html.





n131  Cheryl W. Thompson, Jack Johnson, Former Prince George's Exec, Sentenced
to 7 Years in Corruption, WASH. POST (Dec. 6, 2011),
https://www.washingtonpost.com/ilocal/crime/former-pr-georges-exec-jack-b-johnso
n-is-sentenced-to-7-years/2011/12/01/gIQAKa7iZO_story.html?tid=a_inl.





n132  Matt Zapotosky, Pr. George's Exec.-Elect Urged to Keep Hylton, WASH. POST
(Nov. 18, 2010),
http://voices.washingtonpost.com/crime-scene/matt-zapotosky/pr-georges-activists
-urge-exec.html.





n133  Matt Zapotosky, Prince George's Police Officer Indicted, WASH. POST (Oct.
27, 2010),
http://www.washingtonpost.com/wp-dyn/content/article/2010/10/26/AR2010102607607.
html.





n134  Matt Zapotosky, Prince George's Probes Officers' Criminal Cases, WASH.
POST (Oct. 7, 2010),
http://www.washingtonpost.com/wp-dyn/content/article/2010/10/06/AR2010100607126.
html.





n135  Matt Zapotosky, Audit Confirms Training of Police Cadets in Testing
Scandal, WASH. POST Mar. 18, 2011, at B1.





n136  Lynh Bui & Arelis R. Hernandez, Magaw Retires as Prince George's Police
Chief but Stays with County, WASH. POST (Dec. 11, 2015),
https://www.washingtonpost.com/local/public-safety/magaw-retires-as-prince-georg
es-police-chief-but-stays-with-county/2015/12/11/16400fcc-9fa6-11e5-bce4-708fe33
e3288_story.html ("Many also credit Magaw for improving transparency and
community relations by hiring a former television news journalist to run media
relations.").





n137  Consent Decree, United States v. City of Los Angeles, 2:00-cv-11769-GAF-RC
(C.D. Cal. June 15, 2001),
http://www.lapdonline.org/assets/pdf/final_consent_decree.pdf.





n138  Id.





n139  Id.





n140  The Function and Role of the Board of Police Commissioners, L.A. POLICE
DEP'T, http://www.lapdonline.org/police_commission/content_basic_view/900 (last
visited Sept. 4, 2016).





n141  Patrick McGreevy, N.Y. Firm Chosen to Monitor Reforms, L.A. TIMES (May 19,
2001), http://articles.latimes.com/2001/may/19/local/me-65453.





n142  Order Re: Transition Agreement, United States v. City of Los Angeles,
2:00-cv-11769-GAF-RC (C.D. Cal. July 17, 2009),
https://www.justice.gov/sites/default/files/crt/legacy/2010/12/15/US_v_LosAngele
s_TA-Order_071709.pdf.





n143  Joel Rubin, Federal Judge Lifts LAPD Consent Decree, L.A. TIMES (May 16,
2013),
http://articles.latimes.com/2013/may/16/local/la-me-lapd-consent-decree-20130517
; Order of Dismissal, United States v. City of Los Angeles, 2:00-cv-11769-GAF-RC
(C.D. Cal. May 15, 2013),
http://www.clearinghouse.net/chDocs/public/PN-CA-0002-0069.pdf.





n144  Kirk Siegler, LAPD Chief Has Lessons to Share About Department's Past
'Ghosts,' NPR (Dec. 15, 2014, 4:30 PM),
http://www.npr.org/sections/codeswitch/2014/12/15/370952512/lapd-chief-has-lesso
ns-to-share-about-departments-past-ghosts.





n145  Carrie Kahn, After Riots, Scandal Sparked Reform in LAPD, NPR (Apr. 25,
2012, 5:50 PM),
http://www.npr.org/2012/04/25/151354376/after-riots-scandal-sparked-reform-in-la
pd.





n146  Rubin, supra note 143.





n147  CHRISTOPHER STONE ET AL., POLICING LOS ANGELES UNDER A CONSENT DECREE: THE
DYNAMICS OF CHANGE AT THE LAPD 1 (2009),
http://www.lapdonline.org/assets/pdf/Harvard-LAPD%20Study.pdf.





n148  Id. at 68.





n149  See IAN AYRES & JONATHAN BOROWSKY, A STUDY OF RACIALLY DISPARATE OUTCOMES
IN THE LOS ANGELES POLICE DEPARTMENT (2008),
https://www.aclusocal.org/wp-content/uploads/2015/09/11837125-LAPD-Racial-Profil
ing-Report-ACLU.pdf. Their analysis of traffic and pedestrian stops from June
2003 to June 2004 found that "African Americans and Hispanics are over-stopped,
over-frisked, over-searched, and over-arrested." Id. at i. An analysis of these
data published in 2006 by another team of academic researchers made similar
findings, though presented their conclusions in starkly different language. See
ANALYSIS GROUP, PEDESTRIAN AND MOTOR VEHICLE POST-STOP DATA ANALYSIS REPORT
(2006),
http://assets.lapdonline.org/assets/pdf/ped_motor_veh_data_analysis_report.pdf.





n150  Maeve Reston & Joel Rubin, Los Angeles to Pay $ 13 Million to Settle May
Day Melee Lawsuits, L.A. TIMES (Feb. 5, 2009),
http://articles.latimes.com/2009/feb/05/local/me-lapd-settlement5.





n151  Siegler, supra note 144; Tim Rutten, LAPD Has Made Great Strides, Thanks
to Consent Decree, Reform Minded Chiefs, L.A. DAILY NEWS (Aug. 22, 2014, 10:56
AM),
http://www.dailynews.com/opinion/20140822/lapd-has-made-great-strides-thanks-to-
consent-decree-reform-minded-chiefs-tim-rutten.





n152  STONE ET AL., supra note 147, at 68.





n153  See Special Investigations Reports, OFFICE OF THE INSPECTOR GENERAL L.A.
POLICE COMMISSION,
http://www.oig.lacity.org/#!special-investigations-reports/onf50 (last visited
Nov. 1, 2016).





n154  Between November 2013 and March 2014, Author reviewed the contents of 350
U.S. police and sheriff's department websites in an attempt to document the
extent to which local law enforcement agencies use the Internet to share
information with the public. Each website was scored on a 26-point scale,
tracking the presence of data ranging from officer contact information and
department social media presence to data on traffic stops and use of force. The
full dataset is on file with author.





n155  Tom Hayden, Has Bratton's LAPD Really Reformed?, NATION (July 20, 2009),
https://www.thenation.com/article/has-brattons-lapd-really-reformed/.





n156  Daniel B. Wood, Los Angeles Riots: 20 Years Later, Has LAPD Reformed?,
CHRISTIAN SCI. MONITOR (Apr. 25, 2012), http://www.csmonitor.com/USA/2012/0425/
Los-Angeles-riots-20-years-later-has-LAPD-reformed.





n157  Jeffrey Benzing, Pittsburgh Police Could Face Second Federal Consent
Decree, Peduto Says, PUBLICSOURCE (July 1, 2014),
http://publicsource.org/from-the-source/pittsburgh-police-could-face-second-fede
ral-consent-decree-peduto-says#.V79Mw1dlnVo.






n158  Alana Semuels, How to Fix a Broken Police Department, ATLANTIC (May 28,
2015),
http://www.theatlantic.com/politics/archive/2015/05/cincinnati-police-reform/393
797/.





n159  Danny Vinik, We've Been Here Before. A Solution Exists, NEW REPUBLIC (Aug.
18, 2014),
http://www.newrepublic.com/article/119133/cincinnatis-2001-race-riots-reveal-sol
utions-fergusons-unrest; Jon Schuppe, Blueprint for Peace: What Ferguson Can
Learn From Cincinnati, NBC NEWS (Aug. 29, 2014, 11:52 AM),
http://www.nbcnews.com/storyline/michael-brown-shooting/blueprint-peace-what-fer
guson-can-learn-cincinnati-n191911.





n160  Consent Decree, supra note 137.





n161  IKERD &WALKER, supra note 37.





n162  Walker, supra note 23, at 91.





n163  ROBERT C. DAVIS ET AL., TURNING NECESSITY INTO VIRTUE: PITTSBURGH'S
EXPERIENCE WITH A FEDERAL CONSENT DECREE 1 (2002),
http://archive.vera.org/sites/default/files/resources/downloads/Pittsburgh_conse
nt_decree.pdf; STONE ET AL., supra note 147.





n164  Order Re: Transition Agreement, supra note 142. Of course, there are
exceptions to this general rule. In Los Angeles, the transition from DOJ
oversight to department autonomy was made more gradual by a 2009 Transitional
Agreement (TA). Under the TA, the federal court maintained jurisdiction over the
case and authority to mandate continued federal oversight unless and until the
LAPD addressed the remaining matters to the satisfaction of the presiding judge.





n165  Chris Megerian, Gov. Corzine Signs Racial Profiling Reforms into Law,
NJ.COM (Aug. 27, 2009, 8:55 PM),
http://www.nj.com/news/index.ssf/2009/08/gov_corzine_signs_racial_profi.html.





n166  Childress, supra note 9.





n167  STEVEN H. ROSENBAUM, SPECIAL LITIGATION SECTION, U.S. DEP'T OF JUSTICE,
INVESTIGATION OF THE CLEVELAND DIVISION OF POLICE 3 (July 23, 2002),
https://www.justice.gov/sites/default/files/crt/legacy/2010/12/15/cleveland_uof.
pdf.





n168  Id. at 4.





n169  VANITA GUPTA & STEVEN M. DETTELBACH, U.S. DEP'T OF JUSTICE, INVESTIGATION
OF THE CLEVELAND DIVISION OF POLICE 3 (Dec. 4, 2014),
https://www.justice.gov/sites/default/files/opa/press-releases/attachments/2014/
12/04/cleveland_division_of_police_findings_letter.pdf ("We found that CDP
officers too often use unnecessary and unreasonable force in violation of the
Constitution. Supervisors tolerate this behavior and, in some cases, endorse it.
. . . CDP's pattern or practice of excessive force is both reflected by and
stems from its failure to adequately review and investigate officers' uses of
force; fully and objectively investigate all allegations of misconduct . . .
.").


                               5 of 41 DOCUMENTS


                               The New York Times

                             March 27, 2016 Sunday
                              Late Edition - Final

The Sky Beat

BYLINE: By GEOFF MANAUGH.

Geoff Manaugh is the writer of BldgBlog, a blog about architecture, and the
author of the forthcoming book ''A Burglar's Guide to the City,'' from which
this article is adapted.

SECTION: Section MM; Column 0; Magazine Desk; FEATURE; Pg. 42

LENGTH: 3329 words


The air-support division of the Los Angeles Police Department operates out of a
labyrinthine building on Ramirez Street in the city's downtown, near the Los
Angeles River. A looming mass of utilitarian architecture tucked beside the 101
Freeway, the complex appears to have no real public face; here the view from the
street matters little. Instead, like much of the city around it, the air-support
division makes more sense when seen from above.

On the first of several flights I would take with the division over the course
of the last three years, our helicopter lifted off into the haze of a July
afternoon. The true bulk of the structure below us finally revealed itself. The
building's landing deck alone seemed nearly the size of an aircraft carrier's,
and from this new, elevated perspective, the headquarters indeed resembled a
landlocked warship in the heart of the city; a half-dozen other helicopters were
waiting there on the tarmac. The division began with a single helicopter in
1956, and it now has 19 in all, augmented by a King Air fixed-wing plane. The
aircrews operate in a state of constant readiness, with at least two helicopters
in flight at any given time for 21 hours of every day. A ground crew is suited
up and on call for the remaining three, between 5 a.m. and 8 a.m. On weekends,
considered peak hours, the number of airborne helicopters goes up to three,
although in a crisis the division might send as many as four or five ''ships''
up at once.

The police had allowed me to fly with them so that I could see the world from
their perspective. Through its aerial patrols, the division has uniquely
unfettered access to a fundamentally different experience of Los Angeles, one in
which the city must constantly be reinterpreted from above, in real time, with
the intention of locating, tracking and interrupting criminal activity. This
also means that the police are not only thinking about Los Angeles as it
currently exists. Their job is to anticipate things that have yet to occur --
not just where criminals are, but where and when they might arrive next. They
patrol time as well as space. In this sense, although it has been in continual
operation for the past 60 years, the division has much to tell us about policing
the cities of the future.

Soon after we were airborne, a call came in for helicopter support, and we
diverted north, flying nearly to the mountains that separate Los Angeles from
the deserts beyond. A woman had reportedly barricaded herself inside a house
with a loaded 9-millimeter handgun. Why she had done this was not at all clear
-- and it would remain unexplained to us -- but the police needed to set up a
perimeter. They needed someone looking down from above.

A standard two-person helicopter crew consists of a pilot and a tactical flight
officer, or T.F.O. The pilot steers, but the course is set by the T.F.O., who
monitors as many as six simultaneous radio frequencies, including emergency
calls from the ground, as well as chatter from other police helicopters and even
passenger aircraft landing at Los Angeles International Airport. The constant
buzz of layered voices, police codes and call signs was indecipherable to me,
but the T.F.O. can decide in an instant if a given call is worth responding to.
The pilot can change speed and direction significantly, accelerating up to 170
miles an hour, turning so sharply that the crew will sometimes arrive above a
crime scene flying sideways, their bodies parallel to the ground. If none of the
calls are worth answering, however, the crew might wander. Some T.F.O.s have a
working knowledge of Los Angeles arcana to match that of the most veteran
Hollywood tour guide, from the address of Charlie Chaplin's old mansion to the
location of the house used for exterior shots in ''The Brady Bunch.''

My T.F.O. that day was Renée Muro, now 49, a 14-year veteran of the air-support
division who had a ''Got Altitude?'' sticker on the back of her flight helmet.
As we circled the location, she set about identifying, assessing and describing
the streets, including a quick scan of nearby properties where, if the
barricaded woman were to flee, she would most likely end up. For 45 minutes,
Muro suggested placements for officers such that they could prevent any possible
escape route, naming specific corners and clarifying locations, even
occasionally directing police officers to neighbors who were milling about so
they could warn them to head back inside.

This seemed like a particularly difficult case, however, because the street grid
here was ''out of sync,'' Muro explained, with the rest of the city: The
normally orderly numbering system didn't apply, perhaps because the neighborhood
was punctuated by strange L-shaped streets and cul-de-sacs. This presented a
unique narrative challenge for her in relaying which bend in a particular street
she wanted a patrol car to head toward.

Muro persevered, flying in an endless gyre over parking lots, freeway on-ramps
and a confused tangle of empty streets, and I watched as a growing armada of
patrol cars circled below. She patiently arranged them like chess pieces,
forming a tactical geometry that locked down the entire neighborhood. It was
real-time urban planning, as implemented by the police. Before we could learn
the fate of the barricaded woman, however, we had moved on.

With the title of a book published 500 years ago, Thomas More coined a term we
still use today for describing the ideal society. More's ''Utopia'' is equal
parts political theory and moral treatise, its arguments built atop a foundation
of aspirational city planning. His panoramic survey of governance, public safety
and crime, with its vigilant, top-down views of a megacity divided into
districts with clearly defined canals, streets and squares, reads at times like
a literary helicopter shot, as if we are passing over the roofs of an idyllic
metropolis. We see forests and rivers, busy markets and residential
neighborhoods -- a well-ordered geography that More imagined would be governed
by a nearly omnipotent political will, all in the name of the greater good.
Before writing ''Utopia,'' More held a unique judicial position with broad
responsibilities for governmental administration and municipal law enforcement:
He was undersheriff of the City of London. For the last half-millennium, when we
refer to the ideal city, we have been invoking an urban blueprint as imagined by
a cop.

Crime shapes cities -- even Paris, the ''City of Light,'' takes its nickname,
according to one story, from streetlights first instituted as part of a
17th-century police operation -- but the reverse is also true. Cities get the
types of crime their design calls for. This logic extends even down to their
bedrock: Tunnel jobs are almost unimaginable in granite-based Manhattan, for
example, but the soft sedimentary rocks of Los Angeles -- a former seabed --
make it more susceptible to subterranean crime. Infrastructure also plays a
major role in permitting or preventing entire classes of criminal activity. The
construction of the city's freeway system in the 1960s helped to instigate a
later spike in bank-crime activity by offering easy getaways from financial
institutions constructed at the confluence of on-ramps and offramps. This is a
convenient location for busy commuters -- but also for prospective bandits, who
can pull off the freeway, rob a bank and get back on the freeway practically
before the police have been alerted. The maneuver became so common in the 1990s
that the Los Angeles police have a name for it: a ''stop-and-rob.''

The built environment may inadvertently catalyze new forms of illegal activity,
but this also means that the Los Angeles Police Department is constantly
responding to criminal innovation with new forms of police work, often before
the rest of the world even knows they might be necessary. With its campaign of
ubiquitous aerial surveillance, Los Angeles is a kind of real-time R.&D. site
for the world's sprawling megacities, as they, too, try to manage the extralegal
consequences of their newfound expansion.

After my first flight, Cole Burdette, the chief tactical flight officer, who
supervises the training of all the other T.F.O.s, walked me through a quick tour
of the headquarters, a dense warren of small corridors and stairways. Our final
destination was a classroomlike space lined with whiteboards, where we sat down
to talk about crime and the city. With his olive-green flight suit and a
military-style haircut, Burdette, 50, could have passed for an Air Force
officer. He was observant and detailed-oriented; he would frequently restart
entire paragraphs of explanation until he arrived at the correct narrative
sequence, and only then would he move on to his next point or answer. Those
answers were also astonishingly precise in their geographic reference points. He
would bring up exact intersections and even business addresses somewhere out
there in the greater maze of Los Angeles, never once relying on a map. Each
location would then serve a specific role in Burdette's ensuing narrative --
sometimes even five or 10 minutes later -- as he tried to make clear why a
certain crime or event had unfolded in one way and not another.

Los Angeles is a fundamentally different kind of place from New York or Chicago,
he explained, with their skyscrapers and deep, canyonlike streets. Those dense
clusters of high-rises and towers make thorough aerial patrols nearly
impossible, not to mention potentially dangerous. In L.A., by contrast, you
simply cannot see the whole city if you rely solely on ground patrols. Limiting
yourself to roads is not going to work. The aerial perspective is crucial: You
have to think in a distinctly volumetric way about how neighborhoods are
actually linked and what the most efficient routes might be between them. After
all, this is how criminals think, Burdette said, and this is how they pioneer
new ways to escape from you.

Even the region's flight paths have come to influence how criminals use the
city. The heavily restricted airspace around Los Angeles International Airport,
Burdette pointed out, has transformed the surrounding area into a well-known
hiding spot for criminals trying to flee by car. Los Angeles police helicopters
cannot always approach the airport because of air-traffic-control safety
concerns. Indeed, all those planes, with their otherwise-invisible approach
patterns across the Southern California sky, have come to exert a kind of
sculptural effect on local crimes across the city: Their lines of flight limit
the effectiveness of police helicopter patrols and thus alter the preferred
getaway routes.

Burdette's own spatial understanding of Los Angeles easily rivals that of any
urban historian, city planner or local architect. His knowledge of the terrain
is the product of thousands of hours of flight time, during which he has had to
constantly reconcile the moving map of the city displayed on his helicopter's
monitor with the actual streets below. But of course, Burdette has also had the
help of advanced technology.

Over several more flights, each with a different combination of pilot and
tactical flight officer, I was able to see this array of technical devices
firsthand. Each helicopter, for example, contains a unit that picks up signals
from LoJack tracking systems, which are used commercially as a tool for
recovering stolen vehicles. During a slow spell one night, we drifted above a
stretch of the 101 Freeway linking the streets of Hollywood with the San
Fernando Valley, looking for stolen cars in transit. The T.F.O. intently watched
the craft's dashboard display, fishing for signals in the darkness. (To his
apparent disappointment, we found none.)

Later, we tracked a possible stolen sedan, one not equipped with LoJack, using
the next best technological assist: the helicopter's spotlight, a blinding,
50-million-candlepower inferno justifiably known as the Nightsun. It has the
effect of a colossal stage-lighting rig, implying high drama with its focused
glow. ''He's going into the buildings!'' the T.F.O. exclaimed. This meant the
car was heading downtown, where the city's dense core of skyscrapers would
prevent us from following it. The driver wasn't nearly as savvy as the pilot and
T.F.O. thought, however. He soon exited the freeway -- to drive straight home,
we saw, followed by two squad cars and six motorcycle units that we had been
directing all along. The driver was arrested in the street. After we flew away,
we learned from radio chatter that it was simply a D.U.I.

On another flight, I was shown the FLIR, or forward-looking infrared camera. To
demonstrate how it operated, my T.F.O. that night instructed his pilot to head
for the beaches of Santa Monica. Almost at once, the FLIR monitor mounted in the
cockpit lit up with the strangely beautiful thermal flare of human life:
white-glowing forms walking along the beach or lying on dark blankets next to
one another. We flew quite low to the water now as the T.F.O. explained some
basics of infrared visualization, and I watched as apparently sleeping forms,
white-hot, came into sharp focus, curled up beneath lifeguard structures. There
was nowhere to hide, I saw; you could be concealed behind the trunk of a tree,
yet an eerie aura would still surround you, shining like a halo. Looking out the
helicopter window, I saw nothing but blackness, silky and absolute, up and down
the beach in both directions. But when I peered back at the monitor, lights were
moving everywhere, like fireflies.

Those who want to stay hidden from FLIRs are developing countermeasures, of
course. Back on the ground, I asked Burdette about some of their preferred
techniques. ''People are definitely catching on,'' he said. ''They'll rub mud
all over themselves, like that movie 'Predator,' or they'll wrap themselves up
in pool covers to mask their heat signature.''

I laughed. ''Does that work?''

I was expecting him to laugh along with me, but after a slight hesitation, he
said: ''It does work -- except a little bit of light starts to shine out of each
end. Once they've been in there for a while, the temperature builds up, like it
starts to cook a little. That's how we find them.''

In ''City of Quartz,'' his apocalyptic portrait of Los Angeles circa 1990, Mike
Davis described the air-support division as an invasive ''space police,'' a
darkly futuristic force of winged overlords scanning the metropolis from above
and buzz-bombing whole neighborhoods at a time. One of the most memorable
moments in his book is when he describes how police pilots navigate the city:
''To facilitate ground-air synchronization,'' he writes, ''thousands of
residential rooftops have been painted with identifying street numbers,
transforming the aerial view of the city into a huge police grid.'' With this
incredible image, Davis implies that the police have stealthily redesigned urban
space to suit their own needs, even painting our addresses onto our roofs
without us noticing, all so that we can be more easily corralled. For Davis, the
city itself is a police tool, an instrument of authority we can no longer fully
see -- and thus cannot effectively critique or oppose.

Davis is right, of course, that aerial command is an instrument of control, and
a potentially sinister one at that. But he was wrong about the degree to which
the Los Angeles police have been able to mold the landscape. In reality, those
police-branded rooftop numbers are all but nonexistent, at least for now; when I
asked Burdette what he would change if he could redesign the city from the
perspective of a tactical flight officer, he mentioned exactly that idea:
painting large identifying numbers on the roofs of building complexes like
schools and hospitals. If those sorts of facilities could be numbered in a
clockwise direction, starting with the entry building, he explained, directing
officers to a structure deep within the sprawl would be far easier. Thus far,
however, such an ambitious project has been beyond the police department's
institutional reach. Throughout the history of aerial surveillance in Los
Angeles, the urban landscape has largely been an inheritance, beyond the control
of any single authority; the air-support division's real ingenuity has been in
how it responds to a world that it did not, in fact, design.

Precisely as a way of making up for the absence of rooftop numbering, for
instance, the air-support division has deployed something Burdette called ''the
rules of four.'' As guidelines, they fall somewhere between a rule of thumb and
an algorithm, and they allow for nearly instantaneous yet accurate aerial
navigation. ''The way the parcels work in the city of Los Angeles,'' he began,
''is that Main Street and First Street are the hub of the city.'' The street
numbers radiate outward -- by quadrant, east, west, north, south -- with blocks
advancing by hundreds (the 3800 block below 38th Street) and building numbers
advancing by fours (3804, 3808, 3812, etc.). The rest is arithmetic.

''If it's the fourth house south of the corner on the west side of the street,''
Burdette explained, ''then the address is going to be an odd number. The rules
of four mean that I can do four times four -- it's the fourth house, times four
-- which is 16. But, because the numbers on that side of the street are odd, we
know we're going to be looking at either 15 or 17. So, if the address is south
of 38th Street and it's the fourth house on the west side of the street, then
it's going to be 3815 or 3817. It is going to be that address.''

With the rules of four, an otherwise intimidating and uncontrollable knot of
streets takes on newfound clarity. It is no coincidence that the Los Angeles
Police Department built its main headquarters at the center of it all, at the
intersection of First and Main. It placed the department at the numerological
heart of the metropolis, the zero point from which everything else emanates.

As Thomas More proposed, a well-ordered metropolis is a fundamental prerequisite
for any visionary act of urban governance. The air-support division has simply
extended that observation into its understanding of the existing order, in this
case of the city's numbered houses and streets. But if the promise of aerial
policing is to make the city more legible -- to help officers read events more
clearly -- the obvious temptation is to somehow turn the page, to anticipate
future events as well.

And here we confront a final dimension -- time -- and another police technique,
called predictive policing. Pioneered by the U.C.L.A. anthropologist Jeffrey
Brantingham, predictive policing relies upon an interpretive combination of
machine-learning algorithms and deep pools of police data to estimate where
certain types of crime, like car thefts or burglaries, are most likely to happen
next. Brantingham has compared the technique to a Netflix recommendation
algorithm, in that it makes suggestions about the future based on what has
occurred in the recent past. Predictive policing does not try to predict
specific events, but it can help the police identify surprisingly precise areas
of high crime and then direct officers to those areas, casting what they hope
will be a pre-emptive shadow.

With predictive policing, cops will no longer be describing and reacting to the
landscape but writing it, in real time -- and with a far greater impact on
individual neighborhoods than the simple arrangement of police cars on a
stakeout, or even numbers on a roof. In their quest to establish an all-seeing
utopian gaze looking down upon the rooftops of an unsuspecting metropolis, the
police may have stumbled upon their most powerful, and perhaps most worrying,
means of reshaping the city -- one that comes not from seeing, but from being
seen.

Sign up for our newsletter to get the best of The New York Times Magazine
delivered to your inbox every week.




URL: http://www.nytimes.com/2016/03/27/magazine/panopticops.html

LOAD-DATE: March 27, 2016

LANGUAGE: ENGLISH

GRAPHIC: PHOTOS: The Los Angeles Police Department's air-support division is
called in to assist with a possible robbery in progress in the eastern end of
the San Fernando Valley. (MM42-MM43)
 A tactical flight officer surveying the scene in South Los Angeles following a
robbery-in-progress call. (PHOTOGRAPHS BY KEVIN COOLEY FOR THE NEW YORK TIMES)
(MM44)

PUBLICATION-TYPE: Newspaper


                   Copyright 2016 The New York Times Company


                               6 of 41 DOCUMENTS



                              The Washington Post

                            November 18, 2016 Friday
                                Suburban Edition

Policing the future, one crime at a time

BYLINE: Justin Jouvenal

SECTION: A-SECTION; Pg. A01

LENGTH: 2032 words

DATELINE: LOS ANGELES


Prediction software can help focus resources, but some raise bias concerns

LOS ANGELES - Sgt. Charles Coleman popped out of his police SUV and scanned a
trash-strewn street popular with the city's homeless, responding to a crime that
hadn't yet happened.

It wasn't a 911 call that brought the Los Angeles Police Department officer to
this spot, but a whirring computer crunching years of crime data to arrive at a
prediction: An auto theft or burglary would probably occur near here on this
particular morning.

Hoping to head it off, Coleman inspected a line of ramshackle RVs used for
shelter by the homeless, roused a man sleeping in a pickup truck and tapped on
the side of a shack made of plywood and tarps.

"How things going, sweetheart?" he asked a woman who ambled out. Coleman
listened sympathetically as she described how she was nearly raped at knifepoint
months earlier, saying the area was "really tough" for a woman.

Soon, Coleman was back in his SUV on his way to fight the next pre-crime. Dozens
of other LAPD officers were doing the same at other spots, guided by the crime
prognostication system known as PredPol.

"Predictive policing" represents a paradigm shift that is sweeping police
departments across the country. Law enforcement agencies are increasingly trying
to forecast where and when crime will occur, or who might be a perpetrator or a
victim, using software that relies on algorithms, the same math Amazon uses to
recommend books.

"The hope is the holy grail of law enforcement - preventing crime before it
happens," said Andrew G. Ferguson, a University of the District of Columbia law
professor preparing a book on big data and policing.

Now used by 20 of the nation's 50 largest police forces by one count, the
technologies are at the center of an increasingly heated debate about their
effectiveness, potential impact on poor and minority communities, and
implications for civil liberties.

Some police departments have hailed PredPol and other systems as instrumental in
reducing crime, focusing scarce resources on trouble spots and individuals, and
replacing officers' hunches and potential biases with hard data.

But privacy and racial justice groups say there is little evidence the
technologies work and note the formulas powering the systems are largely a
secret.

They are concerned the practice could unfairly concentrate enforcement in
communities of color by relying on racially skewed policing data. And they worry
that officers who expect a theft or burglary is about to happen may be more
likely to treat the people they encounter as potential criminals.

The experiments are one of the most consequential tests of algorithms that are
increasingly powerful forces in our lives, determining credit scores, measuring
job performance and flagging children who might be abused. The White House has
been studying how to balance the benefits and risks they pose.

"The technical capabilities of big data have reached a level of sophistication
and pervasiveness that demands consideration of how best to balance the
opportunities afforded by big data against the social and ethical questions
these technologies raise," the White House wrote in a recent report.

A seismic shift in policing

It was 6:45 a.m. on a Monday, but the sheet of paper Coleman held in his hands
offered a glimpse of how Oct. 24 might go: an auto theft near  Van Nuys and
Glenoaks, a burglary at Laurel Canyon and Roscoe, and so on.

The crime forecast is produced by PredPol at the beginning of each shift. Red
boxes spread across Google maps of the San Fernando Valley, highlighting
500-by-500-square-foot locations where PredPol concluded property crimes were
likely.

The forecast is cutting edge, but it is used in the service of an old-fashioned
policing philosophy: deterrence. Between calls that day, Coleman and other
officers were expected to spend time and engage with people in the roughly 20
boxes PredPol identified around the Foothill Division.

Coleman sat behind the wheel of his SUV, plotting which boxes to hit the way
someone consulting a weather map might weigh whether to bring an umbrella.

"It's not always that we are going to catch someone in the box, but by being
there we prevent crime," said Capt. Elaine Morales, who oversees the Foothill
Division.

Foothill is far from the glitz of Hollywood on the northern edge of L.A., but it
has been at the center of the transformation going on in policing.

The division was one of the first in the nation to adopt predictive policing
five years ago and has helped refine PredPol. The technology has spread to other
LAPD divisions and more than 60 other departments across the country, making it
the nation's most popular predictive-policing system.

PredPol often draws comparisons to the movie "Minority Report," in which a
government unit rounds up future criminals who have not yet committed crimes,
but one of the software's developers said it is not a crystal ball.

Jeff Brantingham, a professor at UCLA, said crime often seems random, but it
follows patterns.

"The question becomes, 'Can we build mathematical structures to understand these
patterns?' The answer is yes, absolutely," Brantingham said. "The best way to
capture the way we think about crime patterns ... is to think about
earthquakes."

That's not just an analogy. Brantingham said a breakthrough moment in PredPol's
development came when one of his partners realized an algorithm that described
seismic activity could be used to predict crime.

Just as earthquakes happen along fault lines, Brantingham explained, research
has shown crime is often generated by structures in the environment, like a high
school, mall parking lot or bar. Additional crimes tend to follow the initial
event near in time and space, like an aftershock.

PredPol uses years of crime data to establish these patterns, and then the
algorithm uses near real-time crime data to predict the next property crime.
Other systems use even more esoteric data - from the weather to phases of the
moon - to arrive at their crime forecasts.

But does it work?

Coleman fired up his SUV and headed out to a PredPol box as streaks of light
poured over the dry hills surrounding L.A. Parents walked their kids to school,
and others rushed to work in the blue-collar, largely Latino community.

Can crime be predicted?

Coleman's SUV was one of only eight police cruisers circulating that morning in
the Foothill, a 46-square-mile area that has a population of more than 180,000.
It's easy to see why any system that could accurately pinpoint crime would be a
major boon to the LAPD.

For decades, police departments have mapped crimes using pushpins on paper maps
and more recently blotchy hot-spot maps on computers. The maps always lagged
behind crime on the street and could offer only general areas to focus  patrols.

Coleman, a strapping and gregarious 26-year veteran of the LAPD, said he and
other officers were initially skeptical that PredPol could anticipate a crime
better than a seasoned officer - and do it in a box the size of a city block.

But he quickly became a believer.

"If you spend three hours in that box the week after you had 10 crimes, the next
week you are going to see three," Coleman said as L.A.'s low-slung houses, palm
trees and strip malls slid by the SUV's windows.

LAPD Cmdr. Sean Malinowski, who pioneered PredPol's use in the department, was
also convinced. He relayed a story of how two of his officers found a thief in a
stolen car in an area where PredPol predicted an auto theft. The person escaped,
but the officers found him again - in another stolen vehicle in another box
where PredPol forecast a theft.

But the data on the effectiveness of PredPol - and other predictive systems -
presents a murkier picture.

PredPol and the LAPD credit the system with helping bring about substantial
reductions in property crime in the Foothill in 2012 through 2014, but crime has
crept back up in the past couple years as it has in the rest of Los Angeles.

A study by Brantingham and other researchers found the system was roughly twice
as good at predicting where crime will occur as the LAPD's crime analysts and
reduced crime 7 percent, but no independent researchers have verified those
claims or looked at PredPol.

The only independent study of a place-based predictive-policing system found the
software had no statistically significant impact on property crime in
Shreveport, La. The system was one created by the researchers, not PredPol.

PredPol is just one iteration of predictive policing.

Police in Kansas City, Mo., and Chicago maintain lists of hundreds of people who
an algorithm predicted were likely to be involved in gun violence, either as
perpetrators or victims. The calculations are based on arrests, gang
affiliations and other variables.

Police warn those on the list they are being watched, while social-service
agencies offer help.

Chicago police said earlier this year that the department's system was effective
- more than 70 percent of the people who were shot and 80 percent of those
arrested for shootings in 2016 were on the list.

But a Rand Corp. study released in the summer found that individuals on a 2013
version of the list were no more or less likely to be the victim of a shooting
than a comparison group. Police dispute the study's findings.

Increasing concerns

Inconclusive benefits are just one critique in an increasingly heated debate
over the systems as they become more widespread.

Predictive policing has become a flash point in the discussion over race and
policing that has roiled the nation in recent years. Malinowski and police
officials elsewhere see PredPol and similar systems as a way to combat bias
among officers by using data to guide patrols.

"Through the use of data, it's less subjective," Malinowski said. "It's
objective."

But the ACLU and 16 other groups issued a statement in August outlining a
variety of concerns about predictive policing, saying such systems give a
technological sheen to old patterns of policing.

David Robinson, a founder of the Upturn think tank, wrote in a report that
accompanies the statement that predictive policing could increase police
presence in poor and minority communities by creating a "ratchet effect."

"The basic problem is those forecasts are only as good as the data they are
based on," Robinson said. "People in heavily policed communities have a tendency
to get in trouble. These systems are apt to continue those patterns by relying
on that biased data."

Brantingham said it is a valid concern, but PredPol uses only data from crimes
reported to the police and that have been verified. He said drug arrests and
other offenses that rely on the discretion of officers are not used because they
are often more heavily enforced in poor and minority communities.

Robinson also pointed out that the public - and even the police who use the
software - often do not know exactly how the systems are flagging particular
locations or individuals. He said that makes accountability impossible.

Ferguson, the UDC law professor, said predictive policing raises a host of
fundamental concerns and questions. He questioned how police will ensure the
accuracy of the vast reams of data the systems rely on. An error could unfairly
cast suspicion on a location or individual.

Ferguson also wonders how predictive systems will affect officers. He
anticipates forecasts will be used as a factor in officers' decisions to reach
the "reasonable suspicion" threshold to stop people on the street and could
color the way officers approach stops.

"When you are told to be on the lookout for a particular crime in a particular
place, that has to affect what you are going to do," Ferguson said.

Coleman arrived at his next PredPol spot around 8:20 a.m. at a busy
intersection. He chatted up three homeless people sitting on a bench at a bus
stop, asking a question for which PredPol had already given him an answer: "How
much crime occurs around here?"

justin.jouvenal@washpost.com

Read more:

A quintessentially American crime declines: Robbing banks doesn't pay as it used
to

Attorney General Lynch: Treat defendants as citizens, not cash registers

He threw a punch that killed a fellow student. Now his guilty conviction could
disappear

LOAD-DATE: November 18, 2016

LANGUAGE: ENGLISH

DISTRIBUTION: Every Zone

PUBLICATION-TYPE: Newspaper


     Copyright 2016 Washingtonpost.Newsweek Interactive Company, LLC d/b/a
                            Washington Post Digital
                              All Rights Reserved


                               7 of 41 DOCUMENTS

          Copyright (c) 2016 President and Fellows of Harvard College
                          Harvard Law & Policy Review

                                  Winter, 2016

                          Harvard Law & Policy Review

                          10 Harv. L. & Pol'y Rev. 15

LENGTH: 10564 words

ARTICLE: The New Surveillance Discretion: Automated Suspicion, Big Data, and
Policing

NAME: Elizabeth E. Joh *

BIO:



   * Professor of Law, University of California, Davis School of Law
(eejoh@ucdavis.edu). Many thanks to Andrew Ferguson, Jane Bambauer, the
participants of the 2015 Vanderbilt Criminal Justice Roundtable, and the
participants of the 2015 Privacy Law Scholars Conference for valuable comments
and suggestions.

 TEXT:
 [*15]  I. INTRODUCTION

   In a crime analytics bureau, a police officer logs in to see what alerts have
been posted by social media software designed to spot potential threats within
the billions of daily online tweets, pins, likes, and posts. On the street, a
police officer uses his body-worn camera to scan a crowd; the feed is sent in
real time back to the department where facial recognition and movement analysis
software alerts the patrol officer as to whether furtive movements or people on
watch lists have been identified. Police follow up on these alerts to identify
people who should be immediately investigated. Other people are dismissed as not
posing an immediate threat but are logged on watch lists for future reference.
No police department has all of this technological ability today, but some will
one day soon.  n1 There is no question that this version of big data policing is
on the cusp of wider adoption,  n2 and it raises key questions about fundamental
issues of police discretion and accountability.

   Whether the police identify a person and choose to investigate him for
suspected criminal activity is a decision largely left up to the police. The
decisional freedom  n3 to focus police attention on a particular person or
persons rather than others--what I'll call "surveillance discretion"  n4--is a
widely accepted means of investigation. Law enforcement would be unimaginable
without it. This task of filtering--identifying suspects from the general
population--exemplifies traditional police work. Police officers usually
generate leads by focusing their attention on particular suspects through
observation, questioning, and information conveyed by witnesses, victims, or
other third parties.

   New technologies have altered surveillance discretion by lowering its costs
and increasing the capabilities of the police to identify suspicious persons.
Furthermore, soon it will be feasible and affordable for the government  [*16]
to record, store, and analyze nearly everything people do.  n5 The police will
rely on alerts generated by computer programs that sift through the massive
quantities of available information for patterns of suspicious activity. The
selection of investigative targets that emerge from big data rather than from
traditional human investigation represents an important expansion in the powers
of the police. That expansion, in turn, calls out for new tools of police
accountability.

   These "big data" tools produce dramatically different ways of identifying
suspects. By applying computer analytics to very large collections of digitized
data,  n6 law enforcement agencies can identify suspicious persons and
activities on a massive scale.  n7 While these tools are useful in tracking down
evidence of past crimes, big data also provides the police with new capabilities
to identify ongoing and future threats. The Department of Homeland Security uses
computer analytics to identify suspicious Twitter feeds that include words such
as "bomb" or "listeria."  n8 Police departments in Santa Cruz (CA), Seattle, and
New York City are experimenting with predictive policing software to identify
geographic places where crime is likely to take place.  n9 One day the police
nationwide may use location-based tweets to inform those same predictions.  n10
The Chicago Police Department already  [*17]  uses big data tools to identify
high risk persons based on the strength of a person's social networks: a
technique borrowed from the military's analysis of insurgent groups.  n11 These
are not investigations about already identified suspects or crimes,  n12 but
rather the identification of potentially suspicious persons, places, and events.

   The exercise of surveillance discretion in traditional policing attracts
little attention from judges or legal scholars. Why? The answer is likely
because 1) we assume that the police should possess such powers, and 2) even if
theoretically worrisome, surveillance discretion is a power greatly limited in
practice. After all, police investigations typically only focus on a limited
number of persons because of practical limitations imposed by resources and
technology. But those assumptions will become outdated when the police possess
the tools to exercise automated surveillance discretion on a massive scale.

   While the details leaked by Edward Snowden about the mass surveillance
programs of the NSA are widely known, less familiar are the growing
technological capabilities of local police departments. Yet these emerging
technologies raise important questions about the expanded surveillance
discretion of the more than 17,000 state and local police departments that
assume primary responsibility for law enforcement in the United States.  n13

   This expansion of surveillance discretion raises important legal and policy
questions with regard to police oversight. In the traditional model of police
investigation, the police may decide, after some initial investigation, to
target a specific person or persons for further scrutiny. The Supreme Court's
decisions make clear that the Fourth Amendment has little regulatory power over
this discretionary process.  n14 Unlike arrests or wiretaps, the decision to
focus police attention on a particular person, without more, is unlikely to be
considered a Fourth Amendment event. Thus, the police are not required to
demonstrate probable cause or reasonable suspicion--the usual standards of
individualized suspicion--to decide whether to conduct surveillance on an
individual.  n15

    [*18]  Surprisingly, there is little discussion of these decisions that the
police make about individuals before any search, detention, or arrest takes
place.  n16 Rather, current unresolved issues of police technology have focused
on whether a particular use is a Fourth Amendment search requiring a warrant and
probable cause. Whether such constitutional requirements apply to the collection
of historical cell site data is one such example.  n17 Courts around the country
have disagreed about whether these situations implicate Fourth Amendment
protections, and it may take years for the United States Supreme Court to
resolve these disputes.

   And while the enforcement discretion of police and prosecutors--whether to
enforce the law against a particular defendant or not--is a familiar topic in
legal scholarship,  n18 surveillance discretion--when, how, and whether the
police may target a person or persons in the initial phases of governmental
investigation--does not attract the same attention. Little scholarship has
addressed when and how people should be considered targets for police
surveillance in the first place--even if the police do nothing but watch
closely. Some attention has already been paid to the use of big data by the
police, such as with predictive policing software, but it addresses an important
but familiar line drawing problem: whether decisions made by software can help
justify conventional Fourth Amendment activities like stop-and-frisks.  n19

   Surveillance discretion addresses the power of the police at an earlier
stage: when the police focus on persons suspected of ongoing or future criminal
activity but before any intervention takes place.  n20 This preliminary
investigative power is essential, since police need to possess some legal means
to develop the required Fourth Amendment standard of individualized suspicion
for a later search or seizure.  n21 This preliminary stage of police
investigation  [*19]  usually receives little attention because it is not
typically considered activity reached by the Fourth Amendment at all.  n22

   Yet this new expansion of surveillance discretion by big data presents an
underappreciated challenge to our usual thinking about police regulation.  n23
How the police will use big data tools, particularly in future-oriented ways, is
as pressing an issue of police accountability as individual officer bias,
excessive force, and other pressing issues currently the topic of public debate.
Unlike a police brutality case captured on a cellphone video, however, expanded
police power by means of big data is difficult for most of the public to see and
understand. Such secrecy and opacity calls for new tools of accountability.

   II. HOW BIG DATA EXPANDS SURVEILLANCE DISCRETION

   Big data will revolutionize the surveillance discretion of the police.  n24
By allowing the identification of large numbers of suspicious activities and
people by sifting through large quantities of digitized data, big data expands
the surveillance discretion of the police.

   Of course, the use of big data is not the first time the police have focused
on numbers, information, or record-keeping. Accurate documentation of crime and
criminals has been a concern that reaches back to the nineteenth century and the
invention of the Bertillonage system.  n25 As they became more professional and
bureaucratic, police of the twentieth century have sometimes been described as
"knowledge workers" for whom information processing, rather than crime control,
is a primary focus.  n26 Even in their crime control capacities, large urban
police departments in the 1990s had already turned toward data-driven or
intelligence-based policing styles, of which the most famous is the N.Y.P.D's
Compstat system.  n27 The use of big  [*20]  data, then, accelerates and
magnifies trends that until now had been slowly moving toward a heavier reliance
on information and computers--with a specific emphasis on data analytics.

   Understanding how expanded surveillance discretion should be regulated
requires both an understanding of the big data phenomenon and how it has begun
to influence policing.

   A. What is Big Data?

   The amount of data in big data almost defies comprehension. Nearly all of the
world's stored information today is digital,  n28 and we are surpassing existing
mathematical terms to quantify it.  n29 The types of information that are now
digitized include ones that once existed in analog format (books, phone call
logs, retail purchases) as well as new kinds of information made possible by
today's technologies (internet searches, social media posts, data from the
Internet of Things).  n30 The Library of Congress, which has archived every
Twitter tweet since 2010, receives about half a billion per day.  n31 Every day,
some of Facebook's 1.15 billion users upload more than 350 million photos to its
website.  n32 And digitization alters the nature of the information itself.
Information that can be digitized can also be collected, searched, quantified,
compared, assessed, and endlessly repurposed.  n33 Most people know this is true
from the automated suggestions they have encountered on services like Facebook,
Netflix, and Amazon.  n34

    [*21]  Apart from its quantity, big data provides a very different way of
understanding and probing the world of information.  n35 Consider how big data
has altered conventional research. If traditional scientific research begins
with a question and then uses that hypothesis to identify and collect the
appropriate data, big data upends that practice.  n36 Because data is being
generated all of the time, researchers working with big data do not have to
shape or limit their data collection. Nor do they need to begin with a question.
Indeed, the question can arise from the data itself. This is why, for example,
the constant stream of posted tweets on Twitter can generate data and insights
for meteorologists, advertisers, and epidemiologists.  n37

   That insight has implications for the surveillance discretion of the police
as well. Just as questions may emerge from the data for the purposes of
research, suspects can emerge from the data for purposes of investigation. These
suspicious persons and activities can appear even if police do not seek a
particular person for a particular crime. Nor do they need to begin the
collection of data, if data is already being collected all of the time.

   Moreover, the search for causality--a primary objective in scientific
research--is rendered unnecessary by big data, since correlations found on a
mass scale can be just as, if not more, useful than attempts to find causes.
n38 That is why, for example, Google's identification of the forty-five search
terms most strongly correlated with historical flu data held the promise of
predicting future outbreaks, even if they provided correlations rather than
causes.  n39 In the big data world, "knowing what is often good enough" rather
than why.  n40 In criminal investigations, it may not be necessary to know why
certain patterns of driving, purchasing, or movement are associated with crime
if the police can claim a high correlation between the two. A high degree of
correlation itself might provide justification for heightened police attention.

    [*22]  B. How Big Data Expands Surveillance Discretion

   Like marketers, health care professionals, and traffic controllers, police
departments have begun to test and adopt the tools of big data. These approaches
hold the potential to change many aspects of traditional policing, including
surveillance discretion. Three examples illustrate the range of big data tools
already in preliminary use or under consideration by police departments.

   The first is the use of automatic license plate readers (sometimes also
referred to as "ALPR" or "ANPR") by the police. While the police have used
cameras to take pictures of car license plates since the 1970s,  n41 ALPR
technology is especially notable today because it has become inexpensive,
sophisticated, and increasingly pervasive.  n42 ALPR systems use cameras mounted
on patrol cars or at fixed locations and data analytics to identify license
plate numbers.  n43 These devices can read up to fifty license plates per
second, and typically record the date, time, and GPS location of every scanned
plate.  n44 ALPR systems then read the scans and compare them against a "hot
list," which contains license plate data for information such as stolen cars,
parking violations, and terrorist watch lists.  n45 One city even has used ALPR
scans to detect those with delinquent property taxes.  n46 The use of multiple
cameras at multiple times makes it possible to see where and when one car (and
presumably the person registered as the owner) moves around in time and space.
Far from a specialized surveillance technique, ALPR cameras are used by the vast
majority of police departments around the country.  n47

    [*23]  A recent investigation by the news outlet Ars Technica shows the
extent of information that can be captured by a single police department's ALPR
system.  n48 Responding to a public records request, the police department of
Oakland, California released 4.6 million scans of 1.1 million unique plates
representing three years' worth of ALPR data.  n49 While most vehicles in the
data set only appeared a few times, some notable exceptions illustrate how much
information ALPR scans can reveal. One car was recorded 459 times over two
years.  n50 Ars Technica, with the help of a data analyst, was able to make
"educated guesses" about the habits and addresses of those identified through
their locational data.  n51

   In addition to the scans taken directly by cameras operated by the police
themselves, private databases of billions of ALPR scans provide the police with
another source of surveillance data. Private ALPR cameras are now a routine tool
of "repo men": repossession agents with truck-mounted ALPR cameras that can scan
up to 8,000 plates a day and compare them against bank default lists.  n52 These
ALPR databases are available both for private and public customers, including
law enforcement agencies. In March 2015, the New York Police Department
announced a proposed contract with Vigilant Solutions, one of the largest ALPR
companies in the United States, with a reported database of 2.2 billion scans.
n53

   These ALPR readers can function as time machines to investigate already
completed crimes. For instance, Vigilant Solutions demonstrates in a YouTube
video how the police, in a hypothetical homicide investigation, can identify
ALPR scans with a specified set of spatial and temporal parameters to see which
cars (and registered drivers) have passed through the area and may serve as
potential suspects.  n54 Similarly, ALPR data can be used to track an individual
person through time and space to determine his whereabouts (to check an alibi,
to investigate a lead, etc.).

   But ALPR data can expand surveillance discretion further to identify as yet
unknown patterns of suspicious activity. Geo-fencing involves the designation of
a specific geographical area that can be circumscribed with an  [*24]  ALPR
"virtual fence" that identifies every car that enters that zone.  n55 Consider,
for example, a program that would identify suspicious patterns of activity, such
as repeated visits by individual drivers to a location associated with drug
trafficking.

   A second use of big data is the collection and analysis of social media data.
While many police departments polled state they monitor social media, these uses
usually take the form of individual officers personally searching or using
social media sites.  n56 The Los Angeles Police Department, for instance,
reportedly directs forty officers for this purpose.  n57 Human monitoring of
social media can include discrete searches for threatening words, suspects, and
gangs. In other cases, the police might find information through social media by
"friending" suspected criminals and learning information through online posts.
n58 But such uses of social media are limited. Individual officers cannot search
for every conceivable variation of suspicious language, and social connections
with suspects online require identifying them in the first place.

   Instead of relying on human beings, a big data approach looks through all, or
nearly all, of the available data and uses computer algorithms to identify
suspicious patterns of activity or to reveal previously unknown links among
criminal suspects. That is the premise of a number of commercial software
products now marketed to police departments.  n59 Social Media Monitor is a
"cloud-based service [that] will watch social networks" for suspicious
activities.  n60 Applying language analytics and sentiment analysis to services
like Twitter and Facebook, Social Media Monitor claims to warn law enforcement
clients of ongoing or potential threats of violence. Another software product,
Intrado's Beware, promotes itself as a "tool to help first responders understand
the nature of the environment they may encounter during the window of a 9-1-1
event."  n61 Beware does so by assigning a "threat rating" to a person based on
an analysis of billions of commercial  [*25]  and public records.  n62 The
Beware algorithm sorts through both information already familiar to the police
(like registered cars and rap sheets) and novel (like "residents' online
comments, social media and recent purchases for warning signs").  n63

   A third example of expanded surveillance discretion is the use of social
network analysis by police to identify suspicious or vulnerable individuals.
n64 Social networks refer to a set of personal connections among a group of
people. The basic unit of analysis in social network analysis consists of the
link between two people.  n65 The ties (relationships) between nodes (people)
can take many forms: drug transactions, phone calls, or physical contacts
between victims and offenders. Based on mathematical modeling, social network
analysis maps a particular groups of relationships. Most importantly, the
approach identifies the relative importance or centrality of nodes
(individuals): "their importance to the criminal system, role, level of
activity, control over the flow of information, and relationships."  n66

   Social network algorithms developed for law enforcement purposes by private
companies promise to identify non-obvious relationships in known criminal
associations. While the police might know the leadership of a criminal gang,
they may not know others who "ha[ve] the most influence in a gang, or who
transmit[] the most information in the fastest amount of time."  n67 This
information can then be used by the police to focus their attentions on
particular individuals that may have escaped police attention through
conventional surveillance.

   The aggressive use of social network analysis by the Chicago Police
Department is illustrative.  n68 Beginning in 2012, the Chicago police have
relied upon the use of network analysis to direct preventive policing measures.
n69 Beginning with the identification of the sixty known gangs and 600  [*26]
factions within the city, the Chicago police then map out these relationships to
identify both positive and negative connections among groups and individual
members.  n70 The name of a shooting victim, for instance, might trigger a
computer warning to the police that four individuals should be treated with
suspicion, not because of anything they did, but because they are known gang
members feuding with the victim's gang.  n71 In addition, another notification
might alert the police of eight potential members of the victim's own gang who
might be at risk of turning to violence in retaliation.  n72 No traditional
physical evidence links these persons to the actual shooting, but social network
analysis predicts future violence associated with them, and thus directs police
resources and attention.

   The Chicago Police Department uses a "heat list" to focus its preventive
policing efforts. This heat list is based upon research that found that those
with close social ties to a homicide victim were 100 times more likely to be
involved as a future victim or perpetrator of violence. In response, the Chicago
police piloted a program in 2013 to identify these persons at high risk for
future violence.  n73 A computer analysis weighs risk factors: some that are not
especially surprising, such as a person's rap sheet, his warrant or parole
status, weapons or drug arrests, but also some that are, including a person's
acquaintances and the arrest records and possible violent victimization of those
socially connected to the person.  n74 The approximately 400 people who emerge
from the analysis with the highest scores constitute the heat list: a group
targeted for the Chicago Police Department's Custom Notifications program.  n75

   Being on the heat list results in a personal home visit from a Chicago Police
officer, who warns the person of the legal consequences that will result if he
engages in criminal activity.  n76 Those on the list are also told that they are
also at a high risk for becoming victims, not just perpetrators, of future
violence.  n77 Those who receive these "custom notifications" are not always
obvious perpetrators of violence. They might be people who have otherwise
escaped police notice because of an absence of serious convictions or a long rap
sheet.  n78 Moreover, it may be a social connection with a homicide victim that
increases their risk rating.  n79

    [*27]  License plate readers, network software, and social media are not the
only way the police use big data in intelligence or to predict suspicious
activity. Predictive policing models that attempt to focus police attention to
locations where crime is likely to occur in the future are already in use.  n80
Moreover, some of these tools may be used in combination. License plate
recognition tied with network analysis might be used to find cars associated in
time and space with a car of primary interest to the police.

C. How the New Surveillance Discretion is Different

   Surveillance discretion isn't new, but with big data tools the police have
greatly expanded powers. This section examines what is distinct about the new
surveillance discretion, as well as its potential benefits and concerns.

   1. Characteristics

   Innocent data aggregated to suspicious big data: Big data tools permit the
police to sift through vast amounts of data that have no obvious connections to
crime but through computer assisted analysis may suggest criminally suspicious
activity. This is similar to traditional surveillance discretion; courts have
permitted police to conduct stops based on facts that would not seem suspicious
to us at all. Yet it is different, vastly different, in scale.

   Mining social connections: Whether social connections can be plotted on a
map, through online postings, or through social network analysis, big data tools
allow law enforcement agencies to collect, aggregate, and analyze social
connections using tailored algorithms. Rather than a specialized human skill,
n81 mining social connections might one day be an ordinary aspect of local
police departments.

   From active investigations to passive alerts: The traditional methods the
police use to identify or predict ongoing or future crimes require time and
effort. The process is by necessity inefficient; by deciding to focus on some
individuals, the police miss other opportunities. More generally, decisions to
focus human resources on some kinds of suspicious activity rather than others
reflect enforcement priority decisions that all law enforcement agencies must
make.

    [*28]  Automating the suspicion analysis--in whole or in part--could
dramatically change policing. Some information that previously would not have
been known to individual officers, either because it was unknown or because it
would have been too cumbersome to retrieve quickly, becomes part of the
investigations process. Big data might also bring new and unexpected insights
about criminal behavior.  n82 The scale of automation also widens the scope of
surveillance over many more potentially suspicious persons.

   2. Potential Benefits

   Diminishing troubling uses of discretion: Big data tools, at least in theory,
promise to introduce more fairness into surveillance discretion. Traditional
policing relies upon an officer's ability to identify suspicious behavior. But
because "nothing is inherently suspicious,"  n83 conventional police decisions
are normative judgments that are highly dependent on subjective considerations,
and sometimes improper ones.  n84 How police identify suspicious people thus
sometimes reflects stereotypes about race and class, particularly about young
African American men in economically depressed neighborhoods. After all, the
police, like the rest of us, are "cognitive misers" who rely upon shortcuts to
process the world around most efficiently.  n85 Discretion also plays a role in
departmental as well as individual decisions. Departments set priorities on
whether to focus on prostitution and drugs sales on the streets, for instance,
rather than within private spaces.  n86

   Big data tools could curb police discretion in two ways. First, algorithms
that search for suspicious activity could greatly reduce or eliminate race- or
class-based biases for which the police are often criticized (although this too
may hide hidden problems).  n87 Second, certain crimes that may be especially
amenable to big data policing, particularly white-collar financial fraud, may
lead to more equitable distribution of law enforcement resources.  n88

   Alternatives to flawed investigative tools: Increasing reliance on big data
tools might one day eclipse the use of traditional surveillance and
investigation  [*29]  methods that have received significant criticism. Consider
police reliance on informants.  n89 When police rely on one or a few people to
identify suspects, the results are necessarily skewed. Informants only identify
people they know, from the neighborhoods they know. Informant culture then plays
a key role in reproducing racial disparities within the criminal justice system.
n90 Rather than rely on the usual suspects or the usual neighborhoods, big data
programs search through all available information for future or ongoing crimes.
n91

   Big data tools might also supplant some needs for covert policing in the
physical world. Undercover operations are justified as a "dirty but necessary"
business because without them, many types of crimes could not otherwise be
investigated.  n92 Big data tools may provide an alternative. White collar
crime, for instance, is now difficult to identify without undercover
investigations (and informants). However, with a computer program that can scan
the enormous quantities of securities trading data for patterns of potential
insider trading,  n93 law enforcement officials may be able to rely less on
covert operations, often criticized for their secrecy and implementation.
Alternatively, though, the police may simply use big data tools in addition to
covert tactics they adopt online.  n94

   Production of data: Big data policing will produce information capable of
audits and third party examination--a stark contrast from conventional
surveillance. Fourth Amendment law requires police to provide specific
articulable facts to justify stops and arrests.  n95 These reasons are usually a
mix of experience and observation. To make matters more difficult, the police
feel pressure to conform their justifications to requirements about legally
sufficient reasons that will hold up in court if challenged. Yet the complete
explanation for what motivates a stop is likely unknowable, even to the officer
himself. What stands out in an officer's mind as suspicious is the product of an
"idiosyncratic, unaccountable, unknowable personal algorithm."  n96 Moreover, in
its Fourth Amendment decisions, the Supreme Court has  [*30]  shown little
interest in subjecting the internal decision-making processes of police officers
to any real scrutiny.  n97

   3. Potential Concerns

   Old problems in new packages: How, whether, and when the police use their
legal authority to make choices poses a basic challenge for democratic policing.
Law enforcement is impossible without giving the police choices, yet delegating
the police discretion raises questions about fair-minded law enforcement in a
democratic society.  n98 Compounding our discomfort with police discretion is
the fact that police are notoriously secretive, not just about their discretion
but about nearly everything.  n99 In theory, the increasing use of computers and
numbers might force policing practices to be more transparent and accountable.
Yet powerful big data tools can operate secretly and without public awareness in
ways that cases of street police brutality cannot.

   Hidden discretion: By applying data analytics to digitized information, big
data tools appear to provide an objective analysis of information. But
discretionary human decisions can play an important role in big data in ways
that may not be obvious. First, very basic decisions about big data tools
involve discretion: which mathematical model to adopt, what data to use, and how
to display that data, among other considerations.  n100 Second, police
departments will make choices about how and where to apply big data tools; these
are discretionary decisions similar to how departments deploy human resources.
Predictive policing software, already in use by some police departments, focuses
heavily on property crimes because its predictions about other crimes are not as
accurate.  n101

   The information used by big data tools may also be products of hidden police
discretion.  n102 Arrest information, at least for minor offenses, reflects
highly discretionary decisions. If arrest records are used in an analysis to
focus police resources, this can lead to further discretionary arrest patterns
against the same neighborhoods and people. Even more reflective of police
discretion are field interview cards: information officers collect about people
[*31]  they encounter on the street for consensual, information-producing
conversations.  n103 Contact cards are unlikely to have an even or random
distribution. Once transformed into data, this information can appear neutral
and objective, even though they are the products of individual discretionary
decisions. Moreover these highly discretionary decisions can be further
influenced by other ones, such as departmental pressures to produce contact
cards, or by metrics that assess officer productivity through consensual
contacts, stops, and arrests.

   Clerical mistakes and errors: In the dystopian 1985 movie Brazil, the plot
centers on a kind of big data mistake: a clerical error leads to the government
detention and death of a Mr. Buttle, instead of the intended target, a Mr.
Tuttle.  n104 While the movie offers a dark satire of a highly bureaucratic
state, its observations are relevant today. The sheer amount of information that
the police, like many other institutions and industries, must confront and
assess is "overwhelming."  n105 Errors and mistakes are inevitable. The
consequences of big data errors and distortions in policing can be severe. When
marketers make decisions based on a faulty algorithm, the results may be
embarrassing or annoying, but the stakes are comparatively low.  n106 The same
cannot be said of policing. The wrong person may be eventually detained, perhaps
at gunpoint. Or she may face unwarranted humiliation because of police attention
that may be noticed by family, friends, or employers.

   For instance, algorithms can rely upon data that is itself incomplete or
erroneous. For example, on the evening of March 30, 2009, San Francisco Police
officers conducted a "high risk" traffic stop of Denise Greene, a
forty-seven-year-old African American woman with no criminal record.  n107 An
automatic license plate reader mounted on a SFPD patrol car alerted officers
that Greene's car was stolen.  n108 The result, however, was a false hit; the
camera misidentified Greene's car because the scan was blurry.  n109 The police
discovered their mistake, but not until after Greene was forced to kneel outside
of her car at gunpoint, and to undergo a physical pat-down and a search of her
car.  n110

    [*32]  The surveillance tax: Even short of an investigative detention or
arrest, surveillance can be intrusive. Knowledge of surveillance alone can
inhibit our ability to engage in free expression, movement, and unconventional
behavior. Judges and lawmakers have also occasionally acknowledged the
stigmatizing effect of investigation itself, even if the police take no
physically intrusive actions. As a Congressional report noted in 1984, "[t]he
stigma which results from involvement in any investigation is substantial."
n111 In neighborhoods with a fraught relationship between the community and the
police, a "preventive" visit may be misinterpreted as the targeted person's
conversion to an informant: a misinterpretation with potentially fatal
consequences.  n112

   Even in small doses, expansive uses of surveillance discretion can be
worrisome. Expanded considerably, it is even more troubling, especially as big
data tools have eroded the natural limits placed on surveillance discretion.
Increased use of tools with a wider surveillance scope further increases the
costs of "hassle": increased police attention or intervention that later turns
out to be unwarranted.  n113 These burdens of time, humiliation, and insecurity
in law enforcement are inevitable,  n114 but increasing these surveillance
burdens requires accountability tools to accompany them.

   Eliminating good discretion: If technology could eliminate some bad uses of
police discretion (such as racial bias), it has the potential to dampen the
power of good police discretion as well. Good discretion means many things,
including giving an otherwise technically eligible person a break on behavior
which would otherwise warrant a summons, a citation, or an arrest. Good
discretion also includes what police might know about a neighborhood and its
community: local knowledge that might not be amenable to data capture. Personal
relationships and neighborhood knowledge can help police distinguish real
dangers from false ones. An initial determination about suspicion, once
perceived in context, may lead to a conclusion that nothing is amiss at all. In
other words, traditional surveillance discretion is an aspect of local,
contextualized police knowledge.

   III. ACCOUNTABILITY FOR EXPANDED SURVEILLANCE DISCRETION

   When the police can watch many more people and activities with increasing
sophistication and at lower cost, we need new transparency and accountability
mechanisms. This section considers what issues will be raised by the development
of new accountability mechanisms, as well as some suggestions for what form
those mechanisms might take.

    [*33]  A. Why the Fourth Amendment Does Not Apply

   Traditionally surveillance discretion is a power enjoyed by the police with
few legal constraints. When the police investigate a crime, they might decide to
focus their attention on one particular person or group of people to confirm or
dispel suspicions that arise after their preliminary investigation. The police
may watch or follow the suspect on the street, talk to his associates, or comb
through publicly available information.  n115

   So long as the police confine the targets of their investigation to areas
that are not private--even if their methods are secretive or covert--the police
are not required to have any particular individualized suspicion about the
suspect to focus their attention on him.  n116 How long the police watch a
person, why the police decide to investigate one person rather than another, and
why they decide to investigate a crime at all are matters for police discretion,
largely because the Fourth Amendment does not usually apply to these activities.
n117

   That the Fourth Amendment does not regulate these early stages of
investigation draws on well-established Supreme Court case law. Ever since the
Supreme Court formulated the "reasonable expectation of privacy" test nearly
fifty years ago in Katz v. United States,  n118 it is generally understood that
the police are free to investigate public places, speak with people
consensually,  n119 and access information that has already been given to third
parties.  n120 None of these areas are searches for Fourth Amendment purposes.
All of these areas are those in which people "knowingly expose" information to
the public, and thus also to the police.  n121

Fourth Amendment requirements apply, then, after the police have decided to use
any information they have collected as a basis to interfere with a person's
legally recognized interests. If the police subject a person to a temporary
investigative detention, they are required to have reasonable suspicion  [*34]
before doing so.  n122 An arrest or full search requires probable cause, and in
some cases, prior judicial approval in the form of a warrant.  n123

   Before that point of intervention, however, the police can select a person or
group of persons for particular attention without having to provide a
justification for doing so. The police are "not restricted by being required to
have a reasonable suspicion to observe or investigate persons in public and
public data . . . to detect those [persons] who commit crime."  n124 In other
words, surveillance that does not intrude upon recognized Fourth Amendment
interests requires no prior justification by the police.  n125 The who, how, and
why of police decisions to single out persons for attention is a matter of
police discretion.

   And because the Fourth Amendment does not regulate surveillance discretion,
courts have had little to say about it. In response to claims that police
surveillance is overly intrusive or controlling, courts have been generally
unsympathetic. Lawful surveillance in the form of officers "walking their 'beat'
or riding in 'prowl cars' " has been described as "proper police function," even
if the surveillance might influence the targeted person's actions in public.
n126 As the Eighth Circuit observed in one case, "judicial review of
investigative decisions, like oversight of prosecutions, tends 'to chill law
enforcement by subjecting the [investigator's] motives and decisionmaking to
outside inquiry.'"  n127 In rejecting claims regarding surveillance discretion,
some courts have simply stated that "there is no constitutional right to be free
of investigation."  n128 The only caveat that courts raise is that surveillance
discretion cannot be "exercised in a discriminatory fashion."  n129

    [*35]  The view that no individual has a right to be free of investigation
has also been the premise of a related legal question: whether the police must
have at least reasonable suspicion before beginning an undercover operation
targeting a particular person. The answer from courts has been a resounding
"no."  n130 Consider the ABSCAM scandal of the 1970s, which began with an FBI
undercover operation that focused first on the trafficking of stolen property
but eventually turned to political corruption. Evidence from ABSCAM eventually
led to the convictions of several government officials, including a U.S. Senator
and six members of the House of Representatives. Once ABSCAM was brought to
public attention,  n131 members of Congress considered whether individualized
suspicion requirements should apply at this earlier investigative stage, but
proposed legislation imposing a warrant requirement for undercover
investigations never came to pass.  n132

   In some rare instances, police surveillance by itself can give rise to
constitutional claims. "Otherwise lawful surveillance" by the police can be the
basis of a civil rights claim if the surveillance interferes with other
constitutional rights.  n133 For example, in October 2015, the Third Circuit
reinstated a federal civil rights lawsuit alleging that the NYPD violated First
Amendment and Equal Protection rights by engaging in a surveillance program of
Newark's Muslim community.  n134 The Supreme Court's 1972 decision in Laird v.
Tatum,  n135 however, makes it difficult for plaintiffs to win cases simply
because they are concerned about the effects of lawfully collected surveillance.
In Laird, the plaintiffs claimed that Army surveillance of civilian political
activity infringed upon their First Amendment rights.  n136 The Supreme Court
held, however, that the Laird plaintiffs lacked standing to bring their claims
because they lacked any justiciable injury. Absent a "specific present objective
harm due to the surveillance or threat of a specific future harm," "the mere
existence, without more, of a governmental investigative and data-gathering
activity" could not form the basis of a federal  [*36]  lawsuit.  n137 As a
result of this standard, lawsuits complaining only about intrusive but otherwise
lawful surveillance often fail.  n138

   Because so few cases state much about surveillance discretion other than to
acknowledge the wide latitude given to police to exercise their powers, we might
look to other analogous areas of the law where courts have considered challenges
to the preliminary exercises of governmental power.

   For instance, many defendants have challenged the discretion of police and
prosecutors for singling them out for arrest or prosecution. Many cases have
considered defendants' claims that the police (or prosecutors) have unfairly or
arbitrarily focused on them. But here too courts have yielded considerable
discretion to law enforcement officials in deciding how, whether, and when to
exercise their powers.  n139 Claims of discriminatory enforcement in violation
of the Fourteenth Amendment are available in theory, but in practice most fail
because of the difficulty of proving the necessary elements.  n140 Moreover, the
Supreme Court's decisions in Whren v. United States  n141 and Atwater v. City of
Lago Vista  n142 foreclose the ability of defendants to complain of arbitrary or
pretextual enforcement in Fourth Amendment claims.  n143

   What serves as a check on traditional surveillance discretion of the police,
then, if not Fourth Amendment law? The answer lies in practical rather than
legal restraints. First, surveillance has been naturally limited by the expense
and limits of available technology. While the police have adopted many new
technological advances over time, in the first 150 years of policing local
police departments were simply not capable of constant and pervasive
surveillance. Employing armies of officers to watch any particular person or
persons all of the time is impracticable for ordinary police departments.  n144
And the use of high-tech surveillance methods until recently has  [*37]  been
limited; what means existed have been prohibitively expensive for most local
police departments. Thus, "as a practical matter, investigative agencies will
rarely expend their limited manpower and resources on a mere whim . . . ."  n145

   Second, the mere visibility of most traditional police practices provides a
check on police behavior because an objecting public can monitor and sometimes
call for change.  n146 Most routine street policing is visible. Indeed, as
recent national attention to several cases of people who have died in encounters
with the police has shown, bystander videos have led to protests and calls for
action with regard to excessive force.  n147

   Thus, the Fourth Amendment is unlikely to be a useful choice to curb
surveillance discretion. To be sure, judges and law professors have raised
concerns that the Supreme Court's Fourth Amendment cases decided in the 1980s
give insufficient protections to those whose movements and actions in public
have been monitored by the police, particularly since that information in the
aggregate can provide highly revealing information about one's religious
beliefs, health conditions, political affiliations, and vices.  n148 Thus, some
have argued that police collection of large amounts of a person's "public" data
should constitute a Fourth Amendment search even if the collection of each data
point in isolation would not likely be considered a search. This "mosaic theory"
of the Fourth Amendment may be helpful to defendants when the police single them
out for particularized data collection.  n149 As to whether big data analysis
might provide a basis for individualized suspicion,  [*38]  some commentators
have already raised doubts as to whether the Fourth Amendment alone should
regulate these determinations.  n150

   But the Fourth Amendment's focus on individualized suspicion and its
conceptualization of rights that better describe a physical rather than a
digital world is likely a poor fit for expanded surveillance discretion.
Certainly those at the receiving end of the increased scrutiny made possible by
big data may complain that the police have insufficient justification. Yet when
the police are sifting through the data of hundreds, thousands, or millions of
people at the same time, we cannot expect the police to provide individualized
suspicion before looking at a lone online post.

   If big data is changing the structure of police discretion, then commensurate
tools of accountability should focus on reining in these practices as a whole.
Because all big data tools pose similar concerns, accountability measures should
focus on policy outcomes rather than technology specific measures.  n151

B. The Secrecy Problem

   Secrecy often accompanies the new surveillance discretion. Some of this
secrecy can be attributed to the private companies providing the police with the
software or data they use. Moreover, the police themselves tend to be secretive
and insular in ways that inhibit external oversight. For these reasons, we often
know little about the adoption or development of surveillance discretion.

   First, big data tools are often private market products; police departments
are just another group of customers. In a number of recent instances, private
companies providing surveillance technology have required agreements from police
departments that prevent disclosure of information about the technology itself.

   For example, civil liberties organizations and journalists have discovered
the police use of cell site simulators, a surveillance technology that tricks
nearby cell phones into providing data by behaving as a fake mobile cell tower.
n152 Detailed information about the use of these devices, sometimes referred to
as "stingrays" or IMSI catchers, is difficult to find, however, because the
dominant manufacturer of these devices, the Harris Corporation, has required
participating law enforcement agencies to sign nondisclosure  [*39]  agreements.
n153 Nondisclosure agreements bar police departments adopting the technology
from disclosing "any information"  n154 relating to the surveillance equipment
to any third parties, private and public.  n155 Some prosecutors have even
chosen to withdraw evidence in cases rather than be forced to disclose details
about any possible use of this cellphone surveillance technology.  n156 After
several investigative reports on stingray use, the Department of Justice
announced in September 2015 new rules that would apply to the use of cellphone
surveillance technology by the Department of Justice, including a warrant
requirement.  n157

   Similarly, Vigilant, one of the country's largest ALPR companies, includes in
its terms and conditions a requirement of its licensees (i.e., police
departments) that they "agree not to voluntarily provide ANY information,
including interviews, related to [Vigilant] products or its services to any
member of the media without express written consent of [Vigilant]."  n158 Little
prevents other companies from imposing similar requirements as a condition of
sale or use by police departments.

    [*40]  Even without explicit nondisclosure agreements, big data tools can
remain secret because they contain proprietary information that companies may be
unwilling to release. Nor are private companies producing these tools subject to
public records laws that would require them to divulge relevant and useful
information.

   Second, police departments have varied widely in their willingness to provide
public access to their big data tools. The variation in ALPR policies is
illustrative. As we saw with the police department of Oakland, California, the
police agreed to provide journalists with their ALPR data. Other police
departments, however, have resisted public records requests for ALPR data on the
ground that all collected scans may be useful for investigations.  n159

C. Big Data Accountability

   Transparency and accountability measures should be a first step to address
some of the concerns raised by expanded surveillance discretion. This includes
not only independent oversight measures familiar in traditional policing but
also forms of "algorithmic accountability."  n160 What should such
accountability measures address?

   Does it exist? Sometimes the most important question is whether the police
have adopted a new surveillance technology at all. Local governments could
require police departments to seek approval before the purchase of new
technologies that expand surveillance capabilities. For instance, a surveillance
notification ordinance passed in Seattle, Washington,  n161 requires city
council approval before any city department acquires "surveillance equipment."
n162 The ordinance requires not only notification about a planned purchase of
any surveillance equipment, but also a "mitigation plan describing how the
department's use of the equipment will be regulated to protect privacy,
anonymity, and limit the risk of potential abuse."  n163 Public approval for new
surveillance technology purchases could also include approval for  [*41]  third
parties with whom police departments might contract for such services.  n164

   Without such required disclosures, local governmental bodies may find out
about technologies that significantly expand surveillance discretion only by
accident or happenstance. In 2014, the city council of Bellingham, Washington,
held a formal public hearing expressing alarm after news that its police
department planned to purchase Intrado's Beware social media analysis software
with a federal grant.  n165 The Council urged its police department not to
purchase Beware.  n166 The police department withdrew its grant request after
the city council voted to ask the department to do so.  n167

   How is it being used? Securing public approval is only a first step. Local
governments can take additional measures to ensure continuing public oversight
of big data technologies that expand surveillance discretion. For example, local
governments can require police departments to adopt "surveillance use policies"
that specify how and when surveillance technologies might be used.  n168

   Logging requirements can enable accountability by ensuring third parties can
access and review how big data policing tools work. Local governments can
provide independent third parties with responsibilities and powers to review how
such programs work.  n169 Auditors should be given access to both the technology
and the data produced by it (e.g., access controls and audit logs).  n170

   How accurate is it? With that knowledge, we can assess the nature of the raw
information used by these computer algorithms. As we have seen, some kinds of
information reflect highly discretionary decisions. Arrests are often the
outcome of decision-making about enforcement priorities, law enforcement
resources, and other contingencies. That a person is a known gang member is a
contestable designation. Yet these factors may be used to justify further law
enforcement attention, if not eventual detention or arrest.

    [*42]  How effective is it? When we know whether and how the police have
adopted a big data tool to expand their surveillance discretion, we can assess
whether such technologies are worth their financial, institutional, and social
costs. For example, ALPR surveillance is touted as a quick, efficient, and
cost-effective policing technology, but we often know little about how well the
technology reduces crime. The available evidence suggests that comparatively few
crimes are identified through mass plate collection. In Oakland, California,
journalists reported that the "hit" rate of its ALPR use--when compared to the
number of license plate scans captured--was a mere 0.16%.  n171

   IV. CONCLUSION

   The police have always possessed surveillance discretion. Big data promises
to expand and accelerate their ability to discover crime and identify suspects.
One day the ability to sort, score, and predict social activity will be an
ordinary aspect of policing, in the same way we now experience entertainment,
dating, and shopping.

   Yet the use of big data in policing will be different because of its
consequences. To be sure, big data policing may remedy some entrenched policing
inequities. And it may heighten expectations about accountability. But enhancing
the scope and power of the police to designate people as suspects will also
further complicate longstanding concerns about discretion. Secrecy about these
processes, moreover, can further alienate the public from the police. Because
policing is a democratic institution and not just a technological enterprise,
those concerns should trouble us.

Legal Topics:

For related research and practice materials, see the following legal topics:
Constitutional LawBill of RightsFundamental RightsSearch & SeizureProbable
CauseCriminal Law & ProcedureSearch & SeizureSearch WarrantsGeneral
OverviewGovernmentsLocal GovernmentsPolice Power

FOOTNOTES:





n1  See Edwin Chan & Alex Dobuzinskis, U.S. Police Struggle to Uncover Threats
on Social Media, REUTERS (Dec. 26, 2014),
http://www.reuters.com/article/2014/12/26/us-usa-police-socialmedia-idUSKBN0K40M
D20141226 [http://perma.cc/UWA9-239V] (describing fact that fatal shooting of
NYPD officers was preceded by Instagram post by shooter).





n2  See, e.g., Andrew Guthrie Ferguson, Big Data and Predictive Reasonable
Suspicion, 163 U. PA. L. REV. 327, 410 (2015).





n3  Thanks to Jane Bambauer for this phrase.





n4  Elizabeth E. Joh, Policing by Numbers: Big Data and the Fourth Amendment, 89
U. WASH. L. REV. 35, 61 (2014).





n5  See JOHN VILLASENOR, RECORDING EVERYTHING: DIGITAL STORAGE AS AN ENABLER OF
AUTHORITARIAN GOVERNMENTS 1 (Dec. 14, 2011), http://www.brookings.edu/
/media/research/files/papers/2011/12/14-digital-storage-villasenor/1214_digital_
storage_villasenor.pdf [http://perma.cc/U2TB-RYNW].





n6  See, e.g., Steve Lohr, How Big Data Became So Big, N.Y. TIMES (Aug. 11,
2012),
http://www.nytimes.com/2012/08/12/business/how-big-data-became-so-big-unboxed.ht
ml [http://perma.cc/B67F-CL9U] ("Big Data is a shorthand label that typically
means applying the tools of artificial intelligence, like machine learning, to
vast new troves of data beyond that captured in standard databases.").





n7  Here big data refers to any application of any type of computer analytics to
large sets of digitized data. Somewhat confusingly, the legal and popular
scholarship interchangeably uses similar and overlapping terms in this area,
such as datamining, databasing, machine learning, and artificial intelligence.
See Michael Rich, Machine Learning, Automated Suspicion Algorithms, and the
Fourth Amendment, U. PA. L. REV. (forthcoming) (manuscript at 8),
http://ssrn.com/abstract=2593795 [http://perma.cc/D8UA-ZFT3]. For instance, in
his thorough analysis of how big data will change the reasonable suspicion
calculus, Andrew Guthrie Ferguson uses big data to mean extremely large
quantities of data, with or without data analytics. See Ferguson, supra note 2
("Big data refers to the accumulation and analysis of unusually large data
sets.").





n8  Somini Sengupta, In Hot Pursuit of Numbers to Ward Off Crime, N.Y. TIMES:
BITS (June 19, 2013),
http://bits.blogs.nytimes.com/2013/06/19/in-hot-pursuit-of-numbers-to-ward-off-c
rime/ [http://perma.cc/G2TJ-66EC].





n9  See, e.g., Rich Calder, NYPD Wants to Add Crime-Predicting Software to
Arsenal, N.Y. POST (July 8, 2015),
http://nypost.com/2015/07/08/nypd-wants-to-add-crime-predicting-software-to-arse
nal/ [http://perma.cc/6PR9-ZZDT]; Heather Kelly, Police Embracing Tech That
Predicts Crimes, CNN (May 26, 2014),
http://www.cnn.com/2012/07/09/tech/innovation/police-tech/
[http://perma.cc/NJB6-U2VE]; Bellamy Pailthorp, Seattle, Tacoma Rolling Out New
'Predictive Policing' Software, KPLU (Feb. 27, 2013),
http://www.kplu.org/post/seattle-tacoma-rolling-out-new-predictive-policing
-software [http://perma.cc/G6F5-ZCYD].





n10  See Rob Lever, Researchers Use Twitter to Predict Crime, YAHOO NEWS (Apr.
20, 2014),
https://sg.news.yahoo.com/researchers-twitter-predict-crime-021341693.html
[http://perma.cc/7ELW-33EQ].





n11  See Clay Dillow, Building a Social Network of Crime, POPULAR SCIENCE (Jan.
14, 2014), http://www.popsci.com/article/science/building-social-network-crime
[http://perma.cc/UM2C-EDSN].





n12  This might be considered "suspect-driven" and "crime-out" uses of big data.
Jane Bambauer, The Lost Nuance of Big Data Policing, 94 TEX. L. REV.
(forthcoming 2015) (manuscript at 3, 27) (on file with author) (explaining that
"crime-out investigations study clues from an already-committed crime" and
arguing that warrants should be required for suspect-driven big data searches,
but not crime-driven searches).





n13  Brian A. Reaves, Census of State and Local Law Enforcement Agencies, 2008,
U.S. DEP'T OF JUSTICE, July 2011, at 2,
http://www.bjs.gov/content/pub/pdf/csllea08.pdf [http://perma.cc/XAN2-WJYG].





n14  See, e.g., United States v. Wallace, 811 F. Supp. 2d 1265, 1272 (S.D. W.
Va. 2011) ("There is no constitutional prohibition against law enforcement
watching, or following, particular individuals in high-crime areas.").





n15  See, e.g., Safford Unified School Dist. No. 1 v. Redding, 557 U.S. 364, 370
(2009) (noting the Fourth Amendment "generally requires a law enforcement
officer to have probable cause for conducting a search"); Terry v. Ohio, 392
U.S. 1, 20 (1968) (noting that "police must, whenever practicable, obtain
advance judicial approval of searches and seizures through the warrant
procedure").





n16  Of course, some of the scholarship in this area argues that some
collections of data should in fact qualify as Fourth Amendment searches. See,
e.g., Jace C. Gatewood, District of Columbia Jones and the Mosaic Theory--In
Search of a Public Right of Privacy: The Equilibrium Effect of the Mosaic Theory
, 92 NEB. L. REV. 504 (2014).





n17  See, e.g., United States v. Graham, 796 F.3d 332 (4th Cir. 2015) (requiring
a warrant); United States v. Davis, 785 F.3d 498 (11th Cir. 2015) (not requiring
warrant).





n18  See, e.g., Marc L. Miller & Ronald F. Wright, The Black Box, 94 IOWA L.
REV. 125 (2008).





n19  See, e.g., Ferguson, supra note 2.





n20  When defined this way, surveillance discretion does not focus on the use of
big data to determine suspects in completed crimes, or to determine relevant
information about one particular suspect in a completed crime. These types of
suspect-driven investigations raise their own important questions, as recent
cases involving challenges to warrantless searches of historical cell site data
have shown.





n21  See, e.g., Christopher Slobogin, Making the Most of United States v. Jones
in a Surveillance Society: a Statutory Implementation of Mosaic Theory, 8 DUKE
J. CONST. L. & PUB. POL'Y 1, 13 (2012); Bambauer, supra note 12 (manuscript at
9) (arguing that police need some way to build up suspicion about a suspect, and
keeping every last third party record off limits until the case progresses to
probable cause would unacceptably frustrate investigations); Orin S. Kerr, The
Mosaic Theory of the Fourth Amendment, 111 MICH. L. REV. 311, 328 (2012) ("The
repeated use of nonsearch techniques has been considered an essential way to
create probable cause that justifies searches rather than an unlawful search
itself.").





n22  See, e.g., United States v. Wallace, 811 F. Supp. 2d 1265, 1272 (S.D. W.
Va. 2011).





n23  Some scholars are cautiously optimistic about big data policing tools. See,
e.g., Bambauer, supra note 12 (manuscript at 11) ("However, criminal procedure
scholarship has not yet acknowledged how automated searching and filtering can
dramatically change criminal investigations, largely (though not exclusively)
for the better.").





n24  While there is no single definition of big data, most commentators agree
that the term refers to the application of artificial intelligence to large
amounts of digital information. See Lohr, supra note 6.





n25  See SIMON A. COLE, SUSPECT IDENTITIES 32-59 (2001). Alphonse Bertillon, who
in the late nineteenth century developed a method to index offenders based on
physical measurements and observations, introduced the "first modern system of
criminal identification." Id. at 32.





n26  RICHARD ERICSON & KEVIN HAGGERTY, POLICING THE RISK SOCIETY 19 (1997).





n27  Compstat is a "performance management system that is used to reduce crime
and achieve other police department goals" that typically includes "(1) Timely
and accurate information or intelligence; (2) Rapid deployment of resources; (3)
Effective tactics; and (4) Relentless follow-up." See POLICE EXECUTIVE RESEARCH
FORUM, BUREAU OF JUSTICE ASSISTANCE, COMPSTAT: ITS ORIGINS, EVOLUTION, AND
FUTURE IN LAW ENFORCEMENT AGENCIES 2 (2013),
https://www.bja.gov/Publications/PERF-Compstat.pdf [https://perma.cc/8NJL-FW77].
For representative accounts of the NYPD's reliance on Compstat, see, e.g.,
VINCENT E. HENRY, THE COMPSTAT PARADIGM: MANAGEMENT ACCOUNTABILITY IN POLICING,
BUSINESS AND THE PUBLIC SECTOR (2003); ELI B. SILVERMAN, NYPD BATTLES CRIME:
INNOVATIVE STRATEGIES IN POLICING 97-124 (1999).





n28  In 2012, there were approximately 2.7 zettabytes of stored digital
information in the world. See Albert Pimentel, Big Data: The Hidden Opportunity,
FORBES (May 1, 2012),
http://www.forbes.com/sites/ciocentral/2012/05/01/big-data-the-hidden-opportunit
y/ [http://perma.cc/T9XQ-TAEW].





n29  The largest current recognized number is a yottabyte: a digit with
twenty-four zeros. See John Foley, Extreme Big Data; Beyond Zettabytes and
Yottabytes, FORBES (Oct. 9, 2013),
http://www.forbes.com/sites/oracle/2013/10/09/extreme-big-data-beyond-zettabytes
-and-yottabytes/ [http://perma.cc/L56V-SRCP].





n30  See PRESIDENT'S COUNCIL OF ADVISORS ON SCIENCE AND TECHNOLOGY, BIG DATA AND
PRIVACY: A TECHNOLOGICAL PERSPECTIVE (May 2014),
https://www.whitehouse.gov/sites/default/files/microsites/ostp/PCAST/pcast_big_d
ata_and_privacy_-_may_2014.pdf [http://perma.cc/87G9-HSCP] [hereinafter BIG DATA
AND PRIVACY] (distinguishing between data "born digital" and "born analog").





n31  Erin Allen, Update on the Twitter Archive at the Library of Congress,
LIBRARY OF CONGRESS BLOG (Jan. 4, 2013),
http://blogs.loc.gov/loc/2013/01/update-on-the-twitter-archive-at-the-library-of
-congress/ [http://perma.cc/9F9V-8KLB].





n32  INTERNET.ORG, A FOCUS ON EFFICIENCY (Sept. 16, 2013),
http://www.meducationalliance.org/sites/default/files/internet.org_-_a_focus_on_
efficiency.pdf [http://perma.cc/MTY9-6JDG].





n33  See, e.g., VIKTOR MAYER-SCH[#xD6]NBERGER & KENNETH CUKIER, BIG DATA: A
REVOLUTION THAT WILL TRANSFORM HOW WE LIVE, WORK, AND THINK 122 (2013) ("The
crux of data's worth is its seemingly unlimited potential for reuse: its option
value.").





n34  See, e.g., Charles Duhigg, How Companies Learn Your Secrets, N.Y. TIMES
(Feb. 16, 2012), http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html
[http://perma.cc/8CZ2-R647] ("Almost every major retailer, from grocery chains
to investment banks to the U.S. Postal Service, has a 'predictive analytics'
department . . . .").





n35  See, e.g., Adam Frank, Big Data Is the Steam Engine of Our Time, NPR (Mar.
12, 2013),
http://www.npr.org/blogs/13.7/2013/03/12/174028759/big-data-is-the-steam-engine-
of-our-time [http://perma.cc/H676-9EBM] ("Big Data may be the steam engine of
our time.").





n36  MAYER-SCH[#xD6]NBERGER & CUKIER, supra note 33, at 61 ("In a small-data
world, because so little data tended to be available, both causal investigations
and correlation analysis began with a hypothesis, which was then tested to be
either falsified or verified. . . . Today, with so much data around and more to
come, such hypotheses are no longer crucial for correlational analysis.").





n37  Victor Luckerson, What the Library of Congress Plans to Do with All Your
Tweets, TIME (Feb. 25, 2013),
http://business.time.com/2013/02/25/what-the-library-of-congress-plans-to-do-wit
h-all-your-tweets/ [http://perma.cc/F5RN-UB5M].





n38  See MAYER-SCH[#xD6]NBERGER & CUKIER, supra note 33, at 61.





n39  GOOGLE FLU TRENDS,
https://www.google.org/flutrends/about/data/flu/us/data.txt
[http://perma.cc/E6VZ-K6KD]. Google shut down its Flu Trends website in August
2015 after criticism of its forecasting failures, and instead makes its data
available to researchers. Beth Mole, New Flu Tracker Uses Google Search Data
Better than Google, ARS TECHNICA (Nov. 9, 2015),
http://arstechnica.com/science/2015/11/new-flu-tracker-uses-google-search-data-b
etter-than-google/ [http://perma.cc/2SJG-W9CD].





n40  MAYER-SCH[#xD6]NBERGER & CUKIER, supra note 33, at 59 (emphasis in
original).





n41  See, e.g., N.Y STATE DIVISION OF CRIMINAL JUSTICE SERVICES, SUGGESTED
GUIDELINES: OPERATION OF LICENSE PLATE READER TECHNOLOGY 5 (Jan. 2011),
http://www.criminaljustice.ny.gov/ofpa/pdfdocs/finallprguidelines01272011a.pdf
[http://perma.cc/U7YV-7T3T] ("The concept of using cameras as a method to record
a vehicle passing through a specific location and then identifying the
owner/operator has been in development since the 1970s. Early technology could
capture a picture of a license plate and vehicle with the date and time. Upon
retrieving the plate number after searching hours of captured images, the plate
number could then be manually searched against a database. This technology was
time consuming, expensive and limited by lighting and weather conditions.").





n42  See, e.g., id. (describing later analog to digital processing method that,
"while better than earlier methods, still had many drawbacks, including high
costs that limited its general use by state and local governments").





n43  Id. at 11.





n44  Id. at 7.





n45  See id. at 5.





n46  See Theresa Clift, Newport News to Begin Scanning License Plates to Find
Delinquent Taxpayers, DAILY PRESS (Mar. 20, 2015),
http://www.dailypress.com/news/newport-news/dp-nws-nn-license-scanners-20150319-
story.html [http://perma.cc/48LQ-LN64].





n47  See ACLU, YOU ARE BEING TRACKED: HOW LICENSE PLATE READERS ARE BEING USED
TO RECORD AMERICANS' MOVEMENTS 12 (July 2013),
https://www.aclu.org/files/assets/071613-aclu-alprreport-opt-v05.pdf
[https://perma.cc/JFH4-8JK7] (reporting almost three-quarters of law enforcement
agencies surveyed used ALPR technology); see also Cyrus Farivar, Your Car,
Tracked: The Rapid Rise of License Plate Readers, ARS TECHNICA (Sept. 27, 2012),
http://arstechnica.com/tech-policy/2012/09/your-car-tracked-the-rapid-rise-of-li
cense-plate-readers/ [http://perma.cc/N8EZ-2Z7Z] (reporting ALPR use in the
"tens of thousands").





n48  Cyrus Farivar, We Know Where You've Been: Ars Acquires 4.6M License Plate
Scans From the Cops, ARS TECHNICA (Mar. 24, 2015),
http://arstechnica.com/tech-policy/2015/03/we-know-where-youve-been-ars-acquires
-4-6m-license-plate-scans-from-the-cops/ [http://perma.cc/J86S-6HP9].





n49  Id.





n50  See id.





n51  Id.





n52  Bob Parks, Scan Artist, POPULAR SCIENCE (July 7, 2014),
http://www.popsci.com/article/ technology/scan-artist
[http://perma.cc/B73H-53DV].





n53  See Cyrus Farivar, NYPD to Conduct "Virtual Stakeouts," Get Alerts on
Wanted Cars Nationwide, ARS TECHNICA (Mar. 2, 2015),
http://arstechnica.com/tech-policy/2015/03/nypd-to-conduct-virtual-stakeouts-get
-alerts-on-wanted-cars-nationwide/ [http://perma.cc/R4TJNAJP].





n54  VIGILANT SOLUTIONS, Vigilant Solutions License Plate Recognition (LPR) -
Pattern Crime Case Study of Stakeout Feature,
http://vigilantsolutions.com/news/watch-videos [http://perma.cc/WDE7-3UUG].





n55  ACLU, supra note 47.





n56  INT'L ASS'N OF CHIEFS OF POLICE, 2014 SOCIAL MEDIA SURVEY RESULTS (2014),
http://www.iacpsocialmedia.org/Portals/1/documents/2014SurveyResults.pdf
[http://perma.cc/5RSB-KMS5].





n57  Chan & Dobuzinskis, supra note 1.





n58  See, e.g., Oren Yaniv, Cop Helps Take Down Brooklyn Crew Accused of
Burglary Spree by Friending Them on Facebook, N.Y. DAILY NEWS (May 30, 2012),
http://www.nydailynews.com/new-york/helps-brooklyn-crew-accused-burglary-spree-f
riending-facebook-article-1.1086892 [http://perma.cc/8ECP-R3UQ] ("A Brooklyn cop
helped take down a prolific burglary crew by friending its members on Facebook
and monitoring their status updates for boasts about upcoming heists."); see
also Elizabeth E. Joh, Bait, Mask, and Ruse: Technology and Police Deception,
128 HARV. L. REV. F. 246 (2015),
http://harvardlawreview.org/2015/04/bait-mask-and-ruse/
[http://perma.cc/UL4Q-67AJ].





n59  Cf. BIG DATA AND PRIVACY, supra note 30, at 24 ("Analytics is what creates
the new value in big datasets, vastly more than the sum of the values of the
parts.").





n60  Sean Gallagher, Staking Out Twitter and Facebook, New Service Lets Police
Poke Perps, ARS TECHNICA (Nov. 13, 2013),
http://arstechnica.com/information-technology/2013/11/staking-out-twitter-and-fa
cebook-new-service-lets-police-poke-perps/ [http://perma.cc/CN9T-3CBV].





n61  Intrado Beware, INTRADO, http://www.intrado.com/beware
[http://perma.cc/D2CJLNB4].





n62  Brent Skorup, Cops Scan Social Media to Help Assess Your 'Threat Rating',
REUTERS (Dec. 12, 2014),
http://blogs.reuters.com/great-debate/2014/12/12/police-data-mining-looks-throug
h-social-media-assigns-you-a-threat-level/ [http://perma.cc/4L5T-ULB7].





n63  Id.





n64  See, e.g., BIG DATA AND PRIVACY, supra note 30, at 28 ("Social-network
analysis refers to the extraction of information from a variety of
interconnecting units under the assumption that their relationships are
important and that the units do not behave autonomously.").





n65  Jennifer A. Johnson et al., Social Network Analysis: A Systematic Approach
for Investigating, FBI LAW ENFORCEMENT BULLETIN (Mar. 5, 2013),
http://leb.fbi.gov/2013/march/social-network-analysis-a-systematic-approach-for-
investigating [http://perma.cc/47QG-ZNYC].





n66  Id.





n67  Aaron Lester, Police Clicking into Crimes Using New Software, BOSTON GLOBE
(Mar. 18, 2013),
http://www.bostonglobe.com/business/2013/03/17/police-intelligence-one-click-awa
y/DzzDbrwdiNkjNMA1159ybM/story.html [http://perma.cc/L2VN-YDP3] (describing
software by founders of Mark43, http://scottmk43.herokuapp.com/platform.html
[http://perma.cc/E6VH-WRC7] (claiming to be "the very first relationship based
RMS [risk management system]")).





n68  Tony Dokoupil, 'Small World of Murder': As Homicides Drop, Chicago Police
Focus on Social Networks of Gangs, NBC NEWS (Dec. 17, 2013 3:48 AM),
http://www.nbcnews.com/news/other/small-world-murder-homicides-drop-chicago-poli
ce-focus-social-networksf2D11758025 [http://perma.cc/MJ4T-JQX5].





n69  Id.





n70  Id.





n71  See id.





n72  See id.





n73  See Garry F. McCarthy, Custom Notifications in Chicago - Pilot Program
D13-09, CHICAGO POLICE DEP'T,
http://directives.chicagopolice.org/directives-mobile/data/a7a57bf0-13fa59ed-261
13-fa63-2e1d9a10bb60b9ae.html [http://perma.cc/M74N-D9L7].





n74  See Jeremy Gorner, Chicago Police Use 'Heat List' as Strategy to Prevent
Violence, CHI. TRIB. (Aug. 21, 2013),
http://articles.chicagotribune.com/2013-08-21/news/ct-met-heat-list-20130821_1_c
hicago-police-commander-andrew-papachristos-heat-list/2
[http://perma.cc/H5MB-JKKF].





n75  See McCarthy, supra note 73.





n76  See Gorner, supra note 74.





n77  See id.





n78  See id.





n79  These are not the only uses of network analysis by the Chicago Police. For
further discussion, see Jennifer Margolis & DaWana Williamson, Notes from the
Field: Chicago Vio lence Reduction Strategy: Applications of Social Network
Analysis, NATIONAL NETWORK FOR SAFE COMMUNITIES,
http://nnscommunities.org/uploads/Chicago_VRS_SNA_Notes_from_the_Field_0505_FINA
L.pdf [http://perma.cc/7M3D-TQ5N] (discussing network analysis to identify gang
members for "call-ins").





n80  See, e.g., Joh, supra note 4; Andrew Guthrie Ferguson, Predictive Policing
and Reasonable Suspicion, 62 EMORY L. J. 259 (2012).





n81  Cf. Katrin Bennhold, London Police 'Super Recognizer' Walks Beat With a
Facebook of the Mind, N.Y. TIMES (Oct. 9, 2015),
http://www.nytimes.com/2015/10/10/world/europe/london-police-super-recognizer-wa
lks-beat-with-a-facebook-of-the-mind.html [http://perma.cc/8STP-H694] (profiling
British police officer with facial recall ability found among one to two percent
of all people).





n82  See Ferguson, supra note 2, at 395-96 (suggesting that police track sales
commonly used in crimes).





n83  Clive Norris, From Personal to Digital: CCTV, the Panopticon, and the
Technological Mediation of Suspicion and Social Control, in SURVEILLANCE AS
SOCIAL SORTING: PRIVACY, RISK AND DIGITAL DISCRIMINATION 248, 252 (David Lyon
ed., 2003).





n84  Perhaps police suspicion can be best understood as a process generated from
the exigencies of the moment rather than a fixed set of objective criteria. See
David Dixon et al., Reality and Rules in the Construction and Regulation of
Police Suspicion, 17 INT'L J. SOC. L., 185, 185 (1989).





n85  SUSAN FISK & SHELLEY TAYLOR, SOCIAL COGNITION 12 (1984).





n86  See, e.g., Nirej Sekhon, Redistributive Policing, 101 J. CRIM. L. &
CRIMINOLOGY 1171, 1186 (2011) (noting "it is departmental choices--choices made
by policymakers and administrators--that determine how arrests are
distributed").





n87  See infra Part III.C.





n88  Law professors Jane Bambauer and Andrew Ferguson both contend that big data
could make law enforcement more equitable. See Bambauer, supra note 12
(manuscript at 34); Ferguson, supra note 2.





n89  For an incisive critique of police informant use, see Alexandra Natapoff,
Snitching: The Institutional and Communal Consequences, 73 U. CIN. L. REV. 645
(2004).





n90  Id.





n91  Cf. Bambauer, supra note 12 (manuscript at 3) (arguing that "crime-out"
search "constrains police discretion and limits the grip of confirmation bias").





n92  Elizabeth E. Joh, Breaking the Law to Enforce It: Undercover Police
Participation in Crime, 62 STAN. L. REV. 155, 168 (2008).





n93  See Mary Jo White, Keynote Address: 41st Annual Securities Regulation
Institute, S.E.C., http://www.sec.gov/News/Speech/Detail/Speech/1370540677500
[http://perma.cc/NK4H-N7TL] (describing operation of NEAT: National Exam
Analytics Tool).





n94  See, e.g., Tom Hays, NYPD Is Watching Facebook to Fight Gang Bloodshed,
YAHOO! FINANCE (Oct. 2, 2012),
http://finance.yahoo.com/news/nypd-watching-facebook-fight-gang-bloodshed-202724
034.html [http://perma.cc/SC4A-RMXF] (describing "having officers adopt Internet
aliases, create phony profiles and seek to 'friend' suspects to gain access to
nonpublic information").





n95  See Terry v. Ohio, 392 U.S. 1, 21 (1968).





n96  Bambauer, supra note 12 (manuscript at 36).





n97  See, e.g., Whren v. United States, 517 U.S. 806 (1996).





n98  Joseph Goldstein, Police Discretion Not to Invoke the Criminal Process:
Low-Visibility Decisions in the Administration of Justice, 69 YALE L. J. 549
(1960).





n99  See, e.g., Jerome Skolnick, Corruption and the Blue Code of Silence, 3
POLICE PRAC. & RES.: AN INT'L J. 7 (2002).





n100  See, e.g., Joh, supra note 4, at 58; Jennifer Bachner, Predictive Policing
: Preventing Crime with Data and Analytics, IBM CENTER FOR THE BUSINESS OF
GOVERNMENT 21 (2013),
http://www.businessofgovernment.org/sites/default/files/Predictive%20Policing.pd
f [http://perma.cc/KTV6-5VRW].





n101  Predictive Policing: Don't Even Think About It, ECONOMIST (July 20, 2013),
http://www.economist.com/news/briefing/21582042-it-getting-easier-foresee-wrongd
oing-and-spotlikely-wrongdoers-dont-even-think-about-it
[http://perma.cc/FN8B-CU2T]





n102  Sociologist Sarah Brayne describes this hidden police discretion vividly
in her field work with the LAPD and its use of new data-driven surveillance.
Sarah Brayne, Stratified Surveillance: Policing in the Age of Big Data ch. 4
(2015) (unpublished dissertation) (on file with author).





n103  See id.





n104  BRAZIL (20th Century Fox 1985).





n105  Jean-Paul Brodeur & Benoit Dupont, Knowledge Workers or "Knowledge"
Workers?, 16 POLICING & SOC'Y 7, 17 (2006).





n106  However, they can be non-trivial. While consumers have access to their own
credit scores (and are thus provided with an opportunity for corrections), those
afflicted with faulty predictions about whether they are likely to pay a debt or
whether they would take their medications have no means of correcting or
disputing them. E. Scott Reckard, Data Compilers' Secret Scores Have Consumers
Pegged--Fairly or Not, L.A. TIMES (Apr. 8, 2014),
www.latimes.com/business/la-fi-secret-consumer-scores-20140409,0,6240971.story,
[http://perma.cc/VAW5-BYN8]; see also Bambauer, supra note 12 (manuscript at 14)
(noting that "if law enforcement data collection is a problem, it is because law
enforcement is special").





n107  Greene v. San Francisco, 751 F.3d 1039, 1042-43 (9th Cir. 2014).





n108  Id.





n109  Id.





n110  Id.





n111  Cf. STAFF OF S. COMM. ON THE JUDICIARY, 98TH CONG., REP. ON FBI UNDERCOVER
OPERATIONS (Comm. Print 1984).





n112  See, e.g., Gorner, supra note 74, at 2 (" All the attention made him
nervous because his neighbors noticed, leading them, he feared, to wonder if he
was a police snitch.").





n113  See Jane Bambauer, Hassle, 11 MICH. L. REV. 461, 464 (2015).





n114  See Bambauer, supra note 12, at 17.





n115  See, e.g., United States v. Wallace, 811 F. Supp. 2d 1265, 1272 (S.D. W.
Va. 2011) ("There is no constitutional prohibition against law enforcement
watching, or following, particular individuals in high-crime areas.").





n116  See, e.g., State v. Talley, 307 S.W.3d 723, 730 (Tenn. 2010) (noting that
"an investigation by governmental authorities which is not a search as defined
by the Supreme Court may be conducted without probable cause, reasonable
suspicion or a search warrant") (quoting State v. Bell, 832 S.W.2d 583, 589-90
(Tenn. Crim. App. 1991)); cf. United States v. Steinhorn, 739 F. Supp. 268,
271-72 (D. Md. 1990) ("It is readily accepted that law enforcement officials may
conceal their investigatory activities when collecting evidence against
potential defendants without compromising any principles of fairness or
propriety.").





n117  See, e.g., United States v. Taylor, 90 F.3d 903, 908 (4th Cir. 1996) ("[A]
law enforcement 'officer's observations from a public vantage point where he has
a right to be' and from which the activities or objects he observes are 'clearly
visible' do not constitute a search within the meaning of the Fourth Amendment."
(quoting California v. Ciraolo, 476 U.S. 207, 213 (1986))).





n118  Katz v. United States, 389 U.S. 347, 360 (1967).





n119  See, e.g., Illinois v. Lidster, 540 U.S. 419, 425 (2004) (noting "the law
ordinarily permits police to seek the voluntary cooperation of members of the
public in the investigation of a crime").





n120  Smith v. Maryland, 442 U.S. 735, 744 (1979).





n121  Katz, 389 U.S. at 365.





n122  See Terry v. Ohio, 392 U.S. 1, 10 (1968).





n123  See, e.g., Safford Unified Sch. Dist. No. 1 v. Redding, 557 U.S. 364, 370
(2009) (noting the Fourth Amendment "generally requires a law enforcement
officer to have probable cause for conducting a search"); Terry, 392 U.S. at 20
(noting that "police must, whenever practicable, obtain advance judicial
approval of searches and seizures through the warrant procedure").





n124  United States v. Steinhorn, 739 F. Supp. 268, 272 (D. Md. 1990).





n125  See, e.g., Rehberg v. Paulk, 611 F.3d 828, 850 n.24 (11th Cir. 2010) ("The
Constitution does not require evidence of wrongdoing or reasonable suspicion of
wrongdoing by a suspect before the government can begin investigating that
suspect." (citing United States v. Aibejeris, 28 F.3d 97, 99 (11th Cir. 1994)));
Metoyer v. State, 860 S.W.2d 673, 678 (Tex. App. 1993) (stating "neither
probable cause nor reasonable suspicion are necessary to authorize a [police]
surveillance" (citing Hamilton v. State, 590 S.W.2d 503 (Tex. Crim. App.
1979))).





n126  Sckorhod v. Stafford, 550 S.W.2d 799, 803 (Mo. Ct. App. 1977).





n127  Flowers v. Minneapolis, 558 F.3d 794, 798 (8th Cir. 2009) (quoting Wayte
v. United States, 470 U.S. 598, 607 (1985)); see also Sckorhod, 550 S.W.2d at
798 ("Law enforcement's decision about whom to investigate and how, like a
prosecutor's decision whether to prosecute, is ill-suited to judicial review.").





n128  See, e.g., United States v. Trayer, 898 F.2d 805, 808 (D.C. Cir. 1990);
accord Rehberg, 611 F.3d at 850 ("The initiation of a criminal investigation in
and of itself does not implicate a federal constitutional right."); United
States v. Crump, 934 F.2d 947, 957 (8th Cir. 1991); Sloan v. Dep't of Hous. &
Urban Dev., 231 F.3d 10, 18 (D.C. Cir. 2000); Freedman v. Am. Online, Inc., 412
F. Supp. 2d 174, 186 (D. Conn. 2005); cf. Aponte v. Calderon, 284 F.3d 184, 193
(1st Cir. 2002) (noting "it is clear that investigations conducted by
administrative agencies, even when they may lead to criminal prosecutions, do
not trigger due process rights").





n129  Cole v. Fed. Bureau of Investigations, 719 F. Supp. 2d 1229, 1248 (D.
Mont. 2010).





n130  See, e.g., United States v. Allibhai, 939 F.2d 244, 249 (5th Cir. 1991).
In Allibhai, the Fifth Circuit joined those "circuits that have . . . uniformly
dismissed the notion that the government must have a pre-existing basis for
suspecting criminal activity before targeting an individual in an
investigation." The Allibhai court noted that "these decisions are premised upon
the realization that '[a defendant] has no constitutional right to be free of
investigation.'" Id. (quoting United States v. Jacobson, 916 F.2d 467, 469 (8th
Cir. 1990)).





n131  See OFF. OF INSPECTOR GEN., THE FEDERAL BUREAU OF INVESTIGATION'S
COMPLIANCE WITH THE ATTORNEY GENERAL'S INVESTIGATIVE GUIDELINES 41-42 (2005).





n132  See id. at 44.





n133  Bootz v. Childs, 627 F. Supp. 94, 103 (N.D. Ill. 1985) (citing Laird v.
Tatum, 408 U.S. 1, 3 (1972)).





n134  See Hassan v. City of New York, No. 14-1688, 2015 WL 5933354, at *24 (3d
Cir. Oct. 13, 2015); Benjamin Weiser, Lawsuit Over New York Police Surveillance
of Muslims Is Revived, N.Y. TIMES (Oct. 13, 2015),
http://www.nytimes.com/2015/10/14/nyregion/appeals-court-reinstates-lawsuit-over
-police-surveillance-of-muslims.html [http://perma.cc/8CEE-998D].





n135  Laird, 408 U.S. at 3.





n136  Id. at 2.





n137  Id. at 10, 13-14.





n138  See, e.g., Gordon v. Warren Consol. Bd. of Educ., 706 F.2d 778, 780 (6th
Cir. 1983) ("The mere existence of a military data-gathering system does not
constitute a justiciable controversy."); United States v. Jones, 132 S. Ct. 945,
956 (2012) (Sotomayor, J., concurring) ("Awareness that the Government may be
watching chills associational and expressive freedoms."). But see White v.
Davis, 13 Cal. 3d 757, 764-65 (1975) (permitting lawsuit against Los Angeles
Police Department surveillance on state grounds and distinguishing Laird).





n139  Flowers v. City of Minneapolis, 558 F.3d 794, 798 (8th Cir. 2009) ("The
State, of course, retains broad discretion to decide whom to prosecute for
violating the criminal laws, and the State's discretion as to whom to
investigate is similarly broad." (citing Wayte v. United States, 470 U.S. 598,
607 (1985))).





n140  4 LAFAVE, ISRAEL, KING & KERR, CRIMINAL PROCEDURE § 13.4(a) (3d ed. 2014)
(stating elements as "(1) that other violators similarly situated are generally
not prosecuted; (2) that the selection of the claimant was 'intentional or
purposeful'; and (3) that the selection was pursuant to an 'arbitrary
classification.'").





n141  517 U.S. 806, 819 (1996).





n142  532 U.S. 318, 318 (2001).





n143  Pretextual policing refers to those enforcement actions justified by the
police for one reason when they are actually motivated by another. Traffic law
enforcement used to look for evidence of illegal drugs is one example. See, e.g.
, Whren v. United States, 517 U.S. 806, 810-13 (1996).





n144  See United States v. Jones, 132 S. Ct. 945, 963 (2012) (Alito, J.,
concurring) ("In the pre-computer age, the greatest protections of privacy were
neither constitutional nor statutory, but practical. Traditional surveillance
for any extended period of time was difficult and costly and therefore rarely
undertaken.").





n145  See United States v. Allibhai, 939 F.2d 244, 249 (5th Cir. 1991).





n146  See, e.g., Jones, 132 S. Ct. at 956 (Sotomayor, J., concurring) (noting
"ordinary checks that constrain abusive law enforcement practices: 'limited
police resources and community hostility.'" (quoting Illinois v. Lidster, 540
U.S. 419, 426 (2004))).





n147  See Editorial, The Walter Scott Murder, N.Y. TIMES (Apr. 8, 2015),
http://www.nytimes.com/2015/04/09/opinion/the-walter-scott-murder.html
[http://perma.cc/5BSE-HUBN] (noting fatal shooting of fleeing unarmed black man
"would have passed into the annals of history unremarked upon had a bystander
not used a cellphone to document what happened"); J. David Goodman, Man Who
Filmed Fatal Police Chokehold Is Arrested on Weapons Charges, N.Y. TIMES (Aug.
3, 2014),
http://www.nytimes.com/2014/08/04/nyregion/after-recording-eric-garner-chokehold
-ramsey-orta-gets-charged-with-gun-possession.html [http://perma.cc/4LFN-4M8A]
(describing "visceral cellphone images" that "helped galvanize protests and set
off a citywide debate over police practices").





n148  Justice Sotomayor's concurring opinion in Jones illustrates the problem:
"Disclosed in [GPS] data . . . will be trips the indisputably private nature of
which takes little imagination to conjure: trips to the psychiatrist, the
plastic surgeon, the abortion clinic, the AIDS treatment center, the strip club,
the criminal defense attorney, the by-the-hour motel, the union meeting, the
mosque, synagogue or church, the gay bar and on and on." Jones, 132 S. Ct. at
955 (Sotomayor, J., concurring) (quoting People v. Weaver, 909 N.E.2d 1195, 1199
(N.Y. 2009)).





n149  The theory first arose in the case of United States v. Maynard, 615 F.3d
544 (D.C. Cir. 2010), which the Supreme Court later reviewed as Jones, 132 S.
Ct. at 955. For a skeptical view of the mosaic theory, see Orin S. Kerr, The
Mosaic Theory of the Fourth Amendment, 111 MICH. L. REV. 311 (2012).






n150  See, e.g., Rich, supra note 7 (manuscript at 7) (arguing that "[Automated
Suspicion Algorithm] accuracy cannot be regulated through the courts alone").





n151  See BIG DATA AND PRIVACY, supra note 30, at xiii ("To avoid falling behind
the technology, it is essential that policy concerning privacy protection should
address the purpose (the 'what') rather than prescribing the mechanism (the
'how').").





n152  As of April 2015, the American Civil Liberties Union has identified
several federal agencies and fifty-seven agencies in twenty-two states and the
District of Columbia that own or use stingrays. See ACLU, STINGRAY TRACKING
DEVICES: WHO'S GOT THEM?,
https://www.aclu.org/map/stingray-tracking-devices-whos-got-them
[http://perma.cc/5ZT9-WNDP].





n153  See Matt Richtel, A Police Gadget Tracks Phones? Shhh! It's Secret, N.Y.
TIMES (Mar. 15, 2015),
http://www.nytimes.com/2015/03/16/business/a-police-gadget-tracks-phones-shhhits
-secret.html [http://perma.cc/7Y86-6N5C].





n154  The New York Civil Liberties Union in April 2015 published a nondisclosure
agreement the FBI imposed upon the Erie County, New York, Sheriff's Office. The
agreement includes a directive that the Sheriff's Office will "not distribute,
disseminate, or otherwise disclose any information [regarding the stingray] to
the public, including to any non-law enforcement individuals or agencies."
Letter from Christopher M. Piehota, Special Agent in Charge, Buffalo Division,
Fed. Bureau of Investigation, to Scott R. Patronik, Chief, Erie Cty. Sheriff's
Office (June 29, 2012),
http://www.nyclu.org/files/20120629-renondisclsure-obligations(Harris-ECSO).pdf
[http://perma.cc/248A-2N88].





n155  See Kim Zetter, Police Contract With Spy Tool Maker Prohibits Talking
About Device's Use, WIRED (Mar. 4, 2014),
http://www.wired.com/2014/03/harris-stingray-nda/ [http://perma.cc/6MSX-7ACW];
Adam Lynn, Defendant Challenges Use of Secret "Stingray" Cell Device, NEWS
TRIBUNE (Apr. 26, 2015),
http://www.thenewstribune.com/news/local/crime/article26283343.html
[http://perma.cc/7DEM-5V36] (reporting that Tacoma police "have refused to
discuss publicly details of the Stingray, citing a nondisclosure agreement with
the federal authorities who provided them with the tool").





n156  See Cyrus Farivar, Prosecutors Drop Key Evidence at Trial to Avoid
Explaining "Stingray" Use, ARS TECHNICA (Nov. 18, 2014),
http://arstechnica.com/tech-policy/2014/11/prosecutors-drop-key-evidence-at-tria
l-to-avoid-explaining-stingray-use/ [http://perma.cc/5B4EAU9U] (reporting
criminal case in Baltimore in which prosecutors withdrew evidence rather than
provide information about suspected use of stingray surveillance); Robert
Patrick, St. Charles Woman Withdraws Guilty Plea in Case Linked to Secret FBI
Cellphone Tracker, ST. LOUIS POST-DISPATCH (Apr. 25, 2015),
http://www.stltoday.com/news/local/crime-and-courts/st-charles-woman-withdraws-g
uilty-plea-in-case-linked-to/article_70d5ae28-e819-59d8-a391-78fdd4602d9f.html
[http://perma.cc/9ADQ-CPCG] ("In some cities around the country, prosecutors
have dropped cases rather than allow discussion of StingRay use.").





n157  Devlin Barrett, Justice Department Changes Policy on Cellphone
Surveillance, WALL ST. J. (Sept. 3, 2015),
http://www.wsj.com/articles/justice-department-changes-policy-on-cellphone-surve
illance-1441314839 [http://perma.cc/94FF-PY72] (noting however that the rules do
not apply to state or local police use of stingrays).





n158  Cyrus Farivar, NYPD to Conduct "Virtual Stakeouts," Get Alerts on Wanted
Cars Nationwide, ARS TECHNICA (Mar. 2, 2015),
http://arstechnica.com/tech-policy/2015/03/nypd-to-conduct-virtual-stakeouts-get
-alerts-on-wanted-cars-nationwide/ [http://perma.cc/Q2ZLKPNL].





n159  The California Supreme Court in July 2015 granted review of a lawsuit
filed by the Electronic Frontier Foundation (EFF) and the ACLU of Southern
California in which they were denied public records requests for license plate
reader data from the Los Angeles Police and Sheriff's Departments. See Jennifer
Lynch, EFF and ACLU Win Review of Automated License Plate Reader, ELEC. FRONTIER
FOUND. (July 29, 2015),
https://www.eff.org/deeplinks/2015/07/eff-and-aclu-win-review-automated-license-
plate-reader-case [http://perma.cc/4K5RE8XF].





n160  Steve Lohr, If Algorithms Know All, How Much Should Humans Help?, N.Y.
TIMES (Apr. 6, 2015),
http://www.nytimes.com/2015/04/07/upshot/if-algorithms-know-all-how-much-should-
humans-help.html [http://perma.cc/2JT5-BRJD].





n161  Cyrus Farivar, New California Bill Would Require Local Approval for
Stingray Use, ARS TECHNICA (Apr. 16, 2015),
http://arstechnica.com/tech-policy/2015/04/new-california-bill-would-require-loc
al-approval-for-stingray-use/ [http://perma.cc/D6BF-TR8P].





n162  SEATTLE, WASH., ORDINANCE 124142 (Mar. 27, 2013),
http://clerk.seattle.gov/ archives/Ordinances/Ord_124142.pdf
[http://perma.cc/9WPL-MV98].





n163  Id.





n164  An ordinance passed in 2013 by the Spokane, Washington, City Council makes
such explicit reference to third party relationships. See SPOKANE, WASH.,
ORDINANCE No. C-35018 (Aug. 28, 2013); Jamela Debelak, Surveillance: Spokane
Acts to Protect Privacy and Provide Transparency, ACLU OF WASH. ST. (Aug. 21,
2013),
https://aclu-wa.org/blog/surveillance-spokane-acts-protect-privacy-and-provide-t
ransparency [http://perma.cc/UB2F-7LLU].





n165  Tim Johnson, Intrado Intrusion: City Council Backs Away from Social
Spyware, CASCADIA WKLY. (July 9, 2014),
http://www.cascadiaweekly.com/currents/intrado_intrusion[http://perma.cc/692V-EL
RY].





n166  See id. Notably, however, the Council lacked the authority to block the
grant or to direct its expenditure toward a different use.





n167  Dick Conoboy, Intrado Not to Intrude in Bellingham, NORTHWEST CITIZEN
(July 8, 2014),
http://www.nwcitizen.com/entry/intrado-not-to-intrude-in-bellingham
[http://perma.cc/KEG9-PMCG].





n168  ACLU OF CALIFORNIA, MAKING SMART DECISIONS ABOUT SURVEILLANCE 15 (Nov.
2014),
https://www.aclunc.org/sites/default/files/Smart%20About%20Surveillance.pdf
[http://perma.cc/N2GN-VT44]. The guide provides a model local ordinance as well.
See id. at 22-24.





n169  See id. at 19; Bambauer, supra note 12 (manuscript at 43) ("All uses of
pattern-driven algorithms should be subjected to logging so that auditors and
criminal defendants can review how the government has used its data mining
programs.").





n170  ACLU, supra note 168 at 20.





n171  Cyrus Farivar (@cfarivar), TWITTER (Mar. 24, 2014),
https://twitter.com/cfarivar/status/580404313958301696
[https://perma.cc/69YP-7HTL].


                               8 of 41 DOCUMENTS

          Copyright (c) 2016 California Law Review, Inc., a California
                             Nonprofit Corporation
                             California Law Review

                                   June, 2016

                             California Law Review

                             104 Calif. L. Rev. 671

LENGTH: 10546 words

ARTICLE: Big Data's Disparate Impact

NAME: Solon Barocas * & Andrew D. Selbst **

BIO: DOI: http://dx.doi.org/10.15779/Z38BG31

   California Law Review, Inc. (CLR) is a California nonprofit corporation. CLR
and the authors are solely responsible for the content of their publications.



   * Postdoctoral Research Associate, Center for Information Technology Policy,
Princeton University; Ph.D. 2014, New York University, Department of Media,
Culture, and Communication. This research was supported in part by the Center
for Information Technology Policy at Princeton University.


   ** Scholar in Residence, Electronic Privacy Information Center; Visiting
Researcher, Georgetown University Law Center; Visiting Fellow, Yale Information
Society Project; J.D. 2011, University of Michigan Law School. The authors would
like to thank Jane Bambauer, Alvaro Bedoya, Marjory Blumenthal, Danielle Citron,
James Grimmelmann, Moritz Hardt, Don Herzog, Janine Hiller, Chris Hoofnagle,
Joanna Huey, Patrick Ishizuka, Michael Kirkpatrick, Aaron Konopasky, Joshua
Kroll, Mark MacCarthy, Arvind Narayanan, Helen Norton, Paul Ohm, Scott Peppet,
Joel Reidenberg, David Robinson, Kathy Strandburg, David Vladeck, members of the
Privacy Research Group at New York University, and the participants of the 2014
Privacy Law Scholars Conference for their helpful comments. Special thanks also
to Helen Nissenbaum and the Information Law Institute at New York University for
giving us an interdisciplinary space to share ideas, allowing this paper to come
about. Copyright (C) 2016 by Solon Barocas and Andrew Selbst. This Essay is
available for reuse under the Creative Commons Attribution-ShareAlike 4.0
International License, http://creativecommons.org/licenses/by-sa/4.0/. The
required attribution notice under the license must include the article's full
citation information, e.g., "Solon Barocas & Andrew D. Selbst, Big Data's
Disparate Impact, 104 CALIF. L. REV. 671 (2016)."

HIGHLIGHT:

        Advocates of algorithmic techniques like data mining argue that
     these techniques eliminate human biases from the decision-making
     process. But an algorithm is only as good as the data it works with.
     Data is frequently imperfect in ways that allow these algorithms to
     inherit the prejudices of prior decision makers. In other cases, data
     may simply reflect the widespread biases that persist in society at
     large. In still others, data mining can discover surprisingly useful
     regularities that are really just preexisting patterns of exclusion
     and inequality. Unthinking reliance on data mining can deny
     historically disadvantaged and vulnerable groups full participation in
     society. Worse still, because the resulting discrimination is almost
     always an unintentional emergent property of the algorithm's use
     rather than a conscious choice by its programmers, it can be unusually
     hard to identify the source of the problem or to explain it to a court
     .

        This Essay examines these concerns through the lens of American
     antidiscrimination law--more particularly, through VII's prohibition
     of discrimination in employment. In the absence of a demonstrable
     intent to discriminate, the best doctrinal hope for data mining's
     victims would seem to lie in disparate impact doctrine. Case law and
     the Equal Employment Opportunity Commission's Uniform Guidelines,
     though, hold that a practice can be justified as a business necessity
     when its outcomes are predictive of future employment outcomes, and
     data mining is specifically designed to find such statistical
     correlations. Unless there is a reasonably practical way to
     demonstrate that these discoveries are spurious, Title VII would
     appear to bless its use, even though the correlations it discovers
     will often reflect historic patterns of prejudice, others'
     discrimination against members of protected groups, or flaws in the
     underlying data.

     Addressing the sources of this unintentional discrimination and
     remedying the corresponding deficiencies in the law will be difficult
     technically, difficult legally, and difficult politically. There are a
     number of practical limits to what can be accomplished
     computationally. For example, when discrimination occurs because the
     data being mined is itself a result of past intentional
     discrimination, there is frequently no obvious method to adjust
     historical data to rid it of this taint. Corrective measures that
     alter the results of the data mining after it is complete would tread
     on legally and politically disputed terrain. These challenges for
     reform throw into stark relief the tension between the two major
     theories underlying antidiscrimination law: anticlassification and
     antisubordination. Finding a solution to big data's disparate impact
     will require more than best efforts to stamp out prejudice and bias;
     it will require a wholesale reexamination of the meanings of
     "discrimination" and "fairness."


 TEXT:
 [*673]  INTRODUCTION

   "Big Data" is the buzzword of the decade.  n1 Advertisers want data to reach
profitable consumers,  n2 medical professionals to find side effects of
prescription drugs,  n3 supply-chain operators to optimize their delivery
routes,  n4 police to determine where to focus resources,  n5 and social
scientists to study human interactions.  n6 Though useful, however, data is not
a panacea. Where data is used predictively to assist decision making, it can
affect the fortunes of whole classes of people in consistently unfavorable ways.
Sorting and selecting for the best or most profitable candidates means
generating a model with winners and losers. If data miners are not careful, the
process can result in disproportionately adverse outcomes concentrated within
historically disadvantaged groups in ways that look a lot like discrimination.

   Although we live in the post--civil rights era, discrimination persists in
American society and is stubbornly pervasive in employment, housing, credit, and
consumer markets.  n7 While discrimination certainly endures in part due to
decision makers' prejudices, a great deal of modern-day inequality can be
attributed to what sociologists call "institutional" discrimination.  n8
Unconscious, implicit biases and inertia within society's institutions, rather
than intentional  [*674]  choices, account for a large part of the disparate
effects observed.  n9 Approached without care, data mining can reproduce
existing patterns of discrimination, inherit the prejudice of prior decision
makers, or simply reflect the widespread biases that persist in society. It can
even have the perverse result of exacerbating existing inequalities by
suggesting that historically disadvantaged groups actually deserve less
favorable treatment.

   Algorithms  n10 could exhibit these tendencies even if they have not been
manually programmed to do so, whether on purpose or by accident. Discrimination
may be an artifact of the data mining process itself, rather than a result of
programmers assigning certain factors inappropriate weight. Such a possibility
has gone unrecognized by most scholars and policy makers, who tend to fear
concealed, nefarious intentions or the overlooked effects of human bias or error
in hand coding algorithms.  n11 Because the discrimination at issue is
unintentional, even honest attempts to certify the absence of prejudice on the
part of those involved in the data mining process may wrongly confer the
imprimatur of impartiality on the resulting decisions. Furthermore, because the
mechanism through which data mining may disadvantage protected classes is less
obvious in cases of unintentional discrimination, the injustice may be harder to
identify and address.

   In May 2014, the White House released a report titled Big Data: Seizing
Opportunities, Preserving Values (Podesta Report), which hinted at the
discriminatory potential of big data.  n12 The report finds "that big data
analytics have the potential to eclipse longstanding civil rights protections in
how personal information is used in housing, credit, employment, health,
education, and the marketplace."  n13 It suggests that there may be unintended
discriminatory  [*675]  effects from data mining but does not detail how they
might come about.  n14 Because the origin of the discriminatory effects remains
unexplored, the report's approach does not address the full scope of the
problem.

   The Podesta Report, as one might expect from the executive branch, seeks to
address these effects primarily by finding new ways to enforce existing law.
Regarding discrimination, the report primarily recommends that enforcement
agencies, such as the Department of Justice, Federal Trade Commission, Consumer
Financial Protection Bureau, and Equal Employment Opportunity Commission (EEOC),
increase their technical expertise and "develop a plan for investigating and
resolving violations of law in such cases."  n15

   As this Essay demonstrates, however, existing law largely fails to address
the discrimination that can result from data mining. The argument is grounded in
Title VII because, of all American antidiscrimination jurisprudence, Title VII
has a particularly well-developed set of case law and scholarship. Further,
there exists a rapidly emerging field of "work-force science,"  n16 for which
Title VII will be the primary vehicle for regulation. Under Title VII, it turns
out that some, if not most, instances of discriminatory data mining will not
generate liability. While the Essay does not show this to be true outside of
Title VII itself, the problem is likely not particular to Title VII. Rather, it
is a feature of our current approach to antidiscrimination jurisprudence, with
its focus on procedural fairness. The analysis will likely apply to other
traditional areas of discrimination, such as housing or disability
discrimination. Similar tendencies to disadvantage the disadvantaged will likely
arise in areas that regulate legitimate economic discrimination, such as credit
and insurance.

   This Essay proceeds in three Parts. Part I introduces the computer science
literature and proceeds through the various steps of solving a problem with data
mining: defining the target variable, labeling and collecting the training data,
using feature selection, and making decisions on the basis of the resulting
model. Each of these steps creates possibilities for a final result that has a
disproportionately adverse impact on protected classes, whether by specifying
the problem to be solved in ways that affect classes differently, failing to
recognize or address statistical biases, reproducing past prejudice, or
considering an insufficiently rich set of factors. Even in situations where data
miners are extremely careful, they can still effect discriminatory results with
models that, quite unintentionally, pick out proxy variables for protected
classes. Finally, Part I notes that data mining poses the additional problem of
[*676]  giving data miners the ability to disguise intentional discrimination as
accidental.

   In Part II, the Essay reviews Title VII jurisprudence as it applies to data
mining. Part II discusses both disparate treatment and disparate impact,
examining which of the various data mining mechanisms identified in Part I will
trigger liability under either Title VII theory. At first blush, either theory
is viable. Disparate treatment is viable because data mining systems treat
everyone differently; that is their purpose. Disparate impact is also viable
because data mining can have various discriminatory effects, even without
intent. But as Part II demonstrates, data mining combines some well-known
problems in discrimination doctrines with new challenges particular to data
mining systems, such that liability for discriminatory data mining will be hard
to find. Part II concludes with a discussion of the new problems of proof that
arise for intentional discrimination in this context.

   Finally, Part III addresses the difficulties reformers would face in
addressing the deficiencies found in Part II. These difficulties take two forms:
complications internal to the logic of data mining and political and
constitutional difficulties external to the problem. Internally, the different
steps in a data mining problem require constant subjective and fact-bound
judgments, which do not lend themselves to general legislative resolution.
Worse, many of these are normative judgments in disguise, about which there is
not likely to be consensus. Externally, data mining will force society to
explicitly rebalance the two justifications for antidiscrimination law--rooting
out intentional discrimination and equalizing the status of historically
disadvantaged communities. This is because methods of proof and corrective
measures will often require an explicit commitment to substantive remediation
rather than merely procedural remedies. In certain cases, data mining will make
it simply impossible to rectify discriminatory results without engaging with the
question of what level of substantive inequality is proper or acceptable in a
given context. Given current political realities and trends in constitutional
doctrines, legislation enacting a remedy that results from these discussions
faces an uphill battle. To be sure, data mining also has the potential to help
reduce discrimination by forcing decisions onto a more reliable empirical
foundation and by formalizing decision-making processes, thus limiting the
opportunity for individual bias to affect important assessments.  n17 In many
situations, the introduction of data mining will be a boon to civil rights, even
where it fails to root out discrimination altogether, and such efforts should be
encouraged. Yet, understanding when and why discrimination persists in cases of
data-driven decision making reveals important and sometimes troubling limits to
the promise of big data, for which there are no ready solutions.

    [*677]  I. HOW DATA MINING DISCRIMINATES

   Although commentators have ascribed myriad forms of discrimination to data
mining,  n18 there remains significant confusion over the precise mechanisms
that render data mining discriminatory. This Part develops a taxonomy that
isolates and explicates the specific technical issues that can give rise to
models whose use in decision making may have a disproportionately adverse impact
on protected classes. By definition, data mining is always a form of statistical
(and therefore seemingly rational) discrimination. Indeed, the very point of
data mining is to provide a rational basis upon which to distinguish between
individuals and to reliably confer to the individual the qualities possessed by
those who seem statistically similar. Nevertheless, data mining holds the
potential to unduly discount members of legally protected classes and to place
them at systematic relative disadvantage. Unlike more subjective forms of
decision making, data mining's ill effects are often not traceable to human
bias, conscious or unconscious. This Part describes five mechanisms by which
these disproportionately adverse outcomes might occur, walking through a
sequence of key steps in the overall data mining process.

A. Defining the "Target Variable" and "Class Labels"

   In contrast to those traditional forms of data analysis that simply return
records or summary statistics in response to a specific query, data mining
attempts to locate statistical relationships in a dataset.  n19 In particular,
it automates the process of discovering useful patterns, revealing regularities
upon which subsequent decision making can rely. The accumulated set of
discovered relationships is commonly called a "model," and these models can be
employed to automate the process of classifying entities or activities of
interest, estimating the value of unobserved variables, or predicting future
outcomes.  n20 Familiar examples of such applications include spam or fraud
detection, credit scoring, and insurance pricing. These examples all involve
attempts to determine the status or likely outcome of cases under consideration
based solely on access to correlated data.  n21 Data mining helps identify cases
of  [*678]  spam and fraud and anticipate default and poor health by treating
these states and outcomes as a function of some other set of observed
characteristics.  n22 In particular, by exposing so-called "machine learning"
algorithms to examples of the cases of interest (previously identified instances
of fraud, spam, default, and poor health), the algorithm "learns" which related
attributes or activities can serve as potential proxies for those qualities or
outcomes of interest.  n23

   Two concepts from the machine learning and data mining literature are
important here: "target variables" and "class labels." The outcomes of interest
discussed above are known as target variables.  n24 While the target variable
defines what data miners are looking for, "class labels" divide all possible
values of the target variable into mutually exclusive categories.

   The proper specification of the target variable is frequently not obvious,
and the data miner's task is to define it. To start, data miners must translate
some amorphous problem into a question that can be expressed in more formal
terms that computers can parse. In particular, data miners must determine how to
solve the problem at hand by translating it into a question about the value of
some target variable. The open-endedness that characterizes this part of the
process is often described as the "art" of data mining. This initial step
requires a data miner to "understand[] the project objectives and requirements
from a business perspective [and] then convert[] this knowledge into a data
mining problem definition."  n25 Through this necessarily subjective process of
translation, data miners may unintentionally parse the problem in such a way
that happens to systematically disadvantage protected classes.

   Problem specification is not a wholly arbitrary process, however. Data mining
can only address problems that lend themselves to formalization as questions
about the state or value of the target variable. Data mining works exceedingly
well for dealing with fraud and spam because these cases rely on extant, binary
categories. A given instance either is or is not fraud or spam, and the
definitions of fraud or spam are, for the most part, uncontroversial.  n26 A
computer can then flag or refuse transactions or redirect emails according to
[*679]  well-understood distinctions.  n27 In these cases, data miners can
simply rely on these simple, preexisting categories to define the class labels.

   Sometimes, though, defining the target variable involves the creation of new
classes. Consider credit scoring, for instance. Although now taken for granted,
the predicted likelihood of missing a certain number of loan repayments is not a
self-evident answer to the question of how to successfully extend credit to
consumers.  n28 Unlike fraud or spam, "creditworthiness" is an artifact of the
problem definition itself. There is no way to directly measure creditworthiness
because the very notion of creditworthiness is a function of the particular way
the credit industry has constructed the credit issuing and repayment system.
That is, an individual's ability to repay some minimum amount of an outstanding
debt on a monthly basis is taken to be a nonarbitrary standard by which to
determine in advance and all-at-once whether he is worthy of credit.  n29

   Data mining has many uses beyond spam detection, fraud detection, credit
scoring, and insurance pricing. As discussed in the introduction, this Essay
will focus on the use of data mining in employment decisions. Extending this
discussion to employment, then, where employers turn to data mining to develop
ways of improving and automating their search for good employees, they face a
number of crucial choices.

   Like creditworthiness, the definition of a good employee is not a given.
"Good" must be defined in ways that correspond to measurable outcomes:
relatively higher sales, shorter production time, or longer tenure, for example.
When employers mine data for good employees, they are, in fact, looking for
employees whose observable characteristics suggest that they would meet or
exceed some monthly sales threshold, perform some task in less than a certain
amount of time, or remain in their positions for more than a set number of weeks
or months. Rather than drawing categorical distinctions along these lines, data
mining could also estimate or predict the specific numerical value of sales,
production time, or tenure period, enabling employers to rank rather than simply
sort employees.

   These may seem like eminently reasonable things for employers to want to
predict, but they are, by necessity, only part of an array of possible
definitions of "good." An employer may instead attempt to define the target
variable in a more holistic way--by, for example, relying on the grades that
prior employees have received in annual reviews, which are supposed to reflect
[*680]  an overall assessment of performance. These target variable definitions
simply inherit the formalizations involved in preexisting assessment mechanisms,
which in the case of human-graded performance reviews, may be far less
consistent.  n30

   Thus, the definition of the target variable and its associated class labels
will determine what data mining happens to find. While critics of data mining
have tended to focus on inaccurate classifications (false positives and false
negatives),  n31 as much--if not more--danger resides in the definition of the
class label itself and the subsequent labeling of examples from which rules are
inferred.  n32 While different choices for the target variable and class labels
can seem more or less reasonable, valid concerns with discrimination enter at
this stage because the different choices may have a greater or lesser adverse
impact on protected classes. For example, as later Parts will explain in detail,
hiring decisions made on the basis of predicted tenure are much more likely to
have a disparate impact on certain protected classes than hiring decisions that
turn on some estimate of worker productivity. If the turnover rate happens to be
systematically higher among members of certain protected classes, hiring
decisions based on predicted length of employment will result in fewer job
opportunities for members of these groups, even if they would have performed as
well as or better than the other applicants the company chooses to hire.

B. Training Data

   As described above, data mining learns by example. Accordingly, what a model
learns depends on the examples to which it has been exposed. The data that
function as examples are known as "training data"--quite literally, the data
that train the model to behave in a certain way. The character of the training
data can have meaningful consequences for the lessons that data mining happens
to learn. As computer science scholars explain, biased training data leads to
discriminatory models.  n33 This can mean two rather different things,  [*681]
though: (1) if data mining treats cases in which prejudice has played some role
as valid examples to learn from, that rule may simply reproduce the prejudice
involved in these earlier cases; or (2) if data mining draws inferences from a
biased sample of the population, any decision that rests on these inferences may
systematically disadvantage those who are under- or overrepresented in the
dataset. Both can affect the training data in ways that lead to discrimination,
but the mechanisms--improper labeling of examples and biased data
collections--are sufficiently distinct that they warrant separate treatment.

1. Labeling Examples

   Labeling examples is the process by which the training data is manually
assigned class labels. In cases of fraud or spam, the data miners draw from
examples that come prelabeled: when individual customers report fraudulent
charges or mark a message as spam, they are actually labeling transactions and
email for the providers of credit and webmail. Likewise, an employer using
grades previously given at performance reviews is also using prelabeled
examples.

   In certain cases, however, there may not be any labeled data and data miners
may have to figure out a way to label examples themselves. This can be a
laborious process, and it is frequently fraught with peril.  n34 Often the best
labels for different classifications will be open to debate. On which side of
the creditworthy line does someone who has missed four credit card payments
fall, for example?  n35 The answer is not obvious. Even where the class labels
are uncontested or uncontroversial, they may present a problem because analysts
will often face difficult choices in deciding which of the available labels best
applies to a particular example. Certain cases may present some, but not all,
criteria for inclusion in a particular class.  n36 The situation might also work
in reverse, where the class labels are insufficiently precise to capture
meaningful differences between cases. Such imperfect matches will demand that
data miners exercise judgment.

   The unavoidably subjective labeling of examples will skew the resulting
findings such that any decisions taken on the basis of those findings will
characterize all future cases along the same lines. This is true even if such
[*682]  characterizations would seem plainly erroneous to analysts who looked
more closely at the individual cases. For all their potential problems, though,
the labels applied to the training data must serve as ground truth.  n37 Thus,
decisions based on discoveries that rest on haphazardly labeled data or data
labeled in a systematically, though unintentionally, biased manner will seem
valid according to the customary validation methods employed by data miners. So
long as prior decisions affected by some form of prejudice serve as examples of
correctly rendered determinations, data mining will necessarily infer rules that
exhibit the same prejudice.

   Consider a real-world example from a different context as to how biased data
labeling can skew results. St. George's Hospital, in the United Kingdom,
developed a computer program to help sort medical school applicants based on its
previous admissions decisions.  n38 Those admissions decisions, it turns out,
had systematically disfavored racial minorities and women with credentials
otherwise equal to other applicants'.  n39 In drawing rules from biased prior
decisions, St. George's Hospital unknowingly devised an automated process that
possessed these very same prejudices. As editors at the British Medical Journal
noted at the time, "[T]he program was not introducing new bias but merely
reflecting that already in the system."  n40 Were an employer to undertake a
similar plan to automate its hiring decisions by inferring a rule from past
decisions swayed by prejudice, the employer would likewise arrive at a decision
procedure that simply reproduces the prejudice of prior decision makers. Indeed,
automating the process in this way would turn the conscious prejudice or
implicit bias of individuals involved in previous decision making into a
formalized rule that would systematically alter the prospects of all future
applicants. For example, the computer may learn to discriminate against certain
female or black applicants if trained on prior hiring decisions in which an
employer has consistently rejected jobseekers with degrees from women's or
historically black colleges.

   Not only can data mining inherit prior prejudice through the mislabeling of
examples, it can also reflect current prejudice through the ongoing behavior of
users taken as inputs to data mining. This is what Professor Latanya Sweeney
discovered in a study that found that Google queries for black-sounding names
were more likely to return contextual (i.e., key-word triggered)  [*683]
advertisements for arrest records than those for white-sounding names.  n41
Sweeney confirmed that the companies paying for these advertisements had not set
out to focus on black-sounding names; rather, the fact that black-sounding names
were more likely to trigger such advertisements seemed to be an artifact of the
algorithmic process that Google employs to determine which advertisements to
display alongside certain queries.  n42 Although it is not fully known how
Google computes the so-called "quality score" according to which it ranks
advertisers' bids, one important factor is the predicted likelihood, based on
historical trends, that users will click on an advertisement.  n43 As Sweeney
points out, the process "learns over time which [advertisement] text gets the
most clicks from viewers [of the advertisement]" and promotes that advertisement
in its rankings accordingly.  n44 Sweeney posits that this aspect of the process
could result in the differential delivery of advertisements that reflect the
kinds of prejudice held by those exposed to the advertisements.  n45 In
attempting to cater to users' preferences, Google will unintentionally reproduce
the existing prejudices that inform users' choices.

   A similar situation could conceivably arise on websites that recommend
potential employees to employers, as LinkedIn does through its Talent Match
feature.  n46 If LinkedIn determines which candidates to recommend based on the
demonstrated interest of employers in certain types of candidates, Talent Match
will offer recommendations that reflect whatever biases employers happen to
exhibit. In particular, if LinkedIn's algorithm observes that employers disfavor
certain candidates who are members of a protected class, Talent Match may
decrease the rate at which it recommends these candidates to employers. The
recommendation engine would learn to cater to the prejudicial preferences of
employers.

   There is an old adage in computer science: "garbage in, garbage out." Because
data mining relies on training data as ground truth, when those inputs  [*684]
are themselves skewed by bias or inattention, the resulting system will produce
results that are at best unreliable and at worst discriminatory.

2. Data Collection

   Decisions that depend on conclusions drawn from incorrect, partial, or
nonrepresentative data may discriminate against protected classes. The
individual records that a company maintains about a person might have serious
mistakes,  n47 the records of the entire protected class of which this person is
a member might also have similar mistakes at a higher rate than other groups,
and the entire set of records may fail to reflect members of protected classes
in accurate proportion to others.  n48 In other words, the quality and
representativeness of records might vary in ways that correlate with class
membership (e.g., institutions might maintain systematically less accurate,
precise, timely, and complete records for certain classes of people). Even a
dataset with individual records of consistently high quality can suffer from
statistical biases that fail to represent different groups in accurate
proportions. Much attention has focused on the harms that might befall
individuals whose records in various commercial databases are error ridden.  n49
Far less consideration, however, has been paid to the systematic disadvantage
that members of protected classes may suffer from being miscounted and, as a
result, misrepresented in the evidence base.

   Recent scholarship has begun to stress this point. Jonas Lerman, for example,
worries about "the nonrandom, systemic omission of people who live on big data's
margins, whether due to poverty, geography, or lifestyle, and whose lives are
less 'datafied' than the general population's."  n50 Professor Kate Crawford has
likewise warned that "[b]ecause not all data is created or even collected
equally, there are 'signal problems' in big-data sets--dark zones or shadows
where some citizens and communities are overlooked or  [*685]
underrepresented."  n51 Errors of this sort may befall historically
disadvantaged groups at higher rates because they are less involved in the
formal economy and its data-generating activities, have unequal access to and
relatively less fluency in the technology necessary to engage online, or are
less profitable customers or important constituents and therefore less
interesting as targets of observation.  n52 Not only will the quality of
individual records of members of these groups be poorer as a consequence, but
these groups as a whole will also be less well represented in datasets, skewing
conclusions that may be drawn from an analysis of the data.

   As an illustrative example, Crawford points to Street Bump, an application
for Boston residents that takes advantage of accelerometers built into smart
phones to detect when drivers ride over potholes.  n53 While Crawford praises
the cleverness and cost-effectiveness of this passive approach to reporting road
problems, she rightly warns that whatever information the city receives from
Street Bump will be biased by the uneven distribution of smartphones across
populations in different parts of the city.  n54 In particular, systematic
differences in smartphone ownership will very likely result in the
underreporting of road problems in the poorer communities where protected groups
disproportionately congregate.  n55 If the city were to rely on this data to
determine where it should direct its resources, it would only further underserve
these communities. Indeed, the city would discriminate against those who lack
the capability to report problems as effectively as wealthier residents with
smartphones.  n56

   A similar dynamic could easily apply in an employment context if members of
protected classes are unable to report their interest in and qualification for
jobs listed online as easily or effectively as others due to systematic
differences in Internet access. The EEOC has established a program called
"Eradicating Racism & Colorism from Employment" (E-RACE) that aims, at least in
part, to prevent this sort of discrimination from occurring due  [*686]  to an
employer's desire for high-tech hiring, such as video résumés.  n57 E-RACE not
only attempts to lower the barriers that would disproportionately burden
applicants who belong to a protected class, but also ensures that employers do
not develop an inaccurate impression of the incidence of qualified and
interested candidates from these communities. If employers were to rely on
tallies of high-tech candidates to direct their recruiting efforts, for example,
any count affected by a reporting bias could have adverse consequences for
specific populations systematically underrepresented in the dataset. Employers
would deny equal attention to those who reside in areas incorrectly pegged as
having a relatively lower concentration of qualified candidates.

   Additional and even more severe risks may reside in the systematic omission
of members of protected classes from such datasets. The Street Bump and Internet
job application examples only discuss decisions that depend on raw tallies,
rather than datasets from which decision makers want to draw generalizations and
generate predictions. But data mining is especially sensitive to statistical
bias because data mining helps to discover patterns that organizations tend to
treat as generalizable findings even though the analyzed data only includes a
partial sample from a circumscribed period. To ensure that data mining reveals
patterns that hold true for more than the particular sample under analysis, the
sample must be proportionally representative of the entire population, even
though the sample, by definition, does not include every case.  n58

   If a sample includes a disproportionate representation of a particular class
(more or less than its actual incidence in the overall population), the results
of an analysis of that sample may skew in favor of or against the over- or
underrepresented class. While the representativeness of the data is often simply
assumed, this assumption is rarely justified and is "perhaps more often
incorrect than correct."  n59 Data gathered for routine business purposes tend
to lack the rigor of social scientific data collection.  n60 As Lerman points
out, "Businesses may ignore or undervalue the preferences and behaviors of
[*687]  consumers who do not shop in ways that big data tools can easily
capture, aggregate, and analyze."  n61

   In the employment context, even where a company performs an analysis of the
data from its entire population of employees--avoiding the apparent problem of
even having to select a sample--the organization must assume that its future
applicant pool will have the same degree of variance as its current employee
base. An organization's tendency, however, to perform such analyses in order to
change the composition of their employee base should put the validity of this
assumption into immediate doubt. The potential effect of this assumption is the
future mistreatment of individuals predicted to behave in accordance with the
skewed findings derived from the biased sample. Worse, these results may lead to
decision procedures that limit the future contact an organization will have with
specific groups, skewing still further the sample upon which subsequent analyses
will be performed.  n62 Limiting contact with specific populations on the basis
of unsound generalizations may deny members of these populations the opportunity
to prove that they buck the apparent trend.

   Overrepresentation in a dataset can also lead to disproportionately high
adverse outcomes for members of protected classes. Consider an example from the
workplace: managers may devote disproportionate attention to monitoring the
activities of employees who belong to a protected class and consequently observe
mistakes and transgressions at systematically higher rates than others, in part
because these managers fail to subject others who behave similarly to the same
degree of scrutiny. Not only does this provide managers with justification for
their prejudicial suspicions, but it also generates evidence that overstates the
relative incidence of offenses by members of these groups. Where subsequent
managers who hold no such prejudicial suspicions cannot observe everyone
equally, they may rely on this evidence to make predictions about where to focus
their attention in the future and thus further increase the disproportionate
scrutiny that they place on protected classes.

   The efficacy of data mining is fundamentally dependent on the quality of the
data from which it attempts to draw useful lessons. If these data capture the
prejudicial or biased behavior of prior decision makers, data mining will learn
from the bad example that these decisions set. If the data fail to serve as a
good sample of a protected group, data mining will draw faulty lessons that
could serve as a discriminatory basis for future decision making.

    [*688]  C. Feature Selection

   Through a process called "feature selection," organizations--and the data
miners that work for them--make choices about what attributes they observe and
subsequently fold into their analyses.  n63 These decisions can also have
serious implications for the treatment of protected classes if those factors
that better account for pertinent statistical variation among members of a
protected class are not well represented in the set of selected features.  n64
Members of protected classes may find that they are subject to systematically
less accurate classifications or predictions because the details necessary to
achieve equally accurate determinations reside at a level of granularity and
coverage that the selected features fail to achieve.

   This problem arises because data are necessarily reductive representations of
an infinitely more specific real-world object or phenomenon.  n65 These
representations may fail to capture enough detail to allow for the discovery of
crucial points of contrast. Increasing the resolution and range of the analysis
may still fail to capture the mechanisms that account for different outcomes
because such mechanisms may not lend themselves to exhaustive or effective
representation in the data, if such representations even exist. As Professors
Toon Calders and Indr[#x117] [#x17D]liobait[#x117] explain, "[I]t is often
impossible to collect all the attributes of a subject or take all the
environmental factors into account with a model."  n66 While these limitations
lend credence to the argument that a dataset can never fully encompass the full
complexity of the individuals it seeks to represent, they do not reveal the
inherent inadequacy of representation as such.

   At issue, really, are the coarseness and comprehensiveness of the criteria
that permit statistical discrimination and the uneven rates at which different
groups happen to be subject to erroneous determinations. Crucially, these
erroneous and potentially adverse outcomes are artifacts of statistical
reasoning rather than prejudice on the part of decision makers or bias in the
composition of the dataset. As Professor Frederick Schauer explains, decision
makers that rely on statistically sound but nonuniversal generalizations "are
being simultaneously rational and unfair" because certain individuals are
"actuarially saddled" by statistically sound inferences that are nevertheless
inaccurate.  n67  [*689]  Obtaining information that is sufficiently rich to
permit precise distinctions can be expensive. Even marginal improvements in
accuracy may come at significant practical costs and may justify a less granular
and encompassing analysis.  n68

   To take an obvious example from the employment context, hiring decisions that
consider academic credentials tend to assign enormous weight to the reputation
of the college or university from which an applicant has graduated, even though
such reputations may communicate very little about the applicant's job-related
skills and competencies.  n69 If equally competent members of protected classes
happen to graduate from these colleges or universities at disproportionately low
rates, decisions that turn on the credentials conferred by these schools, rather
than some set of more specific qualities that more accurately sort individuals,
will incorrectly and systematically discount these individuals. Even if
employers have a rational incentive to look beyond credentials and focus on
criteria that allow for more precise and more accurate determinations, they may
continue to favor credentials because they communicate pertinent information at
no cost to the employer.  n70

   Similar dynamics seem to account for the practice known as "redlining,"  n71
in which financial institutions employ especially general criteria to draw
distinctions between subpopulations (i.e., the neighborhood in which individuals
happen to reside), despite the fact that such distinctions fail to capture
significant variation within each subpopulation that would result in a different
assessment for certain members of these groups. While redlining in America is
well known to have had its basis in racial animus and prejudice,  n72 decision
makers operating in this manner may attempt to justify their behavior by
pointing to the cost efficiency of relying on easily accessible information. In
other words, decision makers can argue that they are willing to tolerate higher
rates of erroneous determinations for certain groups because the benefits
[*690]  derived from more granular data--and thus better accuracy--do not
justify the costs. Of course, it may be no coincidence that such cost-benefit
analyses seem to justify treating groups composed disproportionately of members
of protected classes to systematically less accurate determinations.  n73
Redlining is illegal because it can systematically discount entire areas
composed primarily of members of a protected class, despite the presence of some
qualified candidates.  n74

   Cases of so-called rational racism are really just a special instance of this
more general phenomenon--one in which race happens to be taken into
consideration explicitly. In such cases, decision makers take membership in a
protected class into account, even if they hold no prejudicial views, because
such membership seems to communicate relevant information that would be
difficult or impossible to obtain otherwise. Accordingly, the persistence of
distasteful forms of discrimination may be the result of a lack of information,
rather than a continued taste for discrimination.  n75 Professor Lior
Strahilevitz has argued, for instance, that when employers lack access to
criminal records, they may consider race in assessing an applicant's likelihood
of having a criminal record because there are statistical differences in the
rates at which members of different racial groups have been convicted of crimes.
n76 In other words, employers fall back on more immediately available and coarse
features when they cannot access more specific or verified information.  n77 Of
course, as Strahilevitz points out, race is a highly imperfect basis upon which
to predict an individual's criminal record, despite whatever differences may
exist in the rates at which members of different racial groups have been
convicted of crimes, because it is too coarse as an indicator.  n78

    [*691]  D. Proxies

   Cases of decision making that do not artificially introduce discriminatory
effects into the data mining process may nevertheless result in systematically
less favorable determinations for members of protected classes. This is possible
when the criteria that are genuinely relevant in making rational and
well-informed decisions also happen to serve as reliable proxies for class
membership. In other words, the very same criteria that correctly sort
individuals according to their predicted likelihood of excelling at a job--as
formalized in some fashion--may also sort individuals according to class
membership.

   In certain cases, there may be an obvious reason for this. Just as "mining
from historical data may . . . discover traditional prejudices that are endemic
in reality (i.e., taste-based discrimination)," so, too, may data mining
"discover patterns of lower performances, skills or capacities of
protected-by-law groups."  n79 These discoveries not only reveal the simple fact
of inequality, but they also reveal that these are inequalities in which members
of protected classes are frequently in the relatively less favorable position.
This has rather obvious implications: if features held at a lower rate by
members of protected groups nevertheless possess relevance in rendering
legitimate decisions, such decisions will necessarily result in systematically
less favorable determinations for these individuals. For example, by conferring
greater attention and opportunities to employees that they predict will prove
most competent at some task, employers may find that they subject members of
protected groups to consistently disadvantageous treatment because the criteria
that determine the attractiveness of employees happen to be held at
systematically lower rates by members of these groups.  n80

   Decision makers do not necessarily intend this disparate impact because they
hold prejudicial beliefs; rather, their reasonable priorities as profit seekers
unintentionally recapitulate the inequality that happens to exist in society.
Furthermore, this may occur even if proscribed criteria have been removed from
the dataset, the data are free from latent prejudice or bias, the features are
especially granular and diverse, and the only goal is to maximize classificatory
or predictive accuracy. The problem stems from what researchers call "redundant
encodings," cases in which membership in a protected class happens to be encoded
in other data.  n81 This occurs when a particular piece of data or certain
values for that piece of data are highly correlated with  [*692]  membership in
specific protected classes. Data's significant statistical relevance to the
decision at hand helps explain why data mining can result in seemingly
discriminatory models even when its only objective is to ensure the greatest
possible accuracy for its determinations. If there is a disparate distribution
of an attribute, a more precise form of data mining will be more likely to
capture that distribution. Better data and more features will simply come closer
to exposing the exact extent of inequality.

E. Masking

   Data mining could also breathe new life into traditional forms of intentional
discrimination because decision makers with prejudicial views can mask their
intentions by exploiting each of the mechanisms enumerated above. Stated simply,
any form of discrimination that happens unintentionally can also be orchestrated
intentionally. For instance, decision makers could knowingly and purposefully
bias the collection of data to ensure that mining suggests rules that are less
favorable to members of protected classes.  n82 They could likewise attempt to
preserve the known effects of prejudice in prior decision making by insisting
that such decisions constitute a reliable and impartial set of examples from
which to induce a decision-making rule. And decision makers could intentionally
rely on features that only permit coarse-grained distinction
making--distinctions that result in avoidably higher rates of erroneous
determinations for members of a protected class. In denying themselves
finer-grained detail, decision makers would be able to justify writing off
entire groups composed disproportionately of members of protected classes. A
form of digital redlining, this decision masks efforts to engage in intentional
discrimination by abstracting to a level of analysis that fails to capture lower
level variations. As a result, certain members of protected classes might not be
seen as attractive candidates. Here, prejudice rather than some legitimate
business reason (such as cost) motivates decision makers to intentionally
restrict the particularity of their decision making to a level that can only
paint in avoidably broad strokes. This condemns entire groups, composed
disproportionately of members of protected classes, to systematically less
favorable treatment.

   Because data mining holds the potential to infer otherwise unseen attributes,
including those traditionally deemed sensitive,  n83 it can indirectly determine
individuals' membership in protected classes and unduly discount, penalize, or
exclude such people accordingly. In other words, data mining could grant
decision makers the ability to distinguish and disadvantage members of protected
classes even if those decision makers do not have access to explicit information
about individuals' class membership. Data mining could  [*693]  instead help to
pinpoint reliable proxies for such membership and thus place institutions in the
position to automatically sort individuals into their respective class without
ever having to learn these facts directly.  n84 The most immediate implication
is that institutions could employ data mining to circumvent the barriers, both
practical and legal, that have helped to withhold individuals' protected class
membership from consideration.

Additionally, data mining could provide cover for intentional discrimination of
this sort because the process conceals the fact that decision makers determined
and considered the individual's class membership. The worry, then, is not simply
that data mining introduces novel ways for decision makers to satisfy their
taste for illegal discrimination; rather, the worry is that it may mask actual
cases of such discrimination.  n85 Although scholars, policy makers, and lawyers
have long been aware of the dangers of masking,  n86 data mining significantly
enhances the ability to conceal acts of intentional discrimination by finding
ever more remote and complex proxies for proscribed criteria.  n87

   Intentional discrimination and its masking have so far garnered
disproportionate attention in discussions of data mining,  n88 often to the
exclusion of issues arising from the many forms of unintentional discrimination
described above. While data mining certainly introduces novel ways to
discriminate intentionally and to conceal those intentions, most cases of
employment discrimination are already sufficiently difficult to prove; employers
motivated by conscious prejudice would have little to gain by pursuing these
complex and costly mechanisms to further mask their intentions.  n89 When it
comes to data mining, unintentional discrimination is the more pressing concern
because it is likely to be far more common and easier to overlook.

    [*694]  II.

   TITLE VII LIABILITY FOR DISCRIMINATORY DATA MINING

   Current antidiscrimination law is not well equipped to address the cases of
discrimination stemming from the problems described in Part I. This Part
considers how Title VII might apply to these cases. Other antidiscrimination
laws, such as the Americans with Disabilities Act, will exhibit differences in
specific operation, but the main thrust of antidiscrimination law is fairly
consistent across regimes, and Title VII serves as an illustrative example.  n90

   An employer sued under Title VII may be found liable for employment
discrimination under one of two theories of liability: disparate treatment and
disparate impact.  n91 Disparate treatment comprises two different strains of
discrimination: (1) formal disparate treatment of similarly situated people and
(2) intent to discriminate.  n92 Disparate impact refers to policies or
practices that are facially neutral but have a disproportionately adverse impact
on protected classes.  n93 Disparate impact is not concerned with the intent or
motive for a policy; where it applies, the doctrine first asks whether there is
a disparate impact on members of a protected class, then whether there is some
business justification for that impact, and finally, whether there were less
discriminatory means of achieving the same result.  n94

   Liability under Title VII for discriminatory data mining will depend on the
particular mechanism by which the inequitable outcomes are generated. This Part
explores the disparate treatment and disparate impact doctrines and analyzes
which mechanisms could generate liability under each theory.

A. Disparate Treatment

   Disparate treatment recognizes liability for both explicit formal
classification and intentional discrimination.  n95 Formal discrimination, in
which membership in a protected class is used as an input to the model,
corresponds to an employer classifying employees or potential hires according to
membership in a protected class and differentiating them on that basis. Formal
[*695]  discrimination covers both the straightforward denial of opportunities
based on protected class membership and the use of rational racism.  n96 In
traditional contexts, rational racism is considered rational because there are
cases in which its users believe it is an accurate, if coarse-grained, proxy--or
at least the best available one in a given situation.  n97 In the world of data
mining, though, that need not be the case. Even if membership in a protected
class were specified as an input, the eventual model that emerges could see it
as the least significant feature. In that case, there would be no discriminatory
effect, but there would be a disparate treatment violation, because considering
membership in a protected class as a potential proxy is a legal classificatory
harm in itself.  n98

   Formal liability does not correspond to any particular discrimination
mechanism within data mining; it can occur equally well in any of them. Because
classification itself can be a legal harm, irrespective of the effect,  n99 the
same should be true of using protected class as an input to a system for which
the entire purpose is to build a classificatory model.  n100 The irony is that
the use of protected class as an input is usually irrelevant to the outcome in
terms of discriminatory effect, at least given a large enough number of input
features. The target variable will, in reality, be correlated to the membership
in a protected class somewhere between 0 percent and 100 percent. If the trait
is perfectly uncorrelated, including membership in the protected class as an
input will not change the output, and there will be no discriminatory effect.
n101 On the other end of the spectrum, where membership in the protected class
is perfectly predictive of the target variable, the fact will be redundantly
encoded in the other data. The only way using membership in the protected class
as an explicit feature will change the outcome is if the information is
otherwise not rich enough to detect such membership. Membership in the protected
class will prove relevant to the exact extent it is already redundantly encoded.
Given a rich enough set of features, the chance that such membership is
redundantly encoded approaches certainty. Thus, a data mining model with a large
number of variables will determine the extent to which membership in a protected
class is relevant to the sought-after trait whether or not that information is
an input. Formal discrimination therefore should have no bearing whatsoever on
the  [*696]  outcome of the model. Additionally, by analyzing the data, an
employer could probabilistically determine an employee's membership in that same
protected class, if the employer did indeed want to know.

   To analyze intentional discrimination other than mere formal discrimination,
a brief description of disparate treatment doctrine is necessary. A Title VII
disparate treatment case will generally proceed under either the
McDonnell-Douglas burden-shifting scheme or the Price-Waterhouse "mixed motive"
regime.  n102 Under the McDonnell-Douglas framework, the plaintiff who has
suffered an adverse employment action has the initial responsibility to
establish a prima facie case of discrimination by demonstrating that a similarly
situated person who is not a member of a protected class would not have suffered
the same fate.  n103 This can be shown with circumstantial evidence of
discriminatory intent, such as disparaging remarks made by the employer or
procedural irregularities in promotion or hiring; only very rarely will an
employer openly admit to discriminatory conduct. If the plaintiff successfully
demonstrates that the adverse action treated protected class members
differently, then the burden shifts to the defendant-employer to offer a
legitimate, nondiscriminatory basis for the decision. The defendant need not
prove the reason is true; his is only a burden of production.  n104 Once the
defendant has offered a nondiscriminatory alternative, the ultimate burden of
persuasion falls to the plaintiff to demonstrate that the proffered reason is
pretextual.  n105

   In the data mining context, liability for masking is clear as a theoretical
matter, no matter which mechanism for discrimination is employed. The fact that
it is accomplished algorithmically does not make it less of a disparate
treatment violation, as the entire idea of masking is pretextual. In fact, in
the traditional, non--data mining context, the word masking has occasionally
been used to refer to pretext.  n106 Like in any disparate treatment case,
however, proof will be difficult to come by, something even truer for masking.
n107

    [*697]  The McDonnell-Douglas framework operates on a presumption that if
the rationale that the employer has given is found to be untrue, the employer
must be hiding his "true" discriminatory motive.  n108 Because the focus of the
McDonnell-Douglas framework is on pretext and cover-up, it can only address
conscious, willful discrimination.  n109 Under the McDonnell-Douglas framework,
a court must find either that the employer intended to discriminate or did not
discriminate at all.  n110 Thus, unintentional discrimination will not lead to
liability.

   A Title VII disparate treatment case can also be tried under the mixed-motive
framework, first recognized in Price Waterhouse v. Hopkins  n111 and most
recently modified by Desert Palace, Inc. v. Costa.  n112 In the mixed-motive
framework, a plaintiff need not demonstrate that the employer's
nondiscriminatory rationale was pretextual, but merely that discrimination was a
"motivating factor" in the adverse employment action.  n113 As a practical
matter, this means that the plaintiff must show that the same action would not
have been taken absent the discriminatory motive.  n114 As several commentators
[*698]  have pointed out, motive and intent are not necessarily synonymous.
n115 Motive can be read more broadly to include unconscious discrimination,
including anything that influences a person to act, such as emotions or desires.
n116 Nonetheless, courts have conflated the meanings of motive and intent such
that the phrase "motive or intent" has come to refer only to conscious choices.
n117 Thus, while most individual decision making probably belongs in a
mixed-motive framework, as each decision a person makes comprises a complicated
mix of motivations,  n118 the mixed-motive framework will be no better than the
pretext framework at addressing bias that occurs absent conscious intent.  n119

   Except for masking, discriminatory data mining is by stipulation
unintentional. Unintentional disparate treatment is not a problem that is new to
data mining. A vast scholarly literature has developed regarding the law's
treatment of unconscious, implicit bias.  n120 Such treatment can occur when an
employer has internalized some racial stereotype and applies it or, without
realizing it, monitors an employee more closely until the employer finds a
violation.  n121 The employee is clearly treated differently, but it is not
intentional, and the employer is unaware of it. As Professor Samuel Bagenstos
summarized, at this point, "it may be difficult, if not impossible, for a court
to go back and reconstruct the numerous biased evaluations and perceptions that
ultimately resulted in an adverse employment decision."  n122 Within the
scholarly literature, there is "[s]urprising unanimity" that the law does not
adequately address unconscious disparate treatment.  n123

    [*699]  There are a few possible ways to analogize discriminatory data
mining to unintentional disparate treatment in the traditional context, based on
where one believes the "treatment" lies. Either the disparate treatment occurs
at the decision to apply a predictive model that will treat members of a
protected class differently, or it occurs when the disparate result of the model
is used in the ultimate hiring decision. In the first scenario, the intent at
issue is the decision to apply a predictive model with known disproportionate
impact on protected classes. In the second, the disparate treatment occurs if,
after the employer sees the disparate result, he proceeds anyway. If the
employer continues because he liked the discrimination produced in either
scenario, then intent is clear. If not, then this just devolves into a standard
disparate impact scenario, with liability based on effect. Under disparate
impact theory, deciding to follow through on a test with discriminatory effect
does not suddenly render it disparate treatment.  n124

   Another option is to imagine the model as the decision maker exhibiting
implicit bias. That is, because of biases hidden to the predictive model such as
nonrepresentative data or mislabeled examples, the model reaches a
discriminatory result. This analogy turns every mechanism except proxy
discrimination into the equivalent of implicit bias exhibited by individual
decision makers. The effect of bias is one factor among the many different
factors that go into the model-driven decision, just like in an individual's
adverse employment decision.  n125 Would a more expansive definition of motive
fix this scenario?

   Because the doctrine focuses on human decision makers as discriminators, the
answer is no. Even if disparate treatment doctrine could capture unintentional
discrimination, it would only address such discrimination stemming from human
bias. For example, the person who came up with the idea for Street Bump
ultimately devised a system that suffers from reporting bias,  n126 but it was
not because he or she was implicitly employing some racial stereotype. Rather,
it was simply inattentiveness to problems with the sampling frame. This is not
to say that his or her own bias had nothing to do with it--the person likely
owned a smartphone and thus did not think about the people who do not--but no
one would say that it was even implicit bias against protected  [*700]  classes
that motivated the decision, even under the expansive definition of the word
"motive."  n127

   The only possible analogy relevant to disparate treatment, then, is to those
data mining mechanisms of unintentional discrimination that reflect a real
person's bias--something like LinkedIn's Talent Match recommendation engine,
which relies on potentially prejudiced human assessments of employees.  n128 As
a general rule, an employer may not avoid disparate treatment liability by
encoding third-party preferences as a rationale for a hiring decision.  n129
But, once again, to be found liable under current doctrine, the employer would
likely both have to know that this is the specific failure mechanism of the
model and choose it based on this fact.

   There is one other interesting question regarding disparate treatment
doctrine: whether the intent standard includes knowledge. This is not a problem
that arises often when a human is making a single employment determination.
Assuming disparate treatment occurs in a given case, it is generally either
intended or unconscious. What would it mean to have an employer know that he was
treating an employee differently, but still take the action he had always
planned to take without intent to treat the employee differently? It seems like
an impossible line to draw.  n130

   With data mining, though, unlike unconscious bias, it is possible to audit
the resulting model and inform an employer that she will be treating individuals
differently before she does so. If an employer intends to employ the model, but
knows it will produce a disparate impact, does she intend to discriminate? This
is a more realistic parsing of intent and knowledge than in the case of an
individual, nonsystematic employment decision. Neither pretext nor motive exists
here, and throughout civil and criminal law, "knowledge" and "intent" are
considered distinct states of mind, so there would likely be no liability. On
the other hand, courts may use knowledge of discrimination as evidence to find
intent.  n131 And while the statute's language only covers intentional
discrimination,  n132 a broad definition of intent could include knowledge or
[*701]  substantial certainty of the result.  n133 Because the situation has not
come up often, the extent of the "intent" required is as yet unknown.  n134

   In sum, aside from rational racism and masking (with some difficulties),
disparate treatment doctrine does not appear to do much to regulate
discriminatory data mining.

B. Disparate Impact

   Where there is no discriminatory intent, disparate impact doctrine should be
better suited to finding liability for discrimination in data mining. In a
disparate impact case, a plaintiff must show that a particular facially neutral
employment practice causes a disparate impact with respect to a protected class.
n135 If shown, the defendant-employer may "demonstrate that the challenged
practice is job related for the position in question and consistent with
business necessity."  n136 If the defendant makes a successful showing to that
effect, the plaintiff may still win by showing that the employer could have used
an "alternative employment practice" with less discriminatory results.  n137

   The statute is unclear as to the required showing for essentially every
single element of a disparate impact claim. First, it is unclear how much
disparate impact is needed to make out a prima facie case.  n138 The EEOC,
charged with enforcing Title VII's mandate, has created the so-called
"four-fifths rule" as a presumption of adverse impact: "A selection rate for any
race, sex, or ethnic group which is less than four-fifths . . . of the rate for
the group  [*702]  with the highest rate will generally be regarded . . . as
evidence of adverse impact."  n139 The Uniform Guidelines on Employment
Selection Procedures (Guidelines) also state, however, that smaller differences
can constitute adverse impact and greater differences may not, depending on
circumstances. Thus, the four-fifths rule is truly just a guideline.  n140 For
the purposes of this Part, it is worthwhile to just assume that the
discriminatory effects are prominent enough to establish disparate impact as an
initial matter.  n141

   The next step in the litigation is the "business necessity" defense. This
defense is, in a very real sense, the crux of disparate impact analysis,
weighing Title VII's competing goals of limiting the effects of discrimination
while allowing employers discretion to advance important business goals. Griggs
v. Duke Power Co.  n142--the decision establishing the business necessity
defense alongside disparate impact doctrine itself--articulated the defense in
several different ways:


     A challenged employment practice must be "shown to be related to job
     performance," have a "manifest relationship to the employment in
     question," be "demonstrably a reasonable measure of job performance,"
     bear some "relationship to job-performance ability," and/or "must
     measure the person for the job and not the person in the abstract."
     n143


The Supreme Court was not clear on what, if any, difference existed between
job-relatedness and business necessity, at one point seeming to use the terms
interchangeably: "The touchstone is business necessity. If an employment
practice which operates to exclude Negroes cannot be shown to be related to job
performance, the practice is prohibited."  n144 The focus of the Court was
clearly on future job performance, and the term "job-related" has come to mean a
practice that is predictive of job performance.  n145 Because the definitions of
job-relatedness and business necessity have never been clear, courts defer when
applying the doctrine and finding the appropriate balance.  n146

   Originally, the business necessity defense seemed to apply narrowly. In
Griggs, Duke Power had instituted new hiring requirements including a high
school diploma and success on a "general intelligence" test for previously
[*703]  white-only divisions. Duke Power did not institute such requirements in
divisions where it had previously hired black employees.  n147 The Court ruled
that the new requirements were not a business necessity because "employees who
have not completed high school or taken the tests have continued to perform
satisfactorily and make progress in departments for which the high school and
test criteria are now used."  n148 Furthermore, the requirements were
implemented without any study of their future effect.  n149 The Court also
rejected the argument that the requirements would improve the "overall quality
of the workforce."  n150

   By 1979, the Court began treating business necessity as a much looser
standard.  n151 In New York City Transit Authority v. Beazer,  n152 the transit
authority had implemented a rule barring drug users from employment, including
current users of methadone, otherwise known as recovering heroin addicts. In
dicta, the Court stated that a "narcotics rule," which "significantly serves"
the "legitimate employment goals of safety and efficiency," was "assuredly" job
related.  n153 This was the entire analysis of the business necessity defense in
the case. Moreover, the rationale was acceptable as applied to the entire
transit authority, even where only 25 percent of the jobs were labeled as
"safety sensitive."  n154 Ten years later, the Court made the business necessity
doctrine even more defendant-friendly in Wards Cove Packing Co. v. Atonio.  n155
After Wards Cove, the business necessity defense required a court to engage in
"a reasoned review of the employer's justification for his use of the challenged
practice. . . . [T]here is no requirement that the challenged practice be
'essential' or 'indispensable' to the employer's business for it to pass muster
. . . ."  n156 The Court also reallocated the burden to plaintiffs to prove that
business necessity was lacking and even referred to the defense as a "business
justification" rather than a business necessity.  n157 The Wards Cove Court went
so far that Congress directly addressed the decision in the Civil Rights Act of
1991 (1991 Act), which codified disparate impact and reset the standards to the
day before Wards Cove was decided.  n158

   Because the substantive standards for job-relatedness or business necessity
were uncertain before Wards Cove, however, the confusion persisted  [*704]  even
after the 1991 Act was passed.  n159 At the time, both sides--civil rights
groups and the Bush administration, proponents of a rigorous and more lenient
business necessity defense respectively--declared victory.  n160

   Since then, courts have recognized that business necessity lies somewhere in
the middle of two extremes.  n161 Some courts require that the hiring criteria
bear a "manifest relationship"  n162 to the employment in question or that they
be "significantly correlated" to job performance.  n163 The Third Circuit was
briefly an outlier, holding "that hiring criteria must effectively measure the
'minimum qualifications for successful performance of the job'" in order to meet
the strict business necessity standard.  n164 This tougher standard would, as a
practical matter, ban general aptitude tests with any disparate impact because a
particular cutoff score cannot be shown to distinguish between those able and
completely unable to do the work.  n165 For example, other unmeasured skills and
abilities could theoretically compensate for the lower score on an aptitude
test, rendering a certain minimum score not "necessary" if it does not measure
minimum qualifications.  n166 In a subsequent case, however, the Third Circuit
recognized that Title VII does not require an employer to choose someone "less
qualified" (as opposed to unqualified) in the name of nondiscrimination and
noted that aptitude tests can be legitimate hiring tools if they accurately
measure a person's qualifications.  n167 The court concluded:


      [*705]  Putting these standards together, then, we require that
     employers show that a discriminatory hiring policy accurately--but not
     perfectly--ascertains an applicant's ability to perform successfully
     the job in question. In addition, Title VII allows the employer to
     hire the applicant most likely to perform the job successfully over
     others less likely to do so.  n168


Thus, all circuits seem to accept varying levels of job-relatedness rather than
strict business necessity.  n169

   The last piece of the disparate impact test is the "alternative employment
practice" prong. Shortly after Griggs, the Supreme Court decided Albemarle Paper
Co. v. Moody, holding in part that "[i]f an employer does then meet the burden
of proving that its tests are 'job related,' it remains open to the complaining
party to show that other tests or selection devices, without a similarly
undesirable racial effect, would also serve the employer's legitimate interest
in 'efficient and trustworthy workmanship.'"  n170 This burden-shifting scheme
was codified in the 1991 Act as the "alternative employment practice"
requirement.  n171 Congress did not define the phrase, and its substantive
meaning  [*706]  remains uncertain. Wards Cove was the first case to use the
specific phrase, so Congress's instruction to reset the law to the pre--Wards
Cove standard is particularly perplexing.  n172 The best interpretation is most
likely Albemarle's reference to "other tests or selection devices, without a
similarly undesirable racial effect."  n173 But this interpretation is slightly
odd because in Albemarle, business necessity was still somewhat strict, and it
is hard to imagine a business practice that is "necessary" while there exists a
less discriminatory alternative that is just as effective.  n174 If business
necessity or job-relatedness is a less stringent requirement, though, then the
presence of the alternative employment practice requirement does at least give
it some teeth.

   Now return to data mining. For now, assume a court does not apply the strict
business necessity standard but has some variation of "job related" in mind (as
all federal appellate courts do today).  n175 The threshold issue is clearly
whether the sought-after trait--the target variable--is job related, regardless
of the machinery used to predict it. If the target variable is not sufficiently
job related, a business necessity defense would fail, regardless of the fact
that the decision was made by algorithm. Thus, disparate impact liability can be
found for improper care in target variable definition. For example, it would be
difficult for an employer to justify an adverse determination based on the
appearance of an advertisement suggesting a criminal record alongside the search
results for a candidate's name. Sweeney found such a search to have a disparate
impact,  n176 and the EEOC and several federal courts have interpreted Title VII
to prohibit discrimination on the sole basis of criminal record, unless there is
a specific reason the particular conviction is related to the job.  n177 This
[*707]  is true independent of the fact that the disparity is an artifact of
third-party bias; all that matters is whether the target variable is job
related. In the end, though, because determining that a business practice is not
job related actually requires a normative determination that it is instead
discriminatory, courts tend to accept most common business practices for which
an employer has a plausible story.  n178

   Once a target variable is established as job related, the first question is
whether the model is predictive of that trait. The nature of data mining
suggests that this will be the case. Data mining is designed entirely to predict
future outcomes, and, if seeking a job-related trait, future job performance.
One commentator lamented that "[f]ederal case law has shifted from a prospective
view of meritocracy to a retrospective view, thereby weakening disparate impact
law."  n179 The author meant that, in Griggs, the Court recognized that
education and other external factors were unequal and therefore discounted a
measure of meritocracy that looked to past achievements, in favor of comparing
the likelihood of future ones. But by the time the Court had decided Wards Cove,
it had shifted to a model of retrospective meritocracy that presumed the
legitimacy of past credentials, thus upholding the status quo.  n180 While data
mining must take the past--represented by the training data--as given, it
generates predictions about workplace success that are much more accurate than
predictions based on those past credentials that disparate impact doctrine has
come to accept.  n181 In a hypothetical perfect case of data mining, the
available information would be rich enough that reliance on the past information
would fully predict future performance. Thus, robust data mining would likely
satisfy even the Griggs Court's standard that the models are looking toward
future job performance, not merely past credentials.

   The second question asks whether the model adequately predicts what it is
supposed to predict. In the traditional context, this question arises in the
case of general aptitude tests that might end up measuring unrelated elements of
cultural awareness rather than intelligence.  n182 This is where the different
data  [*708]  mining mechanisms for discriminatory effects matter. Part I
posited that proxy discrimination optimizes correctly. So if it evidences a
disparate impact, it reflects unequal distribution of relevant traits in the
real world. Therefore, proxy discrimination will be as good a job predictor as
possible given the current shape of society. Models trained on biased samples
and mislabeled examples, on the other hand, will result in correspondingly
skewed assessments rather than reflect real-world disparities. The same effect
may be present in models that rely on insufficiently rich or insufficiently
granular datasets: by designation they do not reflect reality. These models
might or might not be considered job related, depending on whether the errors
distort the outcomes enough that the models are no longer good predictors of job
performance.

   The Guidelines have set forth validation procedures intended to create a
job-relatedness standard. Quantifiable tests that have a disparate impact must
be validated according to the procedures in the Guidelines if possible;
otherwise, a presumption arises that they are not job related.  n183 Under the
Guidelines, a showing of validity takes one of three forms: criterion-related,
content, or construct.  n184 Criterion-related validity "consist[s] of empirical
data demonstrating that the selection procedure is predictive of or
significantly correlated with important elements of job performance."  n185 The
"relationship between performance on the procedure and performance on the
criterion measure is statistically significant at the 0.05 level of
significance. . . ."  n186 Content validity refers to testing skills or
abilities that generally are or have been learned on the job, though not those
that could be acquired in a "brief orientation."  n187 Construct validity refers
to a test designed to measure some innate human trait such as honesty. A user of
a construct "should show by empirical evidence that the selection procedure is
validly related to the construct and that the construct is validly related to
the performance of critical or important work behavior(s)."  n188

   As a statistical predictive measure, a data mining model could be validated
by either criterion-related or construct validity, depending on the trait being
sought. Either way, there must be statistical significance showing that the
result of the model correlates to the trait (which was already determined to be
an important element of job performance). This is an exceedingly low bar for
data mining because data mining's predictions necessarily rest on demonstrated
[*709]  statistical relationships. Data mining will likely only be used if it is
actually predictive of something, so the business necessity defense solely comes
down to whether the trait sought is important enough to job performance to
justify its use in any context.

   Even assuming the Guidelines' validation requirement is a hurdle for data
mining, some courts ignore the Guidelines' recommendation that an unvalidated
procedure be rejected, preferring to rely on "common sense" or finding a
"manifest relationship" between the criteria and successful job performance.
n189 Moreover, it is possible that the Supreme Court inadvertently overruled the
Guidelines in 2009. In Ricci v. Destefano, a case that will be discussed in
greater detail in Part III.B, the Court found no genuine dispute that the tests
at issue met the job-related and business necessity standards  n190 despite not
having been validated under the Guidelines and despite the employer actively
denying that they could be validated.  n191 While the business necessity defense
was not directly at issue in Ricci, "[o]n the spectrum between heavier and
lighter burdens of justification, the Court came down decidedly in favor of a
lighter burden."  n192

   Thus, there is good reason to believe that any or all of the data mining
models predicated on legitimately job-related traits pass muster under the
business necessity defense. Models trained on biased samples, mislabeled
examples, and limited features, however, might trigger liability under the
alternative employment practice prong. If a plaintiff can show that an
alternative, less discriminatory practice that accomplishes the same goals
exists and that the employer "refuses" to use it, the employer can be found
liable. In this case, a plaintiff could argue that the obvious alternative
employment practice would be to fix the problems with the models.

   Fixing the models, however, is not a trivial task. For example, in the
LinkedIn hypothetical, where the demonstrated interest in different kinds of
employees reflects employers' prejudice, LinkedIn is the party that determines
the algorithm by which the discrimination occurs (in this case, based on
reacting to third-party preferences). If an employer were to act on the
recommendations suggested by the LinkedIn recommendation engine, there  [*710]
would not be much he could do to make it less reflective of third-party
prejudice, aside from calling LinkedIn and asking nicely. Thus, it could not
really be said that the employer "refuses" to use an alternative employment
practice. The employer could either use the third-party tool or not. Similarly,
it might be possible to fix an app like Street Bump that suffers from reporting
bias, but the employer would need access to the raw input data in order to do
so.  n193 In the case of insufficiently rich or granular features, the employer
would need to collect more data in order to make the model more discerning. But
collecting more data can be time consuming and costly,  n194 if not impossible
for legal or technical reasons.

   Moreover, the under- and overrepresentation of members of protected classes
in data is not always evident, nor is the mechanism by which such under- or
overrepresentation occurs. The idea that the representation of different social
groups in the dataset can be brought into proportions that better match those in
the real world presumes that analysts have some independent mechanism for
determining these proportions. Thus, there are several hurdles to finding
disparate impact liability for models employing data that under- or
overrepresents members of protected classes. The plaintiff must prove that the
employer created or has access to the model, can discover that there is
discriminatory effect, and can discover the particular mechanism by which that
effect operates. The same can be said for models with insufficiently rich
feature sets. Clearly there are times when more features would improve an
otherwise discriminatory outcome. But it is, almost by definition, hard to know
which features are going to make the model more or less discriminatory. Indeed,
it is often impossible to know which features are missing because data miners do
not operate with causal relationships in mind. So while theoretically a less
discriminatory alternative would almost always exist, proving it would be
difficult.

   There is yet another hurdle. Neither Congress nor courts have specified what
it means for an employer to "refuse" to adopt the less discriminatory procedure.
Scholars have suggested that perhaps the employer cannot be held liable until it
has considered the alternative and rejected it.  n195 Thus, if the employer has
run an expensive data collection and analysis operation without ever being made
aware of its any discriminatory tendencies, and the employer cannot afford to
re-run the entire operation, is the employer "refusing" to use a less
discriminatory alternative, or does one simply not exist? How much would the
error correction have to cost an employer before it is not seen as a refusal to
use the procedure?  n196 Should the statute actually be interpreted to mean that
an  [*711]  employer "unreasonably refuses" to use an alternative employment
practice? These are all difficult questions, but suffice it to say, the prospect
of winning a data mining discrimination case on alternative employment practice
grounds seems slim.

   The third and final consideration regarding disparate impact liability for
data mining is whether a court or Congress might reinvigorate strict business
necessity.  n197 In that case, things look a little better for plaintiffs
bringing disparate impact claims. Where an employer models job tenure,  n198 for
example, a court may be inclined to hold that it is job related because the
model is a "legitimate, non-discriminatory business objective."  n199 But it is
clearly not necessary to the job. The same reasoning applies to mining for any
single trait that is job related--the practice of data mining is not focused on
discovering make-or-break skills. Unless the employer can show that below the
cut score, employees cannot do the work, then the strict business necessity
defense will fail. Thus, disparate impact that occurs as an artifact of the
problem-specification stage can potentially be addressed by strict business
necessity.

   This reasoning is undermined, though, where employers do not mine for a
single trait, but automate their decision process by modeling job performance on
a holistic measure of what makes good employees. If employers determine traits
of a good employee by simple ratings, and use data mining to appropriately
divine good employees' characteristics among several different variables, then
the argument that the model does not account for certain skills that could
compensate for the employee's failings loses its force. Taken to an extreme, an
8,000-feature holistic determination of a "good employee" would still not be
strictly "necessary." Holding a business to such a standard, however, would
simply be forbidding that business from ranking candidates if any disparate
impact results. Thus, while the strict business necessity defense could prevent
myopic employers from creating disparate impacts by their choice of target
variable, it would still not address forms of data mining that model general job
performance rather than predict specific traits.

   Disparate impact doctrine was created to address unintentional
discrimination. But it strikes a delicate balance between allowing businesses
the leeway to make legitimate business judgments and preventing "artificial,
arbitrary, and unnecessary" discrimination.  n200 Successful data mining
operations will often both predict future job performance and have some  [*712]
disparate impact. Unless the plaintiff can find an alternative employment
practice to realistically point to, a tie goes to the employer.

C. Masking and Problems of Proof

   Masking poses separate problems for finding Title VII liability. As discussed
earlier, there is no theoretical problem with finding liability for masking.
n201 It is a disparate treatment violation as clear as any. But like traditional
forms of intentional discrimination, it suffers from difficulties of proof.
While finding intent from stray remarks or other circumstantial evidence is
challenging in any scenario, masking presents additional complications for
detection.

Data mining allows employers who wish to discriminate on the basis of a
protected class to disclaim any knowledge of the protected class in the first
instance while simultaneously inferring such details from the data. An employer
may want to discriminate by using proxies for protected classes, such as in the
case of redlining.  n202 Due to housing segregation, neighborhood is a good
proxy for race and can be used to redline candidates without reference to race.
n203 This is a relatively unsophisticated example, however. It is possible that
some combination of musical tastes,  n204 stored "likes" on Facebook,  n205 and
network of friends  n206 will reliably predict membership in protected classes.
An employer can use these traits to discriminate by setting up future models to
sort by these items and then disclaim any knowledge of such proxy manipulation.

   More generally, as discussed in Part I, any of the mechanisms by which
unintentional discrimination can occur can also be employed intentionally. The
example described above is intentional discrimination by proxy, but it is also
possible to intentionally bias the data collection process, purposefully
mislabel examples, or deliberately use an insufficiently rich set of features,
n207 though some of these would probably require a great deal of sophistication.
These methods of intentional discrimination will look, for all intents and
purposes, identical to the unintentional discrimination that can result from
data mining. Therefore, detecting discrimination in the first instance will
require the same techniques as detecting unintentional discrimination, namely a
disparate impact analysis. Further, assuming there is no circumstantial evidence
like an employer's stray remarks with which to prove intent, a plaintiff might
attempt  [*713]  to prove intent by demonstrating that the employer is using
less representative data, poorer examples, or fewer and less granular features
than he might otherwise use were he interested in the best possible candidate.
That is, one could show that the neutral employment practice is a pretext by
demonstrating that there is a more predictive alternative.

   This looks like disparate impact analysis. A plaintiff proving masked
intentional discrimination asks the same question as in the "alternative
employment practice" prong: whether there were more relevant measures the
employer could have used.  n208 But the business necessity defense is not
available in a disparate treatment case,  n209 so alternative employment
practice is not the appropriate analysis. Scholars have noted, though, that the
line between disparate treatment and disparate impact in traditional Title VII
cases is not always clear,  n210 and sometimes employer actions can be
legitimately categorized as either or both.  n211 As Professor George Rutherglen
has pointed out, "Concrete issues of proof, more than any abstract theory,
reveal the fundamental similarity between claims of intentional discrimination
and those of disparate impact. The evidence submitted to prove one kind of claim
invariably can be used to support the other."  n212 Rutherglen's point is
exactly what must happen in the data mining context: disparate treatment and
disparate impact become essentially the same thing from an evidentiary
perspective.

   To the extent that disparate impact and treatment are, in reality, different
theories, they are often confused for each other. Plaintiffs will raise both
types of claims as a catch-all because they cannot be sure on which theory they
might win, so both theories will be in play in a given case.  n213 As a result,
courts often seek evidence of state of mind in disparate impact cases  n214 and
objective, statistical evidence in disparate treatment cases.  n215 Assuming the
two theories are not functionally the same, using the same evidence for
disparate treatment and disparate impact will only lead to more confusion and,
as a result, more uncertainty within the courts. Thus, despite its clear nature
as a theoretical violation, it is less clear that a plaintiff will be able to
win a masking disparate treatment case.

   A final point is that traditionally, employers who do not want to
discriminate go to great lengths to avoid raising the prospect that they have
[*714]  violated the law. Thus they tend to avoid collecting information about
attributes that reveal an individual's membership in a protected class.
Employers even pay third parties to collect relatively easy-to-find information
on job applicants, such as professional honors and awards, as well as
compromising photos, videos, or membership in online groups, so that the third
party can send back a version of the report that "remove[s] references to a
person's religion, race, marital status, disability and other information
protected under federal employment laws."  n216 This allows employers to
honestly disclaim any knowledge of the protected information. Nonetheless, if an
employer seeks to discriminate according to protected classes, she would be able
to infer class membership from the data. Thus, employers' old defense to
suspicion of discrimination--that they did not even see the information--is no
longer adequate to separate would-be intentional discriminators from employers
that do not intend to discriminate.

   III.

   THE DIFFICULTY FOR REFORMS

   While each of the mechanisms for discrimination in data mining presents
difficulties for Title VII as currently written, there are also certain
obstacles to reforming Title VII to address the resulting problems. Computer
scientists and others are working on technical remedies,  n217 so to say that
there are problems with legal remedies does not suggest that the problems with
discrimination in data mining cannot be solved at all. Nonetheless, this Part
focuses on the legal aspects. As it illustrates, even assuming that the
political will to reform Title VII exists, potential legal solutions are not
straightforward.

   This Part discusses two types of difficulties with reforming Title VII.
First, there are issues internal to the data mining process that make legal
reform difficult. For example, the subjectivity in defining a "good employee" is
unavoidable, but, at the same time, some answers are clearly less discriminatory
than others.  n218 How does one draw that line? Can employers gain access to the
additional data necessary to correct for collection bias? How much will it cost
them to find it? How do we identify the "correct" baseline historical data to
avoid reproducing past prejudice or the "correct" level of detail and
granularity in a dataset? Before laws can be reformed, policy-level answers to
these basic technical, philosophical, and economic questions need to be
addressed at least to some degree.

    [*715]  Second, reform will face political and constitutional constraints
external to the logic of data mining that will affect how Title VII can be
permissibly reformed to address it. Not all of the mechanisms for discrimination
seem to be amenable to procedural remedies. If that holds true, only
after-the-fact reweighting of results may be able to compensate for the
discriminatory outcomes. This is not a matter of missing legislation; it is a
matter of practical reality. Unfortunately, while in many cases no procedural
remedy will be sufficient, any attempt to design a legislative or judicial
remedy premised on reallocation of employment outcomes will not survive long in
the current political or constitutional climate, as it raises the specter of
affirmative action. Politically, anything that even hints at affirmative action
is a nonstarter today, and to the extent that it is permissible to enact such
policies, their future constitutionality is in doubt.  n219

A. Internal Difficulties

1. Defining the Target Variable

   Settling on a target variable is a necessarily subjective exercise.  n220
Disputes over the superiority of competing definitions are often insoluble
because the target variables are themselves incommensurable. There are, of
course, easier cases, where prejudice or carelessness leads to definitions that
subject members of protected classes to avoidably high rates of adverse
determinations. But most cases are likely to involve genuine business
disagreements over ideal definitions, with each having a potentially greater or
lesser impact on protected classes. There is no stable ground upon which to
judge the relative merits of definitions because they often reflect competing
ideas about the very nature of the problem at issue.  n221 As Professor Oscar
Gandy has argued, "[C]ertain kind[s] of biases are inherent in the selection of
the goals or objective functions that automated systems will [be] designed to
support."  n222 There is no escape from this situation; a target variable must
reflect judgments about what really is the problem at issue in making hiring
decisions. For certain employers, it might be rather obvious that the problem is
one of reducing the administrative costs associated with turnover and training;
for others, it might be improving sales; for still others, it might be
increasing  [*716]  innovation. Any argument for the superiority of one target
variable over the other will simply make appeals to competing and incommensurate
values.

   For these same reasons, however, defining the target variable also offers an
opportunity for creative thinking about the potentially infinite number of ways
of making sound hiring decisions. Data miners can experiment with multiple
definitions that each seem to serve the same goal, even if these fall short of
what they themselves consider ideal. In principle, employers should rely on
proxies that are maximally proximate to the actual skills demanded of the job.
While there should be a tight nexus between the sought-after features and these
skills, this may not be possible for practical and economic reasons. This leaves
data miners in a position to dream up many different nonideal ways to make
hiring decisions that may have a greater or less adverse impact on protected
classes.

   The Second Circuit considered such an approach in Hayden v. County of Nassau.
n223 In Hayden, the county's goal was to find a police entrance exam that was
"valid, yet minimized the adverse impact on minority applicants."  n224 The
county thus administered an exam with twenty-five parts that could be scored
independently. By design, a statistically valid result could be achieved by one
of several configurations that counted only a portion of the test sections,
without requiring all of them.  n225 The county ended up using nine of the
sections as a compromise, after rejecting one configuration that was more
advantageous to minority applicants but less statistically sound.  n226 This is
a clear example of defining a problem in such a way that it becomes possible to
reduce the disparate impact without compromising the accuracy of the assessment
mechanism.

2. Training Data

a. Labeling Examples

   Any solution to the problems presented by labeling must be a compromise
between a rule that forbids employers from relying on past discrimination and
one that allows them to base hiring decisions on historical examples of good
employees. In theory, a rule that forbids employers from modeling decisions
based on historical examples tainted by prejudice would address the problem of
improper labeling. But if the only examples an employer has to draw on are those
of past employees who had been subject to discrimination, all learned rules will
recapitulate this discrimination.

   Title VII has always had to balance its mandate to eliminate discrimination
in the workplace with employers' legitimate discretion. For  [*717]  example,
one of the most common selection procedures that explicitly reproduced past
discrimination was seniority.  n227 Seniority was, and is still often, a
legitimate metric for promotion and is especially important in collective
bargaining. After the passage of Title VII, however, seniority was also often
used to keep black people from advancing to better jobs because they had not
been hired until Title VII forced employers to hire them.  n228 Despite this
obvious problem with seniority, Title VII contains an explicit carve-out for
"bona fide seniority or merit system[s]."  n229 As a result, the Supreme Court
has held that "absent a discriminatory purpose, the operation of a seniority
system cannot be an unlawful employment practice even if the system has some
discriminatory consequences."  n230 Given the inherent tension between ensuring
that past discrimination is not reproduced in future decisions and permitting
employers legitimate discretion, it should be unsurprising that, when translated
to data mining, the problem is not amenable to a clear solution.

   In fact, this difficulty is even more central to data mining. Data miners who
attempt to remove the influence of prejudice on prior decisions by recoding or
relabeling examples may find that they cannot easily resolve what the
nonprejudicial determination would have been. As Calders and
[#x017D]liobait[#x0117] point out, "[T]he notion of what is the correct label is
fuzzy."  n231 Employers are unlikely to have perfectly objective and exhaustive
standards for hiring; indeed, part of the hiring process is purposefully
subjective. At the same time, employers are unlikely to have discriminated so
completely in the past that the only explanation for rejecting an applicant was
membership in protected classes. This leaves data miners tasked with correcting
for prior prejudice with the impossible challenge of determining what the
correct subjective employment decision would have been absent prejudice. Undoing
the imprint of prejudice on the data may demand a complete rerendering of the
biased decisions rather than simply adjusting those decisions according to some
fixed statistical measure.

b. Data Collection

   Although there are some cases with obviously skewed datasets that are
relatively easy to identify and correct, often the source and degree of the bias
will not be immediately apparent.  n232 Street Bump suffered from a visually
[*718]  evident bias when the data was plotted on a map. Boston's Office of New
Urban Mechanics was therefore able to partner with "a range of academics to take
into account issues of equitable access and digital divides."  n233 In many
cases, however, an analyst can only determine the extent of--and correct
for--unintentional discrimination that results from reporting, sampling, and
selection biases if the analyst has access to information that somehow reveals
misrepresentations of protected classes in the dataset. Often, there may be no
practical alternative method for collecting information that would even reveal
the existence of a bias.

   Any attempt to correct for collection bias immediately confronts the problem
of whether or not the employer recognizes the specific type of bias that is
producing disparate results. Then, in order to correct for it, an employer must
have access to the underlying data and often an ability to collect more. Where
more data is clearly not accessible, data miners can proactively compensate for
some of the bias by oversampling underrepresented communities.  n234

   If the employer fails to be proactive or tries and fails to detect the bias
that causes the disparate impact, liability is an open question. As discussed in
Part II.B, liability partly depends on how liberally a court interprets the
requirement that an employer "refuses" to use an alternative scheme.  n235 Even
a liberal interpretation, though, would require evidence of the particular type
of discrimination at issue, coupled with evidence that such an alternative
scheme exists. Thus, finding liability seems unlikely. Worse, where such showing
is possible, there may be no easy or obvious way to remedy the situation.

   To address collection bias directly, an employer or an auditor must have
access to the underlying data and the ability to adjust the model. Congress
could require this directly of any employer using data mining techniques. Some
employers are investing in their own data now and could potentially meet such
requirements.  n236 But employers also seem happy to rely on models developed
and administered by third parties, who may have a far greater set of examples
and far richer data than any individual company.  n237 Furthermore, due to
economies of scale that are especially important in data analysis, one can
imagine that third parties specializing in work-force science will be able to
offer employers this service much less expensively than they could manage it
[*719]  themselves. If Congress attempted to demand that employers have access
to the data, it would face strong resistance from the ever-growing data analysis
industry, whose business depends on the proprietary nature of the amassed
information. More likely, Congress could require audits by a third party like
the EEOC or a private auditor, in order to protect trade secrets, but this still
seems a tall task. Ultimately, because proactive oversampling and retroactive
data correction are at least possible, collection bias has the most promising
prospects for a workable remedy of any of the identified data mining mechanisms.


3. Feature Selection

   Even in the absence of prejudice or bias, determining the proper degree of
precision in the distinctions drawn through data mining can be extremely
difficult. Under formal disparate treatment, this is straightforward: any
decision that expressly classifies by membership in a protected class is one
that draws distinctions on illegitimate grounds. It is far less clear, however,
what constitutes legitimate statistical discrimination when individuation does
not rely on proscribed criteria. In these cases, the perceived legitimacy seems
to depend on a number of factors: (1) whether the errors seem avoidable because
(2) gaining access to additional or more granular data would be trivial or (3)
would not involve costs that (4) outweigh the benefits. This seems to suggest
that the task of evaluating the legitimacy of feature selection can be reduced
to a rather straightforward cost-benefit analysis. Companies would have an
obligation to pursue ever more--and more granular--data until the costs of
gathering that data exceed the benefits conferred by the marginal improvements
in accuracy.

   Unfortunately, as is often the case with cost-benefit analyses, this approach
fails to consider how different actors will perceive the value of the supposed
benefits as well as the costs associated with errors. The obvious version of
this criticism is that "actuarially saddled" victims of inaccurate
determinations may find cold comfort in the fact that certain decisions are
rendered more reliably overall when decision makers employ data mining.  n238 A
more sophisticated version of this criticism focuses on the way such errors
assign costs and benefits to different actors at systematically different rates.
A model with any error rate that continues to turn a profit may be acceptable to
decision makers at a company, no matter the costs or inconvenience to specific
customers.  n239 Even when companies are subject to market pressures that would
[*720]  force them to compete by lowering these error rates, the companies may
find that there is simply no reason to invest in efforts that do so if the
errors happen to fall disproportionately on especially unprofitable groups of
consumers. Furthermore, assessing data mining as a matter of balancing costs and
benefits leaves no room to consider morally salient disparities in the degree to
which the costs are borne by different social groups. This raises the prospect
that there might be systematic differences in the rates at which members of
protected classes are subject to erroneous determinations.  n240 Condemning
these groups to bear the disproportionate burden of erroneous determinations
would strike many as highly objectionable, despite greater accuracy in decision
making for the majority group.  n241 Indeed, simply accepting these cost
differences as a given would subject those already in less favorable
circumstances to less accurate determinations.

   Even if companies assume the responsibility for ensuring that members of
protected classes do not fall victim to erroneous determinations at
systematically higher rates, they could find that increasing the resolution and
range of their analyses still fails to capture the causal relationships that
account for different outcomes because those relationships are not easily
represented in data.  n242 In such cases, rather than reducing the error rate
for those in protected classes, data miners could structure their analyses to
minimize the difference in error rates between groups. This solution may involve
some unattractive tradeoffs, however. In reducing the disparate impact of
errors, it may increase the overall amount of errors. In other words, generating
a model that is equally unfair to protected and unprotected classes might
increase the overall amount of unfairness.

4. Proxies

   Computer scientists have been unsure how to deal with redundant encodings in
datasets. Simply withholding these variables from the data mining exercise often
removes criteria that hold demonstrable and justifiable relevance to the
decision at hand. As Calders and [#x017D]liobait[#x0117] note, "[I]t is
problematic [to remove a correlated attribute] if the attribute to be removed
also carries some objective information about the label [quality of interest]."
n243 Part of the problem seems to be that there is no obvious way to determine
how correlated a relevant attribute must be with class membership to be
worrisome. Nor is there a self-evident way to determine when an attribute is
sufficiently relevant to justify its consideration, despite its high correlation
with class membership. As  [*721]  Professors Devin Pope and Justin Sydnor
explain, "[V]ariables are likely neither solely predictive nor purely proxies
for omitted characteristics."  n244

   But there is a bigger problem here: attempting to ensure fairly rendered
decisions by excising highly correlated criteria only makes sense if the
disparate impact happens to be an avoidable artifact of a particular way of
rendering decisions. And yet, even when denied access to these highly correlated
criteria, data mining may suggest alternative methods for rendering decisions
that still result in the same disparate impact. Focusing on isolated data points
may be a mistake because class membership can be encoded in more than one
specific and highly correlated criterion. Indeed, it is very likely that class
membership is reflected across a number of interrelated data points.  n245 But
such outcomes might instead demonstrate something more unsettling: that other
relevant criteria, whatever they are, happen to be possessed at different rates
by members of protected classes. This explains why, for instance, champions of
predictive policing have responded to critics by arguing that "[i]f you wanted
to remove everything correlated with race, you couldn't use anything. That's the
reality of life in America."  n246 Making accurate determinations means
considering factors that are somehow correlated with proscribed features.

   Computer scientists have even shown that "[r]emoving all such correlated
attributes before training does remove discrimination, but with a high cost in
classifier accuracy."  n247 This reveals a rather uncomfortable truth: the
current distribution of relevant attributes--attributes that can and should be
taken into consideration in apportioning opportunities fairly--is demonstrably
correlated with sensitive attributes because the sensitive attributes have
meaningfully conditioned what relevant attributes individuals happen to possess.
n248 As such, attempts to ensure procedural fairness by excluding certain
criteria from consideration may conflict with the imperative to ensure accurate
determinations. The only way to ensure that decisions do not systematically
disadvantage members of protected classes is to reduce the overall accuracy of
[*722]  all determinations. As Dwork et al. remark, these results "demonstrate a
quanti[t]ative trade-off between fairness and utility."  n249

   In certain contexts, data miners will never be able to fully disentangle
legitimate and proscribed criteria. For example, the workforce optimization
consultancy, Evolv, discovered that "[d]istance between home and work . . . is
strongly associated with employee engagement and retention."  n250 Despite the
strength of this finding, Evolv "never factor[s] [it] into the score given each
applicant . . . because different neighborhoods and towns can have different
racial profiles, which means that scoring distance from work could violate
equal-employment-opportunity standards."  n251 Scholars have taken these cases
as a sign that the "major challenge is how to find out which part of information
carried by a sensitive (or correlated) attribute is sensitive and which is
objective."  n252 While researchers are well aware that this may not be easy to
resolve, let alone formalize into a computable problem, there is a bigger
challenge from a legal perspective: any such undertaking would necessarily wade
into the highly charged debate over the degree to which the relatively less
favorable position of protected classes warrants the protection of
antidiscrimination law in the first instance.

   The problems that render data mining discriminatory are very rarely amenable
to obvious, complete, or welcome resolution. When it comes to setting a target
variable and feature selection, policy cannot lay out a clear path to
improvement; reducing the disparate impact will necessitate open-ended
exploration without any way of knowing when analysts have exhausted the
possibility for improvement. Likewise, policies that compel institutions to
correct tainted datasets or biased samples will make impossible demands of
analysts. In most cases, they will not be able to determine what the objective
determination should have been or independently observe the makeup of the entire
population. Dealing with both of these problems will ultimately fall to
analysts' considered judgment. Solutions that reduce the accuracy of decisions
to minimize the disparate impact caused by coarse features and unintentional
proxies will force analysts to make difficult and legally contestable
trade-offs. General policies will struggle to offer the specific guidance
necessary to determine the appropriate application of these imperfect solutions.
And even when companies voluntarily adopt such strategies, these internal
difficulties will likely allow a disparate impact to persist.

    [*723]  B. External Difficulties

   Assuming the internal difficulties can be resolved, there are further
political and constitutional restraints on addressing Title VII's inadequacies
with respect to data mining. Data mining discrimination will force a
confrontation between the two divergent principles underlying antidiscrimination
law: anticlassification and antisubordination.  n253 Which of these two
principles motivates discrimination law is a contentious debate, and making
remedies available under antidiscrimination law will require a commitment to
antisubordination principles that have thus far not been forthcoming from
legislatures. This is not merely a political concern, as substantive remediation
is becoming ever more suspect constitutionally as well.  n254 While such
remedies may be politically and legally impossible, the nature of data mining
itself makes them practically necessary. Accordingly, these external
difficulties may prevent antidiscrimination law from fully addressing data
mining discrimination.

   Two competing principles have always undergirded antidiscrimination law:
anticlassification and antisubordination. Anticlassification is the narrower of
the two, holding that the responsibility of the law is to eliminate the
unfairness individuals in certain protected classes experience due to decision
makers' choices.  n255 Antisubordination theory, in contrast, holds that the
goal of antidiscrimination law is, or at least should be, to eliminate
status-based inequality due to membership in those classes, not as a matter of
procedure, but of substance.  n256

   Different mitigation policies effectuate different rationales. Disparate
treatment doctrine arose first, clearly aligning with the anticlassification
principle by proscribing intentional discrimination, in the form of either
explicit singling out of protected classes for harm or masked intentional
discrimination. Since disparate impact developed, however, there has never been
clarity as to which of the principles it is designed to effectuate.  n257 On the
one hand, disparate impact doctrine serves anticlassification by being an
"evidentiary dragnet" used to "smoke out" well-hidden disparate treatment.  n258
On the other hand, as an effects-based doctrine, there is good reason to believe
it was intended to address substantive inequality.  n259 In this sense, the
"business  [*724]  necessity" defense is a necessary backstop that prevents
members of traditionally disadvantaged groups from simply forcing their way in
without the necessary skills or abilities.  n260

   Thus, the mapping from anticlassification and antisubordination to disparate
treatment and disparate impact was never clean. Early critics of civil rights
laws actually complained that proscribing consideration of protected class was a
subsidy to black people.  n261 This argument quickly gave way in the face of the
rising importance of the anticlassification norm.  n262 Over the years, the
anticlassification principle has come to dominate the landscape so thoroughly
that a portion of the populace thinks (as do a few Justices on the Supreme
Court) that it is the only valid rationale for antidiscrimination law.  n263

   The move away from antisubordination began only five years after disparate
impact was established in Griggs. In Washington v. Davis, the Court held that
disparate impact could not apply to constitutional claims because equal
protection only prohibited intentional discrimination.  n264 Since then, the
various affirmative action cases have overwritten the distinction between benign
and harmful categorizations of race in favor of a formalistic anticlassification
principle, removed from its origins as a tool to help members of historically
disadvantaged groups.  n265 White men can now bring disparate treatment claims.
n266 If antidiscrimination law is no longer thought to serve the purpose of
improving the relative conditions of traditionally disadvantaged groups,
antisubordination is not part of the equation.

   While the Court has clearly established that antisubordination is not part of
constitutional equal protection doctrine, that it does not mean that
antisubordination cannot animate statutory antidiscrimination law.
Antisubordination and anticlassification came into sharp conflict in Ricci v.
Destefano, a 2009 case in which the City of New Haven refused to certify a
promotion exam given to its firefighters on the grounds that it would have
produced a disparate impact based on its results.  n267 The Supreme Court held
that the refusal to certify the test, a facially race-neutral attempt to correct
for perceived disparate impact, was in fact a race-conscious remedy that
constituted disparate treatment of the majority-white firefighters who would
[*725]  have been promoted based on the exam's results.  n268 The Court held
that disparate treatment cannot be a remedy for disparate impact without a
"strong basis in evidence" that the results would lead to actual disparate
treatment liability.  n269

   Ricci was the first indication at the Supreme Court that disparate impact
doctrine could be in conflict with disparate treatment.  n270 The Court had
previously ruled in essence that the antisubordination principle could not
motivate a constitutional decision,  n271 but it had not suggested that law
effectuating that principle could itself be discriminatory against the dominant
groups. That has now changed.  n272

   The decision has two main consequences for data mining. First, where the
internal difficulties in resolving discrimination in data mining described above
can be overcome, legislation that requires or enables such resolution may run
afoul of Ricci. Suppose, for example, Congress amended Title VII to require that
employers make their training data and models auditable. In order to correct for
detected biases in the training data that result in a model with a disparate
impact, the employer would first have to consider membership in the protected
class. The remedy is inherently race-conscious. The Ricci Court did hold that an
employer may tweak a test during the "test-design stage," however.  n273 So, as
a matter of timing, data mining might not formally run into  [*726]  Ricci if
the bias resulting in a disparate impact is corrected before applied to
individual candidates. After an employer begins to use the model to make hiring
decisions, only a "strong basis in evidence" that the employer will be
successfully sued for disparate impact will permit corrective action.  n274 Of
course, unless every single model used by an employer is subject to a
prescreening audit (an idea that seems so resource intensive that it is
effectively impossible), the disparate impact will be discovered only when the
employer faces complaints. Additionally, while Ricci's holding was limited in
scope, the "strong basis in evidence" standard did not seem to be dictated by
the logic of the opinion, which illustrated a more general conflict between
disparate treatment and disparate impact.  n275

   Second, where the internal difficulties cannot be overcome, there is likely
no way to correct for the discriminatory outcomes aside from results-focused
balancing, and requiring this will pose constitutional problems. For those who
adhere to the anticlassification principle alone, such an impasse may be
perfectly acceptable. They might say that as long as employers are not
intentionally discriminating based on explicitly proscribed criteria, the chips
should fall where they may. To those who believe some measure of substantive
equality is important over and above procedural equality, this result will be
deeply unsatisfying.

   An answer to the impasse created by situations that would require
results-focused rebalancing is to reexamine the purpose of antidiscrimination
law. The major justification for reliance on formal disparate treatment is that
prejudice is simply irrational and thus unfair. But if an employer knows that
his model has a disparate impact, but it is also his most predictive, the
argument that the discrimination is irrational loses any force. Thus, data
mining may require us to reevaluate why and whether we care about not
discriminating.

   Consider another example involving tenure predictions, one in which an
employer ranks potential employees with the goal of hiring only those applicants
that the company expects to retain for longer periods of time. In optimizing its
selection of applicants in this manner, the employer may unknowingly
discriminate against women if the historical data demonstrates that they leave
their positions after fewer years than their male counterparts. If gender
accounts for a sufficiently significant difference in employee tenure, data
mining will generate a model that simply discriminates on the basis of gender or
those criteria that happen to be proxies for gender. Although selecting
applicants with an eye to retention might seem both rational and reasonable,
granting significance to predicted tenure would subject women to systematic
disadvantage if gender accounts for a good deal of the difference in tenure. If
that is the case, any data mining exercise that attempts to predict  [*727]
tenure will invariably rediscover this relationship. One solution could be for
Congress to amend Title VII to reinvigorate strict business necessity.  n276
This would allow a court to accept that relying on tenure is rational but not
strictly "necessary" and that perhaps other factors could make up for the lack
of predicted tenure.

   But this solution and all others must rely on the antisubordination
principle. Consider this question: should the law permit a company to hire no
women at all--or none that it correctly predicts will depart following the birth
of a child--because it is the most rational choice according to their model?
n277 The answer seems obviously to be no. But why not? What forms the basis for
law's objection to rational decisions, based on seemingly legitimate criteria,
that place members of protected classes at systematic disadvantage? The Supreme
Court has observed that, "Title VII requires employers to treat their employees
as individuals, not 'as simply components of a racial, religious, sexual, or
national class.'"  n278 On the strength of that statement, the Court held that
employers could not force women to pay more into an annuity because they, as
women, were likely to live longer.  n279 But it is not clear that this reasoning
translates directly to data mining. Here, the model takes a great deal of data
about an individual, and while it does make a determination based on statistics,
it will make a different one if analyzing two different women. So if the model
said to hire no women, it would be illegal, but, according to the doctrine,
perhaps only because every woman ends up with the same result.

   The only escape from this situation may be one in which the relevance of
gender in the model is purposefully ignored and all factors correlated with
gender are suppressed. The outcome would be a necessarily less accurate model.
The justification for placing restrictions on employers, and limiting the
effectiveness of their data mining, would have to depend on an entirely
different set of arguments than those advanced to explain the wrongfulness of
biased data collection, poorly labeled examples, or an impoverished set of
features. Here, shielding members of protected classes from less favorable
treatment is not justified by combatting prejudice or stereotyping. In other
words, any prohibition in this case could not rest on a procedural commitment to
ensuring ever more accurate determinations. Instead, the prohibition would have
to rest on a substantive commitment to equal representation of women in the
workplace. That is, it would have to rest on a principle of antisubordination.
[*728]  The dilemma is clear: the farther the doctrine gets from substantive
remediation, the less utility it has in remedying these kinds of discriminatory
effects.  n280 But the more disparate impact is thought to embody the
antisubordination principle--as opposed to the "evidentiary dragnet" in service
of the anticlassification norm--the more it will invite future constitutional
challenges.  n281

   This also raises a point about disparate treatment and data mining. Within
data mining, the effectiveness of prohibiting the use of certain information
exists on a spectrum. On one end, the prohibition has little to no effect
because either the information is redundantly encoded or the results do not vary
along lines of protected class. On the other end, the prohibition reduces the
accuracy of the models. That is, if protected class data were not prohibited,
that information would alter the results, presumably by making members of
protected classes worse (or, in some cases, better) off. Thus, as a natural
consequence of data mining, a command to ignore certain data has either no
effect  n282 or the effect of altering the fortunes of those protected classes
in substantive ways. Therefore, with respect to data mining, due to the zero-sum
nature of a ranking system, even disparate treatment doctrine is a reallocative
remedy similar to affirmative action.  n283 Once again, this erodes the
legitimate rationale for on the one hand supporting an anticlassification
principle but on the other, holding fast against antisubordination in this
context. The two principles tend to accomplish the same thing, but one is less
effective at achieving substantive equality.

   This reveals that the pressing challenge does not lie with ensuring
procedural fairness through a more thorough stamping out of prejudice and bias
but rather with developing ways of reasoning to adjudicate when and what amount
of disparate impact is tolerable. Abandoning a belief in the efficacy of
procedural solutions leaves policy makers in an awkward position because there
is no definite or consensus answer to questions about the fairness of specific
outcomes. These need to be worked out on the basis of different normative
principles. At some point, society will be forced to acknowledge that this is
really a discussion about what constitutes a tolerable level of disparate impact
in employment. Under the current constitutional order and in the political
climate, it is tough to even imagine having such a conversation. But, until that
happens, data mining will be permitted to exacerbate existing inequalities in
difficult-to-counter ways.

    [*729]  CONCLUSION

   This Essay has identified two types of discriminatory outcomes from data
mining: a family of outcomes where data mining goes "wrong" and outcomes where
it goes too "right." Data mining can go wrong in any number of ways. It can
choose a target variable that correlates to protected class more than others
would, reproduce the prejudice exhibited in the training examples, draw adverse
lessons about protected classes from an unrepresentative sample, choose too
small a feature set, or not dive deep enough into each feature. Each of these
potential errors is marked by two facts: the errors may generate a manifest
disparate impact, and they may be the result of entirely innocent choices made
by data miners.

   Where data mining goes "right," data miners could not have been any more
accurate given the starting point of the process. This very accuracy, exposing
an uneven distribution of attributes that predict the target variable, gives
such a result its disparate impact. If the data accurately models inequality,
attempts to devise an alternative way of making the same prediction will only
narrow the disparate impact if these efforts reduce the accuracy of the decision
procedure. By now, it should be clear that Title VII, and very likely other
similarly process-oriented civil rights laws, cannot effectively address this
situation.

   This means something different for the two families, and it should be
slightly more surprising for the former. At a high level of abstraction, where a
decision process goes "wrong" and this wrongness creates a disparate impact,
Title VII and similar civil rights laws should be up to the task of solving the
problem; that is ostensibly their entire purpose. But aside from a few more
obvious cases involving manifest biases in the dataset, it is quite difficult to
determine ahead of time what "correct" data mining looks like. A decision maker
can rarely discover that the choice of a particular target variable is more
discriminatory than other choices until after the fact, at which point it may be
difficult and costly to change course. While data miners might have some
intuitions about the influence that prejudice or bias played in the prior
decisions that will serve as training data, data miners may not have any
systematic way of measuring and correcting for that influence. And even though
ensuring reliable samples before training a model is a possibility, the data may
never be perfect. It may be impossible to determine, ex ante, how much the bias
contributes to the disparate impact, it may not be obvious how to collect
additional data that makes the sample more representative, and it may be
prohibitively expensive to do so. Companies will rarely be able to resolve these
problems completely; their models will almost always suffer from some deficiency
that results in a disparate impact. A standard that holds companies liable for
any amount of theoretically avoidable disparate impact is likely to ensnare all
companies. Thus, even at this level of abstraction, it becomes clear that
holding the decision makers responsible for these disparate impacts is at
[*730]  least partly troubling from a due process perspective. Such concerns may
counsel against using data mining altogether. This would be a perverse outcome,
given how much even imperfect data mining can do to help reduce the very high
rates of discrimination in employment decisions.

   If liability for getting things "wrong" is difficult to imagine, how does
liability for getting things "right" make any more sense? That proxy
discrimination largely rediscovers preexisting inequalities suggests that
perhaps Title VII is not the appropriate remedial vehicle. If what is at stake
are the results of decades of historical discrimination and wealth concentration
that have created profound inequality in society, is that not too big a problem
to remedy through individual lawsuits, assuming affirmative action and similar
policies are off the table? Thus, perfect data mining forces the question: if
employers can say with certainty that, given the status quo,  n284 candidates
from protected classes are on average less ready for certain jobs than more
privileged candidates, should employers specifically be penalized for hiring
fewer candidates from protected classes?

   Doctrinally, the answer is yes, to some extent. Professor Christine Jolls has
written that disparate impact doctrine is akin to accommodation in disability
law--that is, both accommodations and disparate impact specifically require
employers to depart from pure market rationality and incur costs associated with
employing members of protected classes.  n285 Similarly, the Title VII annuity
cases  n286 and Title VII's ban on following racist third-party preferences
n287 each require a departure from market rationality. Thus, Title VII makes
that decision to a degree. But to what degree? How much cost must an employer
bear?

Title VII does not require an employer to use the least discriminatory means of
running a business.  n288 Likewise, Title VII does not aim to remedy historical
discrimination and current inequality by imposing all the costs of restitution
and redistribution on individual employers.  n289 It is more appropriately
understood as a standard of defensible disparate impact. One route, then, to
addressing the problems is to make the inquiry more searching and put the burden
on the employer to avoid at least the easy cases. In a system that is as
unpredictable as data mining can be, perhaps the proper way of  [*731]  thinking
about the solution is a duty of care, a theory of negligent discrimination.
n290

   But if Title VII alone cannot solve these problems, where should society look
for answers? Well, the first answer is to question the status quo. Data mining
takes the existing state of the world as a given and ranks candidates according
to their predicted attributes in that world. Data mining, by its very nature,
treats the target variable as the only item that employers are in a position to
alter; everything else that happens to correlate with different values for the
target variable is assumed stable. But there are many reasons to question these
background conditions. Sorting and selecting individuals according to their
apparent qualities hides the fact that the predicted effect of possessing these
qualities with respect to a specific outcome is also a function of the
conditions under which these decisions are made. Recall the tenure example from
Part III.B. In approaching appropriate hiring practices as a matter of selecting
the "right" candidates at the outset, an employer will fail to recognize
potential changes that he could make to workplace conditions. A more
family-friendly workplace, greater on-the-job training, or a workplace culture
more welcoming to historically underrepresented groups could affect the course
of employees' tenure and their long-term success in ways that undermine the
seemingly prophetic nature of data mining's predictions.

   These are all traditional goals for reducing discrimination within the
workplace, and they continue to matter even in the face of the eventual
widespread adoption of data mining. But data can play a role here, too. For
example, comparing the performance of equally qualified candidates across
different workplaces can help isolate the formal policies and institutional
dynamics that are more or less likely to help workers flourish. Research of this
sort could also reveal areas for potential reform.  n291

   Education is also important. Employers may take some steps to rectify the
problem on their own if they better understand the cause of the disparity. Right
now, many of the problems described in Part I are relatively unknown. But the
more employers and data miners understand these pitfalls, the more they can
strive to create better models on their own. Many employers switch to
data-driven practices for the express purpose of eradicating bias;  n292 if
employers discover that they are introducing new forms of bias, they can correct
course.

   Even employers seeking only to increase efficiency or profit may find that
their incentives align with the goals of nondiscrimination. Faulty data and data
[*732]  mining will lead employers to overlook or otherwise discount people who
are actually "good" employees. Where the cost of addressing these problems is at
least compensated for by a business benefit of equal or greater value, employers
may have natural incentives to do so.

   Finally, employers could also make more effective use of the tools that
computer scientists have begun to develop.  n293 Advances in these areas will
depend, crucially, on greater and more effective collaboration between
employers, computer scientists, lawyers, advocates, regulators, and policy
makers.  n294

   This Essay is a call for caution in the use of data mining, not its
abandonment. While far from a panacea, data mining can and should be part of a
panoply of strategies for combatting discrimination in the workplace and for
promoting fair treatment and equality. Ideally, institutions can find ways to
use data mining to generate new knowledge and improve decision making that
serves the interests of both decision makers and protected classes. But where
data mining is adopted and applied without care, it poses serious risks of
reproducing many of the same troubling dynamics that have allowed discrimination
to persist in society, even in the absence of conscious prejudice.

Legal Topics:

For related research and practice materials, see the following legal topics:
Computer & Internet LawOnline AdvertisingSpam EmailLabor & Employment
LawDiscriminationDisparate ImpactEmployment PracticesSelection ProceduresNeutral
FactorsLabor & Employment LawDiscriminationDisparate ImpactProofStatistical
Evidence

FOOTNOTES:





n1  Contra Sanjeev Sardana, Big Data: It's Not a Buzzword, It's a Movement,
FORBES (Nov. 20, 2013),
http://www.forbes.com/sites/sanjeevsardana/2013/11/20/bigdata
[https://perma.cc/9Y37-ZFT5].





n2  Tanzina Vega, New Ways Marketers Are Manipulating Data to Influence You,
N.Y. TIMES: BITS (June 19, 2013, 9:49 PM),
http://bits.blogs.nytimes.com/2013/06/19/new-ways-marketers-are-manipulating-dat
a-to-influence-you [https://perma.cc/238F-9T8X].





n3  Nell Greenfieldboyce, Big Data Peeps at Your Medical Records to Find Drug
Problems, NPR (July 21, 2014, 5:15 AM),
http://www.npr.org/blogs/health/2014/07/21/332290342/big-data-peeps-at-your-medi
cal-records-to-find-drug-problems [https://perma.cc/GMT4-ECBD].





n4  Business by Numbers, ECONOMIST (Sept. 13, 2007),
http://www.economist.com/node/9795140 [https://perma.cc/7YC2-DMYA].





n5  Nadya Labi, Misfortune Teller, ATLANTIC (Jan.--Feb. 2012),
http://www.theatlantic.com/ magazine/archive/2012/01/misfortune-teller/308846
[https://perma.cc/7L72-J5L9].





n6  David Lazer et al., Computational Social Science, 323 SCI. 721, 722 (2009).





n7  Devah Pager & Hana Shepherd, The Sociology of Discrimination: Racial
Discrimination in Employment, Housing, Credit, and Consumer Markets, 34 ANN.
REV. SOC. 181, 182 (2008).





n8  Id.





n9  See Andrew Grant-Thomas & john a. powell, Toward a Structural Racism
Framework, 15 POVERTY & RACE 3, 4 ("'Institutional racism' was the designation
given in the late 1960s to the recognition that, at very least, racism need not
be individualist, essentialist or intentional.").





n10  An "algorithm" is a formally specified sequence of logical operations that
provides step-by-step instructions for computers to act on data and thus
automate decisions. SOLON BAROCAS ET AL., DATA & CIVIL RIGHTS: TECHNOLOGY PRIMER
(2014), http://www.datacivilrights.org/pubs/2014-1030/Technology.pdf
[https://perma.cc/X3YX-XHNA]. Algorithms play a role in both automating the
discovery of useful patterns in datasets and automating decision making that
relies on these discoveries. This Essay uses the term to refer to the latter.





n11  See, e.g., Kate Crawford & Jason Schultz, Big Data and Due Process: Toward
a Framework to Redress Predictive Privacy Harms, 55 B.C. L. REV. 93, 101 (2014)
("[H]ousing providers could design an algorithm to predict the [race, gender, or
religion] of potential buyers or renters and advertise the properties only to
those who [meet certain] profiles."); Danielle Keats Citron & Frank Pasquale,
The Scored Society: Due Process for Automated Predictions, 89 WASH. L. REV. 1, 4
(2014) ("Because human beings program predictive algorithms, their biases and
values are embedded into the software's instructions. . . ."); Danielle Keats
Citron, Technological Due Process, 85 WASH. U. L. REV. 1249, 1254 (2008)
("Programmers routinely change the substance of rules when translating them from
human language into computer code.").





n12  EXEC. OFFICE OF THE PRESIDENT, BIG DATA: SEIZING OPPORTUNITIES, PRESERVING
VALUES (May 2014),
http://www.whitehouse.gov/sites/default/files/docs/big_data_privacy_report_5.1.1
4_final_print.pdf [https://perma.cc/ZXB4-SDL9].





n13  Id. (introductory letter).





n14  Id. at 64 ("This combination of circumstances and technology raises
difficult questions about how to ensure that discriminatory effects resulting
from automated decision processes, whether intended or not, can be detected,
measured, and redressed.").





n15  Id. at 65.





n16  Steve Lohr, Big Data, Trying to Build Better Workers, N.Y. TIMES (Apr. 20,
2013),
http://www.nytimes.com/2013/04/21/technology/big-data-trying-to-build-better-wor
kers.html [https://perma.cc/CEL2-P9XB].





n17  Tal Z. Zarsky, Automated Prediction: Perception, Law, and Policy, COMM.
ACM, Sept. 2012, at 33-35.





n18  Solon Barocas, Data Mining and the Discourse on Discrimination, PROC. DATA
ETHICS WORKSHOP (2014),
https://dataethics.github.io/proceedings/DataMiningandtheDiscourseOnDiscriminati
on.pdf [https://perma.cc/D3LT-GS2X].





n19  See generally Usama Fayyad, The Digital Physics of Data Mining, 44 COMM.
ACM, Mar. 2001, at 62.





n20  More formally, classification deals with discrete outcomes, estimation
deals with continuous variables, and prediction deals with both discrete
outcomes and continuous variables, but specifically for states or values in the
future. MICHAEL J. A. BERRY & GORDON S. LINOFF, DATA MINING TECHNIQUES: FOR
MARKETING, SALES, AND CUSTOMER RELATIONSHIP MANAGEMENT 8-11 (2004).





n21  Pedro Domingos, A Few Useful Things to Know About Machine Learning, COMM.
ACM, Oct. 2012, at 78-80.





n22  Id.





n23  Id.





n24  COMM. ON THE ANALYSIS OF MASSIVE DATA ET AL., FRONTIERS IN MASSIVE DATA
ANALYSIS 101 (2013), http://www.nap.edu/catalog.php?record_id=18374
[https://perma.cc/5DNQ-UFE4]. The machine learning community refers to
classification, estimation, and prediction--the techniques that we discuss in
this Essay as "supervised" learning because analysts must actively specify a
target variable of interest. Id. at 104. Other techniques known as
"unsupervised" learning do not require any such target variables and instead
search for general structures in the dataset, rather than patterns specifically
related to some state or outcome. Id. at 102. Clustering is the most common
example of "unsupervised" learning, in that clustering algorithms simply reveal
apparent hot spots when plotting the data in some fashion. Id. We limit the
discussion to supervised learning because we are primarily concerned with the
sorting, ranking, and predictions enabled by data mining.





n25  PETE CHAPMAN ET AL., CRISP-DM 1.0: STEP-BY-STEP DATA MINING GUIDE 10
(2000).





n26  See David J. Hand, Classifier Technology and the Illusion of Progress, 21
STAT. SCI. 1, 10 (2006).





n27  Though described as a matter of detection, this is really a classification
task, where any given transaction or email can belong to one of two possible
classes, respectively: fraud or not fraud, or spam or not spam.





n28  See generally Martha Ann Poon, What Lenders See A History of the Fair Isaac
Scorecard, (2013) (unpublished Ph.D. dissertation, University of California, San
Diego), http://search.proquest.com/docview/1520318884
[https://perma.cc/YD3S-B9N7].





n29  Hand, supra note 26, at 10.





n30  Joseph M. Stauffer & M. Ronald Buckley, The Existence and Nature of Racial
Bias in Supervisory Ratings, 90 J. APPLIED PSYCHOL. 586, 588-89 (2005) (showing
evidence of racial bias in performance evaluations). Nevertheless, devising new
target variables can have the salutary effect of forcing decision makers to
think much more concretely about the outcomes that justifiably determine whether
someone is a "good" employee. The explicit enumeration demanded of data mining
thus also presents an opportunity to make decision making more consistent, more
accountable, and fairer overall. This, however, requires conscious effort and
careful thinking, and is not a natural consequence of adopting data mining.





n31  Bruce Schneier, Data Mining for Terrorists, SCHNEIER ON SECURITY (Mar. 9,
2006), https://www.schneier.com/blog/archives/2006/03/data_mining_for.html
[https://perma.cc/ZW44-N2KR]; Oscar H. Gandy Jr., Engaging Rational
Discrimination: Exploring Reasons for Placing Regulatory Constraints on Decision
Support Systems, 12 ETHICS & INFO. TECH. 29, 39-40 (2010); Mireille Hildebrandt
& Bert-Jaap Koops, The Challenges of Ambient Law and Legal Protection in the
Profiling Era, 73 MOD. L. REV. 428, 433-35 (2010).





n32  See infra Part I.B.





n33  Bart Custers, Data Dilemmas in the Information Society: Introduction and
Overview, in DISCRIMINATION AND PRIVACY IN THE INFORMATION SOCIETY 3, 20 (Bart
Custers et al. eds., 2013).





n34  Hand, supra note 26, at 10-11.





n35  Id. at 10 ("The classical supervised classification paradigm also takes as
fundamental the fact that the classes are well defined. That is, that there is
some fixed clear external criterion, which is used to produce the class labels.
In many situations, however, this is not the case. In particular, when the
classes are defined by thresholding a continuous variable, there is always the
possibility that the defining threshold might be changed. Once again, this
situation arises in consumer credit, where it is common to define a customer as
'defaulting' if they fall three months in arrears with repayments. This
definition, however, is not a qualitative one (contrast has a tumor/does not
have a tumor) but is very much a quantitative one. It is entirely reasonable
that alternative definitions (e.g., four months in arrears) might be more useful
if economic conditions were to change.").





n36  Id. at 11.





n37  Id. at 12. Even when evaluating a model, the kinds of subtle
mischaracterizations that happen during training will be impossible to detect
because most "evaluation data" is just a small subset of the training data that
has been withheld during the learning process. Any problems with the training
data will be present in the evaluation data.





n38  Stella Lowry & Gordon Macpherson, A Blot on the Profession, 296 BRIT. MED.
J. 657, 657 (1988).





n39  Id. at 657.





n40  Id.





n41  Latanya Sweeney, Discrimination in Online Ad Delivery, COMM. ACM, May 2013,
at 44, 47 (2013).





n42  Id. at 48, 52.





n43  Check and Understand Quality Score, GOOGLE,
https://support.google.com/adwords/answer/2454010?hl=en
[https://perma.cc/A88T-GF8X] (last visited July 26, 2014).





n44  Sweeney, supra note 41, at 52.





n45  The fact that black people may be convicted of crimes at a higher rate than
nonblack people does not explain why those who search for black-sounding names
would be any more likely to click on advertisements that mention an arrest
record than those who see the same exact advertisement when they search for
white-sounding names. If the advertisement implies, in both cases, that a person
of that particular name has an arrest record, as Sweeney shows, the only reason
the advertisements keyed to black-sounding names should receive greater
attention is if searchers confer greater significance to the fact of prior
arrests when the person happens to be black. Id. at 53.





n46  Dan Woods, LinkedIn's Monica Rogati on "What Is a Data Scientist?," FORBES
(Nov. 27, 2011),
http://www.forbes.com/sites/danwoods/2011/11/27/linkedins-monica-rogati-on-what-
is-a-data-scientist [https://perma.cc/N9HT-BXU3].





n47  Data quality is a topic of lively practical and philosophical debate. See,
e.g., Luciano Floridi, Information Quality, 26 PHIL. & TECH. 1 (2013); Richard
Y. Wang & Diane M. Strong, Beyond Accuracy: What Data Quality Means to Data
Consumers, 12 J. MGMT. INFO. SYS. 5 (1996). The components of data quality have
been thought to include accuracy, precision, completeness, consistency,
validity, and timeliness, though this catalog of features is far from settled.
See generally LARRY P. ENGLISH, INFORMATION QUALITY APPLIED (2009).





n48  Cf. Zeynep Tufekci, Big Questions for Social Media Big Data:
Representativeness, Validity and Other Methodological Pitfalls, EIGHTH INT'L
AAAI CONF. WEBLOGS & SOC. MEDIA (2014),
http://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewFile/8062/8151
[https://perma.cc/G4G7-2VZ8].





n49  See, e.g., FED. TRADE COMM'N, REPORT TO CONGRESS UNDER SECTION 319 OF THE
FAIR AND ACCURATE CREDIT TRANSACTIONS ACT OF 2003 A-4 (2012) (finding that
nearly 20 percent of consumers had an error in one or more of their three credit
reports and that 5.4 percent of consumers had errors that could result in less
favorable loan terms).





n50  Jonas Lerman, Big Data and Its Exclusions, 66 STAN. L. REV.ONLINE 55, 57
(2013).





n51  Kate Crawford, Think Again: Big Data, FOREIGN POL'Y (May 10, 2013),
http://www.foreignpolicy.com/articles/2013/05/09/think_again_big_data
[https://perma.cc/S9ZA-XEXH].





n52  See id.; Lerman, supra note 50, at 57.





n53  Crawford, supra note 51 (explaining that a sudden movement suggesting a
broken road will automatically prompt the phone to report the location to the
city).





n54  Id.





n55  See id.





n56  This is, of course, a more general problem with representative democracy.
For a host of reasons, the views and interests of the poor are relatively less
well represented in the political process. See, e.g., Larry M. Bartels, Economic
Inequality and Political Representation, in THE UNSUSTAINABLE AMERICAN STATE 167
(Lawrence Jacobs & Desmond King eds., 2009); MARTIN GILENS, AFFLUENCE AND
INFLUENCE: ECONOMIC INEQUALITY AND POLITICAL POWER IN AMERICA (2012). The worry
here, as expressed by Crawford, is that, for all its apparent promise, data
mining may further obfuscate or legitimize these dynamics rather than overcome
them.





n57  Why Do We Need E-RACE?, EQUAL EMPLOY. OPPORTUNITY COMM'N,
http://www1.eeoc.gov/eeoc/initiatives/e-race/why_e-race.cfm
[https://perma.cc/S3GY-2MD6] (last visited Mar. 1, 2013). Due to the so-called
"digital divide," communities underserved by residential Internet access rely
heavily on mobile phones for connectivity and thus often have trouble even
uploading and updating traditional résumés. Kathryn Zickuhr & Aaron Smith,
Digital Differences, PEW RES. CTR. (Apr. 13, 2012),
http://www.pewinternet.org/2012/04/13/digital-differences
[https://perma.cc/S545-42GY] ("Among smartphone owners, young adults,
minorities, those with no college experience, and those with lower household
income levels are more likely than other groups to say that their phone is their
main source of internet access.").





n58  Data mining scholars have devised ways to address this known problem, but
applying these techniques is far from trivial. See Sinno Jialin Pan & Qiang
Yang, A Survey on Transfer Learning, 22 IEEE TRANSACTIONS ON KNOWLEDGE &DATA
ENG'G 1345, 1354-56 (2010).





n59  Hand, supra note 26, at 7.





n60  David Lazer, Big Data and Cloning Headless Frogs, COMPLEXITY & SOC.
NETWORKS BLOG (Feb. 16, 2014),
https://web.archive.org/web/20140711164511/http://blogs.iq.harvard.edu/netgov/20
14/02/big_data_and_cloning_headless.html [https://perma.cc/TQ9A-TP2Z].





n61  Lerman, supra note 50, at 59.





n62  Practitioners, particularly those involved in credit scoring, are well
aware that they do not know how the person purposefully passed over would have
behaved if he had been given the opportunity. Practitioners have developed
methods to correct for this bias (which, in the case of credit scoring, they
refer to as reject inference). See, e.g., Jonathan Crook & John Banasik, Does
Reject Inference Really Improve the Performance of Application Scoring Models?,
28 J. BANKING & FIN. 857 (2004).





n63  FEATURE EXTRACTION, CONSTRUCTION AND SELECTION 71-72 (Huan Liu & Hiroshi
Motoda eds., 1998).





n64  Toon Calders & Indr[#x117] [#x17D]liobait[#x117], Why Unbiased
Computational Processes Can Lead to Discriminative Decision Procedures, in
DISCRIMINATION AND PRIVACY IN THE INFORMATION SOCIETY, supra note 33, at 43, 46
("[T]he selection of attributes by which people are described in [a] database
may be incomplete.").





n65  Annamarie Carusi, Data as Representation: Beyond Anonymity in E-Research
Ethics, 1 INT'L J. INTERNET RES. ETHICS 37, 48-61 (2008).





n66  Calders & [#x17D]liobait[#x117], supra note 64, at 47.





n67  FREDERICK SCHAUER, PROFILES, PROBABILITIES, AND STEREOTYPES 3-7 (2006).
Insurance offers the most obvious example of this: the rate that a person pays
for car insurance, for instance, is determined by the way other people with
similar characteristics happen to drive, even if the person is a better driver
than those who resemble him on the statistically pertinent dimensions.





n68  Kasper Lippert-Rasmussen, "We Are All Different": Statistical
Discrimination and the Right to Be Treated as an Individual, 15 J. ETHICS 47, 54
(2011) ("[O]btaining information is costly, so it is morally justified, all
things considered, to treat people on the basis of statistical generalizations
even though one knows that, in effect, this will mean that one will treat some
people in ways, for better or worse, that they do not deserve to be treated.");
see also Brian Dalessandro, Claudia Perlich & Troy Raeder, Bigger Is Better, but
at What Cost?: Estimating the Economic Value of Incremental Data Assets, 2 BIG
DATA 87 (2014).





n69  See Matt Richtel, How Big Data Is Playing Recruiter for Specialized Workers
, N.Y. TIMES (Apr. 28, 2013),
http://www.nytimes.com/2013/04/28/technology/how-big-data-is-playing-recruiter-f
or-specialized-workers.html [https://perma.cc/DC7A-W2B5].





n70  As one commentator has put it in contemplating data-driven hiring, "Big
Data has its own bias. . . . You measure what you can measure." Id.





n71  See generally DAVID M. P. FREUND, COLORED PROPERTY: STATE POLICY AND WHITE
RACIAL POLITICS IN SUBURBAN AMERICA (2010).





n72  Id.





n73  While animus was likely the main motivating factor for redlining, the
stated rationales were economic and about housing value. See DOUGLAS S. MASSEY &
NANCY A. DENTON, AMERICAN APARTHEID: SEGREGATION AND THE MAKING OF THE
UNDERCLASS 51-52 (1993). Redlining persists today and may actually be motivated
by profit, but it has the same deleterious effects. See Rachel L. Swarns, Biased
Lending Evolves, and Blacks Face Trouble Getting Mortgages, N.Y. TIMES (Oct. 30
2015), http://www.nytimes.com/2015/10/31/nyregion/hudson-city-bank-settlement.
html [https://perma.cc/P4YX-NTT9].





n74  See Nationwide Mut. Ins. Co. v. Cisneros, 52 F.3d 1351, 1359 (6th Cir.
1995) (holding that the Fair Housing Act prohibited redlining in order "to
eliminate the discriminatory business practices which might prevent a person
economically able to do so from purchasing a house regardless of his race");
NAACP v. Am. Family Mut. Ins. Co., 978 F.2d 287, 300 (7th Cir. 1992).





n75  See generally Andrea Romei & Salvatore Ruggieri, Discrimination Data
Analysis: A Multi-Disciplinary Bibliography, in DISCRIMINATION AND PRIVACY IN
THE INFORMATION SOCIETY, supra note 33, at 109, 120.





n76  Lior Jacob Strahilevitz, Privacy Versus Antidiscrimination, 75 U. CHI. L.
REV. 363, 364 (2008).





n77  Id. This argument assumes that criminal records are relevant to employment,
which is often not true. See infra text accompanying note 175.





n78  Strahilevitz, supra note 76, at 364; see also infra Part II.A. The law
holds that decision makers should refrain from considering membership in a
protected class even if statistical evidence seems to support certain inferences
on that basis. The prohibition does not depend on whether decision makers can
gain (easy or cheap) access to alternative criteria that hold greater predictive
value. See Grutter v. Bollinger, 539 U.S. 306, 326 (2003).





n79  Romei & Ruggieri, supra note 75, at 121.





n80  Faisal Kamiran, Toon Calders & Mykola Pechenizkiy, Techniques for
Discrimination-Free Predictive Models, in DISCRIMINATION AND PRIVACY IN THE
INFORMATION SOCIETY, supra note 33, at 223-24.





n81  Cynthia Dwork et al., Fairness Through Awareness, 3 PROC. INNOVATIONS
THEORETICAL COMPUTER SCI. CONF. 214 app. at 226 (2012) ("Catalog of Evils").





n82  See id. (discussing the "[s]elf-fulfilling prophecy").





n83  See Solon Barocas, Leaps and Bounds: Toward a Normative Theory of
Inferential Privacy 9 (Nov. 11, 2015) (in-progress and unpublished manuscript)
(on file with authors).





n84  Id. at 9-13.





n85  Data miners who wish to discriminate can do so using relevant or irrelevant
criteria. Either way the intent would make the action "masking." If an employer
masked using highly relevant data, litigation arising from it likely would be
tried under a "mixed-motive" framework, which asks whether the same action would
have been taken without the intent to discriminate. See infra Part II.A.





n86  See, e.g., Custers, supra note 33, at 9-10.





n87  See Barocas, supra note 83.





n88  See, e.g., Alistair Croll, Big Data Is Our Generation's Civil Rights Issue,
and We Don't Know It, SOLVE FOR INTERESTING (July 31, 2012, 12:40 PM),
http://solveforinteresting.com/big-data-is-our-generations-civil-rights-issue-an
d-we-dont-know-it [https://perma.cc/BS8S-6T7S]. This post generated significant
online chatter immediately upon publication and has become one of the canonical
texts in the current debate. It has also prompted a number of responses from
scholars. See, e.g., Anders Sandberg, Asking the Right Questions: Big Data and
Civil Rights, PRAC. ETHICS (Aug. 16, 2012),
http://blog.practicalethics.ox.ac.uk/2012/08/asking-the-right-questions-big-data
-and-civil-rights [https://perma.cc/NC36-NBZN].





n89  See Linda Hamilton Krieger, The Content of Our Categories: A Cognitive Bias
Approach to Discrimination and Equal Employment Opportunity, 47 STAN. L. REV.
1161, 1177 (1995).





n90  The biggest difference between the Americans with Disabilities Act and
Title VII is the requirement that an employer make "reasonable accommodations"
for disabilities. 42 U.S.C. § 12112(b)(5) (2012). But some scholars have argued
that even this difference is illusory and that accommodations law is
functionally similar to Title VII, though worded differently. See Samuel R.
Bagenstos, "Rational Discrimination," Accommodation, and the Politics of
(Disability) Civil Rights, 89 VA. L. REV. 825, 833 & n.15 (2003) (comparing
accommodations law to disparate treatment); Christine Jolls, Antidiscrimination
and Accommodation, 115 HARV. L. REV. 642, 652 (2001) (comparing accommodations
law to disparate impact).





n91  See 42 U.S.C. § 2000e; Ricci v. DeStefano, 557 U.S. 557, 577 (2009).





n92  Richard A. Primus, The Future of Disparate Impact, 108 MICH. L. REV. 1341,
1351 n.56 (2010) (explaining that, for historical reasons, disparate treatment
became essentially "not-disparate-impact" and now we rarely notice the two
different embedded theories).





n93  See Griggs v. Duke Power Co., 401 U.S. 424, 430 (1971).





n94  42 U.S.C. § 2000e-2(k).





n95  Id. § 2000e-2(a), (k); see Primus, supra note 92, at 1350-51 n.56.





n96  Michelle R. Gomez, The Next Generation of Disparate Treatment: A Merger of
Law and Social Science, 32 REV. LITIG. 553, 562 (2013).





n97  Strahilevitz, supra note 76, at 365-67.





n98  Richard A. Primus, Equal Protection and Disparate Impact: Round Three, 117
HARV. L. REV. 494, 504 (2003).





n99  See Jed Rubenfeld, Affirmative Action, 107 YALE L.J. 427, 433 (1997)
(discussing "[c]lassificationism"); Primus, supra note 98, at 504, 567-68
(discussing expressive harms).





n100  Membership in a protected class is still a permissible input to a holistic
determination when the focus is diversity, but where classification is the goal,
such as here, it is not. See Grutter v. Bollinger, 539 U.S. 306, 325 (2003)
(noting that "diversity is a compelling state interest" that can survive strict
scrutiny).





n101  That is, not counting any expressive harm that might come from
classification by protected class.





n102  McDonnell Douglas Corp. v. Green, 411 U.S. 792 (1973); Price Waterhouse v.
Hopkins, 490 U.S. 228 (1989).





n103  This is similar to the computer science definition of discrimination.
Calders & [#x17D]liobait?, supra note 64, at 49. ("A classifier discriminates
with respect to a sensitive attribute, e.g. gender, if for two persons which
only differ by their gender (and maybe some characteristics irrelevant for the
classification problem at hand) that classifier predicts different labels.").





n104  St. Mary's Honor Ctr. v. Hicks, 509 U.S. 502, 507 (1993).





n105  Id.





n106  See Keyes v. Sec'y of the Navy, 853 F.2d 1016, 1026 (1st Cir. 1988)
(explaining that it is the plaintiff's burden to show that the proffered reasons
for hiring an alternative were "pretexts aimed at masking sex or race
discrimination"); Custers, supra note 33, at 9-10; Megan Whitehill, Better Safe
than Subjective: The Problematic Intersection of Prehire Social Networking
Checks and Title VII Employment Discrimination, 85 TEMP. L. REV. 229, 250 (2012)
(referring to "[m]asking [p]retext" in the third stage of McDonnell-Douglas
framework).





n107  See supra Part I.E. This is a familiar problem to antidiscrimination law,
and it is often cited as one of the rationales for disparate impact liability in
the first place--to "smoke out" intentional invidious discrimination. See infra
Part III.B.





n108  McDonnell Douglas Corp. v. Green, 411 U.S. 792, 805 (1973) (The plaintiff
"must be given a full and fair opportunity to demonstrate by competent evidence
that the presumptively valid reasons for his rejection were in fact a coverup
for a racially discriminatory decision"). While, as a theoretical matter, the
plaintiff must prove that the employer's reason was a pretext for discrimination
specifically, the Supreme Court has held that a jury can reasonably find that
the fact that an employer had only a pretextual reason to fall back on is itself
circumstantial evidence of discrimination.  Hicks, 509 U.S. at 511 ("The
factfinder's disbelief of the reasons put forward by the defendant (particularly
if disbelief is accompanied by a suspicion of mendacity) may, together with the
elements of the prima facie case, suffice to show intentional discrimination.").





n109  See Tristin K. Green, Discrimination in Workplace Dynamics: Toward a
Structural Account of Disparate Treatment Theory, 38 HARV. C.R.-C.L. L. REV. 91,
114 (2003) ("Presuming that individuals know the real reason for their actions,
the pretext model of disparate treatment provides that an employer can be held
to have discriminated when the plaintiff establishes a minimal prima facie case
and shows that the reason given for the adverse decision is unworthy of
credence."); Susan Sturm, Second Generation Employment Discrimination: A
Structural Approach, 101 COLUM. L. REV. 458, 458 (2001); see also Melissa Hart,
Subjective Decisionmaking and Unconscious Discrimination, 56 ALA. L. REV. 741,
749-50 (2005) (critiquing the courts' requirement of proving employer
"dishonesty," but suggesting that, absent this requirement, Title VII could
handle unconscious discrimination without altering the law).





n110  Krieger, supra note 89, at 1170.





n111  490 U.S. 228 (1989).





n112  539 U.S. 90 (2003).





n113  42 U.S.C. § 2000e-2(m) (2012); Desert Palace, 539 U.S. at 101 ("In order
to obtain [a mixed-motive jury instruction], a plaintiff need only present
sufficient evidence for a reasonable jury to conclude, by a preponderance of the
evidence, that 'race, color, religion, sex, or national origin was a motivating
factor for any employment practice.'"). The efficacy of data mining is
fundamentally dependent on the quality of the data from which it attempts to
draw useful lessons. If these data capture the prejudicial or biased behavior of
prior decision makers, data mining will learn from the bad example that these
decisions set. If the data fail to serve as a good sample of a protected group,
data mining will draw faulty lessons that could serve as a discriminatory basis
for future decision making.





n114  Charles A. Sullivan, Disparate Impact: Looking Past the Desert Palace
Mirage, 47 WM. & MARY L. REV. 911, 914-16, 916 n.20 (2005); see also Krieger,
supra note 89, at 1170-72; D. Don Welch, Removing Discriminatory Barriers:
Basing Disparate Treatment Analysis on Motive Rather than Intent, 60 S. CAL. L.
REV. 733, 740 (1987).





n115  Krieger, supra note 89, at 1243; Sullivan, supra note 114, at 915.





n116  Krieger, supra note 89, at 1243; Sullivan, supra note 114, at 915 n.18
(quoting Motive, OXFORD ENGLISH DICTIONARY (1st ed. 1933)).





n117  Sullivan, supra note 114, at 914-16, 916 n.20.





n118  Amy L. Wax, Discrimination as Accident, 74 IND. L.J. 1129, 1149 & n.21
(1999); Krieger, supra note 89, at 1223. In fact, after the Supreme Court
decided Desert Palace, many scholars thought that it had effectively overruled
the McDonnell-Douglas framework, forcing all disparate treatment cases into a
mixed-motive framework. See, e.g., Sullivan, supra note 114, at 933-36
(discussing the then-emerging scholarly consensus). This has not played out so
far, with courts and scholars split on the matter. See, e.g., Kendall D. Isaac,
Is It "A" or Is It "The"? Deciphering the Motivating-Factor Standard in
Employment Discrimination and Retaliation Cases, 1 TEX. A&M L. REV. 55, 74
(2013) ("McDonnell Douglas has never been overruled and remains widely
utilized."); Barrett S. Moore, Shifting the Burden: Genuine Disputes and
Employment Discrimination Standards of Proof, 35 U. ARK. LITTLE ROCK L. REV.
113, 123-29, 128 n.146 (2012) (noting a circuit split on the issue).





n119  See Krieger, supra note 89, at 1182-83.





n120  See, e.g., Christine Jolls & Cass R. Sunstein, The Law of Implicit Bias,
94 CALIF. L. REV. 969, 978 n.45 (2006) (collecting sources); Linda Hamilton
Krieger & Susan T. Fiske, Behavioral Realism in Employment Discrimination Law:
Implicit Bias and Disparate Treatment, 94 CALIF. L. REV. 997, 1003 n.21 (2006)
(collecting sources).





n121  This example can be ported directly to data mining as overrepresentation
in data collection. See supra Part I.B.2.





n122  Samuel R. Bagenstos, The Structural Turn and the Limits of
Antidiscrimination Law, 94 CALIF. L. REV. 1, 9 (2006).





n123  Sullivan, supra note 114, at 1000. There is, however, no general agreement
on whether the law should treat such discrimination as disparate treatment or
disparate impact. Compare Krieger, supra note 89, at 1231 (explaining that
because the bias causes employers to treat people differently, it should be
considered a disparate treatment violation), with Sullivan, supra note 114, at
969-71 (arguing that the purpose of disparate impact is a catch-all provision to
address those types of bias that disparate treatment cannot reach). This
disagreement is important and even more pronounced in the case of data mining.
See infra Part III. For now, we assume each case can be analyzed separately.





n124  In fact, after Ricci v. DeStefano, 557 U.S. 557 (2009), deciding not to
apply such a test after noticing the discriminatory effect may give rise to a
disparate treatment claim in the other direction.





n125  Bagenstos, supra note 122, at 9; Krieger, supra note 89, at 1185-86 ("Not
only disparate treatment analysis, but the entire normative structure of Title
VII's injunction 'not to discriminate,' rests on the assumption that
decisionmakers possess 'transparency of mind'--that they are aware of the
reasons why they are about to make, or have made, a particular employment
decision.").





n126  See supra note 51 and accompanying text.





n127  Of course, the very presumption of a design's neutrality is itself a bias
that may work against certain people. See Langdon Winner, Do Artifacts Have
Politics?, 109 DAEDALUS 121, 125 (1980). But, as this is a second-order effect,
we need not address it here.





n128  See Woods, supra note 46.





n129  See 29 C.F.R. § 1604.2(a)(1)(iii) (2015) (stating the EEOC's position that
"the preferences of coworkers, the employer, clients or customers" cannot be
used to justify disparate treatment); see also Fernandez v. Wynn Oil Co., 653
F.2d 1273, 1276-77 (9th Cir. 1981); Diaz v. Pan Am. World Airways, Inc., 442
F.2d 385, 389 (5th Cir. 1971).





n130  See Krieger, supra note 89, at 1185 (discussing disparate treatment's
"assumption of decisionmaker self-awareness").





n131  Columbus Bd. of Educ. v. Penick, 443 U.S. 449, 464 (1979) ("[A]ctions
having foreseeable and anticipated disparate impact are relevant evidence to
prove the ultimate fact, forbidden purpose."); Pers. Adm'r of Mass. v. Feeney,
442 U.S. 256, 279 n.25 (1979) ("[W]hen the adverse consequences of a law upon an
identifiable group are . . . inevitable . . . , a strong inference that the
adverse effects were desired can reasonably be drawn.").





n132  42 U.S.C. § 2000e-2(h) (2012).





n133  See Julia Kobick, Note, Discriminatory Intent Reconsidered: Folk Concepts
of Intentionality and Equal Protection Jurisprudence, 45 HARV. C.R.-C.L. L. REV.
517, 551 (2010) (arguing that courts should regularly consider knowledge and
foreseeability of disparate impact as an intended effect); cf. RESTATEMENT
(SECOND) OF TORTS § 8A cmt. b (AM. LAW INST. 1965) ("Intent is not . . . limited
to consequences which are desired. If the actor knows that the consequences are
certain, or substantially certain, to result from his act, and still goes ahead,
he is treated by the law as if he had in fact desired to produce the result.").





n134  Determining that a model is discriminatory is also like trying and failing
to validate a test under disparate impact doctrine. See infra Part II.B. If a
test fails validation, the employer using it would know that he is
discriminating if he applies it, but that does not imply that he is subject to
disparate treatment liability. Nonetheless, validation is part of the business
necessity defense, and that defense is not available against disparate treatment
claims. Thus, the analysis does not necessarily have the same result. 42 U.S.C.
§ 2000e-2(k)(2). One commentator has argued that including knowledge as a state
of mind leading to disparate treatment liability would effectively collapse
disparate impact and disparate treatment by conflating intent and effect. Jessie
Allen, A Possible Remedy for Unthinking Discrimination, 61 BROOK. L. REV. 1299,
1314 (1995). But others still have noted that with respect to knowledge, a claim
is still about the treatment of an individual, not the incidental disparate
impact of a neutral policy. See Carin Ann Clauss, Comparable Worth--The Theory,
Its Legal Foundation, and the Feasibility of Implementation, 20 U. MICH. J.L.
REFORM 7, 62 (1986).





n135  42 U.S.C. § 2000e-2(k)(1)(A).





n136  Id.





n137  Id.





n138  The statute does not define the requirement and Supreme Court has never
addressed the issue. See, e.g., Sullivan, supra note 114, at 954 & n.153. For a
brief discussion of the different approaches to establishing disparate impact,
see Pamela L. Perry, Two Faces of Disparate Impact Discrimination, 59 FORDHAM L.
REV. 523, 570-74 (1991).





n139  Uniform Guidelines on Employment Selection Procedures, 29 C.F.R. §
1607.4(D) (2015) [hereinafter Guidelines].





n140  Id.





n141  We will return to this when discussing the need to grapple with
substantive fairness. See infra Part III.B.





n142  401 U.S. 424 (1971).





n143  Linda Lye, Comment, Title VII's Tangled Tale: The Erosion and Confusion of
Disparate Impact and the Business Necessity Defense, 19 BERKELEY J. EMP. & LAB.
L. 315, 321 (1998) (footnotes omitted) (quoting Griggs v. Duke Power Co., 401
U.S. 424, 431-36 (1971)).





n144  Griggs, 401 U.S. at 431; see also Lye, supra note 143, at 320.





n145  Lye, supra note 143, at 355 & n.206.





n146  Id. at 319-20, 348-53; Amy L. Wax, Disparate Impact Realism, 53 WM. & MARY
L. REV. 621, 633-34 (2011).





n147  Griggs, 401 U.S. at 427-28.





n148  Id. at 431-32.





n149  Id. at 432.





n150  Id. at 431.






n151  See Nicole J. DeSario, Reconceptualizing Meritocracy: The Decline of
Disparate Impact Discrimination Law, 38 HARV. C.R.-C.L. L. REV. 479, 495-96
(2003); Lye, supra note 143, at 328.





n152  440 U.S. 568 (1979).





n153  Id. at 587 & n.31.





n154  Id.





n155  490 U.S. 642 (1989).





n156  Id. at 659.





n157  Id.





n158  42 U.S.C. § 2000e-2(k)(1)(C) (2012).





n159  Legislative history was no help either. The sole piece of legislative
history is an interpretive memorandum that specifies that the standards were to
revert to before Wards Cove, coupled with an explicit instruction in the Act to
ignore any other legislative history regarding business necessity Susan S.
Grover, The Business Necessity Defense in Disparate Impact Discrimination Cases,
30 GA. L. REV. 387, 392-93 (1996).





n160  Andrew C. Spiropoulos, Defining the Business Necessity Defense to the
Disparate Impact Cause of Action: Finding the Golden Mean, 74 N.C. L. REV. 1479,
1484 (1996).





n161  Though courts generally state the standard to reflect this middle
position, the Supreme Court's latest word on disparate impact--in which the
Court reaffirmed the doctrine generally and held that it applied in the Fair
Housing Act--included the decidedly defendant-friendly observation that "private
policies are not contrary to the disparate-impact requirement unless they are
'artificial, arbitrary, and unnecessary barriers.'" Tex. Dep't of Hous. & Cmty.
Affairs v. Inclusive Cmtys. Project, Inc.,135 S. Ct. 2507, 2512 (2015) (quoting
Griggs v. Duke Power Co., 401 U.S. 424, 431 (1971)).





n162  See, e.g., Gallagher v. Magner, 619 F.3d 823, 834 (8th Cir. 2010);
Anderson v. Westinghouse Savannah River Co., 406 F.3d 248, 265 (4th Cir. 2005).





n163  Gulino v. N.Y. State Educ. Dep't, 460 F.3d 361, 383 (2d Cir. 2006) (noting
that hiring criteria are "significantly correlated with important elements of
work behavior which comprise or are relevant to the job or jobs for which
candidates are being evaluated" (quoting Albemarle Paper Co. v. Moody, 422 U.S.
405, 431 (1975))).





n164  El v. Se. Pa. Transp. Auth., 479 F.3d 232, 242 (3d Cir. 2007) (quoting
Lanning v. Se. Pa. Transp Auth., 181 F.3d 478, 481 (3d Cir. 1999)).





n165  Michael T. Kirkpatrick, Employment Testing: Trends and Tactics, 10 EMP.
RTS. & EMP. POL'Y J 623, 633 (2006).





n166  Id. Note, though, that this is similar to arguing that there is a less
discriminatory alternative employment practice. This argument, then, would place
the burden of the alternative employment practice prong on the defendant,
contravening the burden-shifting scheme in the statute. See infra notes 170-74
and accompanying text.





n167  El, 479 F.3d at 242.





n168  Id.





n169  Interestingly, it seems that many courts read identical business necessity
language in the Americans with Disabilities Act to refer to a minimum
qualification standard. See, e.g., Sullivan v. River Valley Sch. Dist., 197 F.3d
804, 811 (6th Cir. 1999) ("[T]here must be significant evidence that could cause
a reasonable person to inquire as to whether an employee is still capable of
performing his job. An employee's behavior cannot be merely annoying or
inefficient to justify an examination; rather, there must be genuine reason to
doubt whether that employee can 'perform job-related functions.'" (quoting 42
U.S.C. § 12112(d)(4)(B))). Presumably, this is because disability, when compared
to race or sex, more immediately raises questions regarding a person's ability
to perform a job. Ironically, however, this means that disparate impact will be
more tolerated where it is less likely to be obviously justified. Christine
Jolls has in fact argued that disparate impact is, to a degree, functionally
equivalent to accommodations law. Jolls, supra note 90, at 652.





n170  422 U.S. 405, 425 (1975) (quoting McDonnell Douglas Corp. v. Green, 411
U.S. 792, 801 (1973)).





n171  42 U.S.C. § 2000e-2(k)(1)(A) (2012). The "alternative employment practice"
test has not always been treated as a separate step. See, e.g., Wards Cove
Packing Co. v. Atonio, 490 U.S. 642, 659 (1989) (treating the alternative
employment practice test as part of the "business justification" phase); Dothard
v. Rawlinson, 433 U.S. 321, 332 (1977) (treating the alternative employment
practice test as a narrow tailoring requirement for the business necessity
defense). The Albemarle Court, though creating a surrebuttal and thus empowering
plaintiffs, seemed to regard the purpose of disparate impact as merely smoking
out pretexts for intentional discrimination.  422 U.S. at 425; see also Primus,
supra note 98, at 537. If the Albemarle Court's approach is correct, treating
the alternative employment practice requirement as a narrow tailoring
requirement does make sense, much as the narrow tailoring requirement of strict
scrutiny in equal protection serves the function of smoking out invidious
purpose.  City of Richmond v. J.A. Croson Co., 488 U.S. 469, 493 (1989);
Rubenfeld, supra note 99, at 428.

   Every circuit to address the question, though, has held that the 1991 Act
returned the doctrine to the Albemarle burden-shifting scheme.  Jones v. City of
Boston, 752 F.3d 38, 54 (1st Cir. 2014); Howe v. City of Akron, 723 F.3d 651,
658 (6th Cir. 2013); Tabor v. Hilti, Inc., 703 F.3d 1206, 1220 (10th Cir. 2013);
Puffer v. Allstate Ins. Co., 675 F.3d 709, 717 (7th Cir. 2012); Gallagher v.
Magner, 619 F.3d 823, 833 (8th Cir. 2010); Gulino v. N.Y. State Educ. Dep't, 460
F.3d 361, 382 (2d Cir. 2006); Int'l Bhd. of Elec. Workers Local Unions Nos. 605
& 985 v. Miss. Power & Light Co., 442 F.3d 313, 318 (5th Cir. 2006); Anderson v.
Westinghouse Savannah River Co., 406 F.3d 248, 277 (4th Cir 2005); Ass'n of
Mexican-Am. Educators v. California, 231 F.3d 572, 584 (9th Cir. 2000); EEOC v
Joe's Stone Crab, Inc., 220 F.3d 1263, 1275 (11th Cir. 2000); Lanning v. Se. Pa.
Transp. Auth., 181 F.3d 478, 485 (3d Cir. 1999). The D.C. Circuit has not
explicitly observed that a burden-shifting framework exists.





n172  Sullivan, supra note 114, at 964; Michael J. Zimmer, Individual Disparate
Impact Law: On the Plain Meaning of the 1991 Civil Rights Act, 30 LOY. U. CHI.
L.J. 473, 485 (1999).





n173  Albemarle, 422 U.S. at 425; accord, e.g., Jones, 752 F.3d at 53 (citing
Albemarle to find meaning in the 1991 Act's text); Allen v. City of Chicago, 351
F.3d 306, 312 (7th Cir. 2003) (same, but with a "see also" signal).





n174  William R. Corbett, Fixing Employment Discrimination Law, 62 SMU L. REV.
81, 92 (2009).





n175  The difference would be whether mining for a single job-related trait,
rather than a holistic ranking of "good employees," is permissible at all. See
infra text accompanying notes 197-99.





n176  Sweeney, supra note 41, at 51.





n177  See El v. Se. Pa. Transp. Auth., 479 F.3d 232, 243 (3d Cir. 2007) (finding
that though the criminal record policy had a disparate impact, it satisfied
business necessity in that case); Green v. Mo. Pac. R.R., 523 F.2d 1290, 1298
(8th Cir. 1975); McCain v. United States, No. 2:14-cv-92, 2015 WL 1221257, at
*17 (D. Vt. Mar. 17, 2015); EQUAL EMP'T OPPORTUNITY COMM'N, CONSIDERATION OF
ARREST AND CONVICTION RECORDS IN EMPLOYMENT DECISIONS UNDER TITLE VII OF THE
CIVIL RIGHTS ACT OF 1964 (2012),
http://www.eeoc.gov/laws/guidance/upload/arrest_conviction.pdf
[https://perma.cc/JY47-2HVT]; see also Univ. of Tex. Sw. Med. Ctr. v. Nassar,
133 S. Ct. 2517, 2540 (2013) ("The position set out in the EEOC's guidance and
compliance manual merits respect."); Michael Connett, Comment, Employer
Discrimination Against Individuals with a Criminal Record: The Unfulfilled Role
of State Fair Employment Agencies, 83 TEMP. L. REV. 1007, 1017 & nn.82-83 (2011)
(citing EQUAL EMP'T OPPORTUNITY COMM'N, POLICY STATEMENT ON THE ISSUE OF
CONVICTION RECORDS UNDER TITLE VII OF THE CIVIL RIGHTS ACT OF 1964 (1987),
http://www.eeoc.gov/policy/docs/convict1.html [https://perma.cc/PY24-V8V7]). But
see, e.g., Manley v. Invesco, 555 Fed. App'x 344, 348 (5th Cir. 2014) (per
curiam) ("Persons with criminal records are not a protected class under Title
VII.").





n178  Michael Selmi, Was the Disparate Impact Theory a Mistake?, 53 UCLA L. REV.
701, 753 (2006).





n179  DeSario, supra note 151, at 481.





n180  Id. at 493; see also infra Conclusion.





n181  See Don Peck, They're Watching You at Work, ATLANTIC (Nov. 20, 2013),
http://www.theatlantic.com/magazine/archive/2013/12/theyre-watching-you-at-work/
354681 [https://perma.cc/JFP8-CZKC] (discussing Google's choice to abandon
traditional hiring metrics because they are not good predictors of performance).





n182  See, e.g., Griggs v. Duke Power Co., 420 F.2d 1225, 1239 n.6 (4th Cir.
1970), rev'd, 401 U.S. 424 (1971) ("Since for generations blacks have been
afforded inadequate educational opportunities and have been culturally
segregated from white society, it is no more surprising that their performance
on 'intelligence' tests is significantly different than whites' than it is that
fewer blacks have high school diplomas.").





n183  29 C.F.R. §§ 1607.3, 1607.5 (2015). The Guidelines also cite two
categories of practices that are unsuitable for validation: informal, unscored
practices and technical infeasibility. Id. § 1607.6(B). For the latter case, the
Guidelines state that the selection procedure still should be justified somehow
or another option should be chosen.





n184  Id. § 1607.5(B).





n185  Id.





n186  Id. § 1607.14(B)(5).





n187  Id. §§ 1607.5(F), 1607.14(C).





n188  Id. § 1607.14(D)(3).





n189  Wax, supra note 146, at 633-34.





n190  David A. Drachsler, Assessing the Practical Repercussions of Ricci, AM.
CONST. SOC'Y BLOG (July 27, 2009), http://www.acslaw.org/node/13829
[https://perma.cc/AH9G-B3GN] (observing that the Court in Ricci v. DeStefano
found no genuine dispute that the unvalidated tests at issue met the job-related
and business necessity standards despite the Guidelines creating a presumption
of invalidity for unvalidated tests that are discriminatory).





n191  New Haven's primary argument was that it had to withdraw the tests or it
would have faced Title VII liability. See Mark S. Brodin, Ricci v. DeStefano:
The New Haven Firefighters Case & the Triumph of White Privilege, 20 S. CAL.
REV. L. & SOC. JUST. 161, 178 n.128 (2011) ("New Haven forcefully argued
throughout the litigation that the exams were 'flawed' and may not have
identified the most qualified candidates for the supervisory positions.").





n192  George Rutherglen, Ricci v. Destefano: Affirmative Action and the Lessons
of Adversity, 2009 SUP CT. REV. 83, 107.





n193  See infra Part III.B.1.





n194  See generally Dalessandro, Perlich & Raeder, supra note 68.





n195  Sullivan, supra note 114, at 964; Zimmer, supra note 172, at 505-06.





n196  For a discussion of courts using cost as a rationale here, see Ernest F.
Lidge III, Financial Costs as a Defense to an Employment Discrimination Claim,
58 ARK. L. REV. 1, 32-37 (2005).





n197  This would likely require Congressional action because strict business
necessity essentially transfers the burden to prove a lack of an alternative
employment practice to the defense. By implication, if a practice is
"necessary," there cannot be alternatives. The statute, as it reads now, clearly
states that the plaintiff has the burden for that prong. 42 U.S.C. § 2000e-2
(k)(1)(A)(ii) (2012).





n198  This is an increasingly common practice in low-wage, high-turnover jobs.
See Peck, supra note 181.





n199  Equal Emp't Opportunity Comm'n v. Joe's Stone Crab, Inc., 220 F.3d 1263,
1275 (11th Cir. 2000); see also Gallagher v. Magner, 619 F.3d 823, 834 (8th Cir.
2010).





n200  Griggs v. Duke Power Co., 401 U.S. 424, 431 (1971).





n201  See supra text accompanying notes 106-07.





n202  See supra Part I.E.





n203  See MASSEY & DENTON, supra note 73, at 51-52.





n204  Croll, supra note 88.





n205  Michal Kosinski, David Stillwell & Thore Graepel, Private Traits and
Attributes Are Predictable from Digital Records of Human Behavior, 110 PROC.
NAT'L ACAD. SCI. 5802 (2013).





n206  Carter Jernigan & Behram F.T. Mistree, Gaydar: Facebook Friendships Expose
Sexual Orientation, FIRST MONDAY (Oct. 5, 2009),
http://firstmonday.org/article/view/2611/2302 [https://perma.cc/G36G-S26X].





n207  See Dwork et al., supra note 81, app. at 226 ("Catalog of Evils").





n208  Cf. Albemarle Paper Co. v. Moody, 422 U.S. 405, 425 (1975) (creating an
alternative employment practice prong for the purpose of rooting out pretext).





n209  42 U.S.C. § 2000e-2(k)(2) (2012).





n210  George Rutherglen, Disparate Impact, Discrimination, and the Essentially
Contested Concept of Equality, 74 FORDHAM L. REV. 2313, 2313 (2006); Stacy E.
Seicshnaydre, Is the Road to Disparate Impact Paved with Good Intentions?: Stuck
on State of Mind in Antidiscrimination Law, 42 WAKE FOREST L. REV. 1141, 1142-43
(2007).





n211  Rutherglen, supra note 210, at 2320-21.





n212  Id. at 2320.





n213  Seicshnaydre, supra note 210, at 1147-48.





n214  Id. at 1153-63.





n215  Rutherglen, supra note 210, at 2321-22.





n216  Jennifer Preston, Social Media History Becomes a New Job Hurdle, N.Y.
TIMES (July 20, 2011),
http://www.nytimes.com/2011/07/21/technology/social-media-history-becomes-a-new-
job-hurdle.html [https://perma.cc/NZ8U-M296].





n217  For a list of the wide-ranging research underway in computer science, see
generally Resources, FAT ML, http://www.fatml.org/resources.html
[https://perma.cc/T2QW-ARHX].





n218  See supra Part I.A.





n219  See Lyle Denniston, Argument Analysis: Now, Three Options on College
Affirmative Action, SCOTUSBLOG (Dec. 9, 2015, 2:47 PM),
http://www.scotusblog.com/2015/12/argument-analysis-now-three-options-on-college
-affirmative-action [https://perma.cc/XF75-N82F] (analysis of oral argument in
Fisher v. Univ. of Tex., 758 F.3d 633 (5th Cir. 2014), cert. granted, 135 S. Ct.
2888, (June 29, 2015)); see also Fisher v. Univ. of Tex., 133 S. Ct. 2411, 2419
(2013) ("[A]ny official action that treats a person differently on account of
his race or ethnic origin is inherently suspect." (internal citation omitted)).





n220  See supra Part I.A.





n221  See David J. Hand, Deconstructing Statistical Questions, 157 J. ROYAL
STAT. SOC'Y. SERIES A (STAT. SOC'Y) 317, 318-20 (1994).





n222  Gandy, supra note 31, at 39.





n223  180 F.3d 42, 47 (2d Cir. 1999).





n224  Id.





n225  Id.





n226  Id.





n227  Selmi, supra note 178, at 715.





n228  See Albemarle Paper Co. v. Moody, 422 U.S. 405, 450 (1975) (Burger, J.,
concurring) ("The basis of Albemarle's liability was that its seniority system
perpetuated the effects of past discrimination . . . .").





n229  42 U.S.C. § 2000e-2(h) (2012).





n230  Trans World Airlines, Inc. v. Hardison, 432 U.S. 63, 82 (1977).





n231  Calders & [#x017D]liobait[#x0117], supra note 64, at 48.





n232  For example, establishing whether and to what extent crime statistics
misrepresent the relative proportion of offenses committed by different social
groups is not an easy task. Especially challenging are those crimes that are
more likely to go under- or unreported if not directly observed by the police.
See BERNARD E. HARCOURT, AGAINST PREDICTION: PROFILING, POLICING, AND PUNISHING
IN AN ACTUARIAL AGE (2007).





n233  Kate Crawford, The Hidden Biases in Big Data, HARV. BUS. REV. (Apr. 1,
2013), https://hbr.org/2013/04/the-hidden-biases-in-big-data
[https://perma.cc/9A7V-3UVD]. Such techniques would also address the concerns
raised in Lerman, supra note 50.





n234  Faisal Kamiran & Toon Calders, Data Preprocessing Techniques for
Classification Without Discrimination, 33 KNOWLEDGE & INFO. SYS. 1, 3 (2011).





n235  See supra Part II.B.





n236  Peck, supra note 181.





n237  See Richtel, supra note 69.





n238  SCHAUER, supra note 67, at 5. As Schauer explains, perfectly
particularized decisions are, of course, a logical impossibility. Accepting this
inherent limitation introduces a different sort of procedural concern:
occasional errors might be tolerable if they are easy to detect and rectify,
which is why, among other things, the perceived legitimacy of decisions often
also depends on due process. See id. at 172; see also Citron, supra note 11.





n239  Gandy, supra note 31, at 36.





n240  Moritz Hardt, How Big Data Is Unfair, MEDIUM (Sept. 26, 2014),
https://medium.com/@mrtz/how-big-data-is-unfair-9aa544d739de
[https://perma.cc/YN44-M4DQ].





n241  See, e.g., Gandy, supra note 31, at 39.





n242  See supra note 64 and accompanying text.





n243  Calders & [#x017D]liobait[#x0117], supra note 64, at 54.





n244  Devin G. Pope & Justin R. Sydnor, Implementing Anti-Discrimination
Policies in Statistical Profiling Models, 3 AM. ECON. J. 206, 206 (2011).





n245  Supra discussion accompanying note 101.





n246  Labi, supra note 5 (quoting Ellen Kurtz, Director of Research for
Philadelphia's Adult Probation and Parole Department).





n247  Toon Calders & Sicco Verwer, Presentation at the European Conference on
Machine Learning and Principles and Practice of Knowledge Discovery in
Databases: Three Na[#xEF]ve Bayes Approaches for Discrimination-Free
Classification 9 (2010), http://wwwis.win.tue.nl/
tcalders/dadm/lib/exe/fetch.php?media=ecmlpkdd_2010_discrimination.pdf
[http://perma.cc/9V72-2NVM].





n248  In a sense, computer scientists have unwittingly furnished the kind of
evidence that social scientists routinely seek: the particular contours of
inequality. See, e.g., SOCIAL INEQUALITY (Kathryn M. Neckerman ed., 2004).





n249  Dwork et al., supra note 81, at 215; cf. Wax, supra note 146, at 711
(noting intractable problems due to a "validity-diversity tradeoff" in
employment metrics).





n250  Peck, supra note 181.





n251  Id. Other companies have not held back from considering this information
for the very same purposes. See Joseph Walker, Meet the New Boss: Big Data, WALL
ST. J. (Sept. 20, 2012),
http://www.wsj.com/news/articles/SB10000872396390443890304578006252019616768
[https://perma.cc/6DHY-M429].





n252  Calders & [#x017D]liobait[#x0117], supra note 64, at 56.





n253  Helen Norton, The Supreme Court's Post-Racial Turn Towards a Zero-Sum
Understanding of Equality, 52 WM. & MARY L. REV. 197, 206-15 (2010); see also
Bagenstos, supra note 122, at 40-42, 40-41 nn.214-15 (collecting sources); Owen
M. Fiss, Groups and the Equal Protection Clause, 5 PHIL. & PUB. AFF. 107, 157
(1976).





n254  See Norton, supra note 253.





n255  Id. at 209.





n256  Id. at 206.





n257  Primus, supra note 98, at 520-23.





n258  Id.; Perry, supra note 138, at 526.





n259  See Griggs v. Duke Power Co., 401 U.S. 424, 429-30 (1971) ("The objective
of Congress in the enactment of Title VII is plain from the language of the
statute. It was to achieve equality of employment opportunities and remove
barriers that have operated in the past to favor an identifiable group of white
employees over other employees. Under the Act, practices, procedures, or tests
neutral on their face, and even neutral in terms of intent, cannot be maintained
if they operate to 'freeze' the status quo of prior discriminatory employment
practices.").





n260  See Tex. Dep't of Hous. & Cmty Aff. v. Inclusive Cmtys. Project, Inc., No.
13-1371, slip op. at 8 (Sup. Ct. 2015) (quoting Griggs, 401 U.S. at 431).





n261  Primus, supra note 98, at 525-26.





n262  Id.





n263  See Bagenstos, supra note 122, at 41.





n264  426 U.S. 229, 246-48 (1976).





n265  Rubenfeld, supra note 99, at 428, 433-36.





n266  Ricci v. DeStefano, 557 U.S. 557 (2009).





n267  Id.





n268  Id.





n269  Id. at 563.





n270  Primus, supra note 92, at 1344; Lawrence Rosenthal, Saving Disparate
Impact, 34 CARDOZO L. REV. 2157, 2162-63 (2013); Norton, supra note 253, at 229.





n271  See Washington v. Davis, 426 U.S. 229, 239 (holding that discriminatory
purpose is necessary to finding a violation of equal protection).





n272  Primus, supra note 92, at 1343. While the decision was formally about
Title VII only, and thus amenable to statutory resolution, the reasoning applied
equally well to a future equal protection claim, endangering the future of
disparate impact. Id. at 1385-87; Bradley A. Areheart, The Anticlassification
Turn in Employment Discrimination Law, 63 ALA. L. REV. 955, 994 (2012); Norton,
supra note 253, at 229-30. Justice Scalia stated as much in his concurrence.
Ricci, 557 U.S. at 594 (Scalia, J., concurring) ("[The Court's] resolution of
this dispute merely postpones the evil day on which the Court will have to
confront the question: Whether, or to what extent, are the disparate-impact
provisions of Title VII of the Civil Rights Act of 1964 consistent with the
Constitution's guarantee of equal protection?"). But the Supreme Court seemed to
pull back from the brink last term, approving of the use of disparate impact in
a new setting--the Fair Housing Act--and engaging deeply with the constitutional
issues that Ricci raised, settling them for now. Samuel R. Bagenstos, Disparate
Impact and the Role of Classification and Motivation in Equal Protection Law
After Inclusive Communities, 101 CORNELL L. REV., at *11-12 (forthcoming 2016),
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2642631
[https://perma.cc/WD43-XW2G]; Richard Primus, Of Visible Race-Consciousness and
Institutional Role: Equal Protection and Disparate Impact After Ricci and
Inclusive Communities, in TITLE VII OF THE CIVIL RIGHTS ACT AFTER 50 YEARS:
PROCEEDINGS OF THE NEW YORK UNIVERSITY 67TH ANNUAL CONFERENCE ON LABOR 295
(2015).





n273  Ricci, 557 U.S. at 585 (majority opinion) ("Title VII does not prohibit an
employer from considering, before administering a test or practice, how to
design that test or practice in order to provide a fair opportunity for all
individuals, regardless of their race. And when, during the test-design stage,
an employer invites comments to ensure the test is fair, that process can
provide a common ground for open discussions toward that end.").





n274  Id. at 585.





n275  See generally id.





n276  Remember that if there is disparate impact, but no liability, it is
because the goal was deemed job-related or satisfied business necessity.





n277  As a matter of case law, this question has essentially been answered. The
Supreme Court has ruled that in the case of women being required to pay more
into an annuity because they would likely live longer, pure market rationality
is not a good enough answer.  Ariz. Governing Comm. v. Norris, 463 U.S. 1073,
1083 (1983) (quoting City of Los Angeles Dep't of Water & Power v. Manhart, 435
U.S. 702, 708 (1978)).





n278  Id.





n279  Id.





n280  Id. at 537.





n281  Primus, supra note 98, at 536-37.





n282  See supra text accompanying note 101.





n283  For an argument that this is true more generally, see Bagenstos, supra
note 90, and Owen M. Fiss, A Theory of Fair Employment Laws, 38 U. CHI. L. REV.
235, 313 (1971) (arguing that a key to understanding antidiscrimination
prohibitions in the employment realm is that the prohibitions "confer[] benefits
on a racial class--blacks").





n284  We cannot stress enough the import of these caveats. Certainty is a strong
and unlikely precondition, and the status quo should not be taken as a given, as
we explain below.





n285  See generally Jolls, supra note 90.





n286  See Ariz. Governing Comm. v. Norris, 463 U.S. 1073, 1083 (1983); City of
Los Angeles Dep't of Water & Power v. Manhart, 435 U.S. 702, 708 (1978).





n287  See 29 C.F.R. § 1604.2(a)(1)(iii) (2015) (stating the EEOC's position that
"the preferences of coworkers, the employer, clients or customers" cannot be
used to justify disparate treatment).





n288  See, e.g., El v. Se. Pa. Transp. Auth., 479 F.3d 232, 242 (3d Cir. 2007).





n289  See Steven L. Willborn, The Disparate Impact Model of Discrimination:
Theory and Limits, 34 AM. U. L. REV. 799, 809-10 (1985).





n290  See generally David Benjamin Oppenheimer, Negligent Discrimination, 141 U.
PA. L. REV. 899 (1993).





n291  Solon Barocas, Putting Data to Work, DATA AND DISCRIMINATION: COLLECTED
ESSAYS 58, 60 (Seeta Pe[#xF1]a Gangadharan, Virginia Eubanks & Solon Barocas
eds., 2014).





n292  Claire Cain Miller, Can an Algorithm Hire Better than a Human?, N.Y. TIMES
(June 25, 2015),
http://www.nytimes.com/2015/06/26/upshot/can-an-algorithm-hire-better-than-a-hum
an.html [https://perma.cc/UR37-83D4].





n293  See list supra note 217.





n294  Joshua A. Kroll, et al., Accountable Algorithms, 165 U. PA. L. REV.
(forthcoming 2017).


                               9 of 41 DOCUMENTS

              Copyright (c) 2015 U.C. Hastings College of the Law
                              Hastings Law Journal

                                  2015 - 2016

                              Hastings Law Journal

                              67 Hastings L.J. 195

LENGTH: 33040 words

Article: Databasing Delinquency

NAME: Kevin Lapp*

BIO: * Associate Professor of Law, Loyola Law School, Los Angeles. This Article
benefitted from presentations at the American Association of Law Schools
("AALS") 2015 Annual Meeting, the American Bar Association's 2014 Fall Institute
on Criminal Justice, the 2015 Southern California Criminal Justice Roundtable,
and the 2014 Southern California Junior Faculty Workshop. Specific thanks to
Alexandra Natapoff, Jason Cade, Katie Tinto, Beth Colgan, Tamar Birckhead,
Elizabeth Pollman, Annette Ruth Appell, Andrew Guthrie Ferguson, Sam Pillsbury,
and Adam Zimmerman for their valuable suggestions on earlier drafts.

HIGHLIGHT:

   Technological advances in recent decades have enabled an unprecedented level
of surveillance by the government and permitted law enforcement to gather,
store, and retrieve in real time enormous amounts of data. After nearly a
century of limited record-making and enhanced confidentiality regarding
juveniles, these data collection practices have quickly expanded to include
youth. This Article uncovers the vast extent of modern data collection and
distribution about juveniles by the criminal justice system from juvenile sex
offender registration and their inclusion in gang and DNA databases, to schools
turned into mandated law enforcement informants, to police and courts
increasingly sharing juvenile records with employers, public housing
authorities, colleges, and the general public.

   The expansion of this modern culture of "dataveillance" to youth has profound
implications. It not only harms individual youth in permanent and stigmatizing
ways, it reshapes the very meaning of childhood, breaching its protected space
and contradicting the special understandings that dominate the regulation of
youth. It also distorts perceptions of juveniles in ways that have lasting
policy consequences. Moreover, this distortion is visited especially heavily on
minority youth and constitutes an engine of racial bias and punitive reforms in
its own right.

   Putting the developmental characteristics of youth, and childhood, at the
center of the analysis, this Article reveals the incoherence and destructiveness
of databasing delinquency. Mindful of the public safety benefits and
inevitability of law enforcement information gathering, it calls for reforms
that would limit the amount of information gathered, stored, and shared about
juveniles. These reforms would add appropriate restraints to law enforcement
data collection so that public safety gains from databasing do not come at the
expense of juvenile privacy, juveniles' life chances, or childhood itself.


 TEXT:
 [*196]

   Introduction


   Technological and scientific advances in recent decades have enabled an
unprecedented level of surveillance and permitted law enforcement to gather,
store, and retrieve in real time enormous amounts of data. From computerized rap
sheets and DNA databases to sex offender and other registries, records of a
person's contact with the criminal justice system no longer rest in a file
folder or card catalog in a  [*197]  local precinct. Instead, they reside
indefinitely on law enforcement servers and, in many cases, the publicly
searchable Internet. n1

   For most of the last century, the criminal justice system limited
recordmaking and increased the confidentiality of data about juveniles. n2 That
reticence and protectiveness no longer prevails because it has been overwhelmed
by technology and a fervid commitment to data collection. Today, the criminal
justice system collects and stores a tremendous amount of information about
juveniles. n3 State and federal laws compel thousands of young people to
register as sex offenders and provide personal information that is posted
online, and mandate DNA collection from juveniles as a result of delinquency
adjudications and arrests. Children as young as ten years old are entered into
databases of known and suspected gang members (often in the absence of an arrest
or even a suspicion of wrongdoing). Public schools across the nation are
required to notify law enforcement when students commit certain behaviors at
school, and law enforcement agencies return the favor, providing schools with
criminal or delinquency information. n4 All of this supplements the information
collected by police during street encounters and bookings and the records
amassed and maintained by criminal and juvenile courts, the numbers of which
have also greatly expanded in recent years. Public and private services
aggregate much of this information, making it available to law enforcement
nationwide, private employers, public housing authorities, colleges, and the
general public, often at no cost. n5

   In the late 1980s, Roger Clarke offered the term "dataveillance" as a way to
conceptualize the new forms of surveillance facilitated by the  [*198]
widespread use of computer-based technology. n6 This Article critically examines
the expansion of the modern culture of "dataveillance" to youth. Collectively,
the robust and expanding data collection and distribution practices described in
this paper produce what I call criminal justice biographies of young people. n7
These one-sided, negative biographies written by a coercive institution label
youth in permanent and stigmatizing ways. This harms individual youth and
distorts the perceptions of them as a group with lasting policy implications.
Yet, the literature on law enforcement surveillance on the one hand, and
traditional juvenile justice on the other, have yet to recognize, much less
fully grapple with, the databasing of delinquency.

   This Article reveals the incoherence and destructiveness of databasing
delinquency, and argues that we must rethink this practice. Mindful of the
public safety benefits and inevitability of law enforcement information
gathering, it calls for reforms that limit the amount of information gathered,
stored, and shared about juveniles. This would not prevent data collection, but
would instead add appropriate restraints so that public safety gains from
databasing do not come at the expense of privacy, juveniles' life chances, or
childhood itself.

   Part I sets the context. Instead of widely discussed constitutional
protections like the Fourth Amendment or privacy, n8 this Article examines
delinquency databasing through the lens of the constructed category of
childhood. Too little legal scholarship has critically examined the role of the
concept of childhood in shaping law and social practices, and the role that law
and social practices play in shaping the conceptions of childhood. n9 This
vacuum leaves juvenile justice scholarship less nuanced than it could be.
Drawing on the insights of critical childhood studies, n10 Part I establishes
the prevailing conception of childhood as a protected space separate from
[*199]  adult society. Marshaling adolescent brain science, psychosocial
research, and recent Supreme Court jurisprudence, it shows that young people's
vulnerability, their capacity for change, and their future as adult members of
society each play an important background role in guiding public policy
regarding youth.

   Part II uncovers the vast extent of modern delinquency databasing. It
explains how, despite youths' vulnerability to harm and capacity for change,
juveniles now find themselves indefinitely cataloged in sex offender registries,
gang databases, and DNA databases. It documents the unprecedented breadth and
permanence of law enforcement and court recordkeeping. It shows how schools have
become mandated law enforcement informants. And it maps the many ways that this
information travels within and outside of the criminal justice system.

   While extensive data collection and publicly available criminal records can
be a rational law enforcement strategy that promotes public safety, Part III
identifies the many harms that databasing delinquency inflicts on juveniles.
They include devastating impacts on their immediate lives in the form of
punishment, restrictions on their life choices, stigma, and (perhaps) increases
in recidivism. Compiled early in the life of their subject, when identities and
character are still taking shape, n11 and skewed in content, these criminal
justice biographies also distort perceptions of juveniles in ways that
facilitate support for punitive policies toward youth and discrimination against
them. This distortion and discrimination is visited especially heavily on
minority youth and constitutes an engine of racial bias in its own right.

   Part III further shows that databasing delinquency reshapes the very meaning
of childhood, breaching its protected space and contradicting the special
understandings that guide the regulation of youth. n12 Rather than honoring the
particular developmental characteristics of youth, databasing delinquency
ignores them and treats young people like adults. This contradicts the
long-dominant diversionary approach to juvenile wrongdoing n13 and gainsays the
fundamental message of a quartet of recent Supreme Court cases that criminal law
and the police cannot proceed against young people "as though they were not
children." n14

    [*200]  Cognizant that this is a critical time in the rebuilding of juvenile
justice norms, n15 Part IV proposes limitations on what information law
enforcement should gather, how long that information should be stored, and with
whom the information may be shared. The principles and values discussed in Part
I - young people's vulnerability, their capacity for change, and their future as
adult members of society - inform the recommendations. The proposed reforms
would reduce the short and long-term harms caused by databasing delinquency,
enabling the criminal justice system to promote public safety and hold juveniles
accountable without unduly hindering their development into productive adults.

   I. Childhood

 We recognize and accommodate many values when we choose how to marshal
technology's unprecedented data collection abilities for law enforcement
purposes. That we have extended the reach of law enforcement dataveillance to
juveniles necessarily injects the developmental characteristics of youth and the
purpose and meaning of childhood into the debate. Therefore, a brief
introduction to the concept of childhood is necessary.

   Childhood is an essential and permanent component of the social order. n16 It
is a natural fact - children are different from adults in known and measurable
ways. n17 Yet childhood marks something more than empirical, biological
realities or chronological age. n18 It is also a social construction, a
contingent category whose boundaries are not inevitable or fixed, but are
instead defined and maintained by law. n19 As such, childhood is the product of
our collective imagination, reflecting prevailing societal priorities and
aspirations. n20 This leads to varying definitions of the scope of childhood:
individuals cannot lawfully drive a vehicle until sixteen, vote  [*201]  until
eighteen, or drink alcohol until twenty-one. n21 The variety in cut-offs is
inevitable, as different activities require different levels of skill or
maturity. Wherever the lines between childhood and adulthood rest, the
expressive function of the law then feeds the law's definition(s) of childhood
back to society, shaping or reinforcing popular views of childhood. n22

   The prevailing conception of childhood today is "a protected space separated
from ... the broader adult society." n23 Childhood is separate from adulthood
because children are different from adults and require their own spaces, rules,
and institutions. n24 Childhood is protected because young people are
vulnerable. They make mistakes and have a greater capacity for change than
adults. As a result, the law applies special rules to young people. n25 Indeed,
it provides an entirely separate forum for adjudicating juvenile matters n26
that delivers youth-focused services and developmentally-appropriate levels of
accountability. As a matter of first principles, the law aims to avoid imposing
harsh, enduring consequences and stigmas so that juveniles do not carry the
burden of their youthful mistakes into adulthood. n27 The ultimate goal is "to
shepherd children into a self-sufficient, democratic, productive, and autonomous
adulthood." n28

   This Part explains how three foundational truths about youth - that they are
vulnerable, that they change, and that they are future adults - guide the law's
approach to childhood.

   A. Youth Are Vulnerable

 Young people by definition are immature. Juveniles are in "the earlier stages
of their emotional growth, their intellectual development is incomplete, they
have had only limited practical experience, and their value systems have not yet
been clearly identified or firmly adopted." n29 Their immaturity profoundly
impacts how they live their lives. First and foremost, it makes them vulnerable.
According to leading juvenile  [*202]  developmental psychologist Laurence
Steinberg, "adolescence is often a period of especially heightened
vulnerability." n30

   Two particular vulnerabilities of youth - their susceptibility to poor
decisionmaking and their physical and emotional immaturity - shape the legal
regulation of juveniles. Juveniles' incomplete cognitive and psychosocial
development undermines their ability to make competent decisions. n31 Young
people are less able to process information quickly and thoughtfully, and have
less general knowledge and experience to draw upon, leading to poorly reasoned
choices. n32 In addition, adolescents are less likely to consider the long-term
consequences of their actions, and are more reward sensitive and less risk
averse than adults. n33 This poor impulse control is compounded by the fact that
they are profoundly attuned to and influenced by peers. n34 Taken together,
these qualities often lead to delinquent behavior. Indeed, largely on account of
these attributes, offending peaks during late adolescence, n35 leading many to
consider delinquency a part of the normal life course. n36

   Their physical and emotional immaturity also makes youth especially
vulnerable to harm. Young people suffer specific, and often greater, harms as
youth, and they are more likely to suffer them because of their youth. n37 They
are, for example, more susceptible to suffering psychological harms than their
adult counterparts under similar circumstances. n38 They are especially
vulnerable to victimization in adult institutions, and are at a greater risk
than adult inmates of psychological harm and suicide. n39 Young people are also
particularly vulnerable to  [*203]  lasting problems as a result of stigma,
including mental health problems, substance abuse, and re-offending. n40
Moreover, particular practices, such as a life-long criminal record or a life
without parole sentence, impose greater harms on juveniles by virtue of the
simple fact that juveniles will live with the sanction longer. n41

   On account of their immaturity and vulnerability, the regulation of youth has
long been infused with the idea that they deserve special protections. n42 This
protective regime first came to legal fruition in the late nineteenth century,
when Progressive Era reformers (the so-called "child savers") passed compulsory
education laws, restricted child labor, and created the child welfare system and
juvenile court. n43 Over one hundred years later, it still prevails. Rules
protect juveniles from being subjected to the same procedures and punishments
imposed on adults. In civil tort proceedings, for example, children are judged
by a "reasonable person of like age, intelligence, and experience under like
circumstances" standard that leads to limited civil responsibility for damages
they cause. n44 To protect minors from "foolishly squandering their wealth
through improvident contracts with crafty adults who would take advantage of
them in the marketplace," n45 a contracting minor may repudiate the contract at
any time before reaching majority or within a reasonable time afterwards. n46

   The protective approach to childhood necessarily includes the criminal law.
The juvenile court was founded over a century ago on the proposition that
children are different from adults and should avoid the punitive and
stigmatizing consequences imposed by criminal court. n47 It survives today
because society continues to recognize that youth deserve a separate, more
protective forum that will impose accountability while  [*204]  honoring the
childhood of those before the court. Many protections extend to those juveniles
processed in criminal court. n48 For instance, the Supreme Court has held that
the death penalty cannot be constitutionally imposed on juveniles because their
"vulnerability and comparative lack of control over their immediate surroundings
mean juveniles have a greater claim than adults to be forgiven for failing to
escape negative influences in their whole environment." n49 Their vulnerability
similarly prevents law enforcement from ignoring childhood during criminal
investigations. n50

   This is not to say that youth are innocents. While vulnerable, juveniles are
autonomous actors who have the ability to recognize right from wrong, and they
exercise that autonomy by choosing, at times, to do bad things. n51 Moreover,
they require and respond to accountability. But youths' reduced culpability and
increased vulnerability to harm mean that the quantity of accountability
appropriate for juvenile behavior is necessarily limited. n52

   B. Youth Change

 Young people are developing in almost every arena: physically, biochemically,
intellectually, emotionally, and psychosocially. Their physical bodies undergo a
growth spurt between the ages of ten and eighteen, n53 and neuroscientists
describe adolescence as a period of profound social cognitive change. n54 It is
also a time when identity is taking  [*205]  shape and character forms. n55 As
the Supreme Court observed, "the signature qualities of youth are transient."
n56

   The dynamism of youth matters greatly to the law's response to juvenile
offending. As explained above, youths' immaturity contributes to delinquent
behavior. Yet most youth desist from delinquency as they mature into adulthood.
n57 Studies frequently find that only five percent to ten percent of adolescent
offenders continue offending in adulthood. n58 This is because many of the
factors associated with antisocial, risky, or criminal behavior lose their
intensity as individuals become more developmentally mature. n59 In fact, it has
proven nearly impossible to researchers to identify which few among the many
youthful offenders will persist into adulthood. n60

   Courts and policymakers have regularly affirmed the relevance of youths'
capacity for change to the proper regulation of childhood. It goes a long way in
explaining why juvenile court was invented, and why it aims to privilege
rehabilitation over punishment. The notion of change pervaded the words of one
of the nation's earliest juvenile court judges, who explained that the purpose
of the juvenile court was "not so much to punish as to reform, not to degrade
but to uplift, not to crush but to develop, not to make him a criminal but a
worthy citizen." n61 As such, delinquency adjudications do not necessarily
become part of a young person's permanent criminal record. n62 Instead, stricter
confidentiality provisions protect them against disclosure, and juvenile court
records  [*206]  typically can be sealed or expunged when the young person
reaches a particular age. n63

   Youth's capacity for change likewise protects them when they are charged in
criminal court. In a trio of recent sentencing cases, the Supreme Court
recognized that "the character of a juvenile is not as well formed as that of an
adult" and that their "personality traits ... are more transitory, less fixed."
n64 Because juveniles are more capable of change than are adults, "their actions
are less likely to be evidence of "irretrievably depraved character' than are
the actions of adults." n65 In short, "a greater possibility exists that a
minor's character deficiencies will be reformed." n66 As a result, the law seeks
to protect them from conclusive judgments and permanent legal disabilities.
According to the Supreme Court, "from a moral standpoint it would be misguided
to equate the failings of a minor with those of an adult." n67 The Constitution
thus forbids the imposition of the death penalty and mandatory life without
parole sentences for crimes committed by youth, and protects youthful offenders
from life without parole for non-homicide crimes. n68

   C. Youth (Ideally) Become (Productive) Adults

 Childhood is "a time-limited developmental category." n69 As leading critical
childhood scholars Allison James and Adrian James observed, "all children do
grow up and, in doing so, leave their "childhood' behind them." n70 That young
people will leave childhood and become adults has two important consequences for
the regulation of childhood. First, children must be taught social norms,
including that society imposes consequences for misbehavior. n71 Second, that
lesson must be delivered in a way that preserves their chances for a productive
adulthood. n72

    [*207]  The juvenile court was created to accomplish both those tasks. n73
Its purpose was to divert juveniles from the criminal process, and its
debilitating punishments and stigma, to a forum where their cases would be
handled by trained specialists dedicated to imposing accountability while
promoting the youth's rehabilitation. n74 Because children are future adults,
the criminal justice system as a whole - including law enforcement and criminal
courts - has a greater interest in promoting youth development and
rehabilitating those who offend than punishing, stigmatizing, and marginalizing
them. Thus, some jurisdictions have recently sought to make transfer of youth
charged with crimes to adult court more difficult n75 and attempted to minimize
the consequences for youth processed in criminal court through legislatively
created classifications like "Youthful Offender" status. n76 Other statutes
limit the amount of restitution juveniles may be ordered to pay to avoid
saddling them with debts that would cripple their transition to independent
adulthood. n77 These policies aim to protect youth from full accountability to
preserve their future life chances.

   These protective impulses reflect the view that severe punishments, permanent
disabilities, and lasting stigma for youthful mistakes do not serve the
long-term interests of society. While reforms have not gone as far as they
might, n78 the vulnerability of youth, their capacity for change,  [*208]  and
their future as adults have taken a more central role in policymaking in the
twenty-first century.

   One notable exception to this trend is law enforcement data collection, where
special protections for youth are falling away. Compiling criminal justice
biographies of youth disregards their vulnerability, discounts their capacity
for change, and makes more difficult the transition to adulthood. The next Part
describes those practices.

   II. The Delinquency Databases

 From street observation to cultivating informants, to fingerprints, body
measurements, and rap sheets, law enforcement has always collected and stored
data to help solve and prevent crime. n79 For decades, law enforcement stored
its data in the memories of individual constables and beat officers, or in
physical card catalogs at the station house. n80 The computer revolution of the
last thirty years has changed that, exponentially increasing the ability of law
enforcement to collect, store, retrieve, and share data. Computer technology has
enabled networked storage, powerful search capacity, real time updating, and
near instantaneous retrieval by officers in the station house and the field.

   This data and database revolution has received significant attention. n81
Still, few have considered the particular concerns raised by aggregating data
about young people. n82 As Part II of this Article demonstrates, in contrast to
decades of practices that mostly shielded young people from accumulating law
enforcement records, the criminal justice system today largely treats juveniles
like adults when it comes to the collection and retention of information.

   All told, the criminal justice system collects a remarkable amount of
information about youth: contacts with police, suspicions, misbehavior, arrests,
charges, convictions, and sentences. But it is not just criminal information
that is being collected, stored, and shared. Law enforcement collects genetic
samples from juveniles; it catalogs their friends, family, associations, and
movements; and the law requires that personal information of youth convicted or
adjudicated delinquent of sex offenses, such as their home address and school,
be posted on the Internet.

    [*209]  The following subpart exposes the broad, interconnected content of
this databasing. It then explains how these practices collectively result in
criminal justice biographies of youth.

   A. Gang Databases

 Law enforcement often collects data on individuals long before a crime is
committed or reported. It regularly compiles dossiers on and surveils those who
it believes are likely to be involved in crime. Just who gets enhanced attention
changes over time. n83 Today, a prime police target is poor, urban, minority
youth, especially those allegedly linked to the scourge of gangs. n84
Anticipating that these youth will become offenders, law enforcement seeks to
gather as much information as it can about them. The modern tool it uses to
collect, organize, and disseminate intelligence information prior to a criminal
case is the gang database.

   Gang databases are repositories for information about known and suspected
gang members. The Los Angeles County Sheriff's Department instituted the first
modern gang database in 1987. n85 Similar gang databases are now maintained
across the nation at the local, state, and federal levels. n86 Gang databases
can include almost anything, but typically record the youth's name, address,
dress, tattoos, locations, behaviors, criminal histories, vehicles, school,
family, and friends. n87 Law enforcement collects the information entered into
the database primarily through routine stops on the street and in schools. n88

   Gang membership is not a crime, and a conviction is not necessary before an
individual's information can be entered into a gang database. n89 Indeed,
neither an arrest nor a criminal investigation need precipitate the
categorization of a youth as gang-involved. n90 Instead, police decide who gets
included. n91 Inclusion can be triggered by street encounters with police,
self-admission, or a combination of other indicators. In some jurisdictions,
[*210]  qualifying criteria are statutory. While that ostensibly limits police
discretion, the qualifying criteria can include vague (and perfectly lawful)
things such as "[being] in a photograph with a known gang member,"
"corresponding with known gang members," frequenting a gang area, or wearing
certain clothing. n92 In Victor Rios's study of Oakland youth, he described how
a fifteen-year-old who was not in a gang ended up in a gang database after he
was attacked while sitting on his front door steps talking with friends. n93
Because the attackers were gang members, detectives assumed that the victim was
as well, and registered him as an active gang member. n94

   The broad criteria for inclusion in gang databases, and the discretion
afforded to law enforcement in deciding whom to include, make it difficult for
young people living in gang-heavy communities to avoid qualifying criteria. Law
enforcement's desire to collect as much intelligence and potential evidence as
possible about those it expects to be offenders encourages it to be
over-inclusive in its classifications. n95 The lack of age limits for inclusion
in gang databases means that children as young as ten are present in gang
databases. n96

   While the particularities of gang databases vary, most use a software
platform that enables the aggregation and organization of information. n97
Typical of gang databases is that of California, known as CalGangs. It is a
web-based intranet system accessible by police via a computer, phone, or web
browser. The California Attorney General described it as a "wide area, low cost,
easy to use, securely networked, relational, intelligence database." n98

   Gang databases impact the lives of juveniles in many ways. Law enforcement
uses gang databases as an investigatory starting point filled with prime
suspects. n99 They influence which individuals and communities are targeted for
policing. Those known or suspected to be in a gang  [*211]  appear to receive
harsher treatment at every stage of the investigation and adjudication
processes. In Tampa, Florida, for example, an individual without an arrest
record was erroneously placed in a gang database and then stopped four times in
three months, barred from the public housing project where he lived, and
arrested for being there. n100 Documented gang members, and those living in
gang-dense neighborhoods, are more likely to be charged with a crime, more
likely to be remanded while awaiting trial, and if a juvenile, more likely to be
tried as an adult (which has been shown to increase recidivism). n101 Courts may
impose special probationary conditions on gang members, forbidding them from
associating with other known or suspected members. n102 At sentencing, gang
enhancement statutes allow courts to add additional years for gang members and
gang-related crimes. Some jurisdictions forbid plea bargains and require
prosecutors to seek the highest penalty possible in gang-related prosecutions.
n103 School officials use gang information to direct security resources and
assign counseling resources. n104

   The structure and management of gang databases make it difficult, if not
impossible, to know whether a particular person has been classified as a gang
member. The information in gang databases is not publicly available. According
to the California Attorney General website, "release of CalGang(R) Criminal
Intelligence Information is on a Right-To-Know (A Law Enforcement Officer) and
Need-To-Know (Legitimate Law Enforcement Purpose) basis only." n105

   Only a few gang databases have provisions that require law enforcement to
notify parents when youth are classified as gang members. n106 Moreover, law
enforcement typically does not offer a procedure for individuals to contest
their inclusion or to seek or confirm their purging from a gang database. This
means that youth classified as gang involved by police can remain in a gang
database (often unbeknownst to them) for years. Even where purging procedures
are in place, they are rarely carried out. n107 There is little incentive for
law enforcement to purge  [*212]  records from their intelligence databases. And
because of how the guidelines governing many gang databases work (purging is
allowed only if no new information is entered regarding an individual for two or
five years), n108 police can intentionally avoid purging by checking in on
someone regularly, entering gang-related information gained during the encounter
(perhaps about friends or family members of the juvenile).

   Though gang databases are not publicly available, and despite the fact that
many youth never know they have been classified by law enforcement as a gang
member, the information in gang databases leaks beyond law enforcement. As a
general matter, criminal law scholar James Jacobs noted that "once information
is entered into an investigative or intelligence database, it can easily migrate
to other public and private databases and, therefore, can become more difficult
to purge or edit effectively." n109 Specific studies of gang database
information have found this to be true. According to one study, "information
collected [in CalGang] has been shared with employers, landlords, Public Housing
and Section 8, and school administrators." n110 Others have found that police
share gang information with schools. n111

   B. Schools as Informants

 Schools have increasingly become a contact point for youth and the criminal
justice system. Scholars in many fields, including law, education, political
science, and sociology, have traced the rise of the culture of control in the
classroom, and its devastating impacts on youth. n112 From metal detectors and
fingerprint identification required for entry, to video surveillance and police
presence on campuses, schools are policed more than ever. n113 In addition,
schools have criminalized normal adolescent behavior: pushing and shoving has
become battery, swiping a classmate's  [*213]  headphones has become theft or
robbery, and talking back to staff has become disorderly conduct or obstructing.
n114 As a result, young people are intentionally and increasingly diverted from
the classroom to the juvenile and criminal justice systems. n115 These practices
are particularly prevalent in urban public schools attended primarily by
minority youth, n116 a disparity that is "not explained by more frequent or more
serious misbehavior by students of color." n117

   The upshot of these changes is that schools are less likely to handle
disciplinary matters internally. n118 This "criminalization of school
discipline" n119 makes schools "the first institution in which most youth have
an opportunity to be marked as failures, criminals, or deviants." n120 The fact
that schools increasingly turn to law enforcement to deal with misbehavior
reinforces the perceived criminality of the acts. In the last two decades,
legislatures across the country have turned schools into mandated informants,
requiring school officials to report to law enforcement a wide variety of
behaviors and suspected acts by students at school. As a result, all sorts of
behavior and suspicions that in the past would have stayed on  [*214]  campus
are now shared with law enforcement. n121 This leads to more criminal justice
contact for youth, disruptions in their education, and negative outcomes. n122

   One main reason that schools are now in the collecting and reporting business
is that Congress has incentivized it. Two major pieces of legislation do most of
the work. The Improving America's Schools Act of 1994 provided funds to public
schools that demonstrated an existing crime problem, compelling schools
nationwide to develop data-collection systems and define crimes broadly so that
they could qualify for federal funds. n123 Many of these funds were spent on
school-police partnerships, such as hiring security or law enforcement officers
to patrol school campuses. n124 The mere presence of these officers both
facilitates reporting and makes more crime possible as refusing to follow the
orders of these school security officers is a crime. n125 Then, in 2001, the No
Child Left Behind Act required school districts receiving federal funds to have
a policy requiring that any student who brings a firearm or weapon to school be
referred to law enforcement. n126

   With federal money tied to documenting crime in school and reporting it to
law enforcement, it is no surprise that almost all states require school
officials to report to law enforcement suspected violent crimes or incidents
that involve deadly weapons or dangerous instruments. n127 Other states go much
farther. Many, including California, require schools to  [*215]  report when
students use, sell, or possess drugs or alcohol. n128 Connecticut requires
principals to notify law enforcement when the principal "believes that any acts
of bullying constitute criminal conduct," n129 and Illinois requires principals
to notify law enforcement of "each incident of intimidation ... and each alleged
incident of intimidation which is reported to him or her." n130 Kansas requires
an immediate report to law enforcement by or on behalf of any school employee
who knows or has reason to believe that a misdemeanor was committed at school or
a school supervised activity. n131 Given the funding incentives, schools are
likely to err on the side of reporting, even when they do not believe (or know)
that an act constitutes a crime.

   The failure of a school employee to report incidents to law enforcement can
carry consequences. For example, it is a Class B misdemeanor in Kansas to
willfully and knowingly fail to report suspected crimes to law enforcement, n132
and it is an infraction punishable by a fine of up to $ 1000 in California for
"any employee of a school district [who] is attacked, assaulted, or physically
threatened by any pupil" to not promptly report the incident to the appropriate
law enforcement authorities. n133

   Schools are not just sharing behavioral information with law enforcement.
Reports have surfaced of schools sharing records with noncriminal justice
government agencies, such as immigration enforcement authorities. n134

   Information also flows from law enforcement to the schools. At least nineteen
states now require courts or law enforcement agencies to provide criminal or
delinquency information to schools. n135

[*216]

   C. Police and Court Records

 While gang databases and schools as informants are relatively recent phenomena,
criminal justice recordkeeping is nothing new. Traditional forms of data
collection include rap sheets, intelligence gathered by police during street
encounters, and court recordkeeping. Technology has transformed the quantity of
information that can be gathered and the ability to retrieve that information at
will. At the same time, the criminal justice system has expanded the kind and
amount of information it keeps about young people. Moreover, juvenile records
are increasingly accessible to the media, employers, schools, government
agencies, victims, and others. n136

   1. Policing Data

 Legislatures and law enforcement have a history of restricting law
enforcement's ability to create records of juveniles. For decades, most states
prohibited police or juvenile authorities from taking fingerprints or
photographs of juvenile suspects, unless taking them was necessary to an
investigation or was otherwise approved by a court. n137 Such restrictions were
"an extension of the efforts to protect the identities of juveniles and to make
their contact with the police and the court less like that experienced by adult
offenders." n138 By restricting the practice, they sought to "safeguard[] the
child from unwarranted indicia of misconduct becoming a part of police and court
records" and protect their privacy. n139

   Identity records of juveniles, once created, benefitted from enhanced
confidentiality and other protections compared to adult law enforcement records.
Juvenile records kept by police were typically held in decentralized, local
systems, apart from adult criminal records. n140 This confined knowledge about a
juvenile's prior contact with the police to the juvenile's locality. Statutory
confidentiality, combined with sealing and expungement provisions, further
ensured against any lasting effect of  [*217]  criminal records. n141 These
practices continued well into the late twentieth century. As recently as 1988,
only a quarter of law enforcement agencies fingerprinted juveniles. n142

   Today, these protections have faded. Juvenile law enforcement records
increasingly resemble adult law enforcement records: they are more regularly
created, include more information, are stored with adult records, and are more
widely available. Nearly every state allows juveniles to be fingerprinted at
arrest. n143 All states allow juvenile arrestees to be photographed, and nearly
all send information about juvenile arrestees to statewide repositories. n144
The FBI authorizes the inclusion of juvenile criminal history record information
in the FBI's National Crime Information Center ("NCIC") database on the same
basis as adult records. n145 The Supreme Court has held that the media cannot be
stopped from disclosing a juvenile arrestee's identity as long as it acquired
the information lawfully. n146

   The impact of eroded protections for youth has been multiplied because
technology has enabled law enforcement to record, store, organize, and retrieve
more data than ever. A traditional method for police to gather information on
individuals is the Field Interview ("FI") card. Known by different names, these
are forms filled out by police officers after encounters with individuals. n147
They record pedigree information (such as name, address, and date of birth) and
details about the encounter. n148 Police often complete FI cards after routine
encounters  [*218]  done without probable cause, a great many of which did not
end in an arrest. n149

   The FI card practice has been transformed by technology. Law enforcement
staff used to record and organize the information by hand, a laborious manual
entry process. The information is now aggregated and stored in computers, making
it easy to search and retrieve. Software companies have developed computer and
smartphone applications that allow officers to complete FI cards using their
smartphones. n150 These applications eliminate the need to manually enter
information recorded by the officer on the paper form into a database, because
both processes happen at once. This reduces the amount of time required for data
entry, enabling law enforcement to record more information after more
encounters. n151 It also makes retrieval and analysis of the information
gathered much easier.

   The archetypal police record, the Record of Arrest and Prosecution ("rap
sheet"), is a lifetime record of an individual's arrests. Developed at the
beginning of the twentieth century, the rap sheet was "created by police for
police use," to enable police to link records with people. n152 Rap sheets are
no longer just for the police. Congress and states have directly authorized
certain industries, businesses, and other groups to obtain criminal histories
from the FBI for job applicants, employees, and volunteers. n153 In 2012, the
FBI processed some seventeen million criminal background checks for employment
and licensing purposes (made possible by networked computers). n154 Moreover,
"some police departments ... go beyond what constitutional and statutory law
requires, aggressively disseminating arrestee information." n155 As a result, a
"system created by police for the police is now more often used to provide
criminal biographies for non-criminal justice purpose." n156

   Law enforcement agencies across the nation also maintain a variety of
intelligence databases that store much more than just records of arrests,
including the gang databases already mentioned, as well as tattoo  [*219]
databases, birthmark and scar databases, teeth databases, and many others. n157
Information in these databases comes from all the information collected by
officers during street encounters and reported in FI cards, as well as from
bookings, 911 calls, complaints by victims, reports on accidents, and moving
violations. n158 Photograph databases collect images taken at arrests and those
gathered from surveillance cameras. n159

   The granddaddy of all law enforcement databases is the NCIC, "an electronic
clearinghouse of crime data that can be tapped into by virtually every criminal
justice agency nationwide, 24 hours a day, 365 days a year." n160 The NCIC
includes fourteen person files that include records on individuals on probation,
parole, supervised release, released on their own recognizance, or during
pretrial sentencing; records on violent gangs and their members; records on
individuals for whom a federal warrant or a felony or misdemeanor warrant is
outstanding; and records of persons with a violent criminal history and persons
who have previously threatened law enforcement. n161 Automated criminal history
record information contained in the Interstate Identification Index is
accessible through the same network as NCIC. n162 Beginning in 1992, the FBI
allowed juvenile criminal history record information in NCIC on the same basis
as adult records. n163

   Together, these technology-enhanced data collection, organization, and
retrieval systems provide law enforcement with more information than ever on
those they have and will encounter on the streets.

   2. Court Recordkeeping

 Court records document what happens when formal criminal charges are filed
against an individual. Whether they are criminal court or juvenile court
records, they include more than just a charge and the end result of the
proceeding. Court records can contain arrest records, detention history, school
records, medical, psychological, and behavioral records, and family and social
history. n164

    [*220]  For those 200,000 juveniles processed annually in criminal court,
n165 convictions and court records are recorded as they are for adults. Other
than the limited availability of "youthful offender" status, and its narrow
protections, no special provisions protect the records of juveniles convicted in
criminal court. n166 This is significant because criminal court records have
long been available for public inspection. According to Jacobs, "only the United
States and Canada permit anyone to look at case files without having to persuade
a judge or clerk that she has a good reason to see the file." n167 Before the
computerization of court records, though, they were difficult to access. n168
Review required physical travel to the local courthouse or record repository and
time spent retrieving and reviewing the records.

   Today, court records are much more accessible, meaning that police and
non-law enforcement personnel can access an individual's court history with
minimal effort. Most state court systems have websites that allow anyone
(sometimes for a fee) to search docket sheets and retrieve criminal court record
information on individuals. Approximately twenty state court systems sell copies
of their criminal court docket sheets to commercial information vendors. n169

   The vast majority of juveniles charged with crimes have their cases handled
in a juvenile court instead of a criminal court. n170 Consistent with the
institution's diversionary aim to "prevent children from being treated as
criminals," n171 juvenile courts have offered more robust protections against
the creation of a criminal dossier. At its inception, juvenile court proceedings
were held in private, before only a judge and not a jury. By design, such
proceedings were not criminal and resulted in something other than a criminal
conviction. n172 Most states limited disclosure of information about juveniles'
adjudications, and required court case files  [*221]  to be automatically sealed
when the juvenile turned twenty-one. n173 When judicial opinions regarding
delinquency proceedings were issued, they protected a juvenile's identity by
using the juvenile's initials instead of her full name.

   Many of these protective policies remain today. There still are no juries,
n174 and case opinions continue to mask the juvenile's identity. Delinquency
adjudications do not necessarily become part of a young person's permanent
criminal record. Instead, stricter confidentiality provisions protect against
disclosure of juvenile adjudications, and juvenile court records typically can
be sealed or expunged at a particular age. n175

   But as with police records, these confidentiality provisions have eroded over
time. Juvenile court proceedings today are less likely to be closed to the
public. n176 Juvenile court records are also more broadly available, as no state
completely protects juvenile court records from dissemination to certain
entities outside the court and law enforcement. n177 Only nine states require a
court order before juvenile court records can be released. Only eighteen states
ensure that juvenile record information is not available to the public or
accessible on any online database. n178 In Maine, for example, anyone can obtain
a person's delinquency adjudications for a thirty-one-dollar fee. n179 Juvenile
records can be obtained in Florida for twenty-four dollars. n180 Arizona and
Idaho provide no confidentiality protections to juvenile court records. n181
Compounding the significance of this confidentiality erosion, the Supreme Court
has  [*222]  also ruled that state laws cannot protect testifying witnesses from
impeachment by these juvenile records. n182

   While juvenile courts used to seal or expunge juvenile court records on their
own initiative, today only five states automatically expunge juvenile records.
n183 In all other states, the youth, or another party, must file a petition and
convince a court at a hearing to seal or expunge a juvenile court record. n184
In many of those states, youth are not advised of their obligation to initiate
sealing or expungement. And as a result, many do not. Even when juveniles do
initiate sealing or expungement procedures, more than half the states include
statutory exceptions to sealing and expungement based on age at time of offense,
the nature of the offense, and the amount of time that has passed since the case
was closed. n185

   The end result is that police and courts create more records about youth than
ever. The records last longer, and they are more accessible by those outside of
courts and law enforcement than ever before.

   D. DNA Databases

 Another controversial criminal justice practice that has similarly expanded to
include juveniles is DNA profiling. In short it works as follows: a biological
sample containing a person's entire genetic code is collected via buccal swab or
blood draw, n186 and analyzed by a laboratory to create a DNA profile. n187 DNA
profiles are then entered into one or more government databases. n188 The
Combined DNA Information System ("CODIS") is a software program that facilitates
the matching of the DNA profiles of known offenders or arrestees to profiles
generated from crime scene DNA evidence. n189

    [*223]  DNA databasing is a powerful tool that makes it possible to solve
crimes quickly and confidently, including very old crimes, and can even
exonerate the wrongfully convicted. n190 Collection of biological samples is
accomplished primarily through contact with the criminal justice system. The
federal government and all fifty states compel DNA collection from anyone
convicted of a felony in criminal court. n191 In every state except Hawaii, this
includes any juvenile convicted of any felony in criminal court. n192 All but
four states also mandate collection from all persons convicted of certain
misdemeanors, including juveniles. n193

   DNA collection from juveniles is not limited to those charged as adults.
Twenty-nine states compel DNA samples from juveniles following a finding of
juvenile delinquency. n194 Of those twenty-nine states, twenty collect DNA for
all felony adjudications, while nine collecting only for a subset of felony
adjudications. n195 Nineteen states mandate DNA collection from juveniles
adjudicated delinquent for a misdemeanor. n196

   Neither a conviction nor a delinquency adjudication is a necessary predicate
for DNA collection. In some states, a mere arrest can trigger compulsory DNA
collection. As of 2014, the federal government and twenty-seven states require
individuals arrested but not yet convicted or adjudicated delinquent to provide
DNA samples. n197 Of the twenty-seven, nineteen permit collection from juveniles
at arrest. n198

    [*224]  Law enforcement also acquires DNA samples from juveniles based on
consent. Most notable in this regard is Orange County, California's "DNA
Collection and Crime Deterrence Program," known colloquially as the "spit and
acquit" program. n199 In place since 2007, "spit and acquit" permits individuals
who are arrested to have their charges dismissed or reduced if they provide law
enforcement with a DNA sample. n200 This DNA collection initiative has
reportedly generated over 90,000 DNA profiles. n201 The program does not
restrict collection from juveniles.

   Even in the absence of such organized DNA collection initiatives, law
enforcement seeks DNA samples from juveniles based on consent. For example,
police went to Albert Einstein Middle School in Sacramento, California, to
obtain DNA cheek swabs from adolescents as part of a murder investigation. n202
Authorities in Brighton, Colorado, similarly acquired consent-based DNA samples
from a twelve and eleven-year-old when their parents were not home as part of an
investigation into car break-ins. n203

   All told, law enforcement has already compiled DNA profiles of hundreds of
thousands of juveniles. n204 Going forward, as many as several hundred thousand
juveniles could be required each year to provide a genetic sample for purposes
of DNA profiling. n205

[*225]

   E. Sex Offender Registration and Community Notification

 While most criminal justice databases collect information primarily for
criminal justice system use, some serve a much broader purpose. They seek to
publicize criminal record information about those who have committed
particularly heinous offenses. In doing so, they enable public shaming and
lasting discrimination.

   The leading example of these data systems are sex offender registries. Under
various federal and state laws, juveniles convicted in criminal court or
adjudicated delinquent in juvenile court for sex offenses can be required to
register with law enforcement on sex offender registries and provide personal
information that is made publicly available via community notification
procedures. In some jurisdictions, these juveniles must register as sex
offenders and are subject to community notification for the rest of their lives.
In others, registration and community notification are time-limited.

   Federal law requires juveniles convicted in adult court of sex offenses to
register on par with adults. n206 Prior to 2006, federal law did not specify
whether juveniles adjudicated delinquent were subject to sex offender
registration, and the states decided themselves whether such juveniles were
subject to registration. n207 Some states required juveniles adjudicated
delinquent to register, but most protected them from it. n208 In 2006, Congress
passed the Adam Walsh Child Protection and Safety Act, which included the Sex
Offender Registration and Notification Act ("SORNA"). n209 SORNA requires
mandatory registration for any juvenile over fourteen adjudicated delinquent for
certain sex offenses. n210 SORNA has three tiers of offenses, and the burdens of
registration and notification flow directly from one's classification. The term
of registration is twenty-five years or life. n211 For certain sex offenses,
SORNA permits, but does not require, states to make juveniles' personal  [*226]
information publicly available on the Internet (under what are commonly called
"community notification" requirements). n212

   Despite the distinctive concerns and goals of juvenile court, including its
greater emphasis on rehabilitation and confidentiality, thirty-four states
subject juveniles adjudicated delinquent of a sex offense to register as sex
offenders in some manner. n213 In some of these states, the minimum age for
registration is lower than SORNA's age of fourteen, or there is no minimum age
requirement for registration. n214 Twenty-five states disclose juveniles'
personal information to the public via some form of community notification. n215
And despite evidence that juvenile sex offenders have exceptionally low
recidivism rates, n216 at least six states impose lifetime registration for
juvenile sex offenders. n217

   Juveniles subject to sex offense registration must provide personal
information (such as name, date of birth, current address, school, and employer)
to law enforcement. n218 A federal database collects all sex offender
registrants and is available to federal, state, and local law enforcement. n219
In addition, community notification statutes require law enforcement to publish
a registrant's personal identifying information to law enforcement, interested
parties, and the public. Today, much of this personal information is accessible
via the Internet. The Dru Sjodin National Sex Offender Public website n220
provides links to all public registries. Users can search particular names or
access a map that indicates the residences of registered sex offenders.
Residency restriction laws prohibit registered sex offenders from living within
a designated distance of places where children gather, such as schools,
playgrounds, parks, and even bus stops. n221 To top it all off, in many states
those subject  [*227]  to sex offender registration must pay registration fees.
Depending on the jurisdiction and the registrant's classification level,
registration fees can cost anywhere between fifty and several hundred dollars.
n222

   While the impetus for sex offender registration stems from the heinousness of
the underlying offense, the scope of behavior that can trigger registration as a
sex offender for juveniles is quite broad. Sex offenses are many and varied -
they range from fondling another over the clothes and grabbing classmates in a
sexual way at school, to consensual sexual intercourse with other minors, to
date and stranger rape. n223 This wide net leads to approximately 15,000 sexual
offense arrests of juveniles in the United States each year. n224

   SORNA does not allow judges any discretion to except a juvenile who has
committed a registerable offense from the registration requirements. n225
Federal law requires registration whether the offense is an adjudication of
delinquency or a criminal conviction, whether it is the juvenile's first
adjudication, whether the juvenile agrees to participate and successfully
completes a counseling or rehabilitation program, and whether the juvenile poses
a very low recidivism risk.

   Since juveniles first became subject to sex offender registration,
legislatures have consistently expanded the number of juveniles subject such
registration. In the last two decades, state and federal legislatures have
imposed on juvenile sex offenders longer registration terms, have required more
juvenile sex offenders to disclose more information about themselves publicly,
and have increasingly restricted their movements and activities, including
outfitting sex offenders with electronic GPS monitoring units. n226 Legislation
has also been amended to turn offenses that were nonregisterable at the time of
conviction or adjudication into triggers of registration, and reclassified
registerable offenses as more serious, increasing the registration or
notification burdens and the consequent restrictions. n227

    [*228]  Sex offender registration profoundly impacts a person's life. It
frustrates access to education, housing, and employment; n228 disrupts families;
n229 and causes social isolation and shame, n230 all of which increase the risk
of delinquency. n231 Some of these disabilities are mandated by law while others
flow from the publicity of the offense. As one juvenile sex offender put it,
"Our mistake is forever available to the world to see. There is no redemption,
no forgiveness. You are never done serving your time. There is never a chance
for a fresh start. You are finished." n232

   Courts predominantly uphold juvenile sex offender registration, juvenile
participation in community notification schemes, and restrictions on juvenile
sex offenders. Many courts have found that such requirements are collateral
consequences of a conviction or adjudication, and not punishment, and therefore
do not run afoul of the Eighth Amendment. n233 Concerns about the propriety and
impact of imposing registration and community notification on juveniles has
recently led to some movement away from juvenile sex offender registry. n234

    [*229]  The following graphic, Figure 1, illustrates the web of access to
the information collected by law enforcement.

 Figure 1


   Databasing delinquency is a massive commitment to data collection by the
criminal justice system about youth. Collectively, the data collection,
retention, and distribution practices described above produce criminal justice
biographies of the lives of youth. n235 The breadth of these biographies,
including not only formal convictions or adjudications but also arrests and
suspicions, and family, friends and associations, make them a damning record of
a particular individual's life. n236 That they are compiled and distributed by
such a powerful and coercive institution, upon which so many public agencies and
private employers rely for background information, make these criminal justice
biographies profoundly important. They unavoidably reflect the race and class
[*230]  enforcement skews in the criminal justice system, making them
particularly troubling. As juvenile justice scholar Barry Feld observed, "at
every stage - arrest, intake, referral, petition, detention, trial, and
disposition - youth of color fare less well than do their White counterparts."
n237 This results in racial skews in data collection, as law enforcement is more
likely to collect and retain information on minorities because it
disproportionately makes contact with people of color. n238 The criminal justice
system also skews against the poor: approximately eighty percent of people
charged with crime are poor, and poor defendants are more likely to be convicted
and incarcerated. n239 As a result, the great bulk of criminal justice
biographies of youth are written about the poor, and people of color (and
especially poor people of color).

   Rational reasons can explain why the criminal justice system in the United
States has come to write biographies of poor, minority youth. Broad data
collection and sharing helps law enforcement manage and solve crime, and has
some role in promoting offender rehabilitation via deterrence and shaming. n240
Accurate and complete police records, including precise physical descriptions
and biometric data, enable law enforcement to correctly and speedily identify
apprehended individuals. n241 Records also provide officers with valuable
information about the people they encounter. n242 The increasing ties between
law enforcement and schools allow schools to address the sometimes significant
crime problems inside and around campus, and remove those who distract from the
learning environment. n243 It also provides law enforcement with more
information about the behavior and associations of young people who spend a
great part of their lives at school. And there are dozens of stories of how DNA
databasing restarted a stalled investigation and helped solve an old  [*231]
crime, bringing a perpetrator to justice or freeing an innocent inmate. n244
Simply put, robust, accessible databases prevent some criminals from avoiding
detection and continuing to terrorize communities.

   The information in these records can also improve the efficiency and
effectiveness of policing and sentencing. Police access to the historical
information in these databases makes it easier for law enforcement to form
probable cause to arrest an individual. n245 It also allows law enforcement to
identify and target high-crime areas, and may enable them to identify
individuals who are more likely to offend. n246 Since peak offending rates occur
during late adolescence, n247 there is arguably no more critical time for law
enforcement to know so much about these individuals. Complete, accessible
records also increase the ability of judges to impose appropriate sentences,
taking full account of an individual's past acts and likelihood of reoffending.

   Mindful of the potential benefits of data collection, the next Part shows how
databasing delinquency harms youth and undermines childhood.

   III. Databasing Harms Youth and Undermines Childhood

 Databasing delinquency inflicts a cascade of harms on juveniles. It leads to
extra policing of their lives and communities, and triggers enhanced punishments
and lasting, destructive stigma. It restricts job, housing, and educational
opportunities. Databasing delinquency also distorts our view of the young people
subject to data collection. By creating one-sided, negative accounts of their
lives, it reinforces fears and stereotypes about juvenile offenders, promoting
more adult-like punitive juvenile justice policies. Not insignificantly, this
distortion is visited  [*232]  especially heavily on minority youth and
constitutes an engine of racial bias in its own right.

   Databasing delinquency also threatens childhood itself. It reflects a narrow
conception of the protective sphere of childhood at odds with longstanding legal
principles, undisputed scientific knowledge, and recent Supreme Court
jurisprudence. By treating young people like adults, it denies certain juveniles
the protections of childhood despite their remaining legally and developmentally
children. This reshapes the very meaning of childhood, breaching its protected
space and contradicting the special understandings that dominate the regulation
of youth.

   A. Databasing Harms Youth

 This Subpart identifies the many ways that gathering information, storing
information, and sharing information about the wrongs and mistakes of youth
harms juveniles. Some of these harms, such as enhanced punishments and
restricted opportunities, are the very point of databasing delinquency. Others,
like self-stigma, are less apparent, or perhaps even unintended, but are
nevertheless significant. The heightened vulnerability that marks adolescence
amplifies the harms caused by these dataveillance practices. That these harms
appear at a critical point in young people's lives, as they transition into
independent adulthood, further increases the short and long-term damage.

   1. Gathering Information Invades Privacy and Stigmatizes Youth

 The criminal justice biographies compiled by delinquency databases include far
more than just convictions or adjudications. They include records of arrests and
incidents at school, many of which are not followed by criminal charges. They
document the youth's friends, families, and associations. They can publicize a
young person's home address, school, and employer. n248 And they include
biological samples containing a person's entire genetic code. n249

   However lawful under the Fourth Amendment, n250 or rationalized by claims of
public safety, the profound amount of information found in delinquency databases
nevertheless constitutes a significant invasion of a young person's privacy.
n251 This invasion of privacy constitutes a harm even if it is considered a
lawful one.

    [*233]  As with adults, invasions of privacy can also lead to psychological
harm in adolescents. n252 This is what privacy scholar M. Ryan Calo
characterizes as the subjective harm of data collection. n253 It includes the
anxiety, embarrassment, or discomfort that accompany the belief that you have
lost control over information about yourself and are being, will be, or have
been watched or monitored. n254 Registered juvenile sex offenders and young
people who live in gang-riddled communities illustrate this kind of subjective
harm. Registered sex offenders cannot know who in the community knows of their
criminal history, but certainly feel anxiety, embarrassment, and discomfort
because their information has been gathered. n255 Likewise, urban youth feel the
"perception of unwanted observation," especially those who get extra attention
from law enforcement because they have been tagged as gang members. n256

   Databasing delinquency causes more than just privacy harm. Gathering the kind
of information included in the delinquency databases has profoundly stigmatizing
effects. Stigma refers to a mark or label of disgrace, shame, or discredit that
isolates certain individuals or groups. n257 Convictions, delinquency
adjudications, and other criminal justice contacts negatively label young
people. "Juvenile delinquent" is, itself, a stigmatic label. n258 The Supreme
Court has long recognized this. In re Winship identified the stigma that results
from being adjudged a delinquent as a liberty interest of "immense importance."
n259 In re Gault found the amount of stigma associated with the delinquent label
"disconcerting." n260

   Researchers Bruce Link and Jo Phelan have shown how stigmatic labels impact
those upon whom they are placed. The process involves five components: labeling,
stereotyping, separation, status loss, and discrimination. n261 Labeling is the
way differences are marked. Delinquency  [*234]  databases mark young people as
delinquents, sex offenders as perverts, n262 school kids as "thugs" and future
criminals, n263 and inner-city youth as gang-bangers. n264 Stereotypes are the
negative attributes linked (however rationally or persuasively) to the labels.
The negative label often serves to separate "them" from "us." Research has shown
how delinquent or criminal labels "embed juveniles into deviant social groups
through association and exclusion." n265 In some cases, "the stigmatized person
is thought to be so different from "us' as to be not really human." n266 This
has certainly happened with juvenile offenders, most infamously in the mid-1990s
when John DiIulio described teenaged offenders as "severely morally impoverished
juvenile super-predators." n267

   These attitudes have internal and external effects. Having your youthful
mistakes and wrongs cataloged leads to an internal stigma that impacts life
chances and choices. According to labeling theory, stigmatic labels are
self-fulfilling prophecies: when juveniles are identified as deviants or
criminals, they are more likely to act like criminals. n268 Delinquency
databasing communicates to the juveniles subject to it that the state believes
they already committed crimes that data collection will help solve, and that
they will commit crimes in the future. n269 Juveniles then internalize this
label, which leads to marginalization and additional offending.

   More recent research has suggested a slightly different mechanism for how
stigmatic criminal labels impact individuals and lead to deviance. "Modified
labeling theory" posits that "the individual's desire to manage shame leads him
to follow strategies such as withdrawal and secrecy," which generate "secondary
deviance." n270 Sex offender registration and  [*235]  community notification
requirements, for example, cause sex offenders to isolate themselves in the
community, away from support systems that help prevent recidivism. n271 The harm
is magnified for juveniles. The label of "sex offender," "child molester," or
"sexual predator" can cause profound damage to a child's development and
self-esteem. n272 The stigma continues even when a juvenile is no longer subject
to registration, and law enforcement no longer publishes her information on a
website. n273 Perhaps it is no surprise then that evidence indicates that sex
offender registration actually raises the risk of recidivism amongst juveniles.
n274

   Likewise, including marginal youth in gang databases (so-called "wannabes")
n275 "potentially drives them into gang membership because they are being
treated as, and known as, gang members." n276 Rather than reducing the crime
problem linked to gangs, it exacerbates it. The same effect appears when
schools, "the first social institution outside of the family in which most youth
have an opportunity to be marked as failures, criminals, or deviants," n277
serve as informants and share information with law enforcement about misbehavior
at school. And at least one international court has recognized the risk of
stigmatization brought by collecting DNA from juveniles. n278

   Stigmatic labels lead criminal justice actors and others to stop seeing young
people as children and to instead see and treat them as criminals. n279 This is
the external stigma of databasing delinquency. Status  [*236]  loss follows,
which is then accompanied by formal and informal discrimination. n280 It should
not be forgotten that juveniles have less mobility than adults, making it "more
difficult for them to escape from a community in which harmful information has
cast them in an unfavorable light." n281

   In short, collecting information harms youth by invading their privacy and
imposing stigma. As David Ball has succinctly put it, "stigma is a sentence of
its own, with real impacts on juveniles' lives." n282 Juveniles' heightened
vulnerability to psychological harm exacerbates the stigmatizing impact of
delinquency databasing.

   2. Storing Information Distorts Perceptions of Developing Youth

 The length of time that the criminal justice system keeps the information it
collects in the delinquency databases imposes additional harms on youth. As
shown above, the duration of storage can be indefinite. Sex offender
registration can last a lifetime, DNA samples and profiles are maintained
indefinitely, and gang databases are rarely purged. n283 Law enforcement
undoubtedly retains the information because it believes that the information
remains valuable long after the events recorded took place, both for its
crime-solving and crime-deterring purposes.

   Adolescence, however, is a time of change. Because "the signature qualities
of youth are transient," n284 youthful behavior does not reflect an individual's
true character. Delinquency is developmentally normal. Offending peaks at
seventeen to eighteen, and quickly and steadily falls thereafter. n285 As a
result, youthful offending is unlikely to be evidence of "irretrievably depraved
character." n286 Indeed, experts agree that it is nearly impossible to predict
which juvenile offenders will persist into adulthood. n287 Therefore, because
the vast majority of juveniles desist, stored criminal history information has
much less value than it does for adults.

    [*237]  In addition, juveniles are less deterrable, meaning that the
ostensible crime-preventing value of databasing delinquency is minimal. Often
sold as tools of deterrence, n288 little empirical data supports a deterrence
justification for aggregate data collection. n289 Whatever deterrence it may
provide is diminished, if not entirely lost, with regard to juveniles. As a
group, juveniles assess risk differently, are more subject to peer influence,
and discount the future more than adults. Each reduces any deterrent effect
derived from the increased likelihood of getting caught in the future or
suffering punishment created by delinquency databases. n290 As juvenile law
experts Christopher Slobogin and Mark Fondacaro put it, the traits that mark
adolescence tend to produce offenders "for whom the deterrent force of the
criminal law is likely to be, literally, an afterthought." n291

   Databasing delinquency ignores these truths about juveniles. Much more than
solving and deterring crime, it marks youth subjected to it as trouble. As a
result, storing data risks producing a community-wide feedback loop. It is well
established that minorities, and minority communities, are policed more heavily
than Whites. n292 DNA databases, primarily populated by arrests and convictions,
are racially skewed. n293 Gang databases are similarly filled with a
disproportionate share of minorities. n294 Sex offender registries also exhibit
racial disparities. n295 The  [*238]  data on school discipline and referrals to
law enforcement are no different. Minority students are punished
disproportionately relative to their violations of school rules, and schools
serving higher percentages of Black students are more likely to suspend, expel,
or refer students to law enforcement officials for violating school rules. n296
As a result, the negative labeling that results from delinquency databasing
falls disproportionately on youth of color. Extensive recordkeeping then becomes
evidence that minorities are more likely to offend, and their communities more
likely to be places of crime, thus generating continued heavy policing and a
greater likelihood of formal intervention. n297

   This feedback loop can produce disturbing results. Designed to prevent
reoffending, storing information may increase recidivism or delay desistance. By
placing juveniles in the pool of usual suspects, databasing increases the
likelihood of their suspicion, detection, and punishment. n298 Evidence suggests
that contact with the criminal justice system is criminogenic, particularly for
juveniles. n299 As such, databasing delinquency may cause perverse effects,
"producing a cohort of more hardened criminals." n300

   Storing prior criminal history can also lead people to wrongly interpret
lawful behavior as suspicious or criminal. Andrew Guthrie Ferguson has shown how
police access to the kind of data gathered in these databases makes it easier
for law enforcement to believe that probable cause exists to arrest an
individual. n301 According to Guthrie Ferguson, "if officers view those
individualized and particularized identifying characteristics - such as prior
convictions, gang associations, and GPS coordinates near the scene of the crime
- as suspicious, then  [*239]  otherwise innocent actions might create a
predictive composite that satisfies the reasonable suspicion standard." n302
Examples abound of young people who experienced a number of police stops after
they were erroneously entered into a gang database, n303 and registered sex
offenders suffering repeated police contact and suspicions as a result of
complaints from residents or false accusations and arrests. n304

   Finally, the challenges of maintaining accurate databases cannot be ignored.
n305 Law enforcement databases suffer from significant accuracy problems. A
National Employment Law Project study recently found that half of FBI records
are flawed. n306 Rap sheets frequently include erroneous information and do not
record arrest dispositions, misleading many to conflate an arrest with a
conviction. n307 Often times, records that were ordered sealed or expunged are
not (despite easy and available technological solutions). n308 In two recent
Supreme Court cases, erroneous information in law enforcement and court
databases led to unlawful arrests of individuals. n309 Ramsey County, Minnesota
stopped using a gang database in 2011 because of concerns about the accuracy of
the information it contained. n310

   This proclivity to inaccuracy heightens the harmful impact of delinquency
databases. As discussed in the next section, that the mistaken or misleading
information is widely distributed (by law enforcement, courts, and private
information venders) compounds the problem. Even if it does get corrected, the
false or outdated information likely remains available on the Internet. n311

    [*240]  The inaccuracy problem could be minimized if law enforcement offered
a procedure for youth to seek or confirm the purging of their information from a
database. But it rarely does. As described above, those required to register as
sex offenders cannot exit the registry until their term of registration expires,
no matter how much evidence of rehabilitation they can provide. While purging is
available in certain circumstances for DNA and gang databases, it is difficult,
and the burden to initiate and substantiate is almost always placed on the
youth. n312 Where purging procedures are in place, they are rarely carried out.
n313

   By storing negative information and including inaccurate or outdated
information, databasing delinquency ignores the foundational principle that
youth change, and instead fixes a criminal label to young people that may
increase offending.

   3. Sharing Information Frustrates the Transition to Adulthood

 The information in delinquency databases is valued by more than just law
enforcement. Employers want access to it. n314 Colleges want access to it. n315
Landlords want to know about it. n316 Journalists want to publish it. n317
Curious neighbors want access to it. n318

   Law enforcement has traditionally restricted access to information it has
about juveniles. Today, through a combination of legislation, information
vendors, and the World Wide Web, all of those people and more can often learn
what contacts people had with the criminal justice  [*241]  system when they
were young. n319 As depicted in Figure 1 in Part II.E, law enforcement,
noncriminal justice government agencies, courts, schools, employers, the media,
and the general public all have some form of access to court records, police
records, and sex offender information. Law enforcement, noncriminal justice
government agencies, and courts each have access to behavior information about
youth at school. Schools and employers are privy to information stored in gang
databases.

   This liberal sharing produces many harms. Foremost among them are the
innumerable formal and informal collateral consequences of contact with the
criminal justice system. As Devah Pager put it, "the "credential' of a criminal
record, like educational or professional credentials, constitutes a formal and
enduring classification of social status, which can be used to regulate access
and opportunity across numerous social, economic, and political domains." n320

   A vast literature recounts the devastating collateral consequences of
criminal justice contact on individual lives. n321 Juveniles no less than adults
suffer these consequences. n322 Accessible arrest and court records restrict
their ability to attend school and secure housing and employment. n323 According
to studies, ninety percent of employers check criminal histories. n324 The
negative impacts arise even when an arrest did not lead to a conviction or
adjudication. n325 Sex offender registration frustrates access  [*242]  to
education, housing, and employment; n326 disrupts families; n327 and causes
social isolation and shame, n328 all of which increase the risk of delinquency.
n329 Some of these disabilities are mandated by law; others flow from the
publicity of the offense. As one juvenile sex offender put it, "Our mistake is
forever available to the world to see." n330

   That the penalties and barriers come at a particularly crucial time for young
people, as they transition to an independent adulthood, enhances the chance that
databasing will produce profound negative effects. n331 Young adults lack social
capital and experience, and their long-term success can turn on their ability to
earn a living wage, begin a career, and start a family in early adulthood. n332
By making all of these things more difficult, databasing delinquency frustrates
the juvenile justice system's rehabilitative goals for youthful offenders,
marginalizing them and hindering their participation in civil society. n333
According to the Ohio Supreme Court:



   For a juvenile offender, the stigma of the label of sex offender attaches at
the start of his adult life and cannot be shaken. With no other offense is the
juvenile's wrongdoing announced to the world. Before a juvenile can even begin
his adult life, before he has a chance to live on his own, the world will know
of his offense. He will never have a chance to establish a good character in the
community. He will be hampered in his education, in his relationships, and in
his work life. His potential will be squelched before it has a chance to show
itself. A juvenile - one who remains under the authority of the juvenile court
and has thus been adjudged redeemable - who is subject to sex offender
notification will have his entire life evaluated through the prism of his
juvenile adjudication. It will be a constant cloud, a once-every-three-month
reminder to himself and the world that he cannot escape the mistakes of his
youth... . It will define his adult life before it has a chance to truly begin.
n334

  [*243]  Of course, suffering consequences for wrongs, including stigma, is
not, by itself, troublesome. As law and philosophy scholar Anita Allen has
explained, "accountability for conduct is a pervasive feature of human
association." n335 Accountability includes being accountable to individuals,
often in the form of providing information about oneself, and accountable for
conduct, typically in the form of negative consequences for wrongs. n336
Criminal law and law enforcement are strong forms of accountability. Modern
surveillance and the data collection practices discussed above represent a
technologically supercharged form of informational accountability. n337

   Some amount of accountability is necessary to regulate childhood. n338 As
future full members of society, children must be taught social norms, and learn
that society imposes consequences for misbehavior. n339 No one maintains that
children not be held to some amount of accountability under the law. The
characteristics that define youth, however, mean that the quantity of
accountability appropriate during childhood is necessarily limited. n340 And the
harms imposed by databasing delinquency, which frustrate juveniles' ability to
succeed in adulthood, go too far.

   B. Databasing Undermines Childhood

 Childhood is fragile. n341 Shifts in public mood can lead to profound changes
in the rights and responsibilities of young people. One such shift took place in
the late 1980s and 1990s, when a spike in violent crime by young people
triggered a moral panic about juvenile offending. n342 Events like the 1988
"Central Park Jogger" case, where five youth were convicted of a beating and
rape that left a woman comatose (a crime, it turned out, that none of the five
committed), n343 and school shootings like the one at Columbine High School,
n344 ignited the panic. Academics in the  [*244]  popular press fueled the flame
by promising a coming generation of "severely morally impoverished juvenile
super-predators." n345 In the public eye, juveniles ceased to be wayward youth
in need of help, and became hardened criminals in need of being locked up. n346

   Reforms throughout the criminal justice system led to more juveniles being
increasingly treated like, and punished alongside, adults. n347 Sentences
increased and laws changed permitting the prosecution of more juveniles in
criminal court. The Supreme Court refused to extend or recognize special
protections for youth. n348 Confidentiality waned. As the authors of a 1989
report on juvenile records wrote, "if an individual wishes to be protected under
the law, then that individual must first act within the law. When a juvenile
chooses a lifestyle of crime and violence, that individual should not expect to
have these activities shielded from disclosure to others." n349

   Juvenile justice scholar Franklin Zimring calls this the "forfeiture theory,"
where "loss of the protected status of youth becomes in effect one penal
consequence of the forbidden act." n350 Juveniles who break the law are seen as
having forfeited, by their conduct, the protections typically afforded to youth.
n351 The forfeiture happens despite their remaining chronologically,
developmentally, and legally children. As Zimring observed, "there is certainly
no logically necessary reason that protective features of youth policy are only
for nice kids." n352

   Databasing delinquency is a stout and expanding remnant of the forfeiture
era. It subjects juveniles to record practices and consequences  [*245]  akin to
those for adults (including juveniles who have committed no crimes). Sex
offender registration, gang databases, DNA collection, and laws turning schools
into informants all emerged after 1980. Holistically, they reflect a narrower
conception of the protective space of childhood than the prevailing notion, and
are at odds with developmental science, the continued existence of juvenile
courts, and recent Supreme Court jurisprudence. As a result, databasing
delinquency does more than cause immediate and lasting harm to individual
juveniles. It reshapes the very meaning of childhood, breaching its protected
space and contradicting the special understandings that policymakers insist must
dominate the regulation of youth.

   The prevailing concept of childhood, and the necessity and propriety of
enhanced protections, is grounded in part on a notion of childhood as innocence.
n353 That childhood is marked by innocence is certainly contested, and
undoubtedly false, especially with regard to adolescents. Despite their
immaturity, juveniles are autonomous actors who have the ability to recognize
right from wrong, and exercise such autonomy by choosing, on occasion, to do bad
things. n354 Indeed, delinquency appears to be a normal part of adolescence.
n355 Their offenses, however, do not make them adults.

   Yet, the criminal justice system, more so than other arenas, tends to treat
young people who do not fit the innocent image as outside of childhood, and thus
not cloaked by (or deserving of) its protections. In the last decade, however, a
shift back to first principles has been evident. The "superpredator era" has
been replaced by "the rebuilding." n356 From the appropriate amount of
punishment to the proper treatment by police, courts and legislatures have
displayed a renewed commitment to the primacy of special protections for youth.
n357 In the wake of a sharp and steady decline in juvenile offending since 1994,
n358 (and perhaps in response to the punitive extremes of 1990s reforms), courts
and legislatures have made it clear that the law must take account of the
differences between  [*246]  youth and adults. n359 As a result, several
juvenile justice policies grounded in the forfeiture theory have been rejected
in recent years. n360

   Yet it is not just the dubious forfeiture theory that undergirds delinquency
databasing. Minority youth need not break the rules before they lose the
protections of childhood. n361 For them, by virtue of being black or brown, they
are perceived as more likely to be criminal, more culpable for the same behavior
committed by White youth, and older than their actual chronological age. Race,
it seems, overrides youth within the criminal justice apparatus. As a result,
minority youth exit childhood's protective space sooner, justifying their
subjection to adult-like law enforcement practices like databasing.

   Americans have long associated blackness and criminality. n362 The perceived
link between blackness and criminality has contributed to racial disparities
throughout criminal justice, including skews in enforcement and punishment of
Black juveniles. n363 One study, for example, found that African American youth
are disproportionately arrested in twenty-six of twenty-nine offense categories,
overrepresented in cases referred to juvenile court, more likely to be formally
charged, more likely to be waived into adult court, and disproportionately
detained in both juvenile and adult facilities. n364 These enforcement skews
then result in racial skews in data collection, as law enforcement is more
likely to collect and retain information on minorities because it
disproportionately makes contact with minorities. n365

   Emerging research connects this racial perception and skew data to the
expanding surveillance of minority youth. Researchers have found that Black
youth are seen as older than their actual age, and more culpable for the same
behavior as White youth. In one study, researchers tested 176 police officers in
large urban areas, mostly White males,  [*247]  average age thirty-seven, and
264 mostly White, female undergraduate students from large public U.S.
universities, to determine their levels of certain types of bias. n366 They
found that Black youth were more likely to be mistaken as older than their
actual age, by an average of 4.5 years. n367 The same study found that White
undergraduate female students judged children up to nine years old as equally
innocent regardless of race, but considered Black children significantly less
innocent than other children in every age group beginning at age ten. n368

   In another study, researchers had a nationally-representative sample of White
Americans participate in an online study about support for life without parole
sentences for juveniles. n369 Participants read a sample about a recipient of
the sentencing option: a fourteen-year-old male with seventeen prior juvenile
convictions on his record who brutally raped an elderly woman. Researchers
manipulated just one word across the two study conditions: in the description of
the example recipient of the sentencing option, the juvenile was described as
either Black or White. The researchers found that "in the Black prime condition,
participants perceived juveniles as more similar to adults in blameworthiness
... than they did in the White prime condition." n370 This led participants in
the Black prime condition to express more support for life without parole
sentences for juveniles in non-homicide cases than did those in the White prime
condition. n371 In short, when test subjects knew the subject of a potential
criminal justice sanction was Black, they showed increased support for punitive
policies. n372

   This effect is occurring in schools as well. Professor Ann Arnett Ferguson
spent over three years observing a racially mixed public intermediate school
(grades four to six). n373 She concluded that African American boys are not seen
as childlike but "adultified," as "naturally naughty," and as "willfully bad."
n374 Their misbehavior was not seen as typical childishness, but was "likely to
be interpreted as symptomatic of  [*248]  ominous criminal proclivities." n375
In one example, a White teacher described African American children who borrowed
books from a classroom without returning them as "looters." As Ferguson put it,
"what might be interpreted as the careless behavior of children is displaced by
images of adult acts of thefts that conjure up violence and mayhem." n376 As a
result of this adultification, Black male youth became exempted from "the
dispensations granted the "child' and the "boy'", justifying increased
surveillance and harsher, more punitive responses to rule-breaking behavior.
n377

   This research shows that race profoundly affects the degree to which
juveniles are afforded the established protection associated with childhood
status. n378 This happens even in the absence of wrongdoing. Indeed, race
appears to override youth when it comes to support for punitive juvenile justice
policies. Black youth are viewed as older than their actual age, are associated
with criminality, and are seen as responsible for their actions at an age when
White youth remain protected by the reduced culpability conception of childhood.
As a result, law enforcement practices like the databasing described here that
treat youth of color like adults flourish.

   IV. Reforms

 There is ample evidence that policymakers are rethinking the punitive,
adult-like policies adopted in a climate of fear and hostility toward juvenile
offenders in the late twentieth century. n379 This momentum toward first
principles led juvenile justice scholar Terry Maroney to describe the current
era as the "rebuilding" of juvenile justice. n380

   In that spirit, this Part offers three recommendations to curbing delinquency
databasing that would realign law enforcement data collection practices with
current developmental research and the prevailing conception of childhood as a
separate, protected space. First, to account for juveniles' unique vulnerability
to harms, laws should limit the amount of information that law enforcement may
collect about juveniles. Second, because most juveniles do not persist in
offending but instead mature into law-abiding individuals, laws should limit the
length of time that gathered information can be retained. Third, in recognition
of juveniles'  [*249]  future lives as adults, laws should restrict law
enforcement's ability to share the information it gathers and stores. This would
have no impact on law enforcement's mission, and would facilitate access to the
employment, higher education, and housing that is so critical as youth
transition to adulthood.

   A. Limiting What Information Is Gathered

 The easiest way to limit the harms caused by databasing delinquency is to not
gather the information in the first place. n381 It would avoid the privacy
intrusion attendant to the gathering of information, and would prevent the
additional punishments and stigma discussed above that ensue. It would also
eliminate the long shadow of a young person's mistakes, helping to ensure that
juveniles enter adulthood with the greatest chance for a productive life.

   But law enforcement will not be prohibited from gathering information in any
foreseeable future. A feasible focus becomes limiting law enforcement's data
collection abilities. Deciding how much to limit it depends in part on the role
of law enforcement with respect to juveniles. If the police play a role similar
to that of a general welfare agency, then all data is potentially pertinent, and
the limitations proposed here will not come to be. n382 But if law enforcement's
mission is limited to crime solving and suppression, then much of the
information about a young person gathered in the delinquency databases loses its
value to law enforcement. Instead, a narrower universe of data collection is
justified. This is especially so for data collection that occurs before a young
person has become the target of a criminal investigation.

   It seems safe to say that the police are not child welfare officials, n383
and therefore every last bit of information about young people is not of police
concern. Gathering data about the friends and associations of juveniles, or
logging reports from schools of bullying, especially in the absence of a
criminal investigation that would make the information relevant, is thus
difficult to justify. On the other hand, it is difficult to cull the information
that has, or might have, intelligence value to law enforcement from that which
does not. n384 Indeed, the belief that it is  [*250]  better to have information
and not need it than to need it and not have it, and the lure of complete
collection, has proven irresistible to the government. n385 One guiding
principle could be that law enforcement may only collect information relevant to
an individual's identity or to a specific investigation.

   Restrictions on law enforcement's ability to gather information are not
impossible. The Fourth and Fifth Amendments stand as foundational hurdles to
unrestricted government data collection. n386 And states still maintain
protective rules for children with regard to police identity records. Take
fingerprints as an example. While some states, such as Alaska, make no
distinctions between juvenile and adult fingerprinting, many others maintain
distinct rules, limiting fingerprinting of youth by age, charge, conviction, or
some combination thereof. n387

   Recent reforms have limited the content of criminal justice biographies of
youth. In several states, both legislative and judicial efforts have restricted
what information law enforcement may gather with respect to juvenile sex
offender registration. As of June 2014, only seventeen states were considered
substantially in compliance with SORNA. n388 Federal officials report that
requiring juveniles to register is the "most significant barrier" to compliance.
n389 In a letter from the State  [*251]  of New York, explaining its decision
not to fully comply with SORNA, the Director of the Office of Sex Offender
Management wrote, "New York has a long standing public policy of treating
juvenile offenders differently from adult offenders so that juveniles have the
best opportunity of rehabilitation and re-integration. The federal requirement
that juveniles be placed on the Sex Offender Registry under SORNA is in direct
conflict with that public policy." n390 Out of similar concerns, the State of
Washington abolished child sex offender registration completely. n391 Courts
have also found juvenile sex offender registration unconstitutional because it
"frustrates two of the fundamental elements of juvenile rehabilitation:
confidentiality and the avoidance of stigma." n392

   Calls for severing the link between schools and law enforcement grow louder
each year. In 2013, Attorney General Eric Holder said in a speech before the
American Bar Association ("ABA") that "[a] minor school disciplinary offense
should put a student in the principal's office and not a police precinct." n393
The American Academy of Pediatrics and the American Psychological Association
have likewise called for an end to harmful disciplinary policies that lead to
criminal justice involvement, urging instead that students be disciplined on a
case-by-case basis and in a developmentally appropriate manner. n394 Across the
country, state departments of education and municipal school districts are
moving away from zero tolerance policies and regular law enforcement involvement
in school matters. n395 In some places, federal civil rights litigation has led
to barriers between the criminal justice system and school information. In
Mississippi, for example, a 2012 Department of Justice Civil Rights Division
lawsuit challenged the City of Meridian's practice of arresting youth for minor
school-based offenses and Lauderdale County's practice of incarcerating youth on
probation for school suspensions and  [*252]  expulsions. n396 An agreement was
reached in June 2015 prohibiting Meridian police officers from arresting youth
for "behavior that is appropriately addressed as a school discipline issue" and
limiting the state's ability to recommend incarceration for violations of
probation that would not otherwise be detainable offenses (i.e., school
suspensions). n397

   That said, the ship full of robust data collection restrictions regarding
youth has likely sailed. Law enforcement agencies need complete and accurate
information to successfully investigate crimes, identify suspects and
perpetrators, and maintain criminal statistics. Broader data collection further
helps law enforcement manage and solve crime, and plays some role in promoting
rehabilitation via deterrence and shaming. Too many crimes have been solved (and
perhaps prevented) because law enforcement collected the otherwise unknown
offender's DNA n398 or knew who a gang member regularly associated with, to roll
back data collection at anywhere other than the margins. Given the ease, low
cost, effectiveness, and popularity of delinquency databases, it would require a
sea change in attitude to generate support for more widespread limits on the
information gathered by law enforcement about juveniles. Even then, the benefits
to juveniles (in reduced privacy and stigma harms) may not outweigh the public
safety harms of increased crime. For that reason, the best chances to minimize
the harms caused by dataveillance rest in restricting the storage and
dissemination of criminal information about youth.

   B. Limiting What Information Is Stored

 Youth change. While many participate in some form of delinquency during
adolescence, most desist as they mature into adulthood. n399 This is because
many of the factors associated with antisocial, risky, or criminal behavior lose
their intensity as individuals become more developmentally mature. n400 That
youth change means that "particularly in the case of the juvenile, ...
yesterday's record does not accurately describe today's  [*253]  individual."
n401 In recognition of this truth, limits on the length of time that law
enforcement can retain records about juveniles should be imposed. These limits
would enable law enforcement to keep information during peak offending years
while also protecting young people from the long shadow of youthful mistakes.

   Numerous proposals have sought to limit the length of time that law
enforcement can retain records about juveniles. Before the dawn of computerized
dataveillance, the ABA issued a report entitled Standards Relating to Juvenile
Records and Information Systems. n402 In it, the ABA recommended that juvenile
police and court records be destroyed if a juvenile who is arrested or detained
is not referred to a court. n403 The report emphasized that unless the
juvenile's police record is also destroyed when the court record is destroyed,
"the destruction of the court record alone would become a relatively meaningless
reform." n404 In a foreshadowing of what has become, the report acknowledged
that the "increasing use of computers to disseminate arrest records magnifies
the risks created by the existence of arrest records." n405 The juvenile crime
wave of the 1980s and early 1990s, and the punitive reforms that followed, meant
the ABA's proposal was not heeded.

   Similar reform proposals are now making headway as policymakers have begun to
reimpose limitations on how long juvenile records may be maintained. In 2014,
Washington state passed a law allowing for most juvenile records to be
automatically sealed when the youth turns eighteen. n406 In explaining the bill,
Representative Ruth Kagi said that "up until today, youth in Washington had
their mistakes follow them forever. The sealing of juvenile records will give
youth the chance to get an education, a job, housing, and a productive life."
n407 Senators Rand Paul and Cory Booker proposed a similar bill at the federal
level in 2014. Their REDEEM Act would automatically seal juvenile criminal
records for nonviolent offenses. n408

   The movement toward protective juvenile record policies is not limited to the
United States. In recent commentary on the European  [*254]  rules for juvenile
offenders, the Council of Europe advised that "sanctions and measures imposed on
juvenile offenders should not be held against them for the rest of their
lives... . Records of the offences of juveniles should not be kept for longer
than absolutely necessary." n409

   Just how long is necessary would undoubtedly be subject to great debate.
Empirics on juvenile offending help to identify an appropriate target. Expunging
police and court records could be triggered when juveniles hit a particular age,
such as eighteen or twenty-one. This would accord with offending data which
shows that offending peaks at seventeen and then sharply and steadily decreases.
n410 As a result, the intelligence value to law enforcement of all that the
delinquency databases contain drops off just as sharply and steadily into the
future. Since it is increasingly unlikely to be actionable information, there is
less justification for continuing to store it. The value of the information
about friends and associations, such as that which fills gang databases,
diminishes even more sharply with time as social groups and activity change.
That databasing causes such extensive harms, not just from the mere gathering of
the information but also from the retention of erroneous information and the
broad sharing of information, increases the need for limiting its storage.

   Alternatively, records could be expunged when a juvenile avoids a conviction
or adjudication for a certain period of time. This would be expungement earned
not by simply growing old, but by behavior. Data about desistance would support
such an approach. Researchers have found that individuals with a prior criminal
justice contact who stay arrest free for seven years or more pose very little
risk of future crime. n411 Moreover, that low risk converges with the risk of a
same-aged individual from the general population at around seven years after
contact, and approaches (though never equals) that of same-aged individuals with
a clean criminal record. n412 Therefore, for juveniles who avoid arrests and
conviction, there would be little risk to public safety of destroying their old
records. The upside would be reduced stigma and fewer barriers to housing,
education, and employment. n413

    [*255]  Indeed, record sealing or destruction mechanisms are already in
place. All states enable the destruction, expunging, or sealing of some juvenile
records. n414 New York, for example, requires fingerprint records to be
destroyed when a person adjudicated delinquent reaches the age of twenty-one or
has been discharged from placement for at least three years and has no
intervening criminal convictions or pending criminal actions. n415 There are
even protections in some states for juveniles charged in criminal court. Under
"Youthful Offender" statutes, accusatory instruments can be sealed and records
that would otherwise be public kept confidential. n416

   The software that enables the delinquency databases could easily accomplish
automatic record deletion. All that it would seemingly require would be an
allocation of resources from the government to develop programs that could
identify records due for sealing or destruction and accomplish the sealing or
destruction.

   C. Limiting What Information Is Shared

 As described above, many are able to access the information in the delinquency
databases. Law enforcement, noncriminal justice government agencies, courts,
schools, employers, the media, and the general public all have some form of
access to court records, police records, and sex offender information. Law
enforcement, noncriminal justice government agencies, and courts each have
access to behavior information about youth at school. Schools and employers are
privy to information stored in gang databases. According to leading criminal
records scholar Jacobs, "the United States, which invented a juvenile court
committed to confidentiality, now is exceptional for the amount of juvenile
offender information that is disclosed to diverse government agencies and the
public." n417

   Once the information gets beyond law enforcement, and into the hands of
employers, school officials, and landlords, the harmful impacts are felt
immediately. Moreover, once the information gets beyond law enforcement, it is
almost impossible to make it go away or control the havoc it wreaks. n418 As a
result, its impact is lasting.

   This liberal policy regarding disclosure is in part linked to the American
commitment to open government and the freedom of the press. And it is also a
result of the gradual shift of law enforcement records from  [*256]  a system
created by police for police to one used heavily by noncriminal justice actors
like employers and schools.

   Distributing the information is particularly harmful because of its
devastating impacts on an individual's ability to secure employment, housing,
and school that accompany sharing criminal history. n419 Not only does criminal
history information sharing frustrate the ability of young people (and adults
with a youthful criminal record) to earn a living, educate themselves, and find
a place to live, all of these factors are linked to desistance. n420

   Instead of punishing youth far into the future, the law should cabin the
information that is gathered and stored by law enforcement to law enforcement as
much as possible. This is especially true for intelligence information like that
gathered in gang databases and nonconviction records, like those for arrests.
Noncriminal justice actors (like employers) are likely to believe that an arrest
reflects a guilty act, when upwards of fifty percent of arrests are not followed
by a conviction. n421 Moreover, the presumption of innocence, "that bedrock
"axiomatic and elementary' principle whose "enforcement lies at the foundation
of the administration of our criminal law,'" n422 demands that the criminal
justice system only share police record information when it reflects certainty
that the act was committed.

   A number of reforms limiting the sharing of law enforcement records have
recently been put in place. As discussed above, jurisdictions are limiting the
extent to which juveniles are subject to sex offender registration, and federal
guidelines do not require that juveniles be subject to community notification
procedures. n423 There is a nationwide movement to restrict what criminal
history information employers can access. n424 Colleges are beginning to add
nuance to their use of criminal history information in admissions instead of
using it as a blunt sorting  [*257]  tool. n425 Public schools have also been
seeking ways to minimize law enforcement involvement in school matters. n426

   As these efforts demonstrate, limiting what criminal history information gets
shared beyond law enforcement is probably the most attainable reform proposal.
It is also arguably the most important. Cabining the information to law
enforcement reduces the negative impact the criminal justice biography may have.
While they are still subject to privacy invasions and stigma harms, and law
enforcement is more likely to police them and their communities (each no small
consequence), law enforcement does not hire them for jobs, accept them to
colleges, or act as their landlord. Without access to the information,
employers, colleges, and landlords will not be able to so easily discriminate
against individuals based on criminal history.

   Conclusion

 Because adolescents are vulnerable, because they change, and because they are
future adults, we must strive for a constellation of practices that protect them
from harm and promote their positive development. The criminal justice system is
a critical part of that constellation. With renewed vigor, courts, legislatures,
and policymakers today are correcting the missteps of the 1990s that favored
treating juveniles like adults in the criminal justice system by reinstating the
primacy of special protections for youth.

   Databasing delinquency - a broad data collection, retention, and distribution
system that treats juveniles on par with adults - reveals that two pernicious
distortions continue to inform this aspect of juvenile justice policy. First,
youth who break the rules are seen as having forfeited the protections of
childhood. Second, childhood status is particularly fragile for minority youth,
who age out of childhood's protective space sooner than White youth. As a
result, many youth are saddled with a record of mistakes and suspicions that
haunt them into adulthood.

   The unwillingness to forgive and forget youthful mistakes embedded in
databasing delinquency ignores the fundamental nature of adolescence. Rather
than pursuing adult-like surveillance practices in the name of public safety
that inflict debilitating short and long-term harms, the developmental
characteristics of youth and the purpose and meaning of childhood must guide
juvenile justice policy. To that end, we must avoid practices that unduly
stigmatize, that permanently punish, and that promote or entrench criminal
behavior. By limiting the information that  [*258]  the criminal justice system
gathers, stores, and shares about juveniles, we can avoid those harms without
frustrating public safety.

Legal Topics:

For related research and practice materials, see the following legal topics:
Criminal Law & ProcedurePostconviction ProceedingsParoleFamily LawDelinquency &
DependencyGeneral OverviewGovernmentsCourtsCourt Records

FOOTNOTES:




n1.  See Simson Garfinkel, Database Nation: The Death of Privacy in the 21st
Century (Deborah Russell ed., 2000); Erin Murphy, Databases, Doctrine and
Constitutional Criminal Procedure, 37 Fordham Urb. L.J. 803, 805-10 (2010)
(recounting the rise of databases in criminal justice).





n2.  Juvenile courts and law enforcement long restricted the information they
gathered about juveniles, limited the length of time it was stored, and
protected the information gathered from disclosure. James B. Jacobs, The Eternal
Criminal Record 114 (2015) ("The practice of sealing and expunging criminal
records was pioneered in the juvenile justice system."). For example, as
recently as 1988, only a quarter of law enforcement agencies fingerprinted
juveniles. Bureau of Justice Statistics, U.S. Dep't of Justice, Juvenile Records
and Recordkeeping Systems (1988).





n3.  See infra Part II. A note on terminology: This Article primarily
contemplates youth aged ten to seventeen. I variously refer to them as
juveniles, youth, young people, and adolescents. However, because of the binary
approach of criminal law (that is, an accused is treated either as a child and
processed in juvenile court, or as an adult subject to the criminal court's
jurisdiction), I occasionally use child, children, and childhood throughout the
piece.





n4.  See infra Part II.B.





n5.  See Margaret Colgate-Love et al., Collateral Consequences of Criminal
Convictions: Law, Policy and Practice 279-80 (2013) (identifying state "central
repositories ... , the courts, private vendors which prepare reports from public
sources, and even correctional institutions and police blotters" as sources of
criminal histories).





n6.  Roger A. Clarke, Information Technology and Dataveillance, 31 Comm. ACM,
May 1988, at 498, 499, 502-04.





n7.  See Ray McDermott & Jason Duque Raley, "The Tell-Tale Body": The
Constitution of Disabilities in School, in Handbook of Social Justice in
Education 431, 438 (William Ayers, Therese Quinn & David Stovall eds., 2009)
(describing school records of misbehavior and missing behavior as "the
institutional biographies that record a child's problems in school files
forever").





n8.  These more traditional doctrinal approaches to assessing law enforcement
data collection offer little promise at the present time as limiting forces. On
privacy, see Jed Rubenfeld, The End of Privacy, 61 Stan. L. Rev. 101 (2008) and
Daniel J. Solove, Digital Dossiers and the Dissipation of Fourth Amendment
Privacy, 75 S. Cal. L. Rev. 1083 (2002). Similarly, Fourth Amendment
jurisprudence offers juveniles fewer protections than it does to adults because
young people are considered to have a reduced expectation of privacy. See
Kristin Henning, The Fourth Amendment Rights of Children at Home: When Parental
Authority Goes Too Far, 53 Wm. & Mary L. Rev. 55, 55 (2011) ("Youth generally
receive less constitutional protection than adults.").





n9.  See, e.g., Annette Ruth Appell, Accommodating Childhood, 19 Cardozo J.L. &
Gender 715, 715 (2013) ("The legal academy has bestowed scant critical
examination on the category of childhood.").





n10.  See David Archard, Children: Rights and Childhood (2d ed., 2004); see also
Allison James & Adrian L. James, Constructing Childhood: Theory, Policy and
Social Practice 20 (2004).





n11.  Roper v. Simmons, 543 U.S. 551, 570 (2005) ("The character of a juvenile
is not as well formed as that of an adult. The personality traits ... are more
transitory, less fixed.").





n12.  See infra Part I.





n13.  See Franklin E. Zimring, The Common Thread: Diversion in Juvenile Justice,
88 Calif. L. Rev. 2477 (2000).





n14.  Miller v. Alabama, 132 S. Ct. 2455, 2466 (2012) (holding mandatory life
without parole sentences for juveniles violate the Eighth Amendment); J.D.B. v.
North Carolina, 131 S. Ct. 2394, 2404 (2011) (holding law enforcement must
consider age when deciding whether an individual is in custody for purposes of
providing a Miranda warning); Graham v. Florida, 560 U.S. 48, 75 (2010)
(outlawing life without parole sentences for individuals who committed
non-homicide crimes under the age of eighteen); Roper, 543 U.S. at 572
(declaring unconstitutional to impose capital punishment for crimes committed by
someone under the age of eighteen).





n15.  Terry A. Maroney, The Once and Future Juvenile Brain, in Choosing the
Future for American Juvenile Justice 189, 211 (Franklin E. Zimring & David S.
Tanenhaus eds., 2014) (calling the current era of juvenile justice reform "the
rebuilding").





n16.  Archard, supra note 10, at 23 ("There are good reasons for thinking that
all societies at all times have had the concept of childhood."); James & James,
supra note 10; The Sociology of Childhood: Essential Readings (Chris Jenks ed.,
1982).





n17.  Brief for Am. Psych. Ass'n, et. al. as Amici Curiae Supporting
Petitioners, Graham v. Florida, Nos. 08-7412, 08-7621, 2009 WL 2236778, 3-4
(2009) (citing neuroscience research showing adolescent brains are not yet fully
developed in regions related to higher-order executive functions such as impulse
control, planning ahead, and risk evaluation).





n18.  Eddings v. Oklahoma, 455 U.S. 104, 115 (1982) ("But youth is more than a
chronological fact.").





n19.  Archard, supra note 10, at 27; Appell, supra note 9, at 735.





n20.  Archard, supra note 10, at 33; Appell, supra note 9, at 736
("Developmental facts do not dictate the contours or boundaries of childhood.
Ideology does.").





n21.  Jonathan Todres, Maturity, 48 Hous. L. Rev. 1107, 1116 (2012) ("Benchmarks
of maturity in the law frequently occur at different points in time.").





n22.  Id.





n23.  Reinventing Childhood After World War II ix (Paula S. Fass & Michael
Grossberg eds., 2012); Archard, supra note 10, at 37 ("The most important
feature of the way in which the modern age conceives of children is as meriting
separation from the world of adults.").





n24.  Miller v. Alabama, 132 S. Ct. 2455, 2469-70 (2012) (identifying
developmental science and common sense as the bases for the fact that "children
are different").





n25.  Id. at 2470 ("It is the odd legal rule that does not have some form of
exception for children.") (emphasis in original).





n26.  Juvenile courts in all fifty states handle child welfare and delinquency
matters.





n27.  See David S. Tanenhaus, Juvenile Justice in the Making (2004).





n28.  Annette Ruth Appell, The Pre-Political Child of Child-Centered
Jurisprudence, 46 Hous. L. Rev. 703, 709 (2009).





n29.  Schall v. Martin, 467 U.S. 253, 265 n.15 (1984); Elizabeth S. Scott &
Laurence Steinberg, Rethinking Juvenile Justice (2008).





n30.  Laurence Steinberg, Cognitive and Affective Development in Adolescence, 9
Trends in Cognitive Sci. 69, 69 (2005).





n31.  Scott & Steinberg, supra note 29, at 35.





n32.  Id. at 36; Laurence Steinberg, A Dual Systems Model of Adolescent
Risk-Taking, 52 Dev. Psychobiol. 216, 217 (2010).





n33.  Scott & Steinberg, supra note 29, at 37.





n34.  Id. at 38; Franklin E. Zimring, Kids, Groups and Crime: Some Implications
of a Well-Known Secret, 72 J. Crim. L. & Criminology 867, 867 (1981)
("Adolescents commit crimes, as they live their lives, in groups.").





n35.  Michael R. Gottfredson & Travis Hirschi, A General Theory of Crime 124
(1990) (stating the age-crime curve has "remained virtually unchanged in 150
years"); Alex R. Piquero et al., The Criminal Career Paradigm, 30 Crime & Just.
359 (2003).





n36.  Terrie E. Moffitt, Adolescence-Limited and Life-Course-Persistent
Antisocial Behavior: A Developmental Taxonomy, 100 Psychol. Rev. 674, 675 (1993)
(Delinquent behavior is "a normal part of teen life.").





n37.  Archard, supra note 10, at 61.





n38.  State ex rel. Juvenile Dep't of Multnomah Cty. v. Millican, 906 P.2d 857,
861 (1995) (De Muniz, J., dissenting) ("Shackling is likely to be more
psychologically jarring for children than adults.").





n39.  Bureau of Justice Assistance, U.S. Dep't of Justice, Juveniles in Adult
Prisons and Jails: A National Assessment (2000). Even institutions specifically
designed for youth, such as juvenile detention centers and foster care group
homes, inflict significant harms on youth. See Barry Holman & Jason Ziedenberg,
Justice Policy Inst., The Dangers of Detention: The Impact of Incarcerating
Youth in Detention and Other Secure Facilities (2006).





n40.  Franklin E. Zimring et al., Sexual Delinquency in Racine: Does Early Sex
Offending Predict Later Sex Offending in Youth and Young Adulthood?, 6
Criminology & Pub. Pol'y 507 (2007) (noting research on adolescent brain
development indicates that youth are particularly vulnerable to the stigma and
isolation that registration and notification create).





n41.  Graham v. Florida, 560 U.S. 48, 71 (2010) ("This reality [that life
without parole is a longer sentence for a juvenile than an adult] cannot be
ignored.").





n42.  Tanenhaus, supra note 27.





n43.  See Anthony M. Platt, The Child Savers: The Invention of Delinquency
(1969). In The Child Savers, Anthony Platt aims to "destroy[] the myth that the
child-saving movement was successful" and argues that the Progressives "helped
to create special judicial and correctional institutions for the labeling,
processing, and management of "troublesome' youth" that "subjected more and more
juveniles to arbitrary and degrading punishments." Id. at xliii, 3.





n44.  Restatement (Second) of Torts § 283.A (1965); see also Restatement (Third)
of Torts: Liability for Physical and Emotional Harm § 10 (2005) ("(a) A child's
conduct is negligent if it does not conform to that of a reasonably careful
person of the same age, intelligence, and experience, except as provided in
Subsection (b) or (c); (b) A child less than five years of age is incapable of
negligence ... .").





n45.  Halbman v. Lemke, 298 N.W.2d 562, 564 (1980).





n46.  E. Allan Farnsworth, Farnsworth on Contracts 230-31 (2d ed. 1998).





n47.  Tanenhaus, supra note 27.





n48.  Elizabeth S. Scott, "Children Are Different": Constitutional Values and
Justice Policy, 11 Ohio St. J. Crim. L. 71, 72 (2013) ("The Court has announced
a broad principle grounded in developmental knowledge that "children are
different' from adult offenders and that these differences are important to the
law's response to youthful criminal conduct.").





n49.  Roper v. Simmons, 543 U.S. 551, 570 (2005).





n50.  J.D.B. v. North Carolina, 131 S. Ct. 2394, 2403-04 (2011) (finding law
enforcement must consider age when deciding whether an individual is in custody
for purposes of providing a Miranda warning because youth are more vulnerable to
outside pressures than adults).





n51.  Scott & Steinberg, supra note 29, at 36.





n52.  Anita L. Allen, Why Privacy Isn't Everything: Feminist Reflections on
Personal Accountability 1, 29 (2003) (noting that young people are "typically
excused from the high level of accountability imposed on adults"); R. Jay
Wallace, Responsibility and the Moral Sentiments 164-65 (1994).





n53.  Jamie Stang & Mary Story, Guidelines for Adolescent Nutrition Services 1
(2005), www.epi.umn.edu/let/pubs/img/adol_ch1.pdf ("A myriad of biological
changes occur during puberty including sexual maturation, increases in height
and weight, completion of skeletal growth accompanied by a marked increase in
skeletal mass, and changes in body composition.").





n54.  Laurence Steinberg, Adolescence (9th ed. 2010); Laurence Steinberg, Should
the Science of Adolescent Brain Development Inform Public Policy?, 50 Ct. Rev.
70, 70 (2014) ("There is now incontrovertible evidence that adolescence is a
period of significant changes in the brain structure and function."); Terry A.
Maroney, The False Promise of Adolescent Brain Science in Juvenile Justice, 85
Notre Dame L. Rev. 89, 95-103 (2009) (summarizing the many findings about
adolescent brain development).





n55.  Jane Kroger, Identity in Adolescence: The Balance Between Self and Other
(2004) (describing adolescence as a time of self-definition and identity
formation).





n56.  Johnson v. Texas, 509 U.S. 350, 368 (1993); Scott & Steinberg, supra note
29, at 32 ("[Adolescence] is transitional because it is marked by rapid and
dramatic change within the individual in the realms of biology, cognition,
emotion, and interpersonal relationships ... .").





n57.  Laurence Steinberg & Elizabeth S. Scott, Less Guilty by Reason of
Adolescence: Developmental Immaturity, Diminished Responsibility, and the
Juvenile Death Penalty, 58 Am. Psychologist 1009, 1015 ("The typical delinquent
youth does not grow up to become an adult criminal ...").





n58.  See Edward P. Mulvey et al., Trajectories of Desistance and Continuity in
Antisocial Behavior Following Court Adjudication Among Serious Adolescent
Offenders, 22 Dev. Psychopathol. 453, 462 (2010) (finding after following over
1000 male adolescent offenders over the course of three years that only 8.7%
were "persisters" in that their offending remained constant throughout the
thirty-six-month period); see also Robert Sampson & John Laub, Life-Course
Desisters? Trajectories of Crime Among Delinquent Boys Followed to Age 70, 41
Criminology 301, 315 (2003) ("Aging out of crime is thus the norm - even the
most serious delinquents desist.").





n59.  Marsha Levick et al., The Eighth Amendment Evolves: Defining Cruel and
Unusual Punishment Through the Lens of Childhood and Adolescence, 15 U. Pa. J.L.
& Soc. Change 285, 297 (2012).





n60.  Roper v. Simmons, 543 U.S. 551, 573 (2005) ("It is difficult even for
expert psychologists to differentiate between the [youthful] offender whose
crime reflects unfortunate yet transient immaturity, and the rare [youthful]
offender whose crime reflects irreparable corruption.").





n61.  Julian W. Mack, The Juvenile Court, 23 Harv. L. Rev. 104, 107 (1910).





n62.  John C. Coffee, Privacy Versus Parens Patriae: The Role of Police Records
in the Sentencing and Surveillance of Juveniles, 57 Cornell L. Rev. 571, 617
(1971) ("Particularly in the case of the juvenile, ... yesterday's record does
not accurately describe today's individual.").





n63.  See Kristin Henning, Eroding Confidentiality in Delinquency Proceedings:
Should Schools and Public Housing Authorities Be Notified?, 79 N.Y.U. L. Rev.
520, 525-30 (2004) (criticizing the erosion of confidentiality protections
regarding juvenile court records).





n64.  Miller v. Alabama, 132 S. Ct. 2455, 2465 (2012); Graham v. Florida, 560
U.S. 48, 89 (2010); Roper, 543 U.S. at 569-70.





n65.  Graham, 560 U.S. at 68.





n66.  Roper, 551 U.S. at 570.





n67.  Id.





n68.  See supra note 13.





n69.  Appell, supra note 28, at 708.





n70.  James & James, supra note 10, at 20.





n71.  Allen, supra note 52, at 4 (noting that "a society cannot afford to fully
leave people alone"); Appell, supra note 28, at 708. In this vein, Theodore
Roosevelt described the early juvenile justice system as a "manufactory of
citizens." Jack M. Holl, Juvenile Reform in the Progressive Era: William R.
George and the Junior Republic Movement 9 (1971).





n72.  Franklin E. Zimring, American Juvenile Justice 18-19 (2005) ("Above almost
all else, we seek a legal policy that preserves the life chances for those who
make serious mistakes ... [and that gives] young law violators the chance to
survive our legal system with their life opportunities still intact ... [.]").





n73.  Mack, supra note 61, at 109 ("To get away from the notion that the child
is to be dealt with as a criminal; to save it from the brand of criminality, the
brand that sticks to it for life; to take it in hand and instead of first
stigmatizing and then reforming it, to protect it from the stigma - this is the
work which is now being accomplished by [the juvenile court].").





n74.  See Zimring, supra note 72, at 18-19.





n75.  See Kim Taylor-Thompson, Minority Rule: Redefining the Age of Criminality,
38 N.Y.U. Rev. L. & Soc. Change 143, 158-59 (2014).





n76.  For example, in New York, "Youthful Offender" status is available to a
limited number of young people charged in criminal court: those at least sixteen
but not yet nineteen, facing certain charges and without certain criminal
history. N.Y. Crim. Proc. § 720.10. Those who qualify benefit from a sealed
accusatory instrument, may have their arraignment and all proceedings conducted
in private, can receive reduced sentences that do not carry the same
consequences as a conviction, and court records are confidential. Crim. Proc.
§§720.15, 720.20, 720.35.





n77.  See, e.g., N.Y. Fam. Ct. Act § 353.6 (capping the amount of restitution
that a juvenile may be ordered to pay at $ 1500). According to the National
Juvenile Defender Center, eight jurisdictions place a cap on the amount of
restitution that may be imposed on a juvenile. See Juvenile Restitution
Statutes, Nat'l Juvenile Def. Ctr.,
http://njdc.info/juvenile-restitution-statutes/ (last visited Dec. 18, 2015).





n78.  See, e.g., Marsha L. Levick & Elizabeth-Ann Tierney, The United States
Supreme Court Adopts a Reasonable Juvenile Standard in J.D.B. v. North Carolina
for Purposes of the Miranda Custody Analysis: Can a More Reasoned Justice System
for Juveniles Be Far Behind?, 47 Harv. C.R.-C.L. L. Rev. 501 (2012) (identifying
duress, provocation, and felony murder as potential areas of future reform).
Many states have delayed implementing the Miller decision outlawing mandatory
life without parole sentences for juveniles. See The Sentencing Project, Slow to
Act: State Responses to 2012 Supreme Court Mandate on Life Without Parole
(2014). Even where juveniles are able to get resentencing hearings, many are
being resentenced to life without parole. Ranjani Chakraborty, Imprisoned at 14,
Illinois Inmate Gets Resentenced to Life Without Parole, Al Jazeera (May 4,
2015, 5:20 PM),
http://america.aljazeera.com/watch/shows/america-tonight/articles/2015/5/4/adolf
o-davis-life-parole.html.





n79.  Simon A. Cole, Suspect Identities: A History of Fingerprinting and
Criminal Identification (2001); Jacobs, supra note 2; Alexandra Natapoff,
Snitching: Criminal Informants and the Erosion of American Justice (2009).





n80.  Murphy, supra note 1, at 807 (2010) ("Old databases were typically paper
files or punch cards that were physically kept and stored in diffused, and at
times difficult to access, locations.").





n81.  See id. (arguing for better regulation of law enforcement databases);
Garfinkel, supra note 1.





n82.  James B. Jacobs, Juvenile Criminal Record Confidentiality, in Choosing the
Future for American Juvenile Justice 149, 157 (Franklin E. Zimring & David S.
Tanenhaus eds., 2014) ("The history of juvenile justice has always been
court-centric, paying much less attention to police and corrections.").





n83.  Jacobs, supra note 2, at 32 (identifying past targets as communists,
Mafioso, and Black militants).





n84.  Nat'l Gang Intelligence Ctr., 2013 National Gang Report.





n85.  Youth Justice Coal., Tracked and Trapped: Youth of Color, Gang Databases
and Gang Injunctions 2 (2012) (referencing the Gang Reporting, Evaluation, and
Tracking System ("GREAT") that stored and analyzed personal information about
alleged gang members).





n86.  Julie Barrows & C. Ronald Huff, Gangs and Public Policy: Constructing and
Deconstructing Gang Databases, 8 Criminology & Pub. Pol'y 675, 683 (2009).





n87.  K. Babe Howell, Gang Databases: Labeled for Life, Champion 28 (2011).





n88.  Youth Justice Coal., supra note 85, at 2.





n89.  James B. Jacobs, Gang Databases: Context and Questions, 8 Criminology &
Pub. Pol'y 705, 705 (2009).





n90.  Youth Justice Coal., supra note 85, at 4.





n91.  Rebecca Rader Brown, The Gang's All Here: Evaluating the Need for a
National Gang Database, 42 Colum. J.L. & Soc. Probs., 294, 319 (2009)
("Documentation procedures in most localities are characterized by high levels
of discretion in identification, review, and processing of information.").





n92.  Howell, supra note 87, at 33.





n93.  Victor M. Rios, Punished: Policing the Lives of Black and Latino Boys
77-78 (2011).





n94.  Id. at 78.





n95.  Barrows & Huff, supra note 86, at 677 ("Many if not most law-enforcement
agencies include marginal gang associates in their databases.").





n96.  Youth Justice Coal., supra note 85, at 11 (noting that as of December
2012, the CalGang database included 23,789 (out of 201,094) individuals age
nineteen or younger: 460 individuals aged ten to fourteen, and 23,329 aged
fifteen to nineteen).





n97.  Rader Brown, supra note 91, at 301 n.43 (noting that GangNet(R) is used by
at least twelve states, the District of Columbia, and multiple federal agencies,
and Canada). At the federal level, the FBI's National Gang Intelligence Center
integrates gang intelligence from federal, state, and local law enforcement.
Gangs, Fed. Bureau of Investigation,
https://www.fbi.gov/about-us/investigate/vc_majorthefts/gangs/ngic (last visited
Dec. 18, 2015).





n98.  CALGANG(R), Office of Att'y Gen., Cal. Dep't of Just.,
http://oag.ca.gov/calgang (last visited Dec. 18, 2015).





n99.  K. Babe Howell, Gang Policing: The Post Stop-and-Frisk Justification for
Profile-Based Policing, 5 U. Denv. Crim. L. Rev. 1, 4 (2015).





n100.  Will Hobson, Police Gang Lists Can Have Life-Long Impacts and Are
Questioned by Legal Experts, Tampa Bay Times (Sept. 15, 2012, 7:08 PM),
http://www.tampabay.com/news/publicsafety/crime/police-gang-lists-can-have-life-
long-impacts-and-are-questioned-by-legal/1251855.





n101.  Rader Brown, supra note 91, at 322.





n102.  Id.





n103.  Id. at 321 ("At least 23 states also impose increased mandatory sentences
for gang crimes ...").





n104.  Jacobs, supra note 89, at 706-07.





n105.  CALGANG(R), supra note 98.





n106.  Rader Brown, supra note 91, at 322 (urging notification procedures on
account of the legal and social consequences of gang classification for young
people).





n107.  Jacobs, supra note 89, at 708 ("Realistically, scrutiny of the gang
database is not going to be a high police-department priority. I think it is
likely that auditing will be conducted shoddily or not at all."); Rader Brown,
supra note 91, at 325-26 ("Current methods of populating and maintaining gang
databases are of questionable reliability and utility. Even where official
criteria and processes are established, implementation and oversight are
lacking.").





n108.  Rader Brown, supra note 91, at 320.





n109.  Jacobs, supra note 89, at 705.





n110.  Youth Justice Coal., supra note 85, at 6.





n111.  Charles M. Katz, Issues in the Production and Dissemination of Gang
Statistics: An Ethnographic Study of a Large Midwestern Police Gang Unit, 49
Crime & Delinq. 485, 504 (2003).





n112.  Aaron Kupchik, Homeroom Security: School Discipline in an Age of Fear
(2010); Schools Under Surveillance: Cultures of Control in Public Education
(Torin Monahan & Rodolfo D. Torres eds., 2010); see also Jason P. Nance, School
Surveillance and the Fourth Amendment, 79 Wis. L. Rev. 79 (2014).





n113.  Schools under Surveillance, supra note 112. Between the 1996-97 and
2007-08 school years, the number of public high schools with full-time law
enforcement and security guards tripled. Jacob Kang-Brown et al., Vera Inst. of
Justice, A Generation Later: What We've Learned About Zero Tolerance in Schools
2 (2013). Racial minority youth are disproportionately subjected to these
surveillance and policing practices. Aaron Kupchik, The School-to-Prison
Pipeline, in Choosing the Future for American Juvenile Justice 4, 96 (Franklin
E. Zimring & David S. Tanenhaus eds., 2014).





n114.  Kupchik, supra note 113, at 96 ("Students today often face suspension,
expulsion, or arrest for behaviors that at one time led to detention or a verbal
reprimand at the principal's office.").





n115.  Catherine Y. Kim, Daniel J. Losen & Damon T. Hewitt, The School-to-Prison
Pipeline: Structuring Legal Reform (2012); What Is The School-ToPrison
Pipeline?, Am. Civ. Liberties Union,
http://www.aclu.org/racial-justice/what-school-prison-pipeline (last visited
Dec. 18, 2015) ("The "school-to-prison pipeline' refers to the policies and
practices that push our nation's schoolchildren, especially our most at-risk
children, out of classrooms and into the juvenile and criminal justice
systems.").





n116.  Nance, supra note 112, at 90 ("Large, urban schools serving primarily
low-income or minority students are more likely to create intense surveillance
environments than other schools, [and] ... tend to rely on heavy-handed,
punitive-based measures to maintain order and control crime" and "are more
inclined to coerce students into compliance and to promote safety by
identifying, apprehending, and excluding students that school officials perceive
as being dangerous, disruptive, or low-performing.").





n117.  U.S. Dep't of Justice & U.S. Dep't of Educ., Dear Colleague Letter on
Nondiscriminatory Administration of School Discipline 4 (Jan. 8, 2014),
http://www2.ed.gov/about/offices/list/ocr/letters/colleague-201401-title-vi.pdf;
Jason P. Nance, Students, Security, and Race, 63 Emory L.J. 1 (2013) (finding
that student race and student poverty were strong predictors for whether a
school chose to employ high surveillance security methods even after controlling
for factors that might influence the school officials' decisions to employ
strict security measures, such as school crime, neighborhood crime, and school
disorder).





n118.  Jason P. Nance, Students, Police, and the School-to-Prison Pipeline, 93
Wash. U. L. Rev. 1, 1 (forthcoming 2015) ("In the past, certain lower-level,
common offenses that occurred at school, such as fighting or threats without use
of a weapon, traditionally were handled only by educators, not by police
officers.").





n119.  Henry A. Giroux, Racial Injustice and Disposable Youth in the Age of Zero
Tolerance, 16 Int'l J. Qualitative Stud. 553, 557-58 (2010); Paul J.
Hirschfield, Preparing for Prison?: The Criminalization of School Discipline in
the USA, 12 Theoretical Criminology 79 (2008).





n120.  Kupchik, supra note 113, at 94.





n121.  See Nancy E. Dowd, What Men?: The Essentialist Error of the "End of Men,"
93 B.U. L. Rev. 1205, 1219 (2013) (noting the "increasing use of arrest as a
form of school discipline for behavior that in the past would have been handled
within school").





n122.  According to a Texas study, a single suspension or expulsion for a
discretionary offense that did not include a weapon almost tripled a student's
likelihood of becoming involved in the juvenile justice system in the following
academic year. Tony Fabelo et al., Justice Ctr. & Pub. Policy Research Inst.,
Breaking Schools' Rules: A Statewide Study of How School Discipline Relates to
Students' Success and Juvenile Justice Involvement (2011).





n123.  Improving America's Schools Act of 1994, Pub. L. No. 103-382, 108 Stat.
3518; Aaron Kupchik & Nicole L. Bracy, To Protect, Serve, and Mentor?, in
Schools Under Surveillance: Cultures of Control in Public Education 21, 22
(Torin Monahan & Rodolfo D. Torres eds., 2010); Jonathan Simon, Governing
Through Crime: How the War on Crime Transformed American Democracy and Created a
Culture of Fear 214-20 (2007).





n124.  In 2000, the U.S. Department of Justice Office of Community Oriented
Police Services ("COPS") awarded $ 68 million in grants to schools across the
country specifically for the hiring of school resource officers. Supporting Safe
Schools, Cmty. Oriented Policing Servs.,
http://www.cops.usdoj.gov/Default.asp?Item=2687 (last visited Dec. 18, 2015).





n125.  In New York, the charge is "obstructing governmental administration."
N.Y. Penal Law § 195.05; Matthew T. Theriot, School Resource Officers and the
Criminalization of Student Behavior, 37 J. Crim. Just. 280, 281 (2009) ("Most
crime occurring at schools historically has not been reported to police, yet
having a police officer available and accessible at school facilitates
reporting.").





n126.  20 U.S.C. § 7151(h)(1) (2001).





n127.  A tremendous thank you to Jason P. Nance, Assistant Professor of Law at
the University of Florida Levin College of Law, who shared with me his initial
fifty-state survey of laws requiring schools to report to law enforcement.





n128.  See, e.g., Cal. Educ. Code § 48902 (West 2014); Del. Code Ann. tit. 14, §
4112(c) (West 2014).





n129.  Conn. Gen. Stat. Ann. § 10-222d(b)(15) (West 2014); N.Y. Educ. Law § 13
(McKinney 2014) (raising that harassment, bullying, or discrimination
constitutes criminal conduct). Nebraska also requires reports of bullying.  Neb.
Rev. Stat. § 79-293 (2014).





n130.  105 Ill. Comp. Stat. Ann. 5/34-84a.1 (LexisNexis 2014).





n131.  Kan. Stat. Ann. § 72-89b03 (2014).





n132.  Kan. Stat. Ann. § 72-89b04 (2014).





n133.  Cal. Educ. Code § 44014 (West 2014).





n134.  Kirk Semple, Immigration Agency's Tactic Spurs Alarm, N.Y. Times, Sept.
18, 2010, at A15 (describing subpoena issued by Immigration and Customs
Enforcement ("ICE") to the New York City Department of Education seeking the
school records of a student enrolled in a public school and noting that "[a]
spokesman for the immigration agency said that it regularly asked schools around
the country for student records, and that most were "completely cooperative'").





n135.  Henning, supra note 63, at 547; Minn. Stat. § 121A.28 (2014) (indicating
that law enforcement must report a drug or alcohol violation to schools); Minn.
Stat. § 260B.171 (2014) (stating that law enforcement must report certain
juvenile court dispositions to schools, and must notify schools if there is
probable cause to believe a juvenile committed certain offenses).





n136.  Juvenile Law Ctr., Failed Policies, Forfeited Futures: A Nationwide
Scorecard on Juvenile Records 6 (2014).





n137.  United States v. Sechrist, 640 F.2d 81, 87 (7th Cir. 1981) (Congress
sought to "ensure that a juvenile's fingerprints or photograph would not be
taken unnecessarily and that once taken, they would remain secret."); Vovos v.
Grant, 555 P.2d 1343, 1347 (Wash. 1976); James Jacobs & Tamara Crepet, The
Expanding Scope, Use, and Availability of Criminal Records, 11 N.Y.U. J. Legis.
& Pub. Pol'y 177, 188 (2008).





n138.  Mary E. Murrell & David Lester, Introduction to Juvenile Delinquency 147,
173-74 (1981).





n139.  Barry C. Feld, Cases and Materials on Juveniles Justice Administration
373 (4th ed. 2013) ("Photographing and fingerprinting connote a criminal process
that may stigmatize or self-label a youth.").





n140.  Bureau of Justice Stats., U.S. Dep't of Justice, Privacy and Juvenile
Justice Records: A Mid-Decade Status Report 3 (1997).





n141.  Id.





n142.  Bureau of Justice Stats., U.S. Dep't of Justice, Juvenile Records and
Recordkeeping Systems v (1988) (calling juvenile fingerprinting "one of the most
intrusive procedures in the juvenile justice process").





n143.  Id.





n144.  Howard N. Snyder & Melissa Sickmund, U.S. Dep't of Justice, Juvenile
Offenders and Victims: 2006 National Report (2006),
http://www.ojjdp.gov/ojstatbb/nr2006/downloads/nr2006.pdf.





n145.  57 Fed. Reg. 31,315, 31,315 (July 15, 1992); 28 C.F.R. § 20.32 (1999)
("Criminal history record information maintained in the III System and the FIRS
shall include serious and/or significant adult and juvenile offenses."); Bureau
of Justice Stats., supra note 140; Jacobs & Crepet, supra note 137, at 188-90.





n146.  Smith v. Daily Mail Publ'g, 443 U.S. 97, 103 (1979) (holding that state
cannot prevent media from disclosing juvenile arrestee's identity via statute);
Okla. Pub. Co. v. Dist. Ct. of Okla., 430 U.S. 308, 309 (1977) (holding that
state cannot prevent media from disclosing juvenile arrestee's identity via
court order).





n147.  For example, in New York City, every stop-and-frisk is supposed to be
recorded in an official UF-250 police report. See Bernard E. Harcourt & Tracey
L. Meares, Randomization and the Fourth Amendment, 78 U. Chi. L. Rev. 809,
862-63 n.210 (2011) ("According to the NYPD's Patrol Guide, a police officer who
stops and frisks an individual must complete a UF-250 if a person is (1) stopped
by force; (2) stopped and frisked or searched; (3) arrested; or (4) stopped and
refuses to identify oneself... . In situations that fall outside these four
contexts, a police officer may fill out a form if he or she desires to do so.")
(citation omitted).





n148.  For an example from Texas, see Texas Law Enforcement Field Interview
Card, Tex. Dep't of Pub. Safety,
http://www.txdps.state.tx.us/internetforms/Forms/INT-7.pdf.





n149.  Jacobs, supra note 2.





n150.  See, e.g., Police Field Interview FI Card,
https://play.google.com/store/apps/details?id=com.wavesystems.ficard&hl=en.





n151.  Paul Clinton, LAPD Rampart's Special Problems Unit, Police: The Law
Enforcement Magazine (Mar. 15, 2013) (Special Problems Unit officers
"relentlessly fill out field interview cards to build a record of every vehicle
stop or contact. Several of the officers use the Field Contact mobile app to
store suspect data including photos, tattoos, and gang affiliation.").





n152.  Jacobs, supra note 2, at 33.





n153.  Id. at 43 (including, for example, banks, housing authorities, and
organizations that provide child care services).





n154.  Madeline Neighly & Maurice Emsellem, Nat'l Emp't Law Project, Wanted:
Accurate FBI Background Checks for Employment 1 (2013).





n155.  Jacobs, supra note 2, at 160-61.





n156.  Id. at 46-47 (discussing the inscrutability of rap sheets, which contain
state criminal code numbers, abbreviations, and jargon that are difficult to
interpret by lay users).





n157.  See Michael S. Schmidt, Have a Tattoo or Walk with a Limp? The Police May
Know, N.Y. Times, Feb. 18, 2010, at A19.





n158.  Id.





n159.  Jennifer Lynch, FBI Plans to Have 52 Million Photos in Its NGI Face
Recognition Database by Next Year, Electronic Frontier Found. (Apr. 14, 2014),
https://www.eff.org/deeplinks/2014/04/fbi-plans-have-52-million-photos-its-ngi-f
ace-recognition-database-next-year.





n160.  National Crime Information Center, Fed. Bureau of Investigation,
http://www.fbi.gov/about-us/cjis/ncic (last visited Dec. 18, 2015).





n161.  NCIC Files, Fed. Bureau of Investigation,
http://www.fbi.gov/about-us/cjis/ncic/ncic_files (last visited Dec. 18, 2015).
The system contains images in addition to document records.





n162.  National Crime Information Center, supra note 160.





n163.  28 C.F.R. § 20.32(a) (1999) ("Criminal history record information
maintained in the III System and the FIRS shall include serious and/or
significant adult and juvenile offenses.").





n164.  Juvenile Law Ctr., supra note 136.





n165.  UCLA Sch. of Law Juvenile Justice Project, The Impact of Prosecuting
Youth in the Adult Criminal Justice System: A Review of the Literature 2 (2010).





n166.  See supra note 76 (explaining Youthful Offender adjudication).





n167.  Jacobs, supra note 2, at 55.





n168.  Id. (describing court records as enjoying "practical obscurity" before
court-record centralization).





n169.  See Francis X. Aumand III & Ronald P.Hawley, SEARCH, Nat'l Consortium for
Just. Info. & Stats., Report of the National Task Force on the Commercial Sale
of Criminal Justice Record Information 5 (2005).





n170.  Charles Puzzanchera et al., Nat'l Ctr. for Juvenile Justice, Juvenile
Court Statistics 2008, 6 (2011), http://www.ncjj.org/pdf/jcsreports/jcs2008.pdf
(noting courts with juvenile jurisdiction handled an estimated 1.65 million
delinquency cases in 2008).





n171.  Miriam van Waters, Youth in Conflict 217 (1927).





n172.  Juvenile courts issue an adjudication, which is not a criminal
conviction. See, e.g., Cal. Welf. & Inst. Code § 203 (West 2014) ("An order
adjudging a minor to be a ward of the juvenile court shall not be deemed a
conviction of a crime for any purpose, nor shall a proceeding in the juvenile
court be deemed a criminal proceeding.").





n173.  Tanenhaus, supra note 27.





n174.  McKeiver v. Pennsylvania, 403 U.S. 528, 549-51 (1971) (holding that
juveniles do not have constitutional right to jury trial in juvenile delinquency
proceeding under either Sixth Amendment or Due Process Clause of Fourteenth
Amendment).





n175.  See Henning, supra note 63, at 525-30.





n176.  Thirty-nine states now permit or require juvenile delinquency hearings to
be open to the public, either for all proceedings or with certain age/offense
requirements influencing the decision. Kristen Rasmussen, Reporters Comm. For
Freedom of Press, Minors Making News: A State-by-State Guide to Juvenile Courts
Nationwide 4-5 (2012); Lina A. Syzmanski, Nat'l Ctr. for Juvenile Justice,
Confidentiality of Juvenile Delinquency Hearings 1 (2008),
http//:www.ncjj.org/PDF/Snapshots/2008/vol13_no5_confidentiality2008.pdf ("The
trend has been for much greater openness in juvenile delinquency hearings.").





n177.  Riya Saha Shah & Lauren Fine, Juvenile Law Ctr., Juvenile Records: A
National Review of State Laws on Confidentiality, Sealing and Expungement 6
(2014),
http://juvenilerecords.jlc.org/juvenilerecords/documents/publications/national-r
eview.pdf.





n178.  Id.





n179.  Jacobs, supra note 82, at 161 ("in at least 30 states the names and
photos of violent and repeat juvenile offenders can be released to the public").





n180.  Nat'l Ass'n of Criminal Def. Lawyers, Collateral Damage: America's
Failure to Forgive or Forget in the War on Crime 61 (2014),
http://www.nacdl.org/restoration/roadmapreport ("You could actually, right now,
purchase every juvenile record for 24 bucks in the state of Florida, even if it
was a seven-year old, even if it was dismissed. It doesn't matter. You can get
the record.").





n181.  Shah & Fine, supra note 177, at 6.





n182.  Davis v. Alaska, 415 U.S. 308, 320-21 (1974).





n183.  Juvenile Law Ctr., supra note 136, at 9.





n184.  Id. at 19.





n185.  Id. at 43-45.





n186.  Julie E. Samuels et al., Urban Inst., Justice Policy Ctr., Collecting DNA
from Juveniles 32-35 (2011),
http://www.urban.org/sites/default/files/alfresco/publication-pdfs/412487-Collec
ting-DNA-from-Juveniles.PDF.





n187.  Erin Murphy, Relative Doubt: Familial Searches of DNA Databases, 109
Mich. L. Rev. 291, 294-97 (2010). A DNA profile consists solely of numbers
describing the number of times certain known sequences repeat themselves and
identifying information for the agency that provided the DNA sample; it does not
contain any personal information (such as the name and address) of the
individual to whom it belongs. H.R. Rep. No. 106-900, pt. 1, at 27 (2000).





n188.  These government databases include the State DNA Index System ("SDIS"),
the Local DNA Index System ("LDIS"), and the National DNA Index System ("NDIS").
Samuels et al., supra note 186, at 10.





n189.  Frequently Asked Questions (FAQs) on the CODIS Program and the National
DNA Index System, Fed. Bureau of Investigation,
http://www.fbi.gov/about-us/lab/biometric-analysis/codis/codis-and-ndis-fact-she
et (last visited Dec. 18, 2015).





n190.  Maryland v. King, 133 S. Ct. 1958, 1966 (2013) ("Law enforcement, the
defense bar, and the courts have acknowledged DNA testing's "unparalleled
ability both to exonerate the wrongly convicted and to identify the guilty. It
has the potential to significantly improve both the criminal justice system and
police investigative practices.'").





n191.  42 U.S.C. § 14135a(a)(1)(A) (2000). Federal law permits the use of force
in taking the DNA sample. Id. § 14135a(a)(4)(A); Collection of DNA Samples, 28
C.F.R. § 28.12(d) (2014). Those who fail to cooperate in DNA collection face a
Class A misdemeanor charge punishable by up to one year in prison. 42 U.S.C. §
14135a(a)(5); 18 U.S.C. § 3559(a)(6) (2012). States have similar provisions.





n192.  Haw. Rev. Stat. § 844D-31 (2014) ("Any person, except for any juvenile,
who is convicted of, or pleads guilty or no contest to, any felony offense ...
shall provide buccal swab samples").





n193.  Hawaii, Idaho, Indiana, and Wyoming collect only for felonies. See Haw.
Rev. Stat. § 844D-31 (2014); Idaho Code § 19-5506 (2014); Ind. Code § 10-13-6-10
(2014); Wyo. Stat. Ann. § 7-19-403 (2011). New York has the broadest regime,
mandating collection following a conviction for any felony and any misdemeanor
except first-time, low-level marijuana possession.  N.Y. Exec. Law § 995(7)
(McKinney 2013).





n194.  See Kevin Lapp, As Though They Were Not Children: DNA Collection from
Juveniles, 89 Tul. L. Rev. 435, 452 (2014) (collecting citations).





n195.  Id. at 454.





n196.  Id.





n197.  Id. at 458. After King (upholding preconviction DNA collection), the
number of states authorizing arrestee DNA collection is likely to rise. At the
time King was decided, several states had yet to begin or fully implement their
arrestee DNA law. Julie E. Samuels et al., Collecting DNA at Arrest: Policies,
Practices, and Implications, Urban Inst. 24 (2013),
http://www.urban.org/research/publication/collecting-dna-arrest-policies-practic
es-and-implications/view/full_report.





n198.  Eight of the nineteen explicitly authorize collection from arrested
juveniles, and another eleven implicitly authorize it by mandating collection
from "persons" or "individuals" and not explicitly defining juveniles out of
those categories. See Lapp, supra note 194, at 459 (collecting citations).





n199.  Elizabeth N. Jones, "Spit and Acquit": Legal and Practical Ramifications
of the DA's DNA Gathering Program, Orange County Law. Mag., Sept. 2009, at 18.





n200.  Id.





n201.  Joseph Goldstein, Police Agencies Are Assembling Records of DNA, N.Y.
Times (June 12, 2013),
http://www.nytimes.com/2013/06/13/us/police-agencies-are-assembling-records-of-d
na.html (noting several cities, including New York City, Denver, Palm Bay,
Florida, are building their own DNA databases).





n202.  Police Collect DNA from Middle-Schoolers in Murder Investigation, L.A.
Times (Apr. 17, 2012, 8:39 AM),
http://latimesblogs.latimes.com/lanow/2012/04/police-collect-dna-from-8th-grader
s-for-murder-investigation.html. In a news report about the DNA collection,
Deputy Jason Ramos of the Sacramento County Sheriff's Department said, "We don't
require the consent of a parent if we're doing it with someone of a younger
age." Id.





n203.  See Brian Maass, Brighton Police Say Taking DNA from Child Victims an
"Oversight,' CBS Denver (Nov. 16, 2011, 11:58 PM),
http://denver.cbslocal.com/2011/11/16/brighton-police-say-taking-dna-from-child-
victims-an-oversight.





n204.  According to a 2011 Urban Institute report, ten states that provided data
had a total of over 121,000 DNA profiles as of the end of 2008 that came from
individuals who were juveniles at the time of collection, representing 6.2% of
all DNA profiles uploaded by these states. Samuels et al., supra note 186, at
17. Taking that ratio as a baseline, 6.2% of the current CODIS DNA profile
database would be approximately 800,000 juvenile profiles. CODIS - NDIS
Statistics, Fed. Bureau of Investigation,
http://www.fbi.gov/about-us/lab/biometric-analysis/codis/ndis-statistics (last
visited Dec. 18, 2015).





n205.  Courts with juvenile jurisdiction handle over 1.5 million delinquency
cases annually. Puzzanchera, supra note 170, at 6. Moreover, in 2012, almost one
million arrests of persons under age eighteen were made in the United States.
FBI Uniform Crime Reports: Table 36, Fed. Bureau of Investigation (2012),
http://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/2012/crime-in-the-u.s.-201
2/tables/36tabledatadecoverviewpdf.





n206.  42 U.S.C. § 16911 (2006) (no exceptions for minors convicted in criminal
court).





n207.  Jacob Wetterling Crimes Against Children and Sexually Violent Offender
Registration Program, 42 U.S.C. §§14071-73 (repealed 2006).





n208.  Nicole I. Pittman & Quyen Nguyen, A Snapshot of Juvenile Sex Offender
Registration and Notification Laws: A Survey of the United States 32 (2011).





n209.  The statute is codified at 42 U.S.C. § 16901-62 (2009).





n210.  42 U.S.C. § 16911(8) (2006) (defining the term "convicted" to include
individuals "adjudicated delinquent as a juvenile ... , but only if the offender
is 14 years of age or older at the time of the offense and the offense
adjudicated was comparable to or more severe than aggravated sexual abuse").
States that are not in substantial compliance with SORNA forfeit federal funds.
Pittman & Nguyen, supra note 208, at 7. ("States that fail to comply ... in a
timely manner will forfeit 10% of their Byrne Memorial Justice Assistance Grant
(JAG) Omnibus Crime federal funding.").





n211.  Adam Walsh Child Protection and Safety Act of 2006, Pub. L. No. 109-248,
§ 111, 120 Stat. 588.





n212.  The National Guidelines for Sex Offender Registration and Notification,
73 Fed. Reg. 38,030 38,032 (July 2, 2008).





n213.  Pittman & Nguyen, supra note 208, at 32.





n214.  See N.C. Gen. Stat. Ann. § 14-208.26(a) (West 2014) (subjecting juveniles
at least eleven years of age at the time of the commission of the offense to sex
offender registration); In re Ronnie A., 585 S.E.2d 311 (S.C. 2003) (holding
registration of eleven-year-old juvenile who was nine at time of offense did not
violate due process).





n215.  Pittman & Nguyen, supra note 208, at 32.





n216.  Michael F. Caldwell et al., An Examination of the Sex Offender
Registration and Notification Act as Applied to Juveniles: Evaluating the
Ability to Predict Sexual Recidivism, 14 Psychol. Pub. Pol'y & L. 89, 105
(2008).





n217.  42 U.S.C. § 16911(5)(C) (2014); Pittman & Nguyen, supra note 208, at 32.





n218.  Victims of Trafficking and Violence Protection Act of 2000, Pub. L. No.
106-386, 114 Stat. 1464 (codified in scattered sections of chapters 18, 22, 27
and 42 of the U.S.C.) (requiring sex offenders to report their enrollment in or
employment at an institution of higher learning).





n219.  Pam Lyncher Sexual Offender Tracking and Identification Act of 1996, 42
U.S.C. § 14072 (1996).





n220.  Nat'l Sex Offender Pub. Website, U.S. Dep't of Just.,
http://www.nsopw.gov/ (last visited Dec. 18, 2015).





n221.  Nicole Pittman & Alison Parker, Human Rights Watch, Raised on the
Registry: The Irreparable Harm of Placing Children on Sex Offender Registries in
the US 40 (2013).





n222.  Id. at 5 (noting that failure to pay fees can lead to rearrest). Colorado
imposes a registration fee of between $ 150 and $ 400, depending on the
seriousness of the sex offense.  Colo. Rev. Stat. § 18-21-103 (2015). Michigan
charges $ 50 annually. Sex Offenders Registration Act, Mich. Comp. Laws §
28.725a(6) (2014).





n223.  David Finkelhor, Richard Ormrod & Mark Chaffin, Juvenile Justice
Bulletin, U.S. Dep't of Justice, Juveniles Who Commit Sex Offenses Against
Minors 3 (2009), http://www.unh.edu/ccrc/pdf/CV171.pdf.





n224.  Caldwell et al., supra note 216, at 105; Charles Puzzanchera, Juvenile
Offenders & Victims: Nat'l Report Series, U.S. Dep't of Justice, Juvenile
Arrests 2011, at 3 (2013), http://www.ojjdp.gov/pubs/244476.pdf (noting that in
2011, 15,400 juveniles were arrested for sex offenses).





n225.  Amy E. Halbrook, Juvenile Pariahs, 65 Hastings L.J. 1, 22 (2013).





n226.  42 U.S.C. § 16981 (2008).





n227.  See, e.g., Lemmon v. Harris, 949 N.E.2d 803, 804-05 (Ind. 2011)
(involving defendant who was originally required to register for ten years was
reclassified to require lifetime registration).





n228.  Elizabeth E. Mustaine et al., Residential Location and Mobility of
Registered Sex Offenders, 30 Am. J. Crim. Just. 177, 190 (2006).





n229.  Richard Tewksbury, Collateral Consequences of Sex Offender Registration,
21 J. Contemp. Crim. Just. 67, 68 (2005); Richard Tewksbury & Matthew Lees,
Perceptions of Sex Offender Registration: Collateral Consequences and Community
Experiences, 26 Soc. Spectrum 309, 331-32 (2006).





n230.  Smith v. Doe, 538 U.S. 84, 99 (2003) ("It must be acknowledged that
notice of criminal conviction subjects the offender to public shame, the
humiliation increasing in proportion to the extent of the publicity. And the
geographic reach of the Internet is greater than anything that could have been
designed in colonial times."); Elizabeth Garfinkle, Coming of Age in America:
The Misapplication of Sex-Offender Registration and Community-Notification Laws
to Juveniles, 91 Calif. L. Rev. 163 (2003).





n231.  Indeed, one study suggested that including juveniles in SORNA Tier 3
could actually create a greater risk to community safety. Caldwell et al., supra
note 216, at 106.





n232.  Pittman & Parker, supra note 221, at 52.





n233.  United States v. Juvenile Male, 670 F.3d 999, 1010 (9th Cir. 2012)
(holding that requiring juvenile sex offenders to register in a database is not
cruel and unusual punishment); In re J.W., 787 N.E.2d 747, 760 (Ill. 2003)
(holding that lifetime juvenile sex offender registration did not constitute
cruel and unusual punishment post-Roper, partially because juveniles'
registration information is not publicly disseminated).





n234.  See infra Part IV.





n235.  See McDermott & Duque Raley, supra note 7, at 438 (describing school
records of misbehavior and missing behavior as "the institutional biographies
that record a child's problems in school files forever").





n236.  Nigel Hamilton, Biography: A Brief History (2010).





n237.  See Donna M. Bishop & Michael J. Leiber, Racial and Ethnic Differences in
Delinquency and Justice System Responses, in The Oxford Handbook of Juvenile
Crime and Juvenile Justice 445 (Barry C. Feld and Donna M. Bishop eds., 2012);
Barry C. Feld, Cops, Kids, and Confessions: Inside the Interrogation Room 10
(2013); Nat'l Council on Crime & Delinq., And Justice for Some: Differential
Treatment of Youth of Color in the Justice System (2007).





n238.  See Feld, supra note 237, at 10.





n239.  Paul D. Butler, Poor People Lose: Gideon and the Critique of Rights, 122
Yale L.J. 2176, 2181 (2013); see also David Cole, No Equal Justice: Race and
Class in the American Criminal Justice System (1999).





n240.  The deterrent value of databasing is contested. See, e.g., Sheldon
Krimsky & Tania Simoncelli, Genetic Justice: DNA Data Banks, Criminal
Investigations, and Civil Liberties 148 (2011) ("Currently there is no empirical
evidence to support the often-stated claim that DNA databases deter crime.").





n241.  See Maryland v. King, 133 S. Ct. 1958, 1971 (2013).





n242.  For example, when an officer pulls over a driver and runs the license
plate, and learns that the owner of the vehicle has prior arrests or convictions
for weapons or violent offenses, the officer can more prudently approach the
individual.





n243.  Nance, supra note 112, at 96-97.





n244.  CODIS - NDIS Statistics, supra note 204 ("As of August 2015, CODIS has
produced over 293,808 hits assisting in more than 279,741 investigations."); see
DNA Exonerations Nationwide, Innocence Project,
http://www.innocenceproject.org/Content/DNA_Exonerations_Nationwide.php (last
visited Dec. 18, 2015) (providing an account of the 330 post-conviction DNA
exonerations to date).





n245.  Andrew Guthrie Ferguson, Big Data and Predictive Reasonable Suspicion,
163 U. Pa. L. Rev. 327, 330 (2015) (imagining a situation where police
investigating a series of robberies use facial recognition software that matches
a person walking down the street in the vicinity of the robberies to an arrest
photo from a computerized database, and that person's criminal history
[instantly displayed in the patrol car] shows prior robbery arrests and
convictions).





n246.  Id. at 370-71 (noting that predictive policing technologies are already
in use, and that several jurisdictions maintain lists of individuals they
predict will commit crimes in the future); Robert L. Mitchell, Predictive
Policing Gets Personal, Computerworld (Oct. 24, 2013, 7:00 AM),
http://www.computerworld.com/article/2486424/government-it/predictivepolicing-ge
ts-personal.html (quoting the Charlotte, N.C. Chief of Police as saying "We
could name our top 300 offenders... . So we will focus on those individuals ...
.").





n247.  Piquero, Farrington & Blumstein, supra note 35, at 424; see also Travis
Hirschi & Michael Gottfredson, Age and the Explanation of Crime, 89 Am. J. Soc.
552, 555 (1983) (The age-crime curve "has remained virtually unchanged in 150
years ...").





n248.  See Pittman & Parker, supra note 221, at 40.





n249.  Erin Murphy, Paradigms of Restraint, 57 Duke L.J. 1321, 1329 (2008)
(noting that most states allow indefinite retention of the DNA sample containing
the individual's entire genetic code).





n250.  Murphy, supra note 1, at 805-10.





n251.  Courts have, for example, acknowledged the "vast amount of sensitive
information that can be mined from a person's DNA and the very strong privacy
interests that all individuals have in this information." United States v.
Amerson, 483 F.3d 73, 86 (2d Cir. 2007); see also Garfinkel, supra note 1.





n252.  Gary B. Melton, Minors and Privacy: Are Legal and Psychological Concepts
Compatible?, 62 Neb. L. Rev. 455, 475, 477 (1983).





n253.  M. Ryan Calo, The Boundaries of Privacy Harm, 86 Ind. L.J. 1131, 1133
(2011).





n254.  Id. at 1145 ("Many subjective privacy harms ... will be backward looking
insofar as the offending observation has already ended at the time of discovery
(or because of it).").





n255.  Pittman & Parker, supra note 221, at 51-52.





n256.  Calo, supra note 253, at 1133; see also Rios, supra note 93, at 78 ("When
the police classified Spider as a gang member, school staff, community workers,
and other adults in the community also adopted this categorization.").





n257.  Erving Goffman, Stigma: Notes on the Management of Spoiled Identity 3 (2d
ed. 1963); Stigma, Oxford English Dictionary 689 (2d ed. 1989) (denoting that in
Greek, the mark or brand known as stigma was used to identify those who were not
full members of ancient Greek society); W. David Ball, The Civil Case at the
Heart of Criminal Procedure: In re Winship, Stigma, and the Civil-Criminal
Distinction, 38 Am. J. Crim. L. 117, 146 (2011).





n258.  Ball, supra note 257, at 148.





n259.  In re Winship, 397 U.S. 358, 363 (1970); Ball, supra note 257, at 139.





n260.  In re Gault, 387 U.S. 1, 23 (1967).





n261.  Bruce G. Link & Jo C. Phelan, Conceptualizing Stigma, 27 Ann. Rev. Soc.
363, 380 (2001).





n262.  Pittman & Parker, supra note 221, at 50; Chrysanthi S. Leon, Sex Fiends,
Perverts, and Pedophiles: Understanding Sex Crime Policy in America (2011).





n263.  Ann Arnett Ferguson, Bad Boys: Public Schools in the Making of Black
Masculinity 2-3 (2000); Nance, supra note 112, at 97 (Schools have "recast
disruptive students as criminals who must be reformed through punitive
measures.").





n264.  Rios, supra note 93; Barrows & Huff, supra note 86, at 678 ("Police often
target the wrong individuals, thereby potentially driving them into gang
membership because they are treated as, and known as, gang members.").





n265.  Ball, supra note 257; Jon Gunnar Bernburg, Marvin D. Krohn & Craig J.
Rivera, Official Labeling, Criminal Embeddedness, and Subsequent Delinquency: A
Longitudinal Test of Labeling Theory, 43 J. Res. Crime & Delinq. 67, 69 (2006).





n266.  Link & Phelan, supra note 261, at 370.





n267.  John J. DiIulio Jr., The Coming of the Super-Predators, Wkly. Standard,
Nov. 27, 1995, at 23.





n268.  Edwin Lemert, Social Pathology (1951); Goffman, supra note 257; Bernburg,
Krohn & Rivera, supra note 265.





n269.  William D. Payne, Negative Labels: Passageways and Prisons, 19 Crime &
Delinq. 33, 35 (1973) (Negative social labels stimulate antisocial behavior;
they create the expectation that an individual will conform to the label and
"play an important part in an individual's passage from merely having committed
a questionable act to possessing a "deviant character.'").





n270.  Ball, supra note 257, at 146; Bruce G. Link et al., A Modified Labeling
Theory Approach to Mental Disorders: An Empirical Assessment, 54 Am. Soc. Rev.
400, 402-03 (1989); Terri A. Winnick & Mark Bodkin, Anticipated Stigma and
Stigma Management Among Those to be Labeled "Ex-Con", 29 Deviant Behav. 295, 301
(2008) ("Secondary deviance is not a direct result of labeling, but rather an
indirect result of coping, or stigma management, which has the ironic effect of
shaping the conditions under which secondary deviance is more likely.").





n271.  Smith v. Doe, 538 U.S. 84, 115 (2003) (Ginsburg, J., dissenting)
(identifying the "profound humiliation and community-wide ostracism" that
attends sex offender community notification); Note, Shame, Stigma, and Crime:
Evaluating the Efficacy of Shaming Sanctions in Criminal Law, 116 Harv. L. Rev.
2187 (2003); Tewksbury, supra note 229, at 68 (identifying lost friends and
harassment and rude treatment among the many stigmatizing effects of sex
offender registration).





n272.  Pittman & Parker, supra note 221, at 50.





n273.  Once information gets on the Internet, it stays there, even after a
person has been removed from the sex offender registry. Id. at 44.





n274.  Caldwell et al., supra note 216, at 106 (including juveniles in SORNA
Tier 3 could actually create a greater risk to community safety).





n275.  K. Babe Howell, Fear Itself: The Impact of Allegations of Gang
Affiliation on Pre-Trial Detention, 23 St. Thomas L. Rev. 620, 647 (2011)
("While Wannabes may commit crimes or delinquent acts either on their own, as
members of wannabe delinquent groups, or to obtain reputation and membership,
the acts are not done for the gang so much as to enhance the individuals'
reputation.").





n276.  Barrows & Huff, supra note 86, at 678; Howell, supra note 87, at 30-31.





n277.  Kupchik, supra note 112, at 94.





n278.  S. & Marper v. United Kingdom, 2008-V Eur. Ct. H.R. 167 (noting the risk
of stigmatization in treating persons who have not been convicted in the same
way as convicted persons by retaining their DNA); compare Feld, supra note 139,
at 373 ("Photographing and fingerprinting connote a criminal process that may
stigmatize or self-label a youth ... .").





n279.  See infra Part III.A.2.





n280.  See infra Part III.A.3.





n281.  Inst. of Judicial Admin., Am. Bar Ass'n, Standards Relating to Juvenile
Records and Information Systems 2 (1979).





n282.  Ball, supra note 257, at 148.





n283.  Id.





n284.  Johnson v. Texas, 509 U.S. 350, 368 (1993); Scott, supra note 48, at 86
n.80 ("Much adolescent criminal activity is the product of developmental
influences and not of bad character.").





n285.  See Moffitt, supra note 36, at 675 ("The rates for both prevalence and
incidence of offending appear highest during adolescence; they peak sharply at
about age 17 and drop precipitously in young adulthood ... by the early 20s, the
number of active offenders decreases by over 50%, and by age 28, almost 85% of
former delinquents desist from offending.").





n286.  Graham v. Florida, 560 U.S. 1, 68 (2009).





n287.  See Roper v. Simmons, 543 U.S. 551, 573 (2004) ("It is difficult even for
expert psychologists to differentiate between the juvenile offender whose crime
reflects unfortunate yet transient immaturity, and the rare juvenile offender
whose crime reflects irreparable corruption.").





n288.  The enacting legislation in several states, for example, includes a
finding that DNA databasing is an important tool in deterring recidivist acts.
See, e.g., Neb. Rev. Stat. § 29-4102 (2010) ("The Legislature finds that DNA
data banks are an important tool ... in deterring and detecting recidivist
acts").





n289.  See, e.g., Krimsky & Simoncelli, supra note 240, at 148 ("Currently there
is no empirical evidence to support the often-stated claim that DNA databases
deter crime."). But see Avinash Bhati, Justice Policy Ctr., Urban Inst.,
Quantifying the Specific Deterrent Effects of DNA Databases 56 (2010),
http://www.urban.org/uploadedpdf/412058_dna_databases.pdf (finding two to three
percent reductions in recidivism risk attributable to specific deterrence for
robbery and burglary resulting from DNA databasing).





n290.  Scott & Steinberg, supra note 29, at 56 ("The research on the general
deterrent effect of legal regulation on juvenile crime is sparse and gives no
clear answer to the question of whether ... punitive measures reduce juvenile
crime.").





n291.  Christopher Slobogin & Mark R. Fondacaro, Juvenile Justice: The Fourth
Option, 95 Iowa L. Rev. 1, 44 (2009).





n292.  Feld, supra note 237, at 10 ("At every stage - arrest, intake, referral,
petition, detention, trial, and disposition - youths of color fare less well
than do their white counterparts ..."); Bishop & Leiber, supra note 237.





n293.  Krimsky & Simoncelli, supra note 240, at 252 (describing racial disparity
in DNA databanks). DNA databases have been referred to as a "Jim Crow database."
Harry G. Levine et al., Drug Arrests and DNA: Building Jim Crow's Database 4
(2008),
http://www.councilforresponsiblegenetics.org/pagedocuments/0rrxbggaei.pdf.





n294.  Of the 201,094 in the CalGang database (as of December 2012), for
example, nearly 20% are African American (6.6% of California population); 66%
Latino (38% of California population). Youth Justice Coal., supra note 85, at
8-9.





n295.  Daniel M. Filler, Silence and the Racial Dimension of Megan's Law, 89
Iowa L. Rev. 1535, 1538 (2004) (noting that community notification provisions
have a significantly disparate racial impact; African Americans are
overrepresented on public registries of criminals).





n296.  Nance, supra note 117, at 48.





n297.  Coffee, supra note 62, at 591 ("The greater the police focus, the more
information is recorded, and the more information recorded, the greater the
chance that police discretion will be influenced by the records created
thereby.").





n298.  Indeed, that is the point of law enforcement intelligence gathering.





n299.  Anhony Petrosino et al., Campbell Systematic Reviews, Formal System
Processing of Juveniles: Effects on Delinquency (2010),
http://www.campbellcollaboration.org/lib/download/761/ (finding in a
comprehensive meta-analysis that juvenile system processing appears not to have
a crime control effect but instead appears to increase delinquency across all
measures); Tamar R. Birckhead, Delinquent by Reason of Poverty, 38 Wash. U. J.L.
& Pol'y 53, 97 (2012) (discussing studies finding criminogenic effect of
juvenile court processing).





n300.  Jennifer L. Doleac, The Effects of DNA Databases on Crime 26 (Dec. 2,
2012) (working paper) (noting that when young offenders "have little
(non-criminal) human capital in the form of education, employment experience, or
ties to friends and family to rely on when they are released").





n301.  Ferguson, supra note 245, at 327 (imagining a situation where police
investigating a series of robberies use facial recognition software that matches
a person walking down the street in the vicinity of the robberies to an arrest
photo from a computerized database, and that person's criminal history
[instantly displayed in the patrol car] shows prior robbery arrests and
convictions).





n302.  Id. at 335.





n303.  Will Hobson, Overhaul Coming to Pinellas Gang Intelligence Database,
Tampa Bay Times (June 9, 2013, 4:30 AM),
http://www.tampabay.com/news/courts/criminal/overhaul-coming-to-pinellas-gang-in
telligence-database/2125725 (describing story of person who was erroneously
placed in database and got pulled over/stopped a bunch of times as a result);
Howell, supra note 87, at 30-31.





n304.  Pittman & Parker, supra note 221, at 3.





n305.  Herring v. United States, 555 U.S. 135, 155 (2009) (Ginsburg, J.,
dissenting) ("The risk of error stemming from these databases is not slim... .
Inaccuracies in expansive, interconnected collections of electronic information
raise grave concerns for individual liberty.").





n306.  Neighly & Emsellem, supra note 154, at 1.





n307.  Jacobs, supra note 2, at 134-35; Legal Action Ctr., The Problem of Rap
Sheet Errors: An Analysis by the Legal Action Center 5 (2013).





n308.  Legal Action Ctr., supra note 307, at 5 (noting that between five percent
and fifteen percent of New York rap sheets contained information about dismissed
cases or violations that should have been sealed); Joy Radice, Administering
Justice: Removing Statutory Barriers to Reentry, 83 U. Colo. L. Rev. 715, 750
(2012). Allocating resources to auditing databases, especially with regard to
old information, is unlikely to ever be a high law enforcement priority.





n309.  In both Arizona v. Evans, 514 U.S. 1 (1995) and Herring v. United States,
555 U.S. 135 (2009), errors in a law enforcement database indicating an
outstanding arrest warrant led to an unlawful arrest and subsequent search by
police that produced contraband.





n310.  Brady Gervais, Ramsey County Pulling Plug on Controversial Gang Database,
Pioneer Press (Aug. 3, 2011, 12:01 AM), http://www.twincities.com/ci_18604634.





n311.  Jacobs, supra note 2, at 307.





n312.  See id.





n313.  Samuels et al., supra note 186, at 7 (finding few DNA profiles are ever
expunged from databases); Joshua D. Wright, The Constitutional Failure of Gang
Databases, 2 Stan. J. Civ. Rts. & Civ. Liberties 115, 115 (2005) ("responsible
agencies systematically fail to adhere to policies requiring names to be purged
after specified amounts of time without criminal or gang activity.").





n314.  Ninety percent of employers conduct background checks on prospective
employees. Michelle Natividad Rodriguez & Maurice Emsellem, Nat'l Emp't Law
Project, 65 Million "Need Not Apply": The Case for Reforming Criminal Background
Checks for Employment 1 (2011).





n315.  The Common Application, used by over 500 colleges, asks about criminal
conviction and school disciplinary records. See The Common Application,
https://www.commonapp.org/Login (last visited Dec. 18, 2015); Ctr. for Cmty.
Alts., The Use of Criminal History Records in College Admissions Reconsidered 1
(2011),
http://www.communityalternatives.org/pdf/Reconsidered-criminal-hist-recs-in-coll
ege-admissions.pdf (finding that sixty-six percent of colleges surveyed collect
criminal history information from applicants).





n316.  David Thacher, The Rise of Criminal Background Screening in Rental
Housing, 33 Law & Soc. Inquiry 5 (2008).





n317.  In the wake of the Ferguson, Missouri death of Michael Brown, the St.
Louis Post-Dispatch filed a petition seeking Michael Brown's juvenile records.
Jeremy Kohler, Judge Denies Request for Michael Brown's Juvenile Records, St.
Louis Post-Dispatch (Sept. 9, 2014, 4:45 PM),
http://www.stltoday.com/news/local/crime-and-courts/judge-denies-request-for-mic
hael-brown-s-juvenile-records/article_43dfd98b-32ec-550d-b399-750133f69203.html.





n318.  Nico Savidge, Cottage Grove Man Arrested on Suspicion of Burning House
Intended for Sex Offender, Wis. St. J. (Feb. 26, 2015),
http://host.madison.com/news/local/crime_and_courts/cottage-grove-man-arrested-o
n-suspicion-of-burning-house-intended/article_083d6199-5d56-5147-8a5e-db19123cbc
ec.html.





n319.  See supra Part I.





n320.  Devah Pager, Marked: Race, Crime, and Finding Work in an Era of Mass
Incarceration 4 (2007).





n321.  See, e.g., Jeremy Travis, Invisible Punishment: An Instrument of Social
Exclusion, in Invisible Punishment: The Collateral Consequences of Mass
Imprisonment 16 (Marc Mauer & Meda Chesney-Lind eds., 2002) (explaining that
collateral consequence laws constitute "invisible punishment," because they
"operate largely beyond public view, yet have very serious, adverse consequences
for the individuals affected"); Nora V. Demleitner, Preventing Internal Exile:
The Need for Restrictions on Collateral Sentencing Consequences, 11 Stan. L. &
Pol'y Rev. 153, 155 (1999).





n322.  Christopher Gowen, Lisa Thurau & Meghan Wood, The ABA's Approach to
Juvenile Justice Reform: Education, Eviction, and Employment: The Collateral
Consequences of Juvenile Adjudication, 3 Duke F.L. & Soc. Change 187 (2011);
Eisha Jain, Arrests as Regulation, 67 Stan. L. Rev. 809 (2015).





n323.  Robert Brame et al., Demographic Patterns of Cumulative Arrest Prevalence
by Ages 18 and 23, 60 Crime & Delinq. 471, 472 (2014) ("There is substantial
research showing that arrested youth are not only more likely to experience
immediate negative consequences such as contact with the justice system, school
failure and dropout, and family difficulties, but these problems are likely to
reverberate long down the life course in terms of additional arrests, job
instability, lower wages, longer bouts with unemployment, more relationship
troubles, and long-term health problems including premature death.").





n324.  Nat'l Emp't Law Project, supra note 314, at 1.





n325.  While some states prohibit employers from asking job applicants to
disclose arrests, many do not. See Are Employers Permitted to Ask Applicants
About Arrests on Job Applications?, Nat'l Hire Network,
http://hirenetwork.org/content/are-employers-permitted-ask-applicants-about-arre
sts-job-applications (last visited Dec. 18, 2015) (identifying thirty-eight
states that allow employers to ask about arrests); see also U.S. Equal Emp't
Opportunity Comm'n, Policy Guidance on the Consideration of Arrest Records in
Employment Decisions Under Title VII of the Civil Rights Act of 1964, as
Amended, 42 U.S.C. §§2000e-2000E17 (1990),
http://www.eeoc.gov/policy/docs/arrest_records.html.





n326.  Mustaine et al., supra note 228, at 190.





n327.  Tewksbury, supra note 229, at 68; Tewksbury & Lees, supra note 229, at
331-32 (2006).





n328.  Smith v. Doe, 538 U.S. 84, 99 (2003) ("It must be acknowledged that
notice of a criminal conviction subjects the offender to public shame, the
humiliation increasing in proportion to the extent of the publicity. And the
geographic reach of the Internet is greater than anything that could have been
designed in colonial times."); Garfinkle, supra note 230, at 204.





n329.  Indeed, one study suggested that including juveniles in SORNA Tier 3
could actually create a greater risk to community safety. Caldwell et al., supra
note 216, at 106.





n330.  Pittman & Parker, supra note 221, at 52.





n331.  For the importance of the emergence into adulthood, see Jeffrey Jensen
Arnett, Emerging Adulthood: What Is it and What Is it Good For?, Child Dev.
Persps. 68 (2007).





n332.  Laurence Steinberg, Age of Opportunity: Lessons from the New Science of
Adolescence (2014).





n333.  See In re J.B., 107 A.3d 1, 14 (Pa. 2014) (finding lifetime registration
for juvenile sex offenders unconstitutional).





n334.  In re C.P., 967 N.E.2d 729, 741-42 (Ohio 2012).





n335.  Allen, supra note 52, at 1.





n336.  Id. at 196 (Accountability promotes order by enforcing norms, deterring
unwanted behavior through punishment or the threat of sanctions. It also
dignifies individuals by "presupposing intelligence, rationality, and
competence.").





n337.  Id. at 15 (describing "The New Accountability" for private life as "bold,
democratic, and super-powered by technology").





n338.  One main purpose of juvenile court is juvenile accountability.





n339.  Allen, supra note 52, at 4 (noting that "a society cannot afford to fully
leave people alone").





n340.  Id. at 29 (stating young people are "typically excused from the high
level of accountability imposed on adults"); Wallace, supra note 52, at 164-65.





n341.  Appell, supra note 9, at 736 ("Developmental facts do not dictate the
contours or boundaries of childhood. Ideology does."); Archard, supra note 10,
at 33.





n342.  Scott & Steinberg, supra note 29, at 109-12.





n343.  Sarah Burns, The Central Park Five: The Untold Story Behind One of New
York City's Most Infamous Crimes (2012).





n344.  House Bill 1501 and Senate Bill 254 were passed by the House and Senate,
respectively, in the wake of the Columbine shooting, and each sought to impose
enhanced sanctions for juveniles. See H.R. 1501, 106th Cong. § 2 (1999)
(lowering the minimum age for federal prosecution of certain crimes to 14); S.
254, 106th Cong. § 102 (1999). See Dave Cullen, Columbine (2009), for a
comprehensive and compelling account of the Columbine tragedy.





n345.  DeIulio, supra note 267, at 23; Alfred S. Regnery, Getting Away with
Murder: Why the Juvenile Justice System Needs an Overhaul, 34 Pol'y Rev. 65, 68
(1985) (contending that juvenile offenders "are criminals who happen to be
young, not children who happen to commit crimes" and that "there is no reason
that society should be more lenient with a 16-year-old first offender than a
30-year-old first offender.").





n346.  Dole Seeks to Get Tough on Young Criminals, L.A. Times, July 7, 1996
(quoting Bob Dole during his 1996 presidential campaign as saying "[a] violent
teenager who commits an adult crime should be treated as an adult in court and
should receive adult punishment"); Virginia Ellis, Lungren to Seek Lower Age for
Trial as Adult, L.A. Times, Jan. 15, 1993, at A3 (quoting California Attorney
General Dan Lungren: "If you commit an adult crime, you'd better be prepared to
do adult time.").





n347.  Maroney, supra note 15, at 189 (calling this period the "superpredator
era").





n348.  See Yarborough v. Alvarado, 541 U.S. 652, 668 (2004) (rejecting argument
that failure to consider juvenile's age in determining custody for Miranda
purposes clearly violated federal law); Stanford v. Kentucky, 492 U.S. 361, 380
(1989) (upholding death penalty for juveniles).





n349.  James A. Rapp, Ronald D. Stephens & Donna Clontz, The Need to Know:
Juvenile Record Sharing 4 (1989).





n350.  Franklin E. Zimring, Toward a Jurisprudence of Youth Violence, 24 Crime &
Just. 477, 483 (1998).





n351.  See James & James, supra note 10, at 179 ("When the idealized images of
childhood are shattered by the actions of children themselves, the protective
mantle of adult care that normally provides protection and nurture, as a
response to the special needs of children, is suddenly set aside.").





n352.  Zimring, supra note 350, at 483.





n353.  Allison James, Chris Jenks, & Alan Prout, Theorizing Childhood 13 (1998)
(tracing the roots of the archetype of the innocent child).





n354.  Scott & Steinberg, supra note 29, at 36.





n355.  Therefore, using innocence as the fulcrum for childhood ignores the
characteristics of adolescence and denies special protections to many youth.





n356.  Maroney, supra note 15, at 189.





n357.  See Scott, supra note 48, at 72 ("the Court has announced a broad
principle grounded in developmental knowledge that "children are different' from
adult offenders and that these differences are important to the law's response
to youthful criminal conduct"); see infra Part IV (explaining that the shift has
been driven in large part by empirical findings about juvenile development).





n358.  Juvenile Arrest Rate Trends, Office of Juvenile Justice & Delinq.
Prevention, U.S. Dep't of Justice,
http://www.ojjdp.gov/ojstatbb/crime/JAR_Display.asp?ID=qa05201 (last visited
Dec. 18, 2015) (briefing national violent crime rates amongst juveniles declined
substantially from the peak in 1994 to historic lows in 2012).





n359.  See Scott, supra note 48, at 72 ("the Court has announced a broad
principle grounded in developmental knowledge that "children are different' from
adult offenders and that these differences are important to the law's response
to youthful criminal conduct").





n360.  See, e.g., Roper v. Simmons, 543 U.S. 551 (2005).





n361.  Most of research discussed here goes to perceptions of Black youth. This
is, in large part, due to the peculiar legacy of slavery in the United States.
See Michelle Alexander, The New Jim Crow: Mass Incarceration in the Age of
Colorblindness (2010). Still, research is finding similar effects with regard to
Latino youth.





n362. " The stereotype of Black Americans as violent and criminal has been
documented by social psychologists for almost 60 years." Jennifer L. Eberhardt,
et al., Seeing Black: Race, Crime, And Visual Processing, 87 J. Personality &.
Soc. Psychol. 876, 876 (2004) (showing that the associations between blackness
and crime is bidirectional, from black to crime and crime to black); Dorothy E.
Roberts, Foreword, Race, Vagueness, and the Social Meaning of Order-Maintenance
Policing, 89 J. Crim. L. & Criminology 775 (1999).





n363.  See Feld, supra note 237 ("At every stage - arrest, intake, referral,
petition, detention, trial, and disposition - youths of color fare less well
than do their white counterparts ..."); Bishop & Leiber, supra note 237 .





n364.  Nat'l Council on Crime & Delinq., supra note 237, at 1-3.





n365.  See id.





n366.  Phillip Atiba Goff et al., The Essence of Innocence: Consequences of
Dehumanizing Black Children, 106 J. Personality & Soc. Psychol. 526 (2014).





n367.  Id. at 532.





n368.  Id. at 540. This correlates with similar research in the school context
which found that Black students were more likely to be suspended than Whites,
even for the same behavior. Kupchik, supra note 112; Nance, supra note 112.





n369.  Aneeta Rattan et al., Race and the Fragility of the Legal Distinction
between Juveniles and Adults, 7 PLoS ONE 1 (2012).





n370.  Id. at 2.





n371.  Id.





n372.  See Kupchik, supra note 112, at 97 ("Black youth are singled out for
punishment because they are perceived to be more threatening, more loud and
disruptive, their style of dress and manners of speaking viewed as "thug-like',
and they are seen as more disrespectful than others to teachers.") (collecting
citations); Ferguson, supra note 263.





n373.  Ferguson, supra note 263.





n374.  Id. at 80.





n375.  Id. at 89; Anne Gregory & Rhona S. Weinstein, The Discipline Gap and
African Americans: Defiance or Cooperation in the High School Classroom, 46 J.
Sch. Psychol. 455, 455 (2008) (arguing teachers perceived African American
students as more defiant, disrespectful, and rule-breaking than other groups).





n376.  Ferguson, supra note 263, at 83.





n377.  Id. at 90 (including carefully preserved data files as proof of
wrongdoing).





n378.  Rattan et al., supra note 369, at 4 ("Juvenile status may be more fragile
than previously considered.").





n379.  See supra Part III.





n380.  Maroney, supra note 15, at 211.





n381.  Edward R. Spalty, Juvenile Police Record-Keeping, 4 Colum. Hum. Rts. L.
Rev. 461, 461 n.6 (1972) ("It seems both fairer and easier to control access to
the youth's record by controlling the formation of the record.").





n382.  Coffee, supra note 62, at 612.





n383.  That is not to say that they do not look out for the welfare of young
people. They most certainly do. But their primary job is to detect and prevent
crime, and to catch offenders.





n384.  Anyone who has listened to the NPR podcast Serial will surely understand
how seemingly stray pieces of information (was there a phone booth in a Maryland
Best Buy parking lot in 1998?) can become key pieces of evidence in a criminal
matter. Serial, Chicago Pub. Media & Ira Glass, http://serialpodcast.org/ (last
visited Dec. 18, 2015).





n385.  See generally Ellen Nakashima, NSA Chief Defends Collecting Americans'
Data, Wash. Post (Sept. 25, 2013),
http://www.washingtonpost.com/world/national-security/nsa-chief-defends-collecti
ng-americans-data/2013/09/25/5db2583c-25f1-11e3-b75d-5b7f66349852_story.html
(describing the NSA's warrantless collection of domestic e-mails and phone call
content and the separate bulk metadata collection program exposed in 2013).





n386.  U.S. Const. amend. IV ("The right of the people to be secure in their
persons, houses, papers, and effects, against unreasonable searches and
seizures, shall not be violated, and no Warrants shall issue, but upon probable
cause, supported by Oath or affirmation, and particularly describing the place
to be searched, and the persons or things to be seized."); U.S. Const. amend. V
(No person "shall be compelled in any criminal case to be a witness against
himself.").





n387.  Alaska Stat. § 47.12.210 (2013); N.J. Stat. Ann. § 2A:4A-61 (West 2014)
(limiting juvenile fingerprinting to those age fourteen and above if charged,
unless a juvenile consents, is detained, or is adjudicated delinquent of an act
which, if committed by an adult, would constitute a crime); Ohio Rev. Code Ann.
§ 109.60 (West 2014) (mandating fingerprints from adults arrested for felonies
and certain misdemeanors but only mandating fingerprints from juveniles for
felonies or an offense of violence).





n388.  See Pittman & Nguyen, supra note 208 ("States that fail to comply with
the Federal SORNA in a timely manner will forfeit 10% of their Byrne Memorial
Justice Assistance Grant (JAG) Omnibus Crime federal funding."); Halbrook, supra
note 225, at 55 (those that are not compliant forgo federal funding); SORNA,
SMART, Office of Just. Programs, http://ojp.gov/smart/sorna.htm (last visited
Dec. 18, 2015) (states refusing to comply include Arizona, Arkansas, California,
Nebraska, and Texas).





n389.  Donna Lyons, Sex Offender Law: Down to the Wire, Nat'l Conf. of St.
Legislatures (June 2011),
http://www.ncsl.org/research/civil-and-criminal-justice/sex-offender-law-down-to
-the-wire.aspx; U.S. Gov't Accountability Office, Sex Offender Registration and
Notification Act: Jurisdictions Face Challenges to Implementing the Act, and
Stakeholders Report Positive and Negative Effects 10 (2013). In 2010, the
mandatory community notification requirements were also removed from the SORNA
Guidelines in response to juvenile advocates' arguments. Supplemental Guidelines
for Sex Offender Registration and Notification, 75 Fed. Reg. 27,362, 27,363 (May
14, 2010) (codified in scattered sections of 42 U.S.C.). The final guidelines
allow states to withhold information about juveniles from the public registry
and still be considered to be in substantial compliance. Supplemental Guidelines
for Sex Offender Registration and Notification, 76 Fed. Reg. 1630 (Jan. 11,
2011) (permitting states to withhold information including e-mail addresses and
other Internet identifiers); see 42 U.S.C. § 16915(a) (2008). States therefore
have the discretion to disseminate juveniles' information publicly, but are not
required to do so. Halbrook, supra note 225, at 24-25.





n390.  Letter from Risa S. Sugarman, Deputy Comm'r, Office of Sex Offender
Mgmt., to Linda Baldwin, Dir., SMART Office, Office of Justice Programs, U.S.
Dep't of Justice (Aug. 23, 2011).





n391.  Wash. Rev. Code Ann. § 9.94A.540 (West 2013).





n392.  In re J.B., 107 A.3d 1, 19 (Pa. 2014) (finding lifetime registration for
juvenile sex offenders unconstitutional); see also In re C.P., 967 N.E.2d 729,
746 (Ohio 2012); People v. Dipiazza, 778 N.W.2d 264, 274 (Mich. Ct. App. 2009)
(holding ten year juvenile sex offender registration requirement cruel and
unusual punishment as applied to a Romeo and Juliet case).





n393.  Eric Holder, Att'y Gen., Remarks at the Annual Meeting of the American
Bar Association's House of Delegates (Aug. 13, 2013).





n394.  Am. Acad. of Pediatrics, Out-of-School Suspension and Expulsion (2013);
Am. Psychol. Ass'n, Are Zero Tolerance Policies Effective in the Schools?: An
Evidentiary Review and Recommendations (2008).





n395.  Jacob Kang-Brown et al., A Generation Later: What We've Learned About
Zero Tolerance in Schools 6 (2013).





n396.  Complaint, United States v. City of Meridian, 4:12-CV168-HTW-LRA (S.D.
Miss. filed Oct. 24, 2012).





n397.  Proposed Settlement Agreement at 4, United States v. City of Meridian,
3:13-CV-978-HTW-LRA (S.D. Miss. filed June 19, 2015).





n398.  See Juan A. Lozano, Hundreds of DNA Matches as Houston Clears DNA
Backlog, Assoc. Press, Feb. 23, 2015.





n399.  Mulvey et al., supra note 58, at 475 (tracking over one thousand male
adolescent offenders over the course of three years and finding that only 8.7%
of participants were "persisters" in that their offending remained constant
throughout the thirty-six-month period); Piquero, Farrington & Blumstein, supra
note 35 (between five percent and ten percent of adolescent offenders become
adult career criminals); Steinberg & Scott, supra note 57, at 1015 ("The typical
delinquent youth does not grow up to become an adult criminal.").





n400.  Levick et al., supra note 59, at 297.





n401.  Coffee, supra note 62, at 617.





n402.  Inst. of Judicial Admin., supra note 281.





n403.  Id. at 35 (providing an exception "if the chief law enforcement officer
of the agency ... certifies in writing that certain information is needed for a
pending investigation involving the commission of a felony, that information,
and information identifying the juvenile, may be retained in an intelligence
file until the investigation is terminated or for one additional year, whichever
is sooner").





n404.  Id. at 152.





n405.  Id. at 150.





n406.  H.R. 1651, 63d Leg., Reg. Sess. (Wash. 2014).





n407.  Press Release, Columbia Legal Servs., Youth Opportunities Act Opens Doors
to Thousands of Young Adults Across Washington State (Apr. 4, 2014).





n408.  S. 2567, 113th Cong. (2014).





n409.  Comm. of Ministers, Council of Europe, Commentary to the European Rules
for Juvenile Offenders Subject to Sanctions or Measures (2008).





n410.  Moffitt, supra note 36, at 675 ("The rates for both the prevalence and
incidence of offending appear highest during adolescence; they peak sharply at
about age 17 and drop precipitously in young adulthood ... By the early 20s, the
number of active offenders decreases by over 50%, and by age 28, almost 85% of
former delinquents desist from offending.").





n411.  Alfred Blumstein & Kiminori Nakamura, Redemption in the Presence of
Widespread Criminal Background Checks, 47 Criminology 327 (2009).





n412.  Id.; see also Kevin Lapp, Reforming the Good Moral Character Requirement
for U.S. Citizenship, 87 Ind. L.J. 1571, 1627-28 (2012) (collecting studies).





n413.  But note the thorny Internet problem, where information, once it gets
there, stays even if official records are sealed or destroyed.





n414.  Juvenile Law Ctr., supra note 136.





n415.  N.Y. Fam. Law § 354.1(7) (McKinney 2014).





n416.  See Taylor-Thompson, supra note 75.





n417.  Jacobs, supra note 82, at 163.





n418.  Jacobs, supra note 2, at 307.





n419.  See supra Part III.A.3.





n420.  See supra Part III.A.3.





n421.  See, e.g., N.Y. State Office of the Att'y Gen., A Report on Arrests
Arising from the New York City Police Department's Stop-and-Frisk Practices 8
(Nov. 2013) (finding that close to half of all stop-and-frisk arrests from 2009
to 2012 did not result in conviction).





n422.  In re Winship, 397 U.S. 358, 363 (1970).





n423.  States have the discretion to disseminate juveniles' information
publicly, but are not required to do so. Halbrook, supra note 225, at 56. SORNA
guidelines allow states to withhold information about juveniles from the public
registry and still be considered to be in substantial compliance. Supplemental
Guidelines for Sex Offender Registration and Notification, 76 Fed. Reg. 1630
(Jan. 11, 2011) (permitting states to withhold information including e-mail
addresses and other Internet identifiers); see 42 U.S.C. § 16915(a) (2008).





n424.  Nat'l Emp't Law Project, Ban the Box: U.S. Cities, Counties, and States
Adopt Fair Hiring Policies to Reduce Unfair Barriers to Employment of People
with Criminal Records (2014).





n425.  Ctr. for Cmty. Alts., supra note 315.





n426.  Justice Policy Inst., Education Under Arrest: The Case Against Police in
Schools 29 (2011).


                               10 of 41 DOCUMENTS

              Copyright (c) 2016 University of Michigan Law School
                         Michigan Journal of Race & Law

                                   Fall, 2016

                         Michigan Journal of Race & Law

                           22 Mich. J. Race & L. 101

LENGTH: 16020 words

ARTICLE: TIGHTENING THE OODA LOOP: POLICE MILITARIZATION, RACE, AND ALGORITHMIC
SURVEILLANCE

NAME: Jeffrey L. Vagle*

BIO: * Lecturer in Law and Executive Director, Center for Technology, Innovation
and Competition, University of Pennsylvania Law School. Thank you to Paul
Bernal, Khiara Bridges, Claudia Diaz, Woody Hartzog, Christopher Hoofnagle,
Ahmed Ghappour, Dorothy Roberts, and Christopher Yoo for comments on earlier
drafts.

HIGHLIGHT:

   This Article examines how military automated surveillance and intelligence
systems and techniques, when used by civilian police departments to enhance
predictive policing programs, have reinforced racial bias in policing. I will
focus on two facets of this problem. First, I investigate the role played by
advanced military technologies and methods within civilian police departments.
These approaches have enabled a new focus on deterrence and crime prevention by
creating a system of structural surveillance where decision support relies
increasingly upon algorithms and automated data analysis tools and automates de
facto penalization and containment based on race. Second, I will explore these
militarized systems, and their effects, from an outside-in perspective, paying
particular attention to the racial, societal, economic, and geographic factors
that play into the public perception of these new policing regimes. I will
conclude by proposing potential solutions to this problem that incorporate tests
for racial bias to create an alternative system that follows a true community
policing model.



     [*101]

TEXT:
 [*102]

   INTRODUCTION

 As militaries transition from a war footing to a postwar posture, they
inevitably shed excess equipment and technology that is outdated, no longer
needed, or too expensive to maintain. In the drawdown from the wars in Iraq and
Afghanistan, the U.S. military found willing recipients of this material in
local and state police departments. In addition to these technology transfers,
local police departments have increasingly adopted military tactics, techniques,
and procedures (TTPs) - originally conceived and designed for military units in
combat operations - for use in their day-to-day policing. This combination has
led to the overall militarization of civilian police forces in the United
States, putting wartime tools in the hands of peace officers.

   This trend toward police militarization has found enthusiastic support from
departments adhering to the "broken windows" theory of policing, especially with
respect to technologies and TTPs meant for intelligence analysis or surveillance
purposes. The locus of this relationship can be found in the information-centric
approaches found in broken windows policing and other zero-tolerance,
quality-of-life police programs. Since military intelligence has long prized
information-centric methods as critical to the goal of actionable intelligence,
militarized systems and approaches appear to be a perfect fit to modern
policing. This phenomenon may be seen as the natural result of the industrial
and post-industrial society's desire to maximize control and efficiency - across
all spheres of life - through careful observation and data analysis. While
advances in policing techniques have garnered many societal benefits, they have
also established a system of structural surveillance that has entered a
renaissance with the help of military technologies. Automated surveillance
analysis systems, developed in the wake of 9/11, have given police departments a
powerful toolkit to advance algorithmic policing strategies.

   But these algorithmic approaches too often target poor and minority
communities, inserting a de facto racial component into the system, even when
the automated intelligence systems are fed "objective" crime data. For example,
in a recent investigation of software used by state and local criminal justice
authorities to predict the risk of recidivism of those booked into city and
county jails, researchers found that these algorithms were not only wildly
inaccurate in their assessments, but were also highly  [*103]  likely to falsely
flag Black defendants as future criminals. n1 Algorithmic "scoring" mechanisms
like this are becoming increasingly common tools for criminal courts and law
enforcement, which are seeking an information-based advantage in the control of
criminal activity. These programs have become so popular, in fact, that Congress
is considering mandating their use in federal prisons. n2

   This Article examines how military automated surveillance and intelligence
systems, when used by civilian police departments to enhance predictive policing
programs, have reinforced racial bias in policing. I will focus on two facets of
this problem. First, my research studies the role played by advanced military
technologies and methods within civilian police departments. These methods have
enabled a new focus on deterrence and crime prevention by creating a system of
structural surveillance where decision support relies increasingly upon
algorithms and automated data analysis tools, and which automates de facto
penalization and containment based on race. Second, I will explore these
systems, and their effects, from an outside-in perspective, paying particular
attention to racial, societal, economic, and geographic factors that play into
the public perception of these policing regimes. I will conclude by proposing
potential solutions to this problem that incorporate tests for racial bias to
create an alternative system that follows a true community policing model.

   I. The Militarization of Police Intelligence Operations

 The militarization of civilian law enforcement agencies (LEAs) has long been
viewed as anathema to the founding principles of the United States and corrosive
to civil liberties in a constitutional democracy generally. n3 Paradoxically,
contemporary American society has increasingly taken a distinctly militaristic
approach to solving its (non-military) political, social, and economic issues,
applying war metaphors to programs and policies to emphasize the seriousness of
the problem and the approach to it, for example, the "war on drugs" or the "war
on poverty." n4 These mixed signals have been the backdrop to a steady increase
in the militarization of U.S. civilian police forces post-World War II, with
racial tensions, "broken  [*104]  windows policing," the "war on drugs," and the
"global war on terror" acting as the primary catalysts of this phenomenon. n5
The most visible aspect of police militarization can be seen in the increased
deployment within LEAs of weapons, equipment, and training designed for use in
combat by militaries. n6 While these manifestations might be the most outwardly
obvious signs of this militarization trend, there is a more basic facet of it
that LEAs have almost universally adopted: intelligence operations. n7

   A. Military Intelligence and the Development of the OODA Loop

 The importance of intelligence operations to the military is a long accepted
principle, since as often quite large and widely distributed organizations,
militaries are expected to think and act as if they were a unitary being. n8 The
pace, environment, and sheer horror of combat combine to create a state of near
chaos - "the realm of uncertainty" - through which militaries are forced to
navigate. n9 To mitigate at least some of the disorienting effects of warfare,
modern militaries must organize themselves around rational, bureaucratic
principles, with robust networks of communication and information management at
their core. n10 Military command structures simply cannot function without the
timely communication of information on a wide range of broad and narrow topics
including terrain, troop strength and movements, civilian considerations,
transportation networks, availability of supplies, enemy disposition and morale,
weather and light conditions, and more - all in support of the theory that the
better prepared and informed army has the advantage. n11 This general concept is
[*105]  often referred to as military intelligence, or more succinctly,
"intelligence." n12

   The term intelligence is not well defined, however, as it draws from a wide
array of broader issues, such as strategy, command and control, and
communications. n13 It is clearly more than an exhaustive cataloging of all
available information. Even if this were possible, such a tool would quickly
prove useless to militaries as their organizations became mired in irrelevant
information, and would be forced to spend valuable time and resources ferreting
out the useful bits. n14 Intelligence, therefore, must produce information in a
form and quantity that can be used by the organization to make timely decisions
regarding plans and operations. This characteristic is often summarized as
"actionable" intelligence. n15 The goal of perfectly actionable intelligence is
often unattainable, however, and is best thought of in aspirational terms. n16

   The industrialization of the 18th, 19th, and 20th centuries yielded
paradigmatic advances in the technology and, subsequently, the conduct of
warfare, which in turn brought with it the critical need for more rapidly-made
decisions based on fresher, more accurate, and more detailed intelligence. n17
The United States military experience in Vietnam illustrated just how crucial
intelligence and communications had become in modern warfare,  [*106]  where
larger, better-equipped forces were often outmatched by much smaller, yet better
informed, groups of guerrillas and regular army soldiers. n18 The post-Vietnam
collapse of the U.S. military sent shock waves through the Pentagon, whose
leadership began the arduous process of rebuilding a communications and
intelligence centric army capable of fighting a fourth generation war. n19

   During this period of U.S. military restructuring, a U.S. Air Force combat
flight instructor named John Boyd, long known by military strategists for his
highly analytical approach to solving military problems, began development of a
general theory of military organizational analysis and action. He sought to
address the challenge of intelligence and communication in a fast-moving
conflict. n20 As a veteran of air combat flying the F-86 Sabre in "MiG Alley"
during the Korean War, Boyd knew well the challenge for fighter pilots of
gathering, processing, and acting on information in a very short amount of time,
all while flying an aircraft filled with jet fuel and munitions at hundreds of
miles per hour, often while being shot at. n21 Boyd, a student not only of the
great modern military theorists such as Clausewitz and J.F.C. Fuller, but also
of philosophers, mathematicians, and physicists, including Kurt Godel and Werner
Heisenberg, actively sought out symmetries and commonalities in his analyses in
an attempt to get at the true root of the problem at hand. n22 His
multidisciplinary approach allowed him to extrapolate common principles from his
experiences, and in 1976, he authored the first of five essays on the cognitive,
[*107]  psychological, and temporal processes core to all military intelligence
analysis and decision-making processes, from the highest command levels to the
lowest. n23

   Boyd's described his groundbreaking theory as a cognitive cycle containing
four tasks: Observation, Orientation, Decision, and Action (OODA) (see Figure
1). n24 These actions worked together to create a feedback loop that gave those
who were more adept at accelerating this loop a tactical advantage over their
less-nimble adversaries. As applied to Boyd's initial use of the term in
aviation combat, a pilot first considers the relevant information available
about the situation ("observation"), such as an adversary's weaponry, their
level of training, and the environmental conditions. The pilot uses these
observations to narrow the possible universe of decisions ("orientation") in the
tactical situation. Based on these first two steps, the pilot selects the best
solution to their tactical problem ("decision") and makes the necessary
adjustments to realize their decision ("action").

    Figure 1: The OODA Loop


 Through informed use of the Boyd Cycle - more often referred to as the OODA
loop - one could not only gain a strategic or tactical advantage over one's
enemy, but in turn, disrupt the enemy's own OODA loop by denying them the
ability to run through its stages due to the speed at  [*108]  which you are
able to run through your own. n25 The goal for any military organization,
according to Boyd, is to increase the speed at which it can navigate this cycle,
or to "tighten" the OODA loop. n26 Therefore, the army that can affect the
tightest OODA loop is able to "get inside" their opponent's cycle, and thus
disrupt their ability to gather, process, and act on intelligence. n27

   The OODA loop, as Boyd observed, characterized the process all living things
go through as part of their everyday survival. n28 Learning and adapting are
what successful individuals and groups accomplish faster than their less lucky
competitors. Boyd's great contribution was distilling this naturally occurring
process into a form, which could be analyzed and implemented by military
strategists and tacticians. Boyd continued to develop this concept through the
mid-1980s and continued to present his theories to large military and civilian
audiences well into his retirement. n29 Boyd's theories enjoyed moderate success
among contemporary military leadership at the time, mainly among theorists and
scholars. But in the early 2000s, his ideas were rediscovered and found a
heightened relevance among a new generation of warriors joining a high-tech
military in a post-9/11 world. n30 This renewed popularity soared even further
when nonmilitary and quasi-military organizations seeking a competitive
advantage over crime through information-centric efficiency - universally
accepted as the path to success since the earliest days of industrialization -
increasingly turned to military organizational theories and doctrines for
inspiration. n31

[*109]

   B. The Audit Society and the Allure of Information Management

 While Boyd's OODA loop theories were revolutionary in their military context,
their foundations began to form nearly two centuries earlier with the emergence
of industrialization and the associated growth of information-centric
organizational theory. n32 The rise of bureaucracy as an efficient means of
organizing at scales unnecessary in agrarian society brought with it a strong
inclination toward surveillance, information processing, and data-based planning
as a means of constant management and improvement, a school of thought both
inspired and followed by military organizational theory. n33 Weber's theory of
legitimate order and authority within a bureaucratic structure, with its "duties
without regard to personal considerations," and an "obligation to obedience,"
provided the sort of military-based organizational socialization needed - albeit
with some allowance of modification for less martial pursuits - for the
management of such modern concepts as large-scale factories, prisons, hospitals,
and law enforcement. n34

   Militaries of the 18th and 19th centuries were quick to adopt these
organizational innovations, which fit well with their existing hierarchical
frameworks and provided the tools to realize a modern form of military
intelligence and personnel management, which contemporary organizational models
would not support. n35 All of these advances were necessary to support and
maintain large armies, but military intelligence was perhaps the biggest
beneficiary of these innovations. The increasing amounts of information
necessary to make military - or, in fact, any state - decisions in a rapidly
modernizing world highlighted the importance of bureaucracy  [*110]  as an
essential tool in dealing with the modern crisis of control. n36 But even with
the benefit of a modern bureaucracy, some of which already existed within
military organizations, an army's ability to process intelligence information
had been quite limited by existing technologies. n37 This limitation of a
military organization's ability to make informed decisions based on "coded"
intelligence information was directly dependent upon its ability to communicate,
store, and process that information, described in Weber's concept of
rationalization. n38 The promise of increasingly detailed intelligence pictures
- improved "situational awareness" - generated by a combination of the improved
organizational methods of Weberian bureaucracy and the advances in
communication, transportation, and information processing technologies of
industrialization, began to move military thinking toward an information-centric
style of warfare. n39

   This quest for more information, better data processing tools, and improved
communication methods has become paradigmatic of modern (and post-modern)
society. n40 This "control revolution," as Beniger puts it, has grown to
permeate every area of society where efficiency is sought, bringing with it a
need to develop metrics for program effectiveness. n41  [*111]  The concept of
civilian police agencies is driven primarily by as the realization of a
society's social control function, and as such, makes them prime candidates for
the information-centric style of organization and leadership. n42

   The quasi-military structure most police departments now adhere to can be
found in the organization of Sir Robert Peel's London Metropolitan Police in
1829, credited as the first modern civilian law enforcement organization. n43
The rapid industrialization of Europe and the United States in the first half of
the 19th century brought with it a sudden increase in the population, much of it
concentrated in urban areas. n44 This caused no small amount of concern among
the upper classes, who feared disease, petty crime, property damage, and
political insurrections, just to name a few of the phobias the ruling elite held
regarding the "dangerous classes." n45 Peel, as Chief Secretary for Ireland,
introduced legislation creating paramilitary forces to suppress Catholic and
nationalist "disturbances." Peel applied the methods he had refined in Ireland
to London and continued the use of the military organization as a model for
civilian law enforcement. n46 In addition, Peel recognized that former members
of the military made excellent candidates for the role of civilian police
officer, since they would arrive on the job pre-acclimated to a quasi-military
environment, and would have an instinctive preference for hierarchy, discipline,
and order. n47

    [*112]  These somewhat practical decisions cannot, however, be separated
entirely from the growth of information-centric organization theory, political
economics, and surveillance technologies which were interlaced with much of the
social, political, and economic activity of industrialization and modernity. In
the period from the mid-18th through the mid-19th centuries, as
industrialization in western nations began to create increasingly complex
systems of interdependencies between manufacturing, capital, energy production,
labor, and markets, new means of communication and control were required to take
full advantage of new economies of scale and realize productivity levels unheard
of under earlier forms of management and organization. n48 As Giddens points
out, advances in the information management enabled organizations to form more
effective bureaucratic structures and gave these budding bureaucracies more
control over the "timing and spacing" of human activities. n49 These advances,
joined with the modern bureaucracy's growing appetite for information ultimately
led to the surveillant assemblage as integrated into our contemporary concept of
governance. n50

   In the mid-1990s, a movement among military theorists began to develop around
the concept of exploiting a technological and communications advantage to create
a new kind of army, where every soldier and piece of material was equipped with
sensors that would allow direct communication  [*113]  of information at the
lowest organizational levels, but would also pass this information up the chain
of command to give military leaders a "God's eye view" of the battle space,
allowing for even tighter OODA loops. n51 This concept, generally known as
network-centric warfare, envisioned the sort of information-driven military
hitherto impossible, now enabled by smaller, faster, and cheaper technology that
was starting to drive American businesses, and especially advances in networking
and communications. n52 Military strategists picked up on the new style of
"bottom-up" management enabled through these technological advances, where
information, gathered from the very edges of an organization and passed to
leadership in near real time, could allow leaders of even the largest businesses
to view, analyze, and make decisions about detailed data - actionable
intelligence - that Weber, Bentham, Mill, and their contemporaries could only
dream of. n53 Following this model, an information-and network-centric military
could be more agile and aware than its adversaries, thus allowing fewer troops
to cover much wider geographic areas, with less equipment, and with dynamic,
ad-hoc supply chains that could place material in the right place at the right
time, a philosophy at the center of Secretary of Defense Donald Rumsfeld's
wholesale "Force Transformation" program of the early-and mid-2000s. n54

   The Bush administration's focus on transforming the military through a
network-centric shift from platforms to networks, while viewed  [*114]  with
skepticism by rank-and-file troops, was enthusiastically accepted by the U.S.
military's civilian and political leadership, and opened up a wide array of new
business opportunities for contractors willing to help implement this vision.
n55 Many of these new programs concentrated on the Command, Control,
Communications, Computers, Intelligence, Surveillance, and Reconnaissance
(C4ISR) space, where the true power of distributed information superiority could
be fully realized. n56 Key programs quickly emerged to build survivable, robust
communications and sensor networks, information operations (IO) platforms,
geospatial analysis tools, computer-assisted targeting platforms, and unmanned
intelligence gathering platforms (colloquially known as drones, and later
equipped with weapons systems of their own), all of which were designed to
support an agile force far superior to the "muscle-bound and clumsy,"
"industrial-age dinosaurs" that were the legacy of outmoded Cold War thinking.
n57

   As the U.S. military began to withdraw from their engagements in Afghanistan
and Iraq, funding streams for contractors who had tooled up in support for
network-centric warfare and force transformation also began to evaporate, and
businesses looking for alternative markets for their C4ISR platforms found a
ready partner in civilian LEAs. n58 Like the military  [*115]  of the mid-1990s,
police departments had also discovered the promise of network-centricity, a
concept that fit well within the quasi-military organizational structures found
in most police organizations. n59 Beginning in the mid-1970s, police
departments, especially those in larger U.S. cities, began to feel political
pressure to address what was widely seen as a crime epidemic and the "downward
spiral of urban decay" that accompanied a post-industrial economic slowdown. n60
The standard tactics built around the police patrol car did not seem to be
having any real success in reducing the crime rate, and LEAs were looking for
alternatives. n61

   In 1982, The Atlantic Monthly published an article written by two social
scientists who, after studying the tactics of police departments, concluded that
disorder and crime are inextricably linked, and, therefore by addressing the
petty crimes associated with community disorder - such as loitering, vandalism,
and public intoxication, "humble" crimes that were generally considered unworthy
of police attention - LEAs will, in turn, prevent the more serious crimes from
flourishing in those areas. n62 The approach became known as "broken windows
policing," named for the tendency for buildings with a broken window to
encourage further window breaking and other forms of vandalism, a phenomenon
described by Stanford psychologist Philip Zimbardo in his well-known abandoned
car experiment. n63

   Police departments in large American cities began to take an active interest
in the broken windows theory, and by the late 1980s and early 1990s, police
departments in New York City, Chicago, and Los Angeles had all implemented some
version of this model. n64 In New York, then-mayor Rudy Giuliani introduced a
version of broken windows known as "zero-tolerance" policing, which placed a
greater emphasis on the "quality  [*116]  of life" issues that Wilson and
Kelling pointed out in their original work. n65 As an early adopter of the
broken windows model, the New York Police Department (NYPD) quickly discovered
that any effective implementation of such a program would require curbing
disorder not only on the streets, but also within the police department itself,
which had been in a decades-long decline of poor leadership, corruption, and an
overall breakdown of discipline. n66 Addressing these (not unrelated) problems
in a city the size of New York, with a sworn police force numbering in the tens
of thousands, would require an approach that could go beyond classical
organizational techniques. n67 The data-and network-centric approaches made
possible by the rapid technological advances beginning in the late 1980s and
early 1990s, and implemented as a successful proof-of-concept by Wal-Mart during
this time, began to instill in the NYPD other police departments a growing faith
in algorithms and automated decision tools. n68

   C. Drugs, Terrorism, and the Blurring of Military and Civilian Spheres

 The confluence of military and police use of data-and network-centric
approaches in their hitherto separate spheres can be traced in its earliest
forms to the war on drugs. n69 As drug trafficking began to be seen not only as
a law enforcement issue, but also a threat to national security, military and
police agencies began to engage as partners in this effort, sometimes through
the exchange of ideas, sometimes quite literally, through interagency actions.
n70 These activities were complicated by the  [*117]  fact that the 1878 Posse
Comitatus Act generally prohibited the use of federal military forces for
domestic law enforcement purposes. n71 Congress amended the Posse Comitatus Act
in 1981 to address this legal obstacle, which allowed for military support of
civilian LEAs, with the clear legislative intent that this military-law
enforcement cooperation be employed in counterdrug operations. n72

   Both the concept and the realization of the war on drugs have a rather spotty
record. n73 The political rhetoric that tends to accompany calls for such a war
creates images of a "dangerous other," who threatens social stability due to lax
morals and inherent inabilities to exercise self-control. n74 Efforts within the
war on drugs are therefore designed to "target" such "deviant" groups within
society, and by doing so, promise to reestablish the societal values held by the
upstanding citizens the laws are there to protect. n75 These words describing
the dangerous other are carefully selected to mask their veiled intent: to play
on white fears of racial minorities. n76 The disproportionate effects of this
war on African-Americans and Hispanics have been well-documented, resulting in
broken social structures, overcrowded prisons, and a retrenchment of Jim Crow
policies (albeit under different names). n77

   A vivid example of the literal law enforcement-military partnership in the
drug war can be found in the 1988 formation of Joint Task Force-6, now known as
Joint Task Force-South (JTF-South), which combined combat and reconnaissance
forces from the Department of Defense (DoD), intelligence services, and civilian
LEAs to patrol sections of the U.S.-Mexican border on drug interdiction
missions. n78 The regular armed border patrols  [*118]  by military personnel
abruptly stopped in 1997, after a young U.S. Marine shot and killed an unarmed
civilian. n79 The American public's appetite for the use of military troops
within its borders evaporated after this incident, only to be revived on
September 11, 2001. n80

   The terrorist attacks of 9/11 opened the floodgates on law
enforcement-military cooperation, with many of the political and legal
objections to such partnerships disappearing almost overnight. This sudden
paradigm shift, brought on by a level of terroristic violence previously
unthinkable in the United States, created an environment within which the
traditionally separate spheres of military and civilian law enforcement began to
significantly blur. n81 The military contractors, large and small, that tooled
up to support the war effort - both the literal combat operations in Afghanistan
and Iraq, as well as the larger, more metaphorical sense - began making much of
this material available to civilian LEAs, including machine guns, semi-automatic
shotguns, night vision equipment, sniper rifles, combat uniforms, grenades, and
high-tech surveillance gear. n82 Many civilian police departments were
especially appreciative of the expansion of two DoD programs designed to equip
LEAs with military gear through the transfer or direct purchase of material. n83
Because of the highly visible nature of military equipment such as armored
personnel carriers, flash-bang grenades, and sniper rifles, much of the
subsequent attention from those examining  [*119]  the increased militarization
of civilian police forces has been focused on these items. n84 But the use of
this sort of military gear by civilian law enforcement is largely limited to
special police units and is not typically found on the average patrol officer.
n85 It is the widespread and increased adoption by civilian police agencies of
military intelligence technologies, many of which are integrated invisibly into
existing police information and decision support tools, which likely has a more
dramatic impact across entire police departments. This invisibility, coupled
with an unproven - or misplaced - faith in these technologies, has led to a
growing system of structural surveillance that has had a disparate racial impact
in many cases.

   II. The Expansion of Algorithmic Policing Strategies

   A. Early Data-Centric Efforts: Compstat and Its Kin

 When then-mayor Rudy Giuliani first began implementing New York City's version
of broken windows policing in the early 1990s, he recognized that the disorder
to be addressed could be found not only on the city's streets while also within
the ranks of the NYPD. n86 Significantly changing the direction of an
organization the size of the NYPD - as a shift to the broken windows policing
model surely required - would be a difficult task in even the most functional of
police departments, something New York City had not had for decades. n87 The
organizational management tools necessary for such an endeavor simply did not
exist until advances in information technology opened up the possibility of
automated, data-and network-centric decision support systems that could take
vast amounts of raw data as input, analyze those data, and provide critical
insights to its human users, all within the relative blink of an eye. n88 It was
[*120]  exactly this sort of system that a few forward thinkers within the NYPD
proposed as a solution to their burgeoning organizational management problem.

   In 1994, NYPD Commissioner William Bratton revealed the Compstat program as a
centralized solution to the department's organizational dilemma. n89 The goal of
the program was to obtain accurate, up-to-date crime statistics at every level
within the department, something that had proven impossible up to that point.
n90 By requiring patrol officers to keep records of their daily activities,
including stops, arrests, and the details of each incident, the NYPD could
collect these data on a computer database, which allowed them to generate weekly
books of city-wide statistics they could slice and dice as they saw fit: if they
wanted statistics on gun crimes specifically, or wished to compare precinct
activity, they could do so with relative ease. n91 With these data and analysis
tools, the NYPD could now begin to efficiently address the city's broken windows
trouble spots, and do so by directing the minimum amount of manpower to the
right place at the right time - exactly the outcome Giuliani and Bratton sought.
n92

   The NYPD began to see a significant amount of success with the Compstat
system, both with their ability to address the "quality of life crimes"
highlighted by broken windows policing, as well as in their ability to
effectively manage a large and growing police force. n93 This successful
adoption gave Compstat a fair amount of national publicity, and it was touted,
alongside broken windows policing, as the new paradigm of crime prevention in
the United States. n94 Soon, other cities began to emulate and adapt Compstat
systems within their own police departments. n95

    [*121]  With the early success of Compstat also came a redoubled faith in
the possibilities of automated law enforcement intelligence systems, allowing
police departments to do more with less. n96 As police departments became
increasingly convinced that the broken windows model of policing, with its
dynamic, problem-oriented approach, would replace the old, static bureaucratic
model that police agencies had relied on for generations, they began to accept
and explore more deeply the managerial tools and techniques offered by
algorithmic, data-driven systems. n97 This new thinking sparked a flurry of
data-and network-centric experiments in LEAs around the world, and revived a
global interest in an intelligence-based model of policing that had been
deployed by British police departments since the 1980s. n98

   B. The Rise of Intelligence-Led Policing

 The British model of "intelligence-led policing" was developed in part as a
response to the privatization initiatives in the UK in the 1980s and 1990s,
where portions of government services were either taken over by private
companies or adopted a private business model within their organizations,
effectively becoming quasi-private agencies. n99 The British National Criminal
Intelligence Service (NCIS), originally organized to address drug trafficking,
and later expanded to include organized crime generally, adopted a business data
processing model to develop the National Intelligence Model (NIM), a nationwide
system for use by all police agencies across the UK, replacing their existing
bureaucratic management processes with an intelligence-led policing model. n100
This model had been developed by British authorities to mimic the traditional
military intelligence model, where data are collected and analyzed in order to
identify patterns and generate actionable intelligence to best prioritize the
deployment of patrols based on a set of problem-oriented goals. n101

    [*122]  It is not difficult to see the allure of such a system. The
combination of tightening budgets, increased public concern over crime and
disorder, and a rising perception that the world had become a more dangerous
place (due in large part to drug trafficking, terrorism, and a general breakdown
of civil order) created an environment that made automated solutions to these
problems all the more credible. Rapid advances in technology and research into
data mining and automated, intelligent decision support systems began to instill
in police departments a newfound enthusiasm for technology not generally seen
since the days of Sputnik and the space race. Researchers began looking for
existing mathematical and physical models, which could provide even faster and
more accurate intelligence. n102 By the late 1990s, police departments began to
consider the possibility that intelligence-led policing, coupled with advanced
technologies and analytical tools, could move LEAs beyond mere crime fighting
and into the realm of crime prevention. n103

   C. The Tantalizing Prospect of Predictive Policing

 Organizations seeking to tighten their respective OODA loops have followed
Boyd's logic to an inevitable conclusion: Instead of merely seeking further
methods to tighten the OODA loop, they find ways to tighten the loop to a point
where it has "inverted into itself" - that is, the decision cycle becomes
predictive, rather than reactive. n104 The possibility of preventing  [*123]
crime before it actually happens has been the Holy Grail of police departments,
especially when local, state, and federal governments were actively looking for
ways to cut back on police budgets. n105 The apparent successes of broken
windows and zero tolerance policing backed by sophisticated decision support
systems like Compstat and intelligence-led policing, gave many in law
enforcement the firm belief that these systems and methodologies would
eventually yield tools that would collect the massive amounts of data now
available from inside and outside of police departments, swiftly store and
analyze those data, and produce results "to anticipate, prevent and respond more
effectively to future crime." n106

   A common trope among police department is that an experienced and talented
officer can apply their knowledge and analytical skills to attain an imperfect
version of predictive policing, but that the model does not scale well. n107 The
benefit these new analytical tools and methods could bring to these officers
could mean the difference between investigating a crime that just occurred
versus preventing the crime from happening in the first place. n108 The savings
to society in administrative costs, property damage, and human lives alone make
this a worthy goal for a data-and network-centric police force.

   But for such a police intelligence system to work as advertised, one needs to
provide it with as much good data as possible from as broad a sampling as
possible so that the pattern recognition models can achieve the nearest thing to
a God's eye view, thus allowing the analyst to find the proverbial needle in the
haystack. n109 This means police agencies need to turn to nontraditional sources
of information, such as social media, as well as developing and refining
internal data sources. n110 The risks inherent in such an approach - especially
if implementation or strategy is rushed or otherwise undertaken without a full
understanding of the implications - can include not only the more obvious issues
of privacy and fairness, but also technical liabilities attributable to cyber
security and the long-term effects on due process, all of which present serious
ethical questions and responsibilities. n111

[*124]

   III. The Enhancement of Structural Surveillance
 and De Facto Race Bias

   A. Criticisms of the Broken Windows Policing Model

 The broken windows policing model, along with the collection of technologies
and techniques supporting this approach, have met with a growing body of
criticisms, even as police departments continue to adopt and promote these
methods. n112 Central to many of these criticisms is the core role that
"disorder" plays in the broken windows model, specifically, the subjective
definition and measurement of the term, as well as the limited beneficiaries of
this approach. n113 These criticisms have seriously questioned the premise of
broken windows, citing statistics that indicate that the broken windows model
has a measurable, direct negative effect on the very neighborhoods and
communities whose "hot spots" were supposedly the beneficiaries of increased
police focus. n114

   Among the sharpest critiques of the broken windows policing model is that,
whatever the original intent was of such programs, their implementations have
been less about policing disorder than about the control of poor neighborhoods
and poor people, most of whom are racial minorities. n115 The longstanding
practice within the American legal system of using  [*125]  race as a signal of
increased risk of criminal behavior combined with programs encouraging police
officers to gather "intelligence" data through arbitrary stop and frisk programs
(sometimes referred to as "enhanced Terry stops") to feed into automated
intelligence systems, has created an environment where racial minorities end up
bearing the costs of broken windows, while wealthy, White communities tend to
see the majority of its benefits. n116 The social disorder that broken windows
policing targets has been shown to be a very fluid concept, where the
perceptions of a minority neighborhood's residents are often far different than
those of the police officers patrolling those neighborhoods, who frequently come
from other, wealthier neighborhoods. n117

   The result of the intelligence data collected based on race or class bias, or
parochial perceptions of social disorder, creates an inherent bias in automated
decision support systems that tends to be reinforced with every trip around the
OODA loop. n118 This result can be directly traced to the sort of feedback loops
data-centric decision support systems like Compstat are prone to encounter. n119
That is, if the data used to initiate an automated decision support tool is
biased or otherwise flawed, the "actionable intelligence" that emerges will
likely also be biased or flawed. If this bad intelligence is then acted upon,
the resulting stops or arrests will likely generate even more bad data, which is
then fed back into the decision support system, and so on. n120

[*126]

   B. Algorithms, Data, Neutrality, and Bias

 What makes automated, predictive policing systems an attractive as a solution
for LEAs seeking to increase efficiency is the same aspect that makes them
potentially dangerous: We tend to implicitly trust algorithms and data since we
assume that computers have no bias, and numbers do not lie. n121 This common
misconception is based on two fundamental misunderstandings of automated
decision support or expert systems. First, while it is true that computers, as
finite state machines that at their core (no pun intended) are strictly limited
to the instructions we give them through their programming, it does not follow
that the algorithms we run on these computers are necessarily unbiased. Computer
programs - algorithms coded by humans into a form a computer's chipset can
interpret - are written with the objectives, design choices, and general
experiences of the programmer as background. The series of instructions, data
structures, and design choices that end up in a finished computer program can
often translate subtle biases, often in unexpected ways. n122

   For example, from an algorithmic modeling perspective, incorrect or
imbalanced input data has long been shown to lead to biased results. n123
Perhaps the most commonly used statistical method in predictive modeling systems
is linear regression, n124 particularly a maximum likelihood linear  [*127]
regression, which is a widely used technique in military and police predictive
intelligence systems. n125 In systems such as these, the data used often contain
a large number of events belonging to one class, while the other class contains
only a few data points, a data disparity known as a class imbalance. n126 This
phenomenon often occurs in data where the event of interest (the crime) is
sampled far more frequently than non-events. n127 This problem also manifests
itself in the differences in class data representations between the sample set
and the actual population, known as sampling bias. n128 There are, of course,
statistical sampling methods to mitigate these effects, but there is no clear
consensus as to which method of class distribution sampling will work best in
all - or even most - situations. n129 The best solutions tend to be those that
are specially selected based on such factors as the statistical methods
employed, the population size, the sample size, and specifics regarding the
event in question. n130 In plain language, this means that a one-size-fits-all
solution is likely to produce questionable results, at best, and at worst,
dangerously biased results. This danger becomes  [*128]  increasingly amplified
when one examines the trend of police analysis being extended from the realm of
geospatial analysis - predicting which neighborhoods are most likely to be crime
hot spots - to the individual, where police keep close tabs on people who,
according to predictive algorithms, are more likely to be involved in future
crimes. n131

   C. The Introduction of Automation Bias

 The rise of the information and audit society and the associated increase in
the use of automated information systems in organizational decision making often
leads to an overreliance on - and overconfidence in - the results of these
systems. This automation bias leads to misuse of automated intelligence systems
combined with automation-induced user complacency. n132 The negative effects of
this automation bias have been seen in healthcare, transportation, power
distribution, defense, and space exploration, often with serious,
life-threatening consequences. n133 There are multiple reasons for this
behavior, including our natural tendencies to seek out paths of least cognitive
effort, to expend less energy when part of a team (including teams with
automated members), and to treat computers as decision-making authorities. n134
These errors have been further categorized into two classes that manifest in
automated environments: omission errors, where operators fail to respond to
system anomalies because the automated system fails to detect or warn of them;
and commission errors, where users  [*129]  blindly follow incorrect guidance
from automated systems in spite of contraindications from other information
sources. n135 Studies have repeatedly shown that automation bias of both types
leads to users making incorrect decisions at a rate as high as 75%, even when
the information they needed to make the correct decision was readily available.
n136

   Automation bias becomes especially dangerous when life or liberty is at
stake. Multiple studies in domains such as health care, air transportation, and
military command and control have repeatedly shown how bias and complacency lead
users of automated systems to make very costly mistakes. n137 In military
environments especially, overconfidence in the authority of automated decision
support systems can be particularly catastrophic, where the importance of
situational awareness is paramount. n138 The average person is well equipped to
engage in naturalistic decision-making processes, where one is expected to solve
real-world problems under a certain amount of stress. n139 We are, however,
prone to overreliance on sources of information that we regard as authoritative.
n140 Military intelligent decision support systems operate within organizational
hierarchies wherein users are predisposed, through their training, to defer to
authorities within their supervisory structure, a trait that remains in effect
when users of these systems seek guidance from algorithms and data structures.
n141 The natural result is an amplification of automation bias in these overtly
hierarchical environments, where users exhibit tendencies to rely exclusively on
automated systems, even when conflicting information  [*130]  is presented by
other available systems. n142 The transfer of military intelligent decision
support systems to civilian law enforcement organizations, where the
paramilitary organizational structure closely resembles that of the military,
makes police susceptible to the same dangerous automation bias exhibited in
military environments. So how do law enforcement organizations take advantage of
continued advances in automated intelligence and decision support techniques
without either further alienating the communities they serve or succumbing to
various data-and algorithm-based biases?

   IV. A Community Policing Solution to Algorithmic Race Bias

 Of course, to completely ignore the opportunities presented by advances in
automation makes no sense. There are many tasks that computers simply do better
than humans, such as repetitive tasks, rapid response to control tasks,
rule-based deductive reasoning, and simultaneous task handling. n143 As our
systems - both human and computer - grow increasingly complex, we need
automation to give us the enhanced capabilities to handle time-critical and
complex control environments. The trick, then, is to recognize the critical role
automated information systems play in these domains, but at the same time,
maintain an informed awareness of the pitfalls an overreliance on automated
decision support can bring. This is of great importance to LEAs, who have a
special duty to their communities, not only to enforce the laws but also to
protect and maintain the health and safety of everyone in those communities.
Allocating the appropriate amount of functionality between police officers and
automated systems is critical to this role. In this Section, I recommend a
two-element approach to this problem that takes into account both the important
social role police play within their communities as well as the phenomenon of
automation and data bias that can artificially reinforce racial disparities in
police treatment.

   A. A Return to the Original Intent of Community Policing

 A significant part of the original broken windows policing concept articulated
by Wilson and Kelling was the role of the police officer in reassuring community
members of their safety, and maintaining a high degree of sensitivity to
signaling by community residents, with respect not only to criminal activity,
but also with their comfort with the police agency itself. n144  [*131]
Community policing requires a more holistic approach to the problem of public
safety that goes beyond mere crime fighting to encompass overall community
health, safety, and quality of life. n145 Under this model, crime fighting was
not an end in itself, but the means toward healthier communities, and was seen
as a more modern, inclusive method of policing. n146

   Too many implementations of broken windows and intelligence-led policing
models, however, failed to follow through on this part of the theory. Rather
than measure their performance - and direct their activities - using data that
reflected a community's overall health and quality of life, systems like
Compstat relied heavily, sometimes exclusively, on traditional crime statistics,
such as the number of stops, arrests, and clearance rates, despite the fact that
these metrics have repeatedly been shown to have little to no bearing on overall
community safety. n147 Sadly, this flawed approach to the original
community-policing concept originates in the fact that these crime statistics
are easy to collect and measure, and police departments have developed a high
degree of comfort with these metrics over the years. n148 Thus, the most direct
approach to solving the problem of bad data leading to biased results from
data-centric decision support tools is to require that police departments retool
their data collection and analysis efforts toward more meaningful metrics.

   Another misinterpreted requirement of the original Wilson and Kelling model
is the concept of proactive policing. Most police departments implementing
broken windows models have designed their systems as incident-oriented
frameworks, which do a poor job at addressing levels of criminality in a
community and serve mainly to feed a cycle of incarceration. n149 The Wilson and
Kelling method of proactive policing focuses instead on the root causes of
criminality, such as poverty, economic and  [*132]  ecological injustice, and
racism, where police departments form part of a larger community team to go
beyond the punishing of window breakers, and actually fix the broken windows.
n150

   Finally, community policing requires police departments to hone their
sensitivities to cultural norms and the needs of the community, since
perceptions of social disorder can be highly dependent upon time, place, and
circumstance, and most police officers are not residents of the communities they
patrol. n151 Public perceptions can also vary by context, which means social
disorder often falls into the "I can't define it, but I know it when I see it"
category. n152 When police officers develop a feel for their communities they
patrol, they will also benefit their departments by providing better, more
meaningful intelligence data, which can then be used to improve their decision
support outcomes. n153

   Police department policies and procedures that are put in place with
automated decision support tools like Compstat, which supports the broken
windows policing regimes, have had a distinctly negative effect on minority
communities. n154 As discussed in Section III above, this problem is not a new
one, but is instead one that has been exacerbated by the use of military tactics
and technologies. n155 LEAs, already obligated to collect evidence, especially
feel the pressure in information societies to observe, collect, record, and
evaluate all available data. n156 This predilection leads police to treat their
communities as intelligence landscapes and people as "data  [*133]  elements,"
n157 resulting in dissociative or adversarial relationships between cop and
citizen. n158

   This result is counter to the original intent behind community policing. n159
In hindsight, there is a certain level of disconnect between the algorithmic
policing model and the community policing model, since algorithmic policing
seeks to build a centralized, automated police force that operates from the
inside out, while the community policing model requires a process that begins
and ends with the citizen. n160 But a key driver behind broken windows and
algorithmic policing is a heightened fear of crime and disorder, a fear that has
not diminished significantly over the past few decades, despite the nearly
universal drop in crime rates nationally. n161 A necessary part of this
transformation, therefore, is to cultivate a base level of trust within police
organizations as well as stakeholder communities. One method of building this
trust is to continue to use the automated policing systems while redesigning
them to focus on local  [*134]  community goals rather than those of police
departments or outside interests. Transparency is critical to this step's
success - police management must create a system through which community members
can not only seek police assistance, but can examine the systems and goals the
police themselves use to guide their day-to-day patrol activities. Another
critical part of this transformation is an immediate increase in accountability
within police departments. Automation bias, data bias, and corrupted procedures
and goals often give police departments a certain amount of artificial cover
when things go badly. However, technological opacity is no substitute for human
accountability up and down the LEA management chain. Finally, law enforcement
resources must be shifted towards a citizen-focused organization, giving
rank-and-file police officers the power to help drive automation policy, while
also giving them the discretion to problem solve independent of the automated
process.

   B. Incorporate Outcome and Process Feedback into Existing Systems

 We live in a time in which our lives are increasingly influenced and affected -
whether we know it or not - by data, algorithms, and machine learning. n162 It
would be a mistake to believe that police departments would somehow be immune to
this trend. Therefore, the solution to modern (or post-modern) problems of
public safety is not to go the way of Ned Ludd, but to develop police decision
support systems with an eye toward civil rights, and avoiding race
discrimination and economic injustice.

   The key principle in developing any of these systems is transparency. In
Floyd et al. v. City of New York, n163 the court held that the NYPD's stop and
frisk program violated the Fourth Amendment by systematically conducting
warrantless searches of pedestrians, the majority of which were African-American
or Hispanic. Under the NYPD's stop-and-frisk program, police made over 4.4
million stops between 2004 and 2012. n164 Over half of these stops were of Black
citizens, thirty percent were of Hispanic citizens, and only ten percent were of
White citizens. n165 The guidelines that backed such a system were based on
opaque police policy decisions implementing a broken windows policing model, and
thereby creating the sort of insular environment that often fails to punish bad
actors and creates perverse incentives. n166 Further, since most police
departments do not employ  [*135]  software developers or statisticians, they
are forced to purchase their decision support systems from third party
contractors. n167 The same principles of transparency should apply to
contractors so as to avoid these problems.

   Next, algorithmic and predictive policing systems need to be based on
accurate and meaningful data. For example, police stop and frisk programs,
despite criticisms and claims of racial bias inherent in these programs, have
been widely supported by LEAs based on their assertions that, while more
minorities are subject to these stops, it is only because minorities commit
disproportionately more crimes than Whites, and not due to any particular bias
of police officers and departments. n168 To support these claims, police often
cite automated police intelligence systems, such as Compstat, to justify these
stops. n169 Statistical studies conducted on stop and frisk data, however, have
shown that minorities are far more likely subjects of these programs, with
statistical patterns pointing toward a structural racial bias, reinforced
through automated decision support tools. n170

   Finally, we must be cognizant of the limitations of purely technical
solutions to human problems. Mathematical and computer models of real-life
systems can, of course, provide critical insights into complex systems, but they
are imperfect. Algorithms for deriving patterns from large amounts of seemingly
random data are getting better as research and technology progress, but their
most effective use within the broken windows policing model is as a supplemental
tool informing human decision making, not as a digital crutch upon which bad
practices and biased policing may rest.

   Further, known biases in automation systems can be mitigated through a number
of established means. For example, automation bias and automation complacency
can be avoided by increasing accountability by the users of a system. n171 By
requiring system operators to provide complete justifications for their
decisions - beyond "the machine told me  [*136]  so" - users will be driven
toward deeper cognitive engagement and awareness of alternative information
sources. n172 The level of automation used in a situation should also be
carefully assessed on a domain basis. That is, the level of automation available
can exceed the level of automation necessary for a given situation. n173
Repetitive, rigid tasks that expect no user decision-making flexibility are
often good candidates for a high degree of automation, while those tasks that
rely on human intuition, pattern perception, and contextual reasoning, are best
served with lower levels of automation. n174 Much of the work of law enforcement
falls into this latter category.

   For the time being, algorithmic and predictive approaches are only as useful
as their human creators. Selecting the proper policing model for every instance
is likely impossible, so one of the most important decisions in the field of
machine learning is the selection of the model that will provide superior
results for a particular problem, a task which still requires an experienced and
informed human in the loop. n175 But this limit can be leveraged as a benefit,
rather than a liability, by using predictive systems to decentralize police
command structures, and allow more creativity and initiative among rank-and-file
patrol officers, characteristics that are critical to a true community-policing
model. n176

   CONCLUSION

 The problem of bias in algorithmic policing has deep roots, as evidenced above.
Solutions to this problem cannot ignore technological advances that help us make
better, more efficient decisions, but they also cannot allow these technologies
to subvert the proper role of public safety in our communities. We live in an
information society that is, once again, experiencing a crisis of control that
we are naturally inclined to solve through data and analytic methods. But our
approach must be based on lessons learned from our successes and failures in
this arena. Many of these failures have led to a trust deficit between
authorities and the communities  [*137]  they govern, especially where racial
prejudices have been part of these failures. Addressing these disparities in
algorithmic policing cannot solve all of these problems, but it is a good start.

Legal Topics:

For related research and practice materials, see the following legal topics:
Constitutional LawBill of RightsFundamental FreedomsFreedom of SpeechPublic
EmployeesGovernmentsLocal GovernmentsPolice PowerTransportation LawAir
TransportationPersonnelPilots

FOOTNOTES:




n1.  See Julia Angwin et al., Machine Bias: There's Software Used Across the
Country to Predict Future Criminals. And it's Biased Against Blacks, ProPublica
(May 23, 2016), https://www
.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
(last visited June 28, 2016).





n2.  Id.





n3.  See Phillip T. Wyrick, Police Militarization: Attitudes Towards the
Militarization of the American Police (May 2013) (unpublished M.A. thesis, East
Tennessee State University) (on file with Digital Commons, East Tennessee State
University), http://dc.etsu.edu/etd/1161/.





n4.  See Peter B. Kraska & Victor E. Kappeler, Militarizing American Police: The
Rise and Normalization of Paramilitary Units, 44 Soc. Probs. 1, 1 (1997) ("This
attention to medicalization neglects other social problems metaphors,
particularly the metaphor of war (e.g., the War on Poverty, the war on
drugs).").





n5.  Id. at 7-9; Amanda Geller & Jeffrey Fagan, Pot as Pretext: Marijuana, Race,
and the New Disorder in New York City Street Policing, 7 J. Empirical Legal
Stud. 591 (2010); Bernard E. Harcourt & Jens Ludwig, Broken Windows: New
Evidence from New York City and a Five-City Social Experiment, 73 U. Chi. L.
Rev. 271 (2006); Jamila Michener, Neighborhood Disorder and Local Participation:
Examining the Political Relevance of "Broken Windows", 35 Pol. Behav. 777
(2013); Steve Herbert, Policing the Contemporary City: Fixing Broken Windows or
Shoring Up Neo-Liberalism?, 5 Theoretical Criminology 445 (2001).





n6.  Peter B. Kraska & Louis J. Cubellis, Militarizing Mayberry and Beyond:
Making Sense of American Paramilitary Policing, 14 Just. Q. 607 (1997).





n7.  Robert W. Taylor & Amanda L. Russell, The Failure of Police "Fusion"
Centers and the Concept of a National Intelligence Sharing Plan, 13 Police Prac.
& Res. 184 (2012).





n8.  Carl von Clausewitz, On War 37-39 (Michael Howard and Peter Paret trans.,
2007).





n9.  Id. at 46.





n10.  M. D. Feld, Information and Authority: The Structure of Military
Organization, 24 Am. Soc. Rev. 15, 17-19 (1959) (arguing that concept of
bureaucratic organization is essential to efficient military operations, where
the principles of military command require levels of predictability and control
at a level of scalability that precludes ad hoc organization. Because warfare
is, by nature, chaotic and corrosive to organization and communication, military
organizations attempt to minimize these effects through levels of bureaucratic
stability that enable information flow - one of the essential requirements of
command.).





n11.  John A. Allen et al., A Framework for Supporting Human Military Planning,
2 Ann. Conf. Int'l Tech Alliance 1, 1-8 (2008) (arguing that the hierarchical
bureaucracy of military organizations is based around the need to efficiently
pass information, intent, plans, and commands up and down the chain of command
that is both time sensitive and scalable to large organizations).





n12.  See Michael I. Handel, Intelligence and the Problem of Strategic Surprise,
in Paradoxes of Strategic Intelligence Essays in Honor of Michael I. Handel 1,
1-58 (Richard K. Betts &Thomas G. Mahnken, eds., 2003).





n13.  See Michael Warner, Wanted: A Definition of "Intelligence," 46 Stud.
Intelligence, 1, 15 (2002).





n14.  See Robert L. Bateman III, Avoiding Information Overload, 78 Mil. Rev.,
53, 53 (1998).





n15.  Andrew Rathmell, Towards Postmodern Intelligence, 17 Intelligence & Nat'l
Security 87, 88-89 (2002).





n16.  In fact, as military intelligence related incidents involving torture,
untruths, and censorship over the past decade have shown us, the remorseless
pursuit of perfectly actionable intelligence has led to bloated military
contractor budgets, loss of friendly and civilian life, and atrocities. See,
e.g., Seymour M. Hersh, Chain of Command, New Yorker 38 (May 17, 2004).





n17.  Military theoreticians divide the history of modern warfare into four
generations, each of which marked by technical, political, economic or social
changes or advances. The first generation of modern warfare emerged with the
widespread use of gunpowder and the shift in Europe from a feudal economy to the
modern nation-state. Second generation warfare is identified with the
nation-state's ability to generate large revenue streams through widespread
taxation on increasing wealth. The German Blitzkrieg is the starting point of
third generation warfare, with high maneuverability being used to break the
protracted impasses characteristic of World War I. Finally, fourth generation
warfare - the mode in which theorists currently put us - is summarized by
enormous advances in communications and weapon technologies along with the rise
of guerilla movements and asymmetric warfare. See Thomas X. Hammes, The Sling
and the Stone: On War in the 21st Century (Zenith Press 2006).





n18.  A prime example of this phenomenon can be found in the January 1968 Tet
Offensive, where North Vietnamese Army (NVA) and Viet Cong (VC) guerilla forces
conducted a series of well-timed, highly-coordinated attacks on U.S. military
installations and South Vietnamese government buildings across all of South
Vietnam. While these attacks were ultimately repulsed by U.S. and South
Vietnamese forces, the widespread effects of the offensive marked the beginning
of the end of the American war in Vietnam. Historians and military theorists
widely attribute much of the success of the outnumbered NVA and VC forces to
poor U.S. military intelligence, which completely failed to anticipate the Tet
Offensive as well as the military, political, and social costs that would follow
from it. See James J. Wirtz, The Tet Offensive: Intelligence Failure in War
(1994).





n19.  See Harry G. Summers, On Strategy: A Critical Analysis of the Vietnam War
(1995). "Fourth-generation warfare" is the term military analysts have used to
describe the post-9/11 style of asymmetric war now seen, where the
first-generation war was Napoleonic in nature, the second-generation war was
Prussian, and the third-generation war was based on rapid maneuver.





n20.  See Scott E. McIntosh, The Wingman-Philosopher of MiG Alley: John Boyd and
the OODA loop, 58 Air Power Hist., 24, 24 (2011)





n21.  See David S. Fadok, John Boyd and John Warden: Air Power's Quest for
Strategic Paralysis (1995). It is somewhat noteworthy that Boyd himself shot
down no enemy aircraft during his combat tour in Korea. This was due not to a
lack of combat sorties - Boyd flew 22 - but to the fact that all of his combat
flights were as a wingman, rather than lead. His perspective and experience in
this role, however, may well have given Boyd the insights he later developed in
his military theories and instruction. See McIntosh, supra note 20.





n22.  See Fadok, supra note 21, at 14-15.





n23.  Id. at 14.





n24.  Since this Article is not devoted to Boyd's OODA loop per se, I will
restrict the cycle's description to its most basic form. Boyd's insight can
still be quite easily seen in this summarized version, as it describes the
rational human behavior found in individuals as well as organizations. For a
detailed analysis of the OODA loop, see Id.; Arthur K. Cebrowski & John J.
Garstka, Network-Centric Warfare: Its Origin and Future, U.S. Naval Inst. Proc.
28 (1998); McIntosh, supra note 20.





n25.  See Fadok, supra note 21.





n26.  See McIntosh, supra note 20, at 29.





n27.  Id. at 26.





n28.  See McIntosh, supra note 20.





n29.  See Bruce Berkowitz, John Boyd: The American Sun Tzu, 47 Orbis 370, 372-73
(2003).





n30.  See infra Section III for a detailed exploration of this phenomenon.





n31.  See, e.g., Mark Bender, Operation Excellence: Succeeding in Business and
Life the U.S. Military Way (2004); Partha Bose, Alexander the Great's Art of
Strategy: The Timeless Leadership Lessons of History's Greatest Empire Builder
(2003); Dan Carrison & Rod Walsh, Semper Fi: Business Leadership the Marine
Corps Way (1999); Scott W. Christie, Precision Guided Leadership: How Modern
Military Doctrine Can Save Corporate America (2003); Gene Klann, Crisis
Leadership: Using Military Lessons, Organizational Experiences, and the Power of
Influence to Lessen the Impact of Chaos on the People You Lead (2003); Anthony
J. Le Storti, When You're Asked to Do the Impossible: Principles of Business
Teamwork and Leadership from the U.S. Army's Elite Rangers (2003); Douglas C.
Bernhardt, 'I Want It Fast, Factual, Actionable' - Tailoring Competitive
Intelligence to Executives' Needs, 27 Long Range Planning 3, 12-24 (1994)
(showing that, since the mid-1990s, businesses and other non-military
organizations have fostered the emergence of a sizable cottage industry of
books, consultants, and other organizational coaches applying military "lessons
learned" to non-military environments). But see Richard H. Kohn, Out of Control:
The Crisis in Civil-Military Relations, 35 Nat'l Interest 1, 3 (1994) (showing
that this phenomenon would have been largely unthinkable in the fifteen years
between the American military's ignominious withdrawal from Vietnam and its
rebuilt success in the First Gulf War. The hangover from this period lingered
through 2001 in the form of military contempt for its civilian leadership).





n32.  See James R. Beniger, The Control Revolution: Technological and Economic
Origins of the Information Society 7 (1986); Max Weber, Economy and Society
969-74 (1978); Edward Higgs, The Rise of the Information State: The Development
of Central State Surveillance of the Citizen in England, 1500-2000, 14 J. Hist.
Soc. 175 (2001); Michael Power, The Audit Explosion (1994); Michael Power,
Evaluating the Audit Explosion, 25 L. & Pol'y. 185, 185-202 (2003).





n33.  See Anthony Giddens, The Nation-State and Violence (1985). See also Ulrich
Beck, Risk Society and the Provident State, in Risk, Environment and Modernity:
Toward a New Ecology, 27 (Scott Lash et al., eds., Martin Chambers trans., 1998)
(describing the need for increased surveillance as a direct result of industrial
society, when the "social, political, ecological, and individual risks created
by the momentum of innovation increasingly elude the control and protective
institutions of industrial society.").





n34.  See Max Weber, The Theory of Social and Economic Organization 330-40
(Talcott Parsons ed., Free Press 2009) (1947).





n35.  The need for larger and more widely distributed militaries, driven largely
by the expanding imperial goals of many nations, created serious organizational
problems for military leadership. Muster lists, payroll records, logistics
planning, and other forms of the modern military's more prosaic tasks benefited
greatly from these new forms of communication and information processing. See
Higgs, supra note 32, at 178.





n36.  Reinhard Bendix notes that any study of modern bureaucracy must
acknowledge both the challenges to and protections of individual freedoms: "It
is clear that these changes are so significant in their implications for the
exercise of power by a government that studies of bureaucracy in the traditional
sense do not suffice. We must search instead for the underlying transformations
in society that have prompted these developments. We must seek to interpret the
technical and social changes which affect governmental bureaucracy, not only in
order to improve the civil service, but in order to understand more fully the
problems of power which it involves." Reinhard Bendix, Bureaucracy and the
Problem of Power, 5 Pub. Admin. Rev. 194, 196 (1945).





n37.  Beniger, supra note 32, at 9.





n38.  Rationalization is the proposition that an organization's creation and
containment of power through control can increase either through increasing the
organization's capability to process coded information or by limiting the amount
of that information to be processed. Id. at 15-16. The modern military modified
this concept by maximizing both precepts: increasing information processing
capability to effectively decrease the amount of information that is processed.





n39.  This is not to say that modernization has solved the military intelligence
problem, of course. Indeed, the same organizational and technological advances
that have enabled the modern military intelligence framework have also yielded
an increasingly complex and chaotic world within which militaries are expected
to operate. See Thomas X. Hammes, The Sling and the Stone: On War in the 21st
Century (Zenith Press 2006); Rathmell, supra note 15, at 87-104.





n40.  See Beniger, supra note 32, at v; Higgs, supra note 32, at 175. (1978).





n41.  This concept is not always as uncontroversial as it might seem on the
surface. For example, one of the chief criticisms of Utilitarianism, an early
version of the information-centric movement originally promulgated by Bentham
and Mill, has been in its concentration on the maximization of utility, which in
turn requires that measurability is always an option. Such an approach cannot
apply to every human endeavor, say critics, as there are concepts like morality
and justice that defy measurement. See Beniger, supra note 32, at 9; Bendix,
supra note 36 at 196. See John Rawls, Justice as Fairness, 67 Phil. rev. 164
(1958).





n42.  The use of the term social control function bears with it a requirement to
explain its definition in this context. Here, I refer to control in its most
general sense - to influence or direct behavior toward some predetermined goal.
This definition is informed by the sociology literature, which examines the
social relationship, the organization, voluntary or compulsory social
participation, and consensual and imposed order. Hence, control, in this sense,
is primarily concerned with the two elements of influence and purpose, and
control theory - in both the sociological and mathematical senses - require
facilities for the communication and processing of information in order to
manage behavior through feedback. See Richard Bellman, Control Theory, 211 Sci.
Am. 186, 186 (1964); William T. Powers, Behavior: The Control of Perception
(1973); Jay Wright Forrester, Industrial Dynamics: A Major Breakthrough for
Decision Makers, 36 Harv. Bus. Rev. 37 (1958).





n43.  James H. Auten, The Paramilitary Model of Police and Police
Professionalism, 4 Police Stud.: Int'l Rev. Police Dev. 67, 67 (1981); J. L.
Lyman, The Metropolitan Police Act of 1829: An Analysis of Certain Events
Influencing the Passage and Character of the Metropolitan Police Act in England,
55 J. Crim. L., Criminology, & Police Sci. 141, 141 (1964); John M. Jermier &
Leslie J. Berkes, Leader Behavior in a Police Command Bureaucracy: A Closer Look
at the Quasi-Military Model, 24 Admin. Sci. Q. 1, 2 (1979).





n44.  See Lyman, supra note 43.





n45.  Giddens argues that the crisis of control brought about by
industrialization required a dramatic change in the state's view of its
citizens, as "no pre-modern states were able even to approach the level of
administrative coordination developed in the [modern] nation-state." Anthony
Giddens, The Consequences of Modernity 57, 60-63 (1990).





n46.  See Tadhg O' Ceallaigh, Peel and Police Reform in Ireland, 1814-18, 6
Studia Hibernica 25, 26-28 (1966); See Lyman, supra note 43, at 149-150; See
Auten, supra note 43, at 67.





n47.  There is something of a "chicken and egg" relationship between Peel's
quasi-military organization of the London Metropolitan Police and the natural
fit with former members of the British military; was a quasi-military
organizational structure selected for its qualities as best suited for civilian
policing, thus making military men (they were all men) the best candidates for
the job? Or was the choice of a quasi-military police force pre-ordained by the
desired characteristics and availability of former soldiers? The literature
suggests the former, but even today, we still see a career transition from a
soldier to a civilian police officer as quite natural. See J. L. Lyman, The
Metropolitan Police Act of 1829: An Analysis of Certain Events Influencing the
Passage and Character of the Metropolitan Police Act in England, 55 J. Crim. L.
Criminology & Police Sci. 141, 152-53 (1964).





n48.  Id. at 7-10. See generally Beniger, supra note 32. Among the innovations
of industrialization, perhaps the most successful is that of the modern
bureaucracy. Rapid advances in manufacturing and transportation technologies
brought an abrupt end to millennia of primarily agricultural societies, and thus
required new modes of thought around societal, economic, and political
questions. New means of social control were necessary, as the dramatic increase
in transactional speed brought about by industrialization quickly outpaced
existing modes of control and interaction, and began to threaten the viability
of existing institutions. Beniger characterizes this phenomenon as a "crisis of
control," a period in which a society's organizational, information processing,
and communication capabilities are outpaced by manufacturing and transportation
technologies, resulting in a systemic loss of political and economic control
which threatens existing social and governmental institutions and structures.





n49.  See Anthony Giddens, The Nation-State and Violence 46-48 (University of
California Press, 2013).





n50.  See Kevin D. Haggerty & Richard V. Ericson, The Surveillant Assemblage, 51
British J. Soc. 605-622 (2000); Sean P. Hier, Probing the Surveillant
Assemblage: On the Dialectics of Surveillance Practices as Processes of Social
Control, 1 Surveillance & Soc'y 399 (2003),
http://www.surveillance-and-society.org. For a complete analysis of this
phenomenon, see Jeffrey L. Vagle, The History, Means, and Effects of Structural
Surveillance, Univ. of Pa. L. Sch. Fac. Scholarship 1 (2016),
http://scholarship.law.upenn.edu/faculty scholarship/1625.





n51.  See Arthur K. Cebrowski & John J. Garstka, Network-Centric Warfare: Its
Origin and Future, 124 in U.S. Naval Inst. Procs. 28-35 (1998),
http://mattcegelske.com/wp-content/uploads/2012/04/ncw origin future.pdf (last
visited Dec. 9, 2016).





n52.  Id.





n53.  One of the better-known examples of early business adopters of this new
information-centric management style is Wal-Mart, which pioneered the concept of
"precision retailing." Wal-Mart generated a competitive advantage by deploying a
network of sensors throughout all levels of the organization. This
infrastructure fed real-time information through Wal-Mart's networks, giving
them the ability to make decisions on extremely accurate and fresh data, a
concept whose usefulness was not lost on military planners. See generally David
S. Alberts, John Garstka & Frederick P. Stein, Network Centric Warfare:
Developing and Leveraging Information Superiority (1999).





n54.  While a full exploration of the history of Rumsfeld's Office of Force
Transformation is beyond the scope of this Article, it is relevant and worth
noting that a wide array of analysis of the performance of the "transformed"
military in Afghanistan and (especially) Iraq, led many to observe that the
optimism about a small, lighter, network-centric military was, at best,
misplaced or premature, and at worst, willfully negligent. See, e.g., Jeffrey L.
Groh, Network-Centric Warfare: Leveraging the Power of Information, 1 U.S. Army
War C. Guide to Nat'l Security Issues: Theory of War & Strategy 323, 331-32
(2008) (enumerating some of the principle criticisms and limitations of
network-centric warfare); Noah Shachtman, How Technology Almost Lost the War: In
Iraq, the Critical Networks Are Social - Not Electronic, Wired, (Nov. 27, 2007),
http://archive.wired.com/politics/security/magazine/15-12/ff
futurewar?currentPage=all (explaining how the claims of the "Wal-Mart model" of
network-centric war fighting led to understaffed and underpowered military units
on the ground); Francis Fukuyama & Abram Shulsky, Military Organization in the
Information Age: Lessons from the World of Business, in Strategic Appraisal: The
Changing Role of Information in Warfare 327-60 (1999).





n55.  In his 2003 Annual Report to the President and Congress, Secretary of
Defense Rumsfeld articulated his vision for a network-centric military, and laid
out the plans, and associated risks, for force transformation. See Dep't of
Def., Secretary of Def., OMB No. 0704-0188, Annual Report to the President and
the Congress, (2003). The proposed transition to a "21st-century military" was
sweeping, with a greater reliance on small, technology-equipped special forces
teams, and a move away from the large, heavy army divisions built up during the
Cold War. Rumsfeld estimated the initial cost of this transformation to be $
24.3 billion, and $ 239 billion overall. Id. Later estimates, however, put the
figure nearer to $ 1 trillion by 2010, with program costs continuing long into
the future. Russell Rumbaugh, Stimson Center, What We Bought: Defense
Procurement from FY01 to FY10, at 5 (2011). For example, the F-35A Joint Strike
Fighter, expected to cost $ 1.5 trillion alone over the life of the program, and
has been questioned as an effective fighting platform. See David Francis, How
DOD's $ 1.5 Trillion F-35 Broke the Air Force, CNBC (July 31, 2014),
http://www.cnbc.com/2014/07/31/how-dods-15-trillion-f-35-broke-the-air-force.
html; David Axe, Air Force Admits: Our New Stealth Fighter Can't Fight, Daily
Beast, (Sept. 17, 2015), http://www.thedailybeast
.com/articles/2015/09/17/air-force-admits-our-new-stealth-fighter-can-t-fight.ht
ml.





n56.  See Jeffrey L. Groh, Network-Centric Warfare: Leveraging the Power of
Information, in 1 U.S. Army War C. Guide to Nat'l Security Issues: Theory of War
& Strategy 323 (J. Boone Bartholomees, Jr. ed., 2008). See generally Peter J.
Dombrowski, Eugene Gholz & Andrew L. Ross, Military transformation and the
Defense Industry After Next (2003).





n57.  John Ferris, Netcentric Warfare, C4ISR and Information Operations: Towards
a Revolution in Military Intelligence?, 19 Intelligence & Nat'l Security 199,
203 (2004); Dombrowski, Gholz & Ross, supra note 56, at 8 (2003); Steve Niva,
Disappearing Violence: JSOC and the Pentagon's New Cartography of Networked
Warfare, 44 Security Dialogue 185, 186 (2013); Peter J. Dombrowski, Eugene Gholz
& Andrew L. Ross, Selling military transformation: The defense industry and
innovation, 46 Orbis 523, 523 (2002).





n58.  See Peter Andreas & Richard Price, From War Fighting to Crime Fighting:
Transforming the American National Security State, 3 Int'l Stud. Rev. 31-52
(2001).





n59.  Id. at 38-40.





n60.  George L. Kelling & William J. Bratton, Declining Crime Rates: Insiders'
Views of the New York City Story, 88 J. Crim. L. & Criminology 1217, 1219 (1998)
(quoting Wesley Skogan, Disorder and Decline: Crime and the Spiral of Urban
Decay in American Neighborhoods 84 (1990)).





n61.  Id.





n62.  James Q. Wilson & George L. Kelling, Broken Windows, Atlantic monthly
March 1982, at 29 (1982).





n63.  Zimbardo established a field study to demonstrate the effects of decaying
community on crime. In his experiment, Zimbardo "abandoned" cars in generally
good condition in multiple locations in the Bronx and Palo Alto. While the cars
left in Palo Alto were generally reported to police and left unmolested, the
cars in the Bronx were almost immediately vandalized and stripped of valuable
parts. The key difference between these two cities, Zimbardo theorized, was the
strong sense of community in Palo Alto, where people cared about what happened
in their neighborhood, and the comparative lack of such a community sentiment in
the Bronx. Zimbardo concluded that a breakdown of shared community values could
lead to a certain anonymity that allowed for petty and serious crime to take
hold. Diary of a Vandalized Car, Time, Feb. 28, 1969, at 62.





n64.  See Harcourt & Ludwig, supra note 5, at 276.





n65.  Giuliani's NYPD put special emphasis on prostitution, graffiti, low-level
drug offenses, and "aggressive" panhandling as symptoms of urban decay and
disorder. Police had largely ignored petty offenses in all but the most extreme
cases up to this point, and Giuliani promulgated a no-tolerance approach as a
method of "reclaiming the open spaces of New York." Judith A. Greene, Zero
Tolerance: A Case Study of Police Policies and Practices in New York City, 45
Crime & Delinq. 171, 171-73 (1999).





n66.  See John A. Eterno & Eli B. Silverman, The New York City Police
Department's Compstat: Dream or Nightmare?, 8 Int'l J. Police Sci. & Mgmt. 218,
219-20 (2006).





n67.  The NYPD had 31,236 full-time sworn officers in 1990. This number does not
include part-time and administrative staff. Brian A. Reaves & Matthew J.
Hickman, U.S. Dep't of Just. Bureau of Just. Stat., Police Departments in Large
Cities, 1990-2000, at 2 (2002).





n68.  See Noah Shachtman, How Technology Almost Lost the War: In Iraq, the
Critical Networks Are Social - Not Electronic, Wired (Nov. 27, 2007),
http://archive.wired.com/politics/security/magazine/15-12/ff
futurewar?currentPage=all; Peter K. Manning, Information Technologies and the
Police, Crime & Just. 349, 350 (1992). See also infra Section 0.





n69.  Early manifestations of police militarization took traditional forms,
where military equipment, such as assault rifles and armored personnel carriers,
and their associated tactics were adopted by civilian police departments,
justified by the increased threat (real or perceived) from drug trafficking in
major U.S. cities. Sandra Bass, Policing Space, Policing Race: Social Control
Imperatives and Police Discretionary Decisions, 28 Soc. Just. 156, 164 (2001).





n70.  See, e.g., Evan Munsing & Christopher J. Lamb, Inst. Nat'l Strategic
Stud., Joint Interagency Task Force-South: The Best Known, Least Understood
Interagency Success 3 (2011).





n71.  Sean J. Kealy, Reexamining the Posse Comitatus Act: Toward a Right to
Civil Law Enforcement, 21 Yale L. & Pol'y Rev. 383, 384 (2003).





n72.  The 1981 Military Cooperation with Law Enforcement Officials Act
encouraged military agencies to supply intelligence, equipment, and training to
civilian police departments. In the 1980s and 1990s, Congress continued to
expand the military's ability to work directly with civilian law enforcement,
through such legislation as the National Defense Authorization Act, which
authorized and funded direct National Guard participation in drug operations.
See Munsing & Lamb, supra note 70; See Kealy, supra note 71.





n73.  When Judge Richard Posner was asked in 1983 whether he thought the nation
was fighting a war on drugs, he responded, "I don't know, but if we are at war,
we're losing." When asked if he had an alternative solution, he said, "Yes, they
ought to legalize it." William J. Bauer, The War on Drugs, Wis. L. Rev. 1, 2-3
(2014).





n74.  Jeff Yates & Andrew B. Whitford, Race in the War on Drugs: The Social
Consequences of Presidential Rhetoric, 6 J. Empirical Legal Stud. 874, 875-77
(2009).





n75.  Id.





n76.  Doris M. Provine, Race and Inequality in the War on Drugs, 7 Ann. Rev. L.
& Soc. Sci. 41, 42 (2011); Yates & Whitford, supra note 74, at 876.





n77.  See Provine, supra note 76, at 47, 54.





n78.  The circumstances of the civilian shooting by JTF-6 personnel are quite
tragic, yet should have been foreseeable under the circumstances. The shooting
took place at night when JTF-6 Marines were using night vision equipment to
patrol a section of the U.S.-Mexican border. Though every Marine was armed,
their explicit orders were to limit their operations to observation and
reconnaissance, relaying all suspicious activity to civilian law enforcement for
possible action. When the JTF-6 Marines thought they heard gunfire in the area,
they immediately returned fire, killing a civilian. Commentators later suggested
that this sort of tragedy was inevitable, because armed marines, trained for
combat, were put in a law enforcement role. JTF-6 further exacerbated the
inherent problems of military-civilian law enforcement activities through their
direct involvement in the 1993 siege of the Branch Davidian compound in Waco,
TX. See Munsing & Lamb, supra note 70.





n79.  Anti-terrorism military cooperation programs within U.S. civilian LEAs
had, of course, existed prior to the events of 9/11, with some commentators
arguing that the fight against terrorism was a far better use of military-law
enforcement partnerships than the war on drugs, since military units were better
trained and equipped to address the special needs of counter-terror operations.
See Kealy, supra note 71, at 419. These early efforts remained somewhat
controversial, however, even among military leaders prior to 2001. These
controversies ended quite abruptly after 9/11. As Cofer Black, the former head
of the CIA's Counterterrorism Center put it when he appeared before the Senate
Intelligence Committee, "There was 'before' 9/11 and 'after' 9/11. After 9/11
the gloves come off." Joint Inquiry Into Intelligence Community Activities
Before and After the Terrorist Attacks of September 11, 2001: Hearing Before the
Select S. Comm. on Intelligence and the Permanent H.R. Select Comm. on
Intelligence, 107th Cong. 589-94 (2004) (statement of Cofer Black, Former Chief,
DCI's Counterterrorist Center, Central Intelligence Agency),
http://www.intelligence.senate.gov/hearings/joint-inquiry-intelligence-community
-activities-and-after-terrorist-attacks-september-11-0.





n80.  See Munsing & Lamb, supra note 70.





n81.  See Peter B. Kraska, Militarization and Policing - Its Relevance to 21st
Century Police, 30 Policing 501, 502-11 (2007).





n82.  See Kraska & Cubellis, supra note 6, at 607-629.





n83.  See Karena Rahall, The Green to Blue Pipeline: Defense Contractors and the
Police Industrial Complex, 36 Cardozo L. Rev. 1785, 1791-92 (2015).





n84.  Id; Kraska, supra note 83; Kraska & Cubellis, supra note 6; Kraska &
Kappeler, supra note 4, at 1-18.





n85.  While this is still true in general, there has been a disturbing trend
across police departments to deploy military gear more widely. This topic goes
beyond the scope of this Article. But see Kraska & Cubellis, supra note 6;
Kraska & Kappeler, supra note 4, at 1-18; Rahall, supra note 83.





n86.  See Kelling & Bratton, supra note 60. See also supra text accompanying
note 60.





n87.  Id.





n88.  While the term big data analytics hadn't yet made its way into our lexicon
in the early 1990s, the concepts and principles therein had begun to take form.
A great deal of enthusiasm emerged for automated decision support tools, expert
systems, and other data intelligence tools, especially in military applications,
where critical decisions based on unmanageable information loads had to be made
within a time span that was too short for human reasoning. See Jeung Choi, Jae
Joo & Dong Cho, Situation/Threat Assessment Fusion System (STAFS), 2 Info.
Fusion, 2002: Proc. Fifth Int'l Conf. 1374 (2002); Jung P. Shim et al., Past,
Present, and Future of Decision Support Technology, 33 Decision Support Sys.
111, 111-13 (2002); Heath A. Ruff, Sundaram Narayanan & Mark H. Draper, Human
Interaction with Levels of Automation and Decision-aid Fidelity in the
Supervisory Control of Multiple Simulated Unmanned Air Vehicles, 11 Presence:
Teleoperators & virtual env'ts 335 (2002).





n89.  There appears to be a relevant disagreement over the meaning behind the
name "Compstat". Many authors have claimed the name is a shortening of "computer
statistics," which Eterno and Silverman demonstrate is incorrect. Eterno &
Silverman, supra note 66, at 218-31. See also Kevin J. Walsh & Vincent E. Henry,
Compstat, OODA Loops and Police Performance Management, 2 Policing 349, 349-58
(2008); James J. Willis, Stephen D. Mastrofski & David Weisburd, Making Sense of
COMPSTAT: A Theory-Based Analysis of Organizational Change in Three Police
Departments, 41 Law & Soc'y Rev. 147-88 (2007).





n90.  See Eterno & Silverman, supra note 66.





n91.  See Eterno & Silverman, supra note 66, at 220.





n92.  See Willis, Mastrofski & Weisburd, supra note 89, at 189-90; see Beniger,
supra note 32, at 399-400, 407-411 (providing historical illustrations of the
organizational leaps made through bureaucratic data processing).





n93.  See Walsh & Henry, supra note 89, at 350-51. By 2000, the number of
full-time sworn officers in the NYPD rose to 40,435. Brian A. Reaves & Matthew
J. Hickman, U.S. Dep't of Just., Bureau of Just. Stat., Police Departments in
Large Cities, 1990-2000, at 2 (2002).





n94.  See David Weisburd et al., Reforming to Preserve: Compstat and Strategic
Problem Solving in American Policing, 2 Criminology & Pub. Pol'y 421, 422
(2002).





n95.  See Willis, Mastrofski & Weisburd, supra note 89, at 189-90; see Beniger
supra note 32, at 399-400, 407-411.





n96.  In 1996, the Compstat system was given the Innovations in American
Government Award, a prestigious honor granted by the Ford Foundation and Harvard
University's John F. Kennedy School of Government. William F. Walsh, Compstat:
An Analysis of an Emerging Police Managerial Paradigm, 24 Policing: Int'l J.
Police Strategy & Mgmt. 347, 347 (2001).





n97.  Id. at 356-58.





n98.  See David L. Carter & Jeremy G. Carter, Intelligence-Led Policing:
Conceptual and Functional Considerations for Public Policy, 20 Crim. Just. Pol'y
Rev. 310-25 (2009) (explaining the history of data-led policing as a paradigm in
the UK and US).





n99.  Id. at 311.





n100.  Id. at 313-15.





n101.  One can see very similar lines of thinking between the British
intelligence-led policing model and the American Compstat model, where automated
systems backed by advanced technology would deliver the "right information ...to
the right people at the right time." Nina Cope, Intelligence Led Policing or
Policing Led Intelligence?: Integrating Volume Crime Analysis into Policing, 44
Brit. J. Criminology 188, 191 (2004). Perhaps unsurprisingly, this almost
exactly echoes the oft-stated goals for the military's network-centric warfare
transformation, where the goal is "getting the right information, faster, to the
right forces - who in turn can take the right action, faster, against the right
objective." John Luddy, Lexington Inst., The Challenge and Promise of
Network-Centric Warfare 3 (2005),
http://lex2015.borczdixon.com/wp-content/uploads/challenge-promise-network-centr
ic-warfare.pdf.





n102.  This analytical method was not necessarily new in the 1990s, since Boyd
and others had been applying these techniques since the 1950s, albeit without
the benefit of the technology available to analysts and researchers toward the
end of the 20th century. But because of these new technological tools, methods
that required a great deal of processing power were now available outside of
supercomputing centers. Complicated models and techniques such as simulated
annealing were explored for their ability to arrive at solutions through complex
analytical methods. See Steven J. D'Amico et al., A simulated Annealing Approach
to Police District Design, 29 Computers & Operations Res. 667-684 (2002).





n103.  See Charlie Beck & Colleen McCue, Predictive Policing: What Can We Learn
from Wal-Mart and Amazon about Fighting Crime in a Recession, 76 Police Chief 18
(2009); Beth Pearsall, Predictive Policing: The Future of Law Enforcement, 266
Nat'l Inst. Just. J. 16-19 (2010).





n104.  Mathematical modeling has long been employed in this manner, using
data-fed simulations to mimic or predict real-world phenomena. Statistical
methods such as Bayesian analysis and Markov chain Monte Carlo (MCMC)
simulations have driven enormous advances in the fields of computer science,
theoretical and applied physics, and the social sciences. See Adrian F. M. Smith
& Gareth O. Roberts, Bayesian Computation via the Gibbs Sampler and Related
Markov Chain Monte Carlo Methods, 55 J. Royal Stat. Soc'y 3 (1993); Bradley P.
Carlin & Siddhartha Chib, Bayesian Model Choice via Markov Chain Monte Carlo
Methods, 57 J. Royal Stat. Soc'y 473-484 (1995). These and related methods have
been combined with research in information theory, decision theory, and neural
networks to create successful extrapolation and predictive systems across a wide
range of fields and problems. See Christopher M. Bishop, Pattern Recognition and
Machine Learning (Michael Jordan et al. eds., 2006).





n105.  See Beck & McCue, supra note 103, at 16-19.





n106.  Pearsall, supra note 103, at 16.





n107.  See Cope, supra note 101.





n108.  See Samuel Greengard, Policing the Future, 55 Comm. ACM 19 (Mar. 2012).





n109.  See Pearsall, supra note 103, at 16-19. For those who have followed the
national security version of this debate, this logical progression will seem
quite familiar. In government hearings across Europe and America, intelligence
agencies have argued that in order to find needles, they need access to the
entire data haystack. See Patrick Wintour, New Spying Legislation is Needed,
Intelligence Committee Will Say, The Guardian, (March 12, 2015, 1:00 PM),
http://www.theguardian.com/uk-news/2015/mar/12/
intelligence-committee-to-report-new-spying-legislation-is-needed.





n110.  See Pearsall, supra note 103, at 17.





n111.  See, e.g., K. Krasnow Waterman & Paula J. Bruening, Big Data analytics:
Risks and Responsibilities, 4 Int'l Data Privacy L. 89 (2014). The ethical
considerations inherent in big data analysis are not mere academic exercises.
The use of algorithmic and data-centric tools by civilian police departments,
coupled with our natural tendency toward automation bias (see Section 0), can
yield very real consequences to those on the wrong end of the equation. See,
e.g., Angwin et. al, supra note 1.





n112.  As crime rates began to drop in cities like New York in the late 1990s,
proponents of broken windows policing claimed this as evidence that this new
policing paradigm was working. See George L. Kelling & William J. Bratton,
Declining Crime Rates: Insiders' Views of the New York City Story, 88 J. Crim.
L. & Criminology. 1217, 1217 (1998). In fact, the drop in crime rates in New
York City was double the national average at the time. Dan M. Kahan, Social
Influence, Social Meaning, and Deterrence, 83 Va. L. Rev. 349, 367-68 (1997).
Critics of the broken windows model, however, argued that its proponents were
too quick to claim responsibility for the drop in crime rates, asserting that
other factors are just as likely, or more likely, to explain the decline, such
as more favorable economic conditions, shifts in drug use, and the general
increase in the New York police force. See, e.g., Joshua C. Hinkle & David
Weisburd, The Irony of Broken Windows Policing, 36 J. Crim. Just. 503 (2008);
Joshua C. Hinkle & Sue-Ming Yang, A New Look into Broken Windows: What Shapes
Individuals' Perceptions of Social Disorder?, 42 J. Crim. Just. 26 (2014); Aaron
R. S. Lorenz, The Windows Remain Broken: How Zero Tolerance Destroyed Due
Process, 12 Pub. Integrity 247 (2010).





n113.  See Jacinta M. Gau & Travis C. Pratt, Revisiting Broken Windows Theory:
Examining the Sources of the Discriminant Validity of Perceived Disorder and
Crime, 38 J. Crim. Just. 758, 758 (2010); Bernard E. Harcourt, Reflecting on the
Subject: A Critique of the Social Influence Conception of Deterrence, the Broken
Windows Theory, and Order-Maintenance Policing New York Style, 97 Mich. L. Rev.
291, 292 (1998).





n114.  See, e.g., Gau & Pratt, supra note 113; Hinkle & Weisburd, supra note
112.





n115.  Empirical evidence collected in cities that have implemented versions of
broken windows policing strongly indicates a race bias in the execution of the
policy. See Jeffrey Fagan & Garth Davies, Street Stops and Broken Windows:
Terry, Race and Disorder in New York City, 28 Fordham Urb. L. J. 457, 458
(2000); Mike King, "Broken Windows," Urban Policing, and the Social Contexts of
Race and Neighborhood (Dis-)Empowerment, 21 Critical Criminology 533, 535
(2013); Robert J. Sampson & Stephen W. Raudenbush, Seeing Disorder: Neighborhood
Stigma and the Social Construction of "Broken Windows," 67 Soc. Psychol. Q. 319,
321 (2004); Forrest Stuart, Race, Space, and the Regulation of Surplus Labor:
Policing African Americans in Los Angeles's Skid Row, 13 Souls 197, 206 (2011).





n116.  See Jeffrey Fagan & Garth Davies, supra note 115. It is worth noting that
Terry v. Ohio, 392 U.S. 1 (1968), which allowed a police officer's "professional
judgment" to serve as the basis for warrantless stops and searches, involves a
race-based decision by a police officer. Specifically, Detective McFadden, who
was White, stopped the defendant, Terry, who was African-American, based on
McFadden's sole observation that Terry was seen in a commercial district far
from an area of the city where most African Americans lived. McFadden stated
Terry's presence "didn't look right to [him] at the time."





n117.  See Joshua C. Hinkle & Sue-Ming Yang, A New Look into Broken Windows:
What Shapes Individuals' Perceptions of Social Disorder?, 42 J. Crim. Just. 26,
33 (2014).





n118.  Some officers within police organizations have also expressed levels of
dissatisfaction with algorithmic tools like Compstat, indicating that the
pressures on lower-level officers within departments from upper management
result in a system of perverse incentives, where the rank-and-file tend to be
rewarded only if they continue to propagate and support the system's existing
structure. See John A. Eterno & Eli B. Silverman, Understanding Police
Management: A Typology of the Underside of Compstat, 5 Prof. Issues Crim. Just.
11, 14-16 (2010).





n119.  Negative feedback loops in police decision support tools have been a
concern for some time, especially if data collection processes are not updated
to fit the goals of the community. See James J. Willis, Stephen D. Mastrofski &
Tammy Rinehart Kochel, Recommendations for Integrating Compstat and Community
Policing, 4 Policing 182, 189-91 (2010).





n120.  See, e.g., Thomas Oommen, Laurie G. Baise & Richard M. Vogel, Sampling
Bias and Class Imbalance in Maximum-Likelihood Logistic Regression, 43
Mathematical Geosciences 99, 118 (2010); Christopher M Bishop, Pattern
Recognition and Machine Learning (Michael Jordan et al. eds., 2006); Brian Mac
Namee et al., The problem of Bias in Training Data in Regression Problems in
Medical Decision Support, 24 Artificial Intelligence in Medicine 51, 54 (2002).





n121.  See J. Elin Bahner, Anke-Dorothea Huper & Dietrich Manzey, Misuse of
Automated Decision Aids: Complacency, Automation Bias and the Impact of Training
Experience, 66 Int'l J. Hum.-Computer Stud. 688, 688-690 (2008); Linda J.
Skitka, Kathleen L. Mosier & Mark Burdick, Does Automation Bias Decision-making?
51 Int'l J. Hum.-Computer Stud. 991, 993 (1999).





n122.  This concept has been generalized into what are known as the "no free
lunch" (NFL) theorems, which state that bias-free learning is futile. For a
detailed description - conceptually and mathematically - of these theorems, see
David H. Wolpert & William G. Macready, No Free Lunch Theorems for Optimization,
1 IEEE Transactions on Evolutionary Computation 67 (1997). See also David H.
Wolpert & William G. Macready, No Free Lunch Theorems for Search 3-5 (Feb. 6,
1995) (unpublished manuscript) (on file with the Sante Fe Institute).





n123.  The problems of unbalanced data have long been recognized in various
fields, such as statistics and econometrics, where a number of novel approaches
have been proposed to account for the data imbalance. See, e.g., S. R. Cosslett,
Maximum Likelihood Estimator for Choice-Based Samples, 49 Econometrica 1289
(1981); Vicente Garcia, Ramon Alberto Mollineda & Jose Salvador Sanchez, On the
k-NN Performance in a Challenging Scenario of Imbalance and Overlapping, 11
Pattern Analysis & Applications 269 (2007); Xu-Ying Liu, Jianxin Wu & Zhi-Hua
Zhou, Exploratory Undersampling For Class-Imbalance Learning, 39 IEEE
Transactions Sys., Man., & Cybernetics, Part B (Cybernetics) 539 (2009); Yuchun
Tang et al., Correspondence, SVMs Modeling for Highly Imbalanced Classification,
39 IEEE Transactions on Sys., Man., & Cybernetics, Part B (Cybernetics) 281
(2009); David P. Williams, Miranda S. Silvious Vincent Myers, Mine
Classification with Imbalanced Data, 6 IEEE Geoscience & Remote Sensing Letters
528 (2009).





n124.  Logistic regression, a variant of statistical linear regression used when
the dependent variable is not continuous but is instead a binary value (e.g.,
"yes/no"), is often used to predict the probability of an event on a range from
0 to 1. Alan Agresti, Categorical Data Analysis 115-116 (2013).





n125.  See Gary King & Langche Zeng, Explaining Rare Events in International
Relations, 55 Int'l Org. 693, 697 (2001); Jacqueline Cohen, Wilpen L. Gorr &
Andreas M. Olligschlaeger, Leading Indicators and Spatial Interactions: A
Crime-forecasting Model for Proactive Police Deployment, 39 Geographical
Analysis 105 (2007); Mapping and Analysing Crime Data (Alex Hirschfield & Kate
Bowers, eds., CRC Press 2003); The Influence of Technology on Social Network
Analysis and Mining 567 (Tansel Ozyer et al. eds., 2013).





n126.  See George Forman, Quantifying Trends Accurately Despite Classifier Error
and Class Imbalance, in Proc. 12th ACM SIGKDD Int'l Conf. on Knowledge,
Discovery & Data Mining 160 (2006). See also Thomas Oommen, Laurie G Baise &
Richard M. Vogel, Sampling Bias and Class Imbalance in Maximum-likelihood
Logistic Regression, 43 Mathematical Geosciences 99, 200 (2010).





n127.  Sampling bias occurs when researchers rely heavily on records that
contain more complete or relevant data, which creates a bias toward those people
or events that are the primary subject of the study, as they tend to have higher
degrees of data sufficiency and are more likely to be included. For example,
hidden bias tends to show up when studying diseases, because sicker patients
tend to have more data. See, e.g., Alexander Rusanov et al., Hidden in Plain
Sight: Bias Towards Sick Patients When Sampling Patients With Sufficient
Electronic Health Record Data For Research, 14 BMC Med. Informatics & Decision
Making 1, 1-2 (2014).





n128.  See, e.g., Hui Zhou & Wencal Du, Studying the Sampling Bias of Network
Topology Discovery, 15 Int'l Info. Inst. 193 (2012); Kenneth P. Burnham & David
R. Anderson, Model Selection and Inference: A Practical Information-Theoretic
Approach 32-35 (2nd ed. 2013); David A. Freedman, David Collier & Jasjeet S.
Sekhon, Statistical Models and Causal Inference: A Dialogue with the Social
Sciences 29 (2010); Yoav Freund, Laszlo Gyorfi & Gyorgy Turan, Sample Selection
Bias Correction Theory, in Algorithmic Learning Theory (Yoav Freund et al. eds.,
2008); Paul Gustafson, Measurement Error and Misclassification in Statistics and
Epidemiology: Impacts and Bayesian Adjustments 22-24 (2003).





n129.  See Gary M. Weiss & Foster Provost, Learning When Training Data are
Costly: The Effect of Class Distribution on Tree Induction, 19 J. Artificial
Intelligence Res. 315 (2003).





n130.  See Oommen, supra note 120, at 118.





n131.  See John Eligon & Timothy Williams, Police Program Aims to Pinpoint Those
Most Likely to Commit Crimes, N.Y. Times (Sept. 24, 2015),
http://www.nytimes.com/2015/09/25/us/police-program-aims-to-pinpoint-those-most-
likely-to-commit-crimes.html.





n132.  See Eugenio Alberdi et al., Why Are People's Decisions Sometimes Worse
With Computer Support?, 5775 Computer Safety 18, 19 (2009); J. Elin Bahner,
Monika F. Elepfandt & Dietrich Manzey, Misuse of Diagnostic Aids in Process
Control: The Effects of Automation Misses on Complacency and Automation Bias, 52
Proc. Hum. Factors & Ergonomics Soc'y 52nd Ann. Meeting 1330, 1330 (2008); See
John D. Lee & Katrina A. See, Trust in Automation: Designing for Appropriate
Reliance, 46 Hum. Factors 50, 76 (2004).





n133.  See Linda J. Skitka, Kathleen Mosier & Mark D. Burdick, Accountability
and Automation Bias, 52 Int'l J. Hum.-Computer Stud. 701 (2000); Mark D. Burdick
et al., The Ameliorating Effects of Accountability on Automation Bias, in Third
Ann. Symp. on Hum. Interaction with Complex Sys. HICS '96, at 142 (1996); Kate
Goddard, Abdul Roudsari & Jeremy C. Wyatt, Automation Bias: Empirical Results
Assessing Influencing Factors, 83 Int'l J. Med. Informatics 368 (2014); John D.
Lee & Katrina A. See, Trust in Automation: Designing for Appropriate Reliance,
46 Hum. Factors 50 (2004).





n134.  In addition to empirical studies on this topic, scholars have collected a
number of anecdotal examples of this phenomenon to better illustrate the point.
One of the earliest identified examples of this can be found in the 1983 Korean
Airlines (KAL) incident, in which Soviet fighters shot down a passenger
aircraft. Forensic examinations and experiments showed that the KAL crew had
grown complacent in their reliance on the aircraft's automated navigation
systems, and followed the systems' recommended headings rather than
cross-checking its results against other navigation methods, as is typically
required. Due to the crew's lack of vigilance and deep trust in the automated
systems, the flight path given by the automated navigation systems led the crew
into Soviet airspace. See Skitka et al., Does Automation Bias Decision-making?,
supra note 121, at 992.





n135.  See Skitka et al., Accountability and Automation Bias, supra note 136, at
702; see Skitka et al., Does Automation Bias Decision-making?, supra note 121,
at 993.





n136.  See Linda J. Skitka, Kathleen Mosier & Mark D. Burdick, Accountability
and Automation Bias, 51 Int'l J. Hum.-Computer Stud. 701, 702 (2000).





n137.  See, e.g., Raja Parasuraman & Dietrich H. Manzey, Complacency and Bias in
Human Use of Automation: An Attentional Integration, 52 Hum. Factors 381 (2010);
Robert J. de Boer, Wijnand Heems & Karel Hurts, The Duration of Automation Bias
in a Realistic Setting, 24 Int'l J. Aviation Psychol. 287 (2014); John M.
McGuirl & Nadine B. Sarter, Supporting Ttrust Calibration and the Effective Use
of Decision Aids by Presenting Dynamic System Confidence Information, 48 Hum.
Factors 656 (2006); Gregory P. Noone & Diana C. Noone, The Debate over
Autonomous Weapons Systems, 47 Case W. Res. J. Int'l L. 25 (2015); Erika Rovira
& Kathleen McGarry & Rajaj Paasuraman, Effects of Imperfect Automation on
Decision Making in a Simulated Command and Control Task, 49 Hum. Factors 76
(2007); William M. Crocoll & Bruce G. Coury, Status or Recommendation: Selecting
the Type of Information for Decision Aiding, 34 Proc. Hum. Factors Soc'y 1524
(1990); Mary L. Cummings, Automation Bias in Intelligent Time Critical Decision
Support Systems, Am. Inst. Aeronautics & Astronautics, AIAA 1st Intelligent
Systems Technical Conf. 1 (2004).





n138.  See Erika Rovira, et al., Effects of Imperfect Automation on
DecisionMmaking in a SimulatedCcommand and Control Task, 49 Hum. Factors 76
(2007).





n139.  See Gary Klein, Naturalistic Decision Making, 50 Hum. Factors 456 (2008).





n140.  See Mary L. Cummings, Automation Bias in Intelligent Time Critical
Decision Support Systems, Am. Inst. Aeronautics & Astronautics, AIAA 1st
Intelligent Systems Technical Conf. (2004).





n141.  Id.





n142.  See Erika Rovira, et al., Effects of Imperfect Automation on Decision
Making in a Simulated Command and Control Task, 49 Hum. Factors 76 (2007).





n143.  See Mary L. Cummings, Automation Bias in Intelligent Time Critical
Decision Support Systems, Am. Inst. Aeronautics & Astronautics, AIAA 1st
Intelligent Systems Technical Conf. 1 (2004). .





n144.  See P.A.J. Waddington, Community Policing, 1 Policing 129, 129-131
(2007).





n145.  See David L. Carter & Allen D. Sapp, Issues and Perspectives of Law
Enforcement Accreditation: A National Study of Police Chiefs, 22 J. Crim. Just.
195 (1994); George L. Kelling & Catherine M. Coles, Fixing Broken Windows:
Restoring Order And Reducing Crime In Our Communities (1997); Wesley G. Skogan,
Police and Community in Chicago: A Tale of Three Cities (2006).





n146.  Id.





n147.  See Peter W. Greenwood, Joan Petersilia & Jan M. Chaiken, The Criminal
Investigation Process 57-58 (1975); Jerome H. Skolnick, Justice Without Trial:
Law Enforcement in Democratic Society (2011).





n148.  See Victor E. Kappeler & Larry K. Gaines, Community Policing: A
Contemporary Perspective 180 (2012).





n149.  See Mike King, "Broken Windows," Urban Policing, and the Social Contexts
of Race and Neighborhood (Dis-)Empowerment, 21 Critical Criminology 533 (2013)
(reviewing Robert Sampson, "Great American City" (2012)); Jeffrey Fagan et al.,
Street Stops and Broken Windows Revisited: The Demography and Logic of Proactive
Policing in a Safe and Changing City, in Race, Ethnicity, and Policing: New and
Essential Readings 333 (Stephen K. Rice & Michael D. White eds., New York
University Press 2009).





n150.  Wesley G. Skogan, Broken Windows: Why - and How - We Should Take Them
Seriously, 7 Criminology & Pub. Pol'y 195, 198-200 (2008).





n151.  See William J. Chambliss, Policing the Ghetto Underclass: The Politics of
Law and Law Enforcement, 41 Soc. Probs. 177-81 (1994).





n152.  See Joshua C. Hinkle & Sue-Ming Yang, A New Look into Broken Windows:
What Shapes Individuals' Perceptions of Social Disorder?, 42 J. Crim. Just. 26
(2014); Robert J. Sampson & Stephen W. Raudenbush, Seeing disorder: Neighborhood
Stigma and the Social Construction of "Broken Windows", 67 Soc. Psychol. Q. 319
(2004); Ioanna Gouseti & Jonathan Jackson, Construal Level Theory and the Fear
of Crime, in Psychology of Crime, Fear and the Media 22 (Derek Chadee ed.,
2016).





n153.  Craig Paterson, 'Street-level Surveillance': Human Agency and the
Electronic Monitoring of Offenders, 4 Surveillance & Soc'y 314 (2007); William
J. Bratton & Sean W. Malinowski, Police Performance Management in Practice:
Taking COMPSTAT to the Next Level, 2 Policing 259, 259-65 (2008).





n154.  See generally Jeffrey Fagan & Garth Davies, Street Stops and Broken
Windows: Terry, Race, and Disorder in New York City, 28 Fordham Urb. L. J. 457
(2000); Yili Xu et al., Discovering the Impact of Community Policing: The Broken
Windows Thesis, Collective Efficacy, and Citizens' Judgment, 42 J. Res. Crime &
Delinq. 147 (2005).





n155.  See Richard L. Block, Fear of Crime and Fear of the Police, 19 Soc.
Probs. 91 (1971); William Bloss, Escalating US Police Surveillance After 9/11:
An Examination of Causes and Effects, 4 Surveillance & Soc'y 208 (2007); Peter
B. Kraska, supra note 84; Peter B. Kraska & Louis J. Cubellis, Militarizing
Mayberry and Beyond: Making Sense of American Paramilitary Policing, 14 Just. Q.
607 (1997).





n156.  See Michael Power, Evaluating the Audit Explosion, 25 Law & Pol'y 185,
187-89(2003).





n157.  See Craig Willse, "Universal Data Elements," or the Biopolitical Life of
Homeless Populations, 5 Surveillance & Soc'y 227 (2008) (describing how homeless
populations are quantified as data elements).





n158.  See Alistair Fraser & Colin Atkinson, Making Up Gangs: Looping, Labelling
and the New Politics of Intelligence-led Policing, 14 Youth Just. 154, 166-67
(2014) ("The cops most of the time tend to put this information into the
[intelligence] database and then we use our judgment maybe to put them in [a
gang] or not."); Craig Paterson, 'Street-Level Surveillance': Human Agency and
the Electronic Monitoring of Offenders, 4 Surveillance & Soc'y 314 (2007)
(discussing the adversarial relations between electronically monitored offenders
and their monitoring officials).





n159.  As originally envisioned in the early 1970s, the core community policing
concept requires police officers to develop a sensitivity to community signaling
regarding crime and disorder. Under this theory, this can only be done by
establishing police foot patrols in neighborhoods, so that individual police
officers can foster close working relationships with the citizens in those
communities. See P.A.J. Waddington, Editorial, Community Policing, 1 Policing
129 (2007) (evaluating the gaps between community policing theory and practice
and the attendant criticisms).





n160.  James J. Willis et al., Recommendations for Integrating Compstat and
Community Policing, 4 Policing 182, 182-83 (2010).





n161.  See Mengyan Dai & Richard R. Johnson, Is Neighborhood Context a
Confounder? Exploring the Effects of Citizen Race and Neighborhood Context on
Satisfaction with the Police, 32 Policing Int'l J. Police Strat. & Mgmt. 595
(2009) (exploring the effects of race and neighborhood on attitudes toward
police); Ioanna Gouseti, Construal Level Theory and Fear of Crime, in Psychology
of Fear, Crime and the Media (Derek Chadee ed., 2015) (examining levels of fear
of crime as they relate to a person's perceived psychological proximity to
crime); Yung-Lien Lai & Jihong Solomon Zhao, The Impact of Race/Ethnicity,
Neighborhood Context, and Police/Citizen Interaction on Residents' Attitudes
Toward the Police, 38 J. Crim. Just. 685 (2010) (a survey of public attitudes
toward police and police behavior, by race, ethnicity, and neighborhood); David
Weisburd et al., The Possible "Backfire" Effects of Hot Spots Policing: An
Experimental Assessment of Impacts on Legitimacy, Fear and Collective Efficacy,
7 J. Exp. Criminology 297, 300-301 (2011) (examining unintended side-effects of
hot spots policing, including an inflated fear of crime); David Weisburd & John
E. Eck, What Can Police Do to Reduce Crime, Disorder, and Fear?, 593 Annals Am.
Acad. Pol. & Soc. Sci. 42, 48-49 (2004) (studying various police techniques and
their effects on reducing crime and fear of crime).





n162.  See generally Pedro Domingos, The Master Algorithm: How the Quest for the
Ultimate Learning Machine Will Remake Our World (2015); Frank Pasquale, The
Black Box Society: The Secret Algorithms That Control Money and Information
(2015).





n163.  959 F. Supp. 2d 540, 560-62 (S.D.N.Y. 2013).





n164.  Id. at 556.





n165.  Id. at 559.





n166.  See David Weisburd & John E. Eck, What Can Police Do to Reduce Crime,
Disorder, and Fear?, 593 Annals Am. Acad. Pol. & Soc. Sci. 42, 50-51 (2004);
Bernard E. Harcourt, Reflecting on the Subject: A Critique of the Social
Influence Conception of Deterrence, the Broken Windows Theory, and
Order-Maintenance Policing New York Style, 97 Mich. L. Rev. 291, 295-96 (1998).
See also Jeremy D. Finn & Timothy J. Servoss, Misbehavior, Suspensions, and
Security Measures in High School: Racial/Ethnic and Gender Differences, 5 J.
Applied Res. on Child. 1, 2 (2015) (exploring the relationships between student
behavior, administrative discipline, race, and gender).





n167.  See generally David Dannels & Heather Smith, Implementation Challenges of
Intelligence Led Policing in a Quasi-rural County, 24 J. Crime & Just. 103
(2001) (examining the technological challenges facing small police departments,
often requiring a reliance on third-party contractors for installation,
training, and maintenance of intelligence systems).





n168.  See Andrew Gelman, Jeffrey Fagan & Alex Kiss, An Analysis of the NYPD's
"Stop-and-Frisk Policy" Policy in the Context of Claims of Racial Bias, 102 J.
Am. Stat. Ass'n 813 (2007).





n169.  See, e.g., Weisburd et al., The Possible "Backfire" Effects of Hot Spots
Policing, supra note 161, at 299-300.





n170.  Gelman, Fagan & Kiss, supra note 168, at 813-14.





n171.  See Linda J. Skitka, Kathleen Mosier & Mark D. Burdick, Accountability
and Automation bias, 52 Int'l J. Human-Computer Stud. 701 (2000).





n172.  Id. at 703-704. See also Mark D. Burdick et al., The Ameliorating Effects
of Accountability on Automation Bias, in Third Ann. Symp. on Hum. Interaction
with Complex Sys. HICS '96, at 174 (1996).





n173.  See Mary L. Cummings, Automation Bias in Intelligent Time Critical
Decision Support Systems, Am. Inst. Aeronautics & Astronautics, AIAA 1st
Intelligent Systems Technical Conf. 1 (2004).





n174.  Id. at 1-2.





n175.  See Christophe Giraud-Carrier, Beyond Predictive Accuracy: What?, in
Proc. ECML-98 Workshop Upgrading on Learning to Meta-Level: Model Selection &
Data Transformation 78 (1998),
http://dml.cs.byu.edu/cgc/pubs/ECML98%20WS%20Summa ry.html.





n176.  See James J. Willis et al., Recommendations for Integrating Compstat and
Community Policing, 4 Policing 182-93 (2010).


                               11 of 41 DOCUMENTS



                                   Iran Daily

                           September 23, 2016 Friday

Experts to create predictive tool to tackle hate crime in Los Angeles

LENGTH: 582  words


Experts from Cardiff University are developing a statistical tool that uses
social media to make real-time predictions of where hate crimes may occur.

The team, from the University's Social Data Science Lab, will be using Los
Angeles County as a test bed for their study, thanks to over $800,000 in funding
from the US Department of Justice, reported Phys.org.

It is the first time that social media has been used in the United States to
create predictive policing models of hate crime.

Over the next three years, the team will be closely scrutinizing data taken from
Twitter and cross-referencing this with reported hate crimes in Los Angeles to
develop markers, or signatures, which could indicate if, and where, a hate crime
is likely to take place at a certain point in time, and then enable police
officers to intervene.

The term hate crime is used to describe a prejudice-motivated crime, often
violent, which occurs when a perpetrator targets a victim because of his or her
affiliation to a social group, such as their sex, ethnicity, disability or
religion.

According to the US Bureau of Justice Statistics (BJS), in 2012 an estimated
293,800 nonfatal violent and property hate crime victimizations occurred in the
United States.

UK official data shows that there were 52,528 hate crimes recorded by the police
in England and Wales in 2014/15, an increase of 18 per cent compared with
2013/14.

Previous research from the Social Data Science Lab has already shown that
Twitter data can be used to identify hot spots, such as certain states or
cities, where hate speech has occurred but where hate crime has not been
reported. One example is an area when recent immigrants may be unlikely to
report crime due to fear of deportation.

Professor Matt Williams, from the University's School of Social Science, said:
"Developing a better understanding of hateful sentiments online and their
relationship with crime on the streets could push law enforcement to better
identify, report and address hate crimes that are occurring offline.

"The insights provided by our work will help US localities to design policies to
address specific hate crime issues unique to their jurisdiction and allow
service providers to tailor their services to the needs of victims, especially
if those victims are members of an emerging category of hate crime targets."

The Los Angeles Police Department has a history of incorporating progressive and
forward-thinking methods into their policing, having previously used
mathematical models to predict other areas of crime, which have been shown to
successfully lower crime rates.

The huge volumes of data that social media now generates has provided
researchers with large swathes of information that can be used to identify
emerging patterns and trends in a number of areas across society, including
crime.

Dr. Pete Burnap, from the University's School of Computer Science and
Informatics, said: "This is the first study in the United States to use social
media data in predictive policing models of hate crime. Predictive policing is a
proactive law enforcement model that has become more common partially due to the
advent of advanced analytics such as data mining and machine-learning methods.

"New analytic approaches and the ability to process very large data sets have
increased the accuracy of predictive models over traditional crime analysis
methods and this project will evaluate if police departments can leverage these
new data and techniques to reduce hate crimes."

LOAD-DATE: September 24, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper

JOURNAL-CODE: 1056


                 Copyright 2016 Iran Cultural & Press Institute
                Provided by Syndigate Media Inc.(Syndigate.info)
                              All Rights Reserved


                               12 of 41 DOCUMENTS

           Copyright (c) 2016 The Ohio State Journal of Criminal Law
                     The Ohio State Journal of Criminal Law

                                   Fall, 2016

                       Ohio State Journal of Criminal Law

                           14 Ohio St. J. Crim. L. 9

LENGTH: 10040 words

ARTICLE: Federal Civil Litigation as an Instrument of Police Reform: A Natural
Experiment Exploring the Effects of the Floyd Ruling on Stop-and-Frisk
Activities in New York City +





   + The authors are aware of the fact that the punctuation of the phrase
stop-and-frisk varies considerably by style guide. The Associated Press, for
example, calls for the words to be in quotations when used as a subject or
object noun phrase, while separating the words with hyphens when used as
compound modifier. But even the Associated Press is wildly inconsistent in how
their style guide is actually used. See Fev, Stopses and Friskses, HEADSUP BLOG:
THORTS AND COMMENTS ABOUT EDITING AND THE DESKLY ARTS (Aug. 12, 2013),
http://headsuptheblog.blogspot.com/2013/08/stopses-and-friskses.html. For the
sake of consistency and readability, we hyphenate the phrase all the time.

NAME: Michael D. White *, Henry F. Fradella **, Weston J. Morrow *** and Doug
Mellom ****

BIO:



   * Professor, School of Criminology and Criminal Justice, Arizona State
University; Associate Director, Center for Violence Prevention and Community
Safety, Arizona State University. Dr. White earned a Ph.D. in criminal justice
from Temple University in 1999.


   ** Professor and Associate Director, School of Criminology and Criminal
Justice, Arizona State University. Dr. Fradella earned a master's in forensic
science and a law degree from The George Washington University in 1993 and a
Ph.D. in justice studies from Arizona State University in 1997.


   *** Assistant Professor, Department of Criminal Justice, University of
Nevada, Reno. Dr. Morrow earned a Ph.D. in criminology and criminal justice from
Arizona State University in 2015.


   **** Doctoral student in the School of Criminology and Criminal Justice at
Arizona State University. Mr. Mellom earned an M.S. in criminal justice from the
University of Wisconsin, Milwaukee.

HIGHLIGHT:


     Stop-and-frisk has emerged as a popular crime control tactic in
     American policing. Though stop-and-frisk has a long, established legal
     history, the recent experiences in many jurisdictions demonstrate a
     strong disconnect between principle and practice. Arguably,
     stop-and-frisk has become the next iteration of a persistent
     undercurrent in racial injustice in American policing, perhaps best
     demonstrated by the recent police killings of Eric Garner, Michael
     Brown, and Freddie Gray--all during stop-and-frisk encounters. Recent
     events have facilitated a national dialogue on police accountability
     and police reform, and federal civil litigation has been central to
     that discussion. Although federal court relief can be pursued through
     a variety of avenues (most frequently by individuals or class actions
     under 42 U.S.C. § 1983 or by the U.S. Department of Justice pursuant
     to 42 U.S.C. § 14141), very little research has examined the impact of
     federal civil litigation on unconstitutional police practices. The
     current study examines the New York City confluence of racial
     injustice in policing, misuse of stop-and-frisk by officers, and
     federal civil litigation designed to precipitate police reform.
     Authors employ a natural experimental design to conduct a year-to-year
     comparison of stop-and-frisk activities and outcomes conducted by the
     NYPD in 2011, during the height of their stop-and-frisk program, and
     2014, one year after a federal court deemed the program
     unconstitutional and ordered reforms. Results show substantial
     improvement in stop-and-frisk practices following the federal civil
     litigation, including reduced prevalence and geographic concentration,
     as well as increased rates of arrest and weapon and contraband
     seizures. Moreover, crime continued to decline in New York as the NYPD
     reformed its stop-and-frisk program. Even though racial disparities in
     those subjected to stops by the NYPD persist, the overall findings
     show positive progress in New York and highlight the role of federal
     civil litigation as an instrument of police reform.


 TEXT:
 [*12]  I. INTRODUCTION

   Police authority to stop, question, and frisk citizens on the street has been
a controversial police practice for more than a century. Consider that in 1942,
Sam B. Warner, a member of the Interstate Commission on Crime, started his law
review article on the Uniform Arrest Act by noting that the law governing police
authority to stop, question, frisk, and arrest suspects "illustrates the
discrepancy between law in the books and the law in action."  n1 Since the early
1990s, this discrepancy has grown into a highly divisive controversy as a
function of a strong disconnect between how police authority to stop, question,
and frisk suspects is supposed to work in principle, and how it has actually
worked in practice.  n2

   On one hand, the practice is grounded in a historical and legal tradition
dating back hundreds of years. The basis of a police officer's authority to
stop, question, and frisk a suspicious person can be traced back to English
common law, as watchmen and private citizens had the authority to "arrest any
suspicious nigh-twalker, and detain him till he give a good account of himself."
n3 That common law approach to stop-and-frisk carried over to some United States
jurisdictions, although the legal authority for the practice was nebulous at
best.  n4 The lack of a clear legal framework for stop-and-frisk led the U.S.
Interstate Commission on Crime to draft the Uniform Arrest Act in 1939.  n5 That
model statute outlined nine different types of police-citizen contacts including
"[q]uestioning and detaining suspects" and "[s]earching suspects for weapons."
n6

   Litigation over various statutes authorizing stop-and-frisk led the U.S.
Supreme Court to formally establish stop-and-frisk as a constitutionally
permissible policing tactic in the landmark 1968 decision in Terry v. Ohio.  n7
In the Terry case, the Court held that police may temporarily detain and
question a citizen if the officer has reasonable, articulable suspicion that a
person may be involved in criminal activity.  n8 The Court also held that
officers may superficially search (frisk) a detained person if there is
reasonable, articulable suspicion that the person may be armed and dangerous.
n9 Since the Terry ruling, the Court has not only  [*13]  consistently
reaffirmed the constitutionality of stop-and-frisk, but also expanded officers'
authority during such stops.  n10

   On the other hand, police use of stop-and-frisk in numerous jurisdictions has
strayed dramatically from the principles set forth in Terry and its progeny.
n11 In some cases, police use of stop-and-frisk has been characterized by gross
overuse and misuse of the strategy, violations of citizens' Fourth and
Fourteenth Amendment rights, strained police-community relationships, low or no
police legitimacy, and significant emotional, psychological, and physical
consequences experienced by citizens.  n12 The New York City Police Department
("NYPD") epitomizes this story. In 1999, the Office of the New York State
Attorney General released a report that examined 175,000 stops and raised
serious questions about their constitutionality, as well as racial disparities
in those who were stopped.  n13 Allegations of racial discrimination in stops
conducted by the NYPD led to two federal lawsuits that mired the NYPD and its
stop-and-frisk program in federal court for more than a decade: Daniels v. City
of New York  n14 and Floyd v. City of New York.  n15 The controversy came to a
head in August 2013, when U.S. District Court Judge Shira Scheindlin ruled that
the NYPD's stop-and-frisk program was unconstitutional.  n16

   Allegations of racial discrimination in Terry stops have not been limited to
New York. In November 2010, the American Civil Liberties Union (ACLU) of
Pennsylvania filed a lawsuit in federal court alleging that the Philadelphia
Police  [*14]  Department was engaged in widespread racial profiling.  n17 A
report of the ACLU of New Jersey examined stop-and-frisk activities of the
Newark Police Department during the last half of 2013 and concluded: "Newark
police officers use stop-and-frisk with troubling frequency. . . . Black
Newarkers bear the disproportionate brunt of stop-and-frisks. . . . [and] [t]he
majority of people stopped [75%] are innocent."  n18 Similar stories have
unfolded in Detroit, Michigan; Chicago, Illinois; Miami Gardens, Florida; New
Orleans, Louisiana; and Pittsburgh, Pennsylvania, just to name a few of the more
prominent examples.

   The cases of Eric Garner in New York City, Michael Brown in Ferguson,
Missouri, and Freddie Gray in Baltimore, Maryland demonstrate the severe and
long-lasting consequences of mass stop-and-frisk programs: Garner, Brown, and
Gray died during encounters with the police that began as Terry stops. Their
deaths, among others, grabbed national headlines, produced widespread public
protest and civil disorder, led to a White House-driven initiative for police
reform, and fostered larger discussions about the mechanisms for responding to
and eliminating widespread racially discriminatory police practices--including
federal civil litigation.  n19

   Despite the controversy surrounding its stop-and-frisk program--and the
federal civil litigation it generated (the Daniels and Floyd cases)--NYPD
officers conducted more than 685,000 stops in 2011, most of which affected New
Yorkers from racial and ethnic minority backgrounds.  n20 In the year following
the Floyd ruling in August 2013 (when the program was deemed unconstitutional by
the federal court), newly-elected mayor William de Blasio dropped the City's
appeal of the ruling, appointed William Bratton as the new Police Commissioner,
and began working with Commissioner Bratton to implement the remedies ordered in
Judge Scheindlin's ruling.  n21 The recent developments in the NYPD
stop-and-frisk case allow the authors to employ a natural experimental design to
assess the impact  [*15]  of the federal civil litigation on stop-and-frisks in
New York during two years: in 2011, when the program was at its height, and in
2014, one year after the Floyd ruling. To do so, we employ descriptive
statistical analyses of NYPD stop-and-frisk data to explore changes in
prevalence, geographic concentration, outcomes (e.g., searches, arrests,
weapons, and contraband seized), and racial disparities among persons stopped.
We also examine crime trends in New York through 2014 to assess whether changes
in stop-and-frisk may have affected the NYPD's ability to fight crime. These
analyses allow us to draw inferences about the impact of the Floyd ruling on
stop-and-frisk practices in New York City. And given the dearth of empirical
research in this area, the current study also offers broader insights on the
potential for federal civil litigation to serve as an effective instrument of
police reform.

   Part II examines the origins of stop-and-frisk, as well as the relevant court
rulings that have shaped officers' authority to engage in temporary detention,
questioning, and frisking of citizens. Part III discusses the persistent
undercurrent of racial injustice in American policing, and highlights the
important context this undercurrent provides for considering the impact of
police use of Terry stops as a mass crime-control strategy. Part IV tells the
New York story, where the undercurrent of racial injustice, stop-and-frisk, and
federal civil litigation have collided for a period of more than two decades.
Part V provides an overview of the two primary mechanisms by which civil
litigation in federal court can be employed as an instrument of police reform
under 42 U.S.C. § 1983 and 42 U.S.C. § 14141. Part VI describes the methods
employed by the authors in the current study and Part VII details the results of
the year-to-year comparison of stop-and-frisk activities and outcomes. Part VIII
discusses the implications of the results for police reform in New York and
highlights the broader role of federal court litigation as an instrument of
police reform in 21st century policing.

   II. THE ORIGINS AND AUTHORITY OF STOP-AND-FRISK  n22

   A law enforcement officer's legal authority to detain and question a
suspicious person dates back to the common law of England. English common law
had very strict rules governing formal arrests.  n23 Legal proscriptions on
investigation of crime, however, were significantly more lax.

 [*16]  A. From English Common Law to the Uniform Arrest Act

   English constables and "watchmen" were permitted to detain
"night-walkers"--suspicious people encountered at night.  n24 Indeed, according
to Sir Matthew Hale's treatise on English common law, those on the night watch
could legally "arrest such as pass by until the morning, and if no suspicion,
they are then to be delivered [released], and if suspicion be touching them,
they shall be delivered to the sheriff."  n25 Even private citizens had the
authority to detain and question suspicious "night-walkers."  n26

   Until 1939, there was considerable variation in how U.S. law handled
police-initiated contacts with citizens that did not reach the level of arrest.
In some states, it was unclear if American common law, borrowing from its
English antecedents, conferred a right to detain and question suspects when the
requirements for a full arrest were clearly absent.  n27 In other jurisdictions,
the right to detain and question suspects was conferred on police by state
statute or by municipal ordinance.  n28 In these states, detentions for
questioning "were generally left to the discretion of individual officers and
were not subject to constitutional protections or judicial oversight."  n29
Inconsistency in state law came to be viewed as "entirely inadequate to meet the
modern needs for questioning and detaining suspects."  n30

   In 1939, the Interstate Commission on Crime authorized a study to examine how
arrests were made across the United States. The study examined the feasibility
of creating a model law that states could adopt to harmonize arrest practices
across the country and to bring the actions of police into alignment with
constitutional standards.  n31 Once drafted, that model law became known as the
Uniform Arrest Act. Its provisions dealt with nine types of police-initiated
contacts with citizens, the first two of which were "[q]uestioning and detaining
suspects" and "[s]earching suspects for weapons."  n32 Section 2 of the Uniform
Arrest Act provided: "A peace officer may stop any person abroad whom he has
reasonable ground to suspect is committing, has committed or is about to commit
a crime . . . . The total period of detention provided for by this section shall
not exceed two hours."  n33 Additionally, Section 3 of the Act stated that an
officer was  [*17]  permitted to conduct a "search for a dangerous weapon . . .
whenever he has reasonable ground to believe [a person stopped or detained for
questioning] . . . possesses a dangerous weapon."  n34

   In 1941, the legislatures of New Hampshire and Rhode Island adopted the
Uniform Arrest Act as the laws of their states.  n35 Delaware followed suit in
1951.  n36 Other states enacted statutes authorizing stop-and-frisk practices
that were not consistent with the Uniform Arrest Act.  n37 As a consequence,
considerable variation persisted across states with regard to stop-and-frisk
authority.  n38 Prompted by the need to clarify the scope of permissible conduct
during stop-and-frisk procedures (and, perhaps, concerns about how vagrancy and
loitering laws contributed to police infringements on constitutionally protected
liberty interests), the U.S. Supreme Court issues three landmark rulings in 1968
that set federal constitutional benchmarks for stop-and-frisk within the
framework of the Fourth Amendment: Terry v. Ohio  n39 and the companion cases of
Sibron v. New York and Peters v. New York.  n40 In the interest of brevity, the
next section summarizes only the key facts and holdings of these cases.  n41

 [*18]  B. Terry, Sibron, and Peters

   In Terry, Detective Martin McFadden testified that he observed two men while
on patrol. The Court summarized McFadden's observations as follows:


     He saw one of the men leave the other one and walk southwest on Huron
     Road, past some stores. The man paused for a moment and looked in a
     store window, then walked on a short distance, turned around and
     walked back toward the corner, pausing once again to look in the same
     store window. He rejoined his companion at the corner, and the two
     conferred briefly. Then the second man went through the same series of
     motions, strolling down Huron Road, looking in the same window,
     walking on a short distance, turning back, peering in the store window
     again, and returning to confer with the first man at the corner. The
     two men repeated this ritual alternately between five and six times
     apiece--in all, roughly a dozen trips. At one point, while the two
     were standing together on the corner, a third man approached them and
     engaged them briefly in conversation. This man then left the two
     others and walked west on Euclid Avenue. Chilton and Terry resumed
     their measured pacing, peering, and conferring. After this had gone on
     for 10 to 12 minutes, the two men walked off together, heading west on
     Euclid Avenue, following the path taken earlier by the third man.  n42


McFadden's observations led him to suspect that the men were planning to commit
a robbery in the store. He therefore approached the men and began to question
them. Fearing that they might be armed, he patted them down and recovered a
revolver on two of the men. McFadden arrested the men for illegal possession of
the firearms.

   In upholding their convictions, the U.S. Supreme Court made it clear that the
Fourth Amendment applies to stop-and-frisk activities.  n43 But "[i]nstead of
applying the probable cause standard to stops-and-frisks, the Court applied the
fundamental test of the Fourth Amendment: the reasonableness under all the
circumstances of the particular governmental invasion of a citizen's personal
security."  n44 In deciding to analyze the reasonableness of Officer McFadden's
[*19]  conduct, the Court approved a line of inquiry that is distinct from
questions of probable cause. Indeed, the Court analyzed the "reasonableness of
Officer McFadden's conduct as a general proposition" by balancing "the need to
search [or seize] against the invasion which the search [or seizure] entails."
n45 Moreover, the Court maintained that this balancing test depends on whether a
law enforcement officer can "point to specific and articulable facts which,
taken together with rational inferences from those facts, reasonably warrant
that intrusion."  n46 The Court then applied a similar balancing test to assess
the reasonableness of McFadden's search for weapons. In doing so, the Court
found the search to be permissible under the Fourth Amendment in large part
because of its limited nature--namely the "pat down" of the men's outer clothing
for weapons: "He did not conduct a general exploratory search for whatever
evidence of criminal activity he might find."  n47

   In Sibron, the defendant was convicted of the unlawful possession of heroin.
Over the course of several hours, a police officer observed the defendant
talking with "six or eight persons whom he (Patrolman Martin) knew from past
experience to be narcotics addicts."  n48 The officer did not hear any of the
conversations, nor did anyone ever pass anything to the defendant during these
conversations. Nonetheless, the officer subsequently approached Sibron and said,
"You know what I am after," prompting Sibron to reach into his pocket. That
action, in turn, caused the officer to reach into Sibron's pocket and retrieve
"several glassine envelopes" that contained heroin.  n49 The U.S. Supreme Court
overturned Sibron's conviction on the grounds that the officer's initial stop
was not supported by reasonable suspicion that Sibron was involved in any
criminal activity. So far as the officer knew, "they might indeed 'have been
talking about the World Series.' The inference that persons who talk to
narcotics addicts are engaged in the criminal traffic in narcotics is simply not
the sort of reasonable inference required to support an intrusion by the police
upon an individual's personal security."  n50 Moreover, the Court determined
that the officer lacked reasonable suspicion that Sibron was armed and
dangerous. In fact, the Court reasoned that the officer's "opening statement to
Sibron--'You know what I am after'--made it abundantly clear that he sought
narcotics" and did not believe that Sibron was reaching for a weapon.  n51

    [*20]  In Peters, an off-duty police officer heard strange noises outside
his apartment door. He investigated and observed two men he had never seen
before "tiptoeing" out of the apartment building in which the officer had lived
for 12 years. "Believing that he had happened upon the two men in the course of
an attempted burglary," the officer "opened his door, entered the hallway and
slammed the door loudly behind him. This precipitated a flight down the stairs
on the part of the two men, and [the officer] gave chase."  n52 The officer
patted down the men and found burglar's tools. The Court affirmed Peters'
conviction because the officer had probable cause to believe the men were
involved in an attempted burglary. In light of the existence of probable cause
to arrest, the search of Peters could be justified as a search incident to
arrest--a more complete search than the limited frisk/patdown for weapons
authorized under Terry.  n53

C. Key Court Cases After 1968

   Terry v. Ohio established the legal parameters for stop-and-frisk in the
United States. The Supreme Court revisited stop-and-frisk just over a decade
later. In two cases, Brown v. Texas  n54 and Ybarra v. Illinois,  n55 the Court
invalidated police actions and reinforced the narrow authority granted under
Terry. By the 1980s, however, courts began to interpret Terry as providing
significant leeway to law enforcement officers to conduct stops. Additionally,
the U.S. Supreme Court directed the lower courts to assess the validity of stops
based on "the whole picture"--or what came to be known as the "totality of the
circumstances."  n56 Perhaps more importantly, the Court told lower courts to
defer to the professional judgment and experience of police when assessing the
totality of the circumstances.  n57

   Throughout the 1980s, the U.S. Supreme Court exempted several classes of
stops from the usual requirements of Terry. For example, in United States v.
Mendenhall, the Court ruled that a stop had not occurred when federal agents
approached the defendant in the open concourse area of an airport.  n58 Because
the  [*21]  agents neither wore uniforms nor displayed weapons, and because they
requested--but did not demand--to see the defendant's ticket and identification,
the Court reasoned that the encounter did not constitute a stop that qualified
as a seizure for Fourth Amendment purposes, but rather a voluntary and
cooperative encounter because at no time should a reasonable person in the
defendant's situation have ever felt that she could not leave.  n59 Then, in
I.N.S. v. Delgado, the "free to leave" test morphed into something even more
restrictive on personal liberty: free to continue working and moving about a
factory while armed agents wearing badges roamed the premises questioning people
about their immigration status.  n60 The Court further narrowed Terry in Florida
v. Bostick when it clarified that law enforcement officers have the authority to
stop and ask basic investigatory questions--including requests to examine
identification or to search luggage of bus passengers--without there being a
seizure for Fourth Amendment purposes "as long as the police do not convey a
message that compliance with their requests is required."  n61 In short, Bostick
all but abandoned Mendenhall's free-to-leave test by changing the inquiry to one
of coercive police tactics through shows of authority.

   In other cases, the U.S. Supreme Court extended the authority of police to
conduct frisks. Consider that in Michigan v. Long, the Court permitted the
police to conduct a brief search of the passenger compartment of a car to look
for hidden weapons.  n62

   Perhaps most importantly, the Court has partially retreated from Sibron's
holding that reasonable suspicion needed to be based on more than just hunches.
In Alabama v. White, the Court upheld a stop of a vehicle based on an anonymous
tip even though there was no indication of the reliability of the tip.  n63
Michigan Department of State Police v. Sitz authorized sobriety checkpoints at
which police stopped drivers without any particularized suspicion of
driving-while-impaired.  n64 Vernonia School District 47J v. Acton upheld random
(i.e., suspicionless) drug testing of student athletes,  n65 and Board of
Education of Independent School Dist.  [*22]  No. 92 of Pottawatomie County v.
Earls extended that reasoning to uphold random drug testing of all students who
participate in any extracurricular activities.  n66 Illinois v. Wardlow approved
an inference of suspicion from flight  n67--an inference that logically extends
to any type of evasive behavior.  n68 Whren v. United States upheld pretextual
stops, thereby allowing police to conduct stops for minor infractions so they
could investigate other, more serious crimes.  n69 And because Minnesota v.
Dickerson approved of the so-called "plain feel" exception,  n70 police likely
have an incentive to frisk people even when they do not actually fear the
presence of a weapon, but rather hope to feel some drugs in the pat down--a
seemingly permissible pretext in light of Whren.  n71

   In sum, the Terry ruling in 1968 set the initial rules for stop-and-frisk.
Since 1980, Court rulings in most of the associated cases have expanded police
authority to stop, question, and frisk citizens. This expanded authority
undoubtedly increased the risk that officers would employ racial, ethnic, and
socio-economic class stereotypes as part of a calculus of suspicion to initiate
stop-and-frisk activities. The expansion of stop-and-frisk authority, and the
increased risk of racial profiling, is especially problematic when considering
the persistent undercurrent of racial injustice throughout nearly two centuries
of American policing.

   III. STOP-AND-FRISK AND THE UNDERCURRENT OF RACIAL INJUSTICE  n72

   An undercurrent of racial injustice and discrimination has served as a
backdrop in professional policing in the United States for the last 175 years.
n73 The larger race relation problems that have defined American policing
provide an  [*23]  important lens through which to view the rulings in Terry and
subsequent cases, as well as the increasing reliance on mass stop-and-frisk
programs in New York and elsewhere.

A. Racial Issues in Terry v. Ohio

   In his opinion in Terry v. Ohio, Chief Justice Warren noted that
stop-and-frisk activities by police contributed to racial strife:

        We would be less than candid if we did not acknowledge that this
     question thrusts to the fore difficult and troublesome issues
     regarding a sensitive area of police activity--issues which have never
     before been squarely presented to this Court. Reflective of the
     tensions involved are the practical and constitutional arguments
     pressed with great vigor on both sides of the public debate over the
     power of the police to "stop and frisk"--as it is sometimes
     euphemistically termed--suspicious persons.  n74

   The opinions in Terry, however, omitted or glossed over several important
facts relevant to the racial issues underlying the case. Indeed, nowhere in any
of the opinions in Terry does any justice mention that both Terry and Chilton
were black men.  n75 Nor does any justice mention that Katz, who was white, was
not charged; he was held as a "suspicious person" and released after two days.
n76 According to the transcript of the trial court's suppression hearing in
Terry, Officer McFadden testified that when he saw the men standing on the
street, "they didn't look right to [him] at the time."  n77 Criminologists
Delores Jones-Brown and Brian Maule suggested that McFadden's attention may have
been drawn to the men on account of their race.  n78 This conclusion is
bolstered by a number of ambiguities and inconsistencies in Officer McFadden's
account of the case, as law professor Lewis R. Katz explained:


     [McFadden] was not acquainted with either man by name or sight, and he
     had received "[a]bsolutely no information regarding [the] men at all."
     Officer McFadden did not explain what about the two men "didn't look
     right" to him. The two men were dressed in topcoats, the standard
     dress  [*24]  of the day. They were engaged in no unusual behavior
     when they initially attracted McFadden's attention. When pressed on
     what about the two men attracted his interest and whether he would
     pursue them as he did if he saw them that day across from the
     courthouse, Officer McFadden replied, "I really don't know."

        What happened as McFadden studied Terry and Chilton depends upon
     which version of Officer McFadden's statement of the facts one reads
     and in which court opinion the facts appear. McFadden watched the men
     over a period ten minutes. He watched as one of the two men left the
     other and walked down the street and looked inside a shop window and
     continued walking, and then walked back to the other man, again
     looking in the shop window. The second man then repeated the same
     behavior. That behavior is the critical conduct which gives rise to
     the stop in this case. If they did it once or twice each, their
     behavior was pretty unremarkable. So, how many times they looked in
     the store window is crucial. In the police report filed the same day
     as the incident, Officer McFadden wrote that the men did this "about
     three times each." Between the day of the event when he wrote the
     police report and his memory was freshest, and the suppression
     hearing, which was almost one year to the day after the event, Officer
     McFadden's memory changed. At the suppression hearing three times each
     became "at least four or five times apiece," which later turned into
     four to six trips each. Moreover, at trial, when asked how many trips
     he observed, Officer McFadden replied, "about four trips, three to
     four trips, maybe four to five trips, maybe a little more, it might be
     a little less. I don't know, I didn't count the trips." The Ohio Court
     of Appeals decision in the case picked up on the uncertainty and
     asserted that the men separated and looked in the window "at least two
     to five times" each. However, by the time the fact worked its way into
     Chief Justice Warren's majority opinion in the Supreme Court, the
     number expands exponentially. He wrote that the men did this "between
     five or six times apiece--in all roughly a dozen trips." Later in the
     majority opinion, Chief Justice Warren came up with still another
     number when he described Terry and Chilton's behavior: "where these
     men pace alternately along an identical route, pausing to stare in the
     same store window roughly twenty-four times." The body of law which
     stems from Terry is dependent upon this single fact.

        Officer McFadden was never sure which store was the subject of the
     suspects' attention. At the suppression hearing he admitted he had no
     experience in observing the activities of individuals who were
     "casing" a store for a robbery. In the police report, Officer McFadden
     indicated that  [*25]  they were looking in an airline ticket office;
     at the suppression hearing, the Detective mentioned an airline office
     or a jewelry store.  n79

   In light of these facts--McFadden's inability to explain why he was initially
suspicious of the men, the ever-changing number of trips the men made up and
down the street, and the uncertainty of the type of store into which the men
were looking--the reasonableness of the initial stop appears to be more open to
debate than the Terry decision suggests. The failure of the Court to address the
questionable reasonableness of the stop in Terry illustrates how the very
foundation of the reasonable suspicion standard in American constitutional law
masks racially disparate stop-and-frisk practices with the cloak of
race-neutrality.  n80

B. Racial Issues Throughout American Policing

   Police scholars George Kelling and Mark Moore developed a widely cited
historical framework that contextualizes 150 years of police history into three
eras: political, reform, and community problem-solving.  n81 Though the Kelling
and Moore framework is useful for examining police history, it has been
criticized for overlooking the role of racism in professional policing. Hubert
Williams and Patrick Murphy, for example, argue that the origins of American
policing are rooted in slave patrols in the South, and that the advances that
have occurred through the "reform" and "community problem-solving" eras excluded
minority citizens.  n82 In effect, as policing progressed through the political,
professional and community problem-solving eras, the minority community was left
behind. Williams and Murphy referred to this as the "minority view" of policing.

   Kelling and Moore published their framework in the late 1980s, but the
experiences of numerous agencies with stop-and-frisk suggest that Williams and
Murphy's "minority view" of policing is still a stark reality. The Philadelphia
Police Department (PPD) stopped more than 250,000 citizens in 2009, prompting
the American Civil Liberties Union of Pennsylvania (ACLU-PA) to file a federal
lawsuit in November 2010.  n83 The lawsuit, Bailey v. City of Philadelphia,
alleged that the PPD was engaged in racial profiling. The litigation resulted in
a settlement agreement between the plaintiffs and the Philadelphia Police
Department that centered on quarterly analysis of stop data by the ACLU-PA,
appointment of an  [*26]  independent monitor, retraining of officers, and new
protocols governing stop-and-frisk practices.  n84 The ACLU-PA subsequently
reported to the court and the settlement monitor that although the number of
stops had declined by 15%,  n85 there had been


     no significant improvement in the quality of stops and frisks. By our
     analysis, pedestrian stops are being made without reasonable suspicion
     in approximately 43-47% of the cases . . . . Frisks are being
     conducted without reasonable suspicion in over 45% of the cases . . .
     . By race, 76% of the stops were of minorities (African-Americans and
     Latinos) and 85% of the frisks were of minorities. The findings as to
     impermissible stops and frisks are particularly disturbing given the
     fact that the Police Department had the time and resources following
     the entry of the Agreement to re-train its officers on stop and frisk
     practices and to establish supervisory reviews to ensure
     accountability for practices that failed to meet clear mandates under
     the Agreement.  n86

   The ACLU-PA's most recent report (as of the writing of this article)
continues to raise questions about the PPD's use of Terry stops. The 2015 report
found that 37% of stops lacked reasonable suspicion; contraband was only found
in 2% of stops and 5% of frisks; and blacks comprised approximately 72% and 79%
of all stops and frisks, respectively, while they made up only 43% of
Philadelphia's population.  n87

   In 2013, the American Civil Liberties Union of New Jersey (ACLU-NJ) evaluated
six months of stop-and-frisk practices in Newark. According to the ACLU-NJ, the
Newark Police Department conducted an average of 2,093 stops per month from July
to December 2013.  n88 The authors note that this translates to a rate of 91
stops per 1,000 residents, a stop rate that was eleven times greater than the
NYPD stop rate during the same time period.  n89 The ACLU-NJ report also
discovered racial disproportionality in stops, as Blacks represented 52% of the
[*27]  population but 75% of those who were stopped by Newark police.  n90 An
investigation into Terry stops by the Miami Gardens Police Department found
that, from 2008-2013, officers had stopped 65,328 individuals, and nearly 1,000
citizens had been stopped 10 or more times.  n91 In 2015, the American Civil
Liberties Union of Illinois (ACLU-IL) published a report claiming that the
Chicago Police Department had "failed to train, supervise and monitor law
enforcement in minority communities for decades, resulting in a failure to
ensure that officers' use of stop and frisk is lawful."  n92 These
stop-and-frisk stories are consistent with Williams and Murphy's "minority view"
and demonstrate the perpetuation of the undercurrent of racial injustice in
American policing.  n93

   Also consider the highly publicized deaths of Eric Garner, Michael Brown, and
Freddie Gray--all of which involved Terry stops. On July 17, 2014, NYPD officers
approached Eric Garner on a street corner in Staten Island because they
suspected that he was selling unlicensed cigarettes.  n94 The incident was
captured on a bystander's cell phone. After brief questioning, officers
attempted to take Garner, a 400-pound man, into custody. During the struggle,
Officer Daniel Pantaleo applied a chokehold and Garner can be heard stating
nearly a dozen times that he cannot breathe. Garner lost consciousness after the
struggle; he was pronounced dead an hour later. Five months later, a grand jury
refused to indict Officer Pantaleo, sparking waves of protests.  n95

   On August 9, 2014, Ferguson police officer Darren Wilson observed Michael
Brown and Dorian Johnson walking in the middle of the street. There is no video
of the incident and the facts are disputed, but what is clear is that the
initial stop of Brown and Johnson led to a struggle between Wilson, who was
still seated in his patrol car, and Brown, who was next to the car.  n96
Physical evidence supports Officer Wilson's assertion that there was a struggle
over Wilson's gun and that one  [*28]  shot was fired while he was still in his
car.  n97 Wilson got out of the patrol car and fired several more shots that
killed Michael Brown. Officer Wilson claimed that Brown had turned and was
charging at him. Other testimony indicated that Brown had his hands up and was
posing no threat to Wilson.  n98 Protests and civil disorder began shortly after
Brown's death and continued for several days. On August 16, 2014, Missouri
Governor Jay Nixon declared a state of emergency in Ferguson. On November 24,
2014, a grand jury declined to indict Officer Wilson for Michael Brown's death.
n99

   On April 12, 2015, Baltimore police officers attempted to stop and question
Freddie Gray. Gray fled from the officers, but he was quickly taken into custody
and arrested for possessing an illegal switchblade. During his transport in a
police van, Gray slipped into a coma and died several days later on April 19th.
n100 Autopsy findings indicate that Gray died from injuries to his spinal cord.
n101 Though there are questions about whether force was used during the arrest,
Baltimore Police Commissioner Anthony Batts acknowledged that Freddie Gray was
not properly secured during the van transport. Protests and civil disorder
erupted after Gray's death. On May 1, 2015, six officers were charged with
Freddie Gray's death by the State Attorney's Office, and on May 21, 2015, a
grand jury indicted the six officers.  n102 A mistrial was declared in the first
trial of one of the officers after the jury failed to reach a unanimous verdict.
n103

   The numerous allegations of racial profiling that have emerged in the wake of
stop-and-frisk programs, and the deaths of Eric Garner, Michael Brown, and
Freddie Gray demonstrate the persistent undercurrent of racial injustice in
American policing--or what Williams and Murphy termed the "minority view" of
[*29]  policing.  n104 Although many U.S. cities continue to struggle with
racial and ethnic tensions in police-citizen relationships, the unique ways in
which stop-and-frisk was implemented in New York contributed to that particular
city having one of the most vexing and persistent problems with policing
communities of color.

   IV. STOP-AND-FRISK AND THE NYPD

   The NYPD story demonstrates how use of stop-and-frisk as a widespread
crime-control strategy can go terribly wrong, leading to the violation of the
constitutional rights of thousands of mostly minority New York City residents
for a period of nearly twenty years. The story represents a collision between a
constitutionally permissible tactic used in an unconstitutional manner, the
persistent undercurrent of racial injustice in policing, and an effort to use
federal civil litigation as a mechanism to force police reform. The next section
describes how this collision developed.

A. Crime, Disorder, and Broken Windows

   New York City, like many cities across the United States, experienced a major
spike in violence, crime, and disorder in the 1980s.  n105 Much of the violence
in New York was driven by the emergence of crack cocaine and competition for the
drug market.  n106 Homicides climbed steadily from 1,392 in 1985 to 2,262 in
1990.  n107 At the same time, the city and subway system were struggling with
rampant social and physical disorder.  n108 Marijuana, heroin, cocaine, and
crack cocaine were regularly and openly being sold on street corners, blocks,
and city parks.  n109 Kelling and Coles estimated that "[a]pproximately 1,200 to
2,000 persons a night" were sleeping in the subway system.  n110

[*30]  The New York Transit Authority appointed William Bratton as chief of the
transit police to address crime and disorder in the subway system.  n111 Chief
Bratton partnered with criminologist George Kelling to develop an enforcement
strategy (based on Wilson and Kelling's "broken windows" theory  n112) that
targeted low-level offenses (e.g., turnstile jumping), as well as social and
physical disorder through frequent arrests and removals from the subway system.
n113 Broken windows theory posits that minor forms of social and physical
disorder cause a breakdown in informal social control as citizen investment in
an area diminishes.  n114 As citizens withdraw from the area, the level of
disorder increases and the risk for more serious types of crime to emerge
becomes greater.  n115 The theory suggests that police focus enforcement efforts
on disorder and quality-of-life offenses as a mechanism for reengaging
law-abiding citizens' commitment to the area.  n116 Under Chief Bratton, the
transit police adopted a broken windows-based strategy in the subway system.
Over the next two years, the level of disorder dropped dramatically, and felony
offenses declined by 30%.  n117

   In 1993, New York City Mayor Rudolph Giuliani appointed William Bratton as
the Commissioner of the NYPD, and Bratton immediately began implementation of a
broken-windows based strategy throughout New York.  n118 Two policy initiatives
defined the NYPD crime-control strategy. First, Reclaiming the Public Spaces of
New York outlined the broken windows theory and articulated an order maintenance
strategy that targeted disorder and quality-of-life offenses through systematic
and aggressive enforcement strategies (e.g., replicating the subway strategy).
n119 Second, Getting Guns off the Streets of New York  n120 outlined  [*31]  the
NYPD's strategy to reduce gun violence through the seizure of illegal firearms
and through the intensive investigation of gun-related incidents.  n121

   Stop-and-frisk emerged as the primary tactic to meet the objectives of both
policy initiatives.  n122 Over the next several years, critics argued that
police over-enforced quality-of-life infractions through a zero-tolerance
approach because officers could easily justify the stops under the reasonable
suspicion standard.  n123 As Waldeck states, there is not "any doubt that the
police use quality-of-life offenses as excuses to fish for drugs, guns, or
evidence of a more serious crime."  n124 The effects of the stop-and-frisk
program were immediate. From 1993 to 1996, arrests rose by 23%, including a 40%
increase in misdemeanor arrests and a 97% increase in drug arrests.  n125 The
NYPD made approximately 40,000 gun-related arrests over a three-year period,
resulting in the removal of more than 50,000 guns from the streets.  n126
Stop-and-frisk also produced a large increase in arrests for marijuana
possession. In 2006, Geller and Fagan reported that there were 32,000 arrests
for marijuana possession, marking a 500% increase from the previous decade.
n127

   The NYPD's use of stop-and-frisk increased steadily in the late 1990s into
the twenty-first century. In 2003, for example, NYPD officers conducted more
than 160,000 stop-and-frisks of citizens.  n128 In 2003, the NYPD implemented
Operation Impact, a hot spots strategy where police commanders identified twenty
four high-crime "Impact Zones" that would be targeted with "saturation foot
patrol in combination with resources from a variety of departmental divisions."
n129 Stop-and-frisk activity increased dramatically over the next several years,
peaking at  [*32]  more than 685,000 in 2011.  n130 As the frequency of stops
increased, critics attacked the strategy's low rates of return. Jones-Brown and
colleagues found that of the 540,320 stops in 2008, just 6% (32,206 stops)
resulted in an arrest and an additional 6.4% (34,802 stops) resulted in a
summons; thus, the percentage of "innocent stops"--those not resulting in
summons or arrest--accounted for roughly 87.6%.  n131 Similarly, the percentage
of stops resulting in the recovery of a gun dropped by 60% from 0.39% (627 guns
recovered out of a total of 160,851 stops) in 2003 to 0.15% in 2008 (824 guns
recovered out of a total of 540,320 stops).  n132 Furthermore, the percentage of
citizen complaints involving stops increased from 24.6% in 2004 to 32.7% in
2008.  n133

   As the use of stop-and-frisk expanded dramatically, the NYPD drifted away
from the central tenets of broken windows theory, and the program devolved into
a strictly zero-tolerance approach against social disorder such as public
drunkenness, vandalism, loitering, panhandling, prostitution, and the like.
n134 In other words, rather than focusing on the "amelioration of physical
disorder" in partnership with the community, the NYPD focused on "interdiction
of social disorder."  n135 These efforts led the NYPD to implement a set of
practices that encouraged the aggressive pursuit of individuals through
stop-and-frisks, rather than mutually beneficial interactions with law-abiding
citizens.  n136 This zero-tolerance mentality compounded the police department's
disconnect from the community in a number of important ways. First, the NYPD
focused less on preventing disorder and alternatives to arrest, and more on
aggressively removing weapons and wanted criminals from the community.  n137
Second, the NYPD de-emphasized informal interactions between police and the
community in the manner advocated by both community policing principles and
broken windows theory.  n138 The lack of police-community engagement was driven
in large part by the management style that Bratton embraced from the private
sector.  n139 This management style stressed  [*33]  innovative approaches on
management accountability, prioritization, and data-driven decision-making.
n140 One of the primary structural modifications to emerge from this management
system was Compstat, a system "defined by timely and accurate information, rapid
deployment of resources, effective tactics, follow-up, and assessment."  n141
Essentially, instead of identifying community needs through engagement with
residents, the NYPD determined community needs through its own data-driven
accountability system (i.e., Compstat).

B. Crime Control Benefits

   During the same time that the NYPD implemented its order-maintenance strategy
to target disorder, illegal gun carrying, and crime (with stop-and-frisk as a
central feature), the city witnessed a large, prolonged drop in crime. From the
mid-1990s to the mid-2000s, street crime in New York City declined approximately
75%--a decrease roughly twice the national average.  n142 In 2007, there were
496 homicides in New York, down from more than 2,200 in 1990.

   Proponents of stop-and-frisk point to New York City's crime decline over the
last two decades as evidence that the tactic is effective. For example, former
NYPD Commissioner Raymond Kelly touted stop-and-frisk at a news conference by
saying:


     Police stops are just one component of multiple efforts by the
     Department that have saved lives and driven the murder rate to record
     lows. In the first 11 years of Mayor Bloomberg's tenure there were
     7,363 fewer murders in New York City compared to the 11 years prior to
     the Mayor taking office.  n143

   Former New York City Mayor Michael Bloomberg similarly praised the
effectiveness of stop-and-frisk in combatting crime, stating: "New York is the
safest big city in the nation, and our crime reductions have been steeper than
any  [*34]  other big city's. For instance, if New York City had the murder rate
of Washington, D.C., 761 more New Yorkers would have been killed last year."
n144

   Whether stop-and-frisk caused or contributed to the crime decline in New York
City is a hotly contested proposition.  n145 Several studies have suggested a
causal connection. Corman and Mocan reported that misdemeanor arrests were
associated with declines in robbery, motor vehicle theft, and grand larceny, but
not homicide, assault, burglary, and rape.  n146 Similarly, Kelling and Sousa
found that misdemeanor arrest levels were significantly associated with
reductions in violent crime, while controlling for several relevant community
factors.  n147 Smith and Purtell found that Operation Impact had a significant
effect on crimes-against-persons in Impact Zones.  n148 Smith and Purtell also
examined the effects of stop-and-frisk on crime in New York, and they found that
there was a significant inverse relationship between stop rates and robbery,
burglary, motor vehicle theft, and homicides rates.  n149 Zimring argued that
New York's crime decline from 1990 through 2009 was largely attributable to the
NYPD's policing practices.  n150

   Conversely, there are a number of studies indicating that the relationship
between stop-and-frisk and the crime decline in New York City is modest at best.
n151 For instance, Rosenfeld and Fornango found that police stops did not  [*35]
decrease robbery and burglary rates.  n152 In a re-analysis of Kelling and
Sousa's data, Harcourt and Ludwig found no significant relationships between
policing minor disorder offenses and New York City's crime decline.  n153
MacDonald and colleagues conducted a comprehensive examination of the crime
effects of Operation Impact (with a specific focus on stop-and-frisk). They
concluded:


     Impact zones were significantly associated with reductions in total
     reported crimes, assaults, burglaries, drug violations, misdemeanor
     crimes, felony property crimes, robberies, and felony violent crimes.
     Impact zones were significantly associated with increases in total
     reported arrests, arrests for burglary, arrests for weapons, arrests
     for misdemeanor crimes, and arrests for property felony crimes. Impact
     zones were also significantly associated with increases in
     investigative stops for suspected crimes, but only the increase in
     stops made based on probable cause indicators of criminal behaviors
     were associated with crime reductions. The largest increase in
     investigative stops in impact zones was based on indicators of
     suspicious behavior that had no measurable effect on crime. The
     findings suggest that saturating high crime blocks with police helped
     reduce crime in New York City, but that the bulk of the investigative
     stops did not play an important role in the crime reductions. The
     findings indicate that crime reduction can be achieved with more
     focused investigative stops.  n154


C. The Social Costs

   Regardless of the impact on crime, there is considerable evidence
demonstrating that the NYPD's stop-and-frisk program exacted significant social
costs that were disproportionately experienced by ethnic minorities. By the end
of the 1990s, stop-and-frisk had become a point of contention among ethnic
minorities. A Vera Institute of Justice study examined the experiences of more
than 500 people who had been stopped by the NYPD:


      [*36]  1) 44% of young people surveyed indicated they had been
     stopped repeatedly--9 times or more.
     2) Less than a third--29%--reported ever being informed of the reason
     for a stop.
     3) 71% of young people surveyed reported being frisked at least once,
     and 64% said they had been searched.
     4) 45% reported encountering an officer who threatened them, and 46%
     said they had experienced physical force at the hands of an officer.
     5) One out of four said they were involved in a stop in which the
     officer displayed his or her weapon.
     6) 61% stated that the way police acted towards them was influenced by
     their age.
     7) 51% indicated that they were treated worse than others because of
     their race and/or ethnicity.  n155


A study by Fagan and colleagues on stop-and-frisk in New York City identified
three noteworthy findings:


     First, stops within neighborhoods take place at rates in excess of
     what would be predicted from the separate and combined effects of
     population demography, physical and social conditions, and the crime
     rate. This excess seems to be concentrated in predominately Black
     neighborhoods. Second, the excess stops in these neighborhoods persist
     over time, even as the Black population declines, crime rates remain
     low and effectively unchanged, the City's overall social and economic
     health improves, and housing and other investments increase across the
     City's neighborhoods, including its poorest and most segregated
     neighborhoods. Third, there appears to be a declining return in crime
     detection from marginal increases in enforcement, and this efficiency
     gap seems to grow over time.  n156

   The racial focus of the NYPD's stop-and-frisk program was acknowledged (and
minimized) by city and police department leaders.  n157 Former Mayor Michael
[*37]  Bloomberg stated publicly that, according to the department's statistics
on violent crime suspects, "we disproportionately stop whites too much and
minorities too little."  n158 In 2013, an officer in the 40th precinct recorded
his commanding officer directing him to stop "the right people, at the right
time, at the right location," described as "male blacks, 14 to 20, 21."  n159
The Center for Constitutional Rights (CCR) interviewed 54 people who had been
subjected to stop-and-frisk in order to paint a clearer picture of the "human
impact" of the stop-and-frisk program. The CCR concluded:


     These interviews provide evidence of how deeply this practice impacts
     individuals and they document widespread civil and human rights abuses
     . . . . The effects of these abuses can be devastating and often leave
     behind lasting emotional, psychological, social, and economic harm. .
     . . Residents of some New York City neighborhoods describe a police
     presence so pervasive and hostile that they feel like they are living
     in a state of siege.  n160


The overt racially charged statements by city and police leaders, along with
clear racial disproportionality in the administration of the stop-and-frisk
program, illustrates the persistent undercurrent of racial injustice in New York
City policing, and provides an important backdrop for the federal litigation
accusing the NYPD of racially-discriminatory policing.

   V. FEDERAL CIVIL LITIGATION AS AN INSTRUMENT OF POLICE REFORM

   Given the decentralized nature of law enforcement in the United States, the
federal courts are often called upon to address allegations of widespread
unconstitutional police practices, such as discriminatory stop-and-frisk
practices.  n161 There are several avenues through which federal court relief
from unconstitutional  [*38]  police practices can be pursued, the two most
frequently used of which are civil lawsuits filed pursuant to either 42 U.S.C. §
1983 or 42 U.S.C. § 14141.

A. Section 1983

   Section 1983 of the Civil Rights Act of 1871 provides civil and criminal
remedies for individuals whose constitutional rights are violated by persons
acting under state authority.  n162 Enacted largely in response to growing
domestic terrorism by the Ku Klux Klan, the Act provides:


     Every person who, under color of any statute, ordinance, regulation,
     custom, or usage, of any State or Territory or the District of
     Columbia, subjects, or causes to be subjected, any citizen of the
     United States or other person within the jurisdiction thereof to the
     deprivation of any rights, privileges, or immunities secured by the
     Constitution and laws, shall be liable to the party injured in an
     action at law, suit in equity, or other proper proceeding for
     redress[.]  n163


Section 1983, introduced by Rep. Samuel Shellabarger (R., Ohio), "was the
subject of only limited debate and was swiftly passed without amendment."  n164
Its primary purpose was to provide a mechanism for private persons to enforce
the rights secured by the Fourteenth Amendment.  n165 Although it has been
amended a few times since its passage, the language of the Act today remains
"essentially unchanged" from the original.  n166

   Section 1983 was hardly used from the time of its enactment until the early
1960s.  n167 In 1961, the U.S. Supreme Court decided Monroe v. Pape.  n168 That
case upheld the authority of the plaintiff to use § 1983 as a jurisdictional
basis for suing police officers who had allegedly conducted an illegal search of
his home in  [*39]  violation of the Fourth Amendment.  n169 Notably, the Court
refused to allow the lawsuit to proceed against the City of Chicago as the
employer of the officers, reasoning that Congress had not intended the word
"person" in § 1983 to apply to municipalities.  n170 Of particular relevance to
this article, however, the Court reversed itself on this key issue in the 1978
case of Monell v. Department of Social Services of the City of New York:  n171


        Our analysis of the legislative history of the Civil Rights Act of
     1871 compels the conclusion that Congress did intend municipalities
     and other local government units to be included among those persons to
     whom § 1983 applies. Local governing bodies, therefore, can be sued
     directly under § 1983 for monetary, declaratory, or injunctive relief
     where, as here, the action that is alleged to be unconstitutional
     implements or executes a policy statement, ordinance, regulation, or
     decision officially adopted and promulgated by that body's officers.
     Moreover, although the touchstone of the § 1983 action against a
     government body is an allegation that official policy is responsible
     for a deprivation of rights protected by the Constitution, local
     governments, like every other § 1983 "person," by the very terms of
     the statute, may be sued for constitutional deprivations visited
     pursuant to governmental "custom" even though such a custom has not
     received formal approval through the body's official decisionmaking
     channels.  n172


Importantly, municipal practices and customs are so broadly defined in Monell
that the terms include whatever the agency does routinely, whether stated in
official policy or not, such that the practice amounts to a custom or usage that
is tantamount to formal law or policy.  n173

   If a number of people have been aggrieved by state actors whose conduct falls
within a municipal policy, practice, or custom, those plaintiffs' § 1983
lawsuits may be certified as a class action under Federal Rule of Civil
Procedure 23(b)(2).  n174 Such class action lawsuits play a critical role in the
enforcement of civil rights. If the plaintiffs are able to establish the
requirements to be certified as  [*40]  a class, as they were in Floyd, they can
present evidence to the court and seek federal injunctive relief against a law
enforcement agency.  n175

   Perhaps because § 1983 claims against municipalities can seek both injunctive
relief and monetary remedies, the decision in Monell led to a dramatic increase
in civil litigation against police because it "opened the 'deep pockets' of
government treasuries to civil rights plaintiffs."  n176 For example, from
1986-1990, the City of Los Angeles paid more than $ 20 million in civil
litigation against police officers.  n177 In 2001, the State of New Jersey paid
$ 12.95 million to plaintiffs in a racial profiling lawsuit against the New
Jersey State Police.  n178 Professors Marc Miller and Ronald Wright reported
that although some of these settlements garner intense media attention,
municipalities quietly settle many more lawsuits than people generally assume,
the majority of which involve "secret settlements" that are filed under seal.
n179

   There have been few evaluations of the impact of § 1983 lawsuits on police
misconduct.  n180 Criminologist Candace McCoy argues that federal lawsuits have
led to improved police practices because of the unique role of insurance
carriers.  n181 That is, in the wake of the Monell ruling, many law enforcement
agencies sought to reduce their exposure to lawsuits by securing liability
insurance.  n182 "But insurance companies would not offer attractively priced
policies if police agencies could not demonstrate that they had done everything
possible to reduce the risk of lawsuits."  n183 Insurance companies began
devising risk management protocols for  [*41]  police that specified mandates
for training, policy, and supervision that met national standards.  n184 McCoy
notes that § 1983 litigation,


     coupled with the professional risk management skills and oversight of
     the private insurance industry, have not been given the credit they
     deserve. This accountability device has probably been the source of
     the most far-reaching yet deep reforms in American policing over the
     past three decades.  n185


B. Section 14141

   The U.S. Department of Justice (DOJ) also plays an important role in
addressing police misconduct that violates citizens' federally protected civil
rights. In 1994, Congress enacted 42 U.S.C. § 14141 as part of the Violent Crime
Control and Law Enforcement Act.  n186 This law is often referred to as "the
Rodney King Law" because Congress enacted it in the wake of widespread media
broadcasts of videotaped footage of real and significant police brutality
against Rodney King at the hands of Los Angeles Police Department officers.
n187 The statute provides as follows:


     (a) Unlawful conduct

        It shall be unlawful for any governmental authority, or any agent
     thereof, or any person acting on behalf of a governmental authority,
     to engage in a pattern or practice of conduct by law enforcement
     officers or by officials or employees of any governmental agency with
     responsibility for the administration of juvenile justice or the
     incarceration of juveniles that deprives persons of rights,
     privileges, or immunities secured or protected by the Constitution or
     laws of the United States.
     (b) Civil action by Attorney General

        Whenever the Attorney General has reasonable cause to believe that
     a violation of paragraph (1) has occurred, the Attorney General, for
     or in the name of the United States, may in a civil action obtain
     appropriate equitable and declaratory relief to eliminate the pattern
     or practice.  n188

    [*42]  Unlike § 1983, which provides a private right of action, § 14141
authorizes the U.S. Attorney General to initiate structural reform litigation
(SRL) against local police departments found to have engaged in systemic
misconduct.  n189 The § 14141 process begins with case selection, wherein the
DOJ typically relies upon media reports, existing litigation, "whistleblowers"
within police departments, academic reports, or information from other federal
government agencies in order to identify departments who may be engaged in
systematic misconduct.  n190 The Civil Rights Division conducts a preliminary
inquiry to determine if the nature and extent of the alleged problem for a given
department warrants a more thorough investigation.  n191 Based on the results of
the preliminary investigation, a department may then be subjected to a formal
inquiry by the Special Litigation Section of the Civil Rights Division
(involving extensive internal investigation of a particular department that may
take years and cost millions of dollars).  n192 If a pattern or practice of
civil rights violations is found during the formal inquiry, the DOJ issues a
technical assistance letter or an investigative findings letter that details the
unconstitutional police practices and the evidence supporting the conclusions.
n193 The DOJ and the agency then begin settlement negotiations over reforms to
be enacted to prevent official litigation in federal court.  n194 If the DOJ and
the agency cannot negotiate a settlement, the DOJ files suit in federal court.

   Successful negotiations between the DOJ and municipalities, either before or
after a formal § 14141 lawsuit is filed, typically lead to either a consent
decree or memorandum of agreement.  n195 The consent decree outlines the
remedies that must  [*43]  be implemented to address the unconstitutional
behavior by officers. The DOJ and the municipality select an external monitor to
oversee the agency's progress towards achieving compliance with the consent
decree.  n196

   A consent decree is typically designed to last five years, though federal
oversight often lasts much longer. For example, the Los Angeles Police
Department was under consent decree for nine years. The Detroit Police
Department was under consent decree for nearly 14 years. And some agencies, such
as the Cleveland Division of Police, have been under consent decree twice. Since
1994, the DOJ has initiated approximately 55 formal inquiries of law enforcement
agencies under the authority of § 14141, leading to 24 settlements or consent
decrees.  n197

   Most § 14141 consent decrees have targeted unconstitutional patterns or
practices involving use of force and racially discriminatory policing in stops,
searches, and arrests. Consent decrees include a wide range of remedies that
address policies, procedures, training, supervision, implementation of early
intervention/risk management systems, enhanced data collection and analysis,
more robust citizen complaint procedures, and adoption of community
outreach/community-oriented policing initiatives.  n198

   There are very few evaluations of § 14141 consent decrees. A Vera Institute
of Justice study from 2005 by Davis, Henderson, and Ortiz assessed the
sustainability of consent decree reform efforts one year after the termination
of the consent decree for the Pittsburgh Bureau of Police.  n199 Kupferberg
examined data on the Los Angeles Police Department (LAPD), the New Jersey State
Troopers, and the New York City Police Department (Daniels case) to assess
whether the consent decrees for each department affected racial disparities in
stops, arrests, and other types of police activity.  n200 Schatmeier identified
key features associated with  [*44]  the implementation of the consent decree
for the Cincinnati Police Department.  n201 Stone, Foglesong, and Cole evaluated
the LAPD's consent decree using observational methods, focus groups, and
quantitative analysis of administrative data.  n202 Chanin conducted a
longitudinal analysis to assess whether consent decree reforms were associated
with sustainable change in citizen complaints, police use of force incidents,
and civil litigation in Cincinnati, Pittsburgh, and the District of Columbia.
n203 Chanin also examined data from stakeholder interviews and monitor reports
to assess the implementation of consent decrees in Pittsburgh, Detroit,
Washington, D.C., Cincinnati, and Prince George's County, Maryland.  n204

   A number of themes emerge from a close reading of this handful of consent
decree studies. First, officers view consent decrees skeptically, and federal
oversight negatively affects officer morale.  n205 Second, though officers
frequently suggested that the consent decree led to less proactive police work,
results from several studies showed increased levels of summons, stops, and
arrests during the consent decree.  n206 Third, there is modest evidence that
both use of force  n207 and citizen complaints  n208 decrease during consent
decrees, though research has not demonstrated that excessive or unlawful force
declined during federal oversight. Fourth, there is also some evidence to
suggest that public satisfaction with police increases as a result of consent
decrees.  n209 Alternatively, several studies have shown that racial disparities
in stops and arrests persisted despite federal oversight.  n210 The dearth of
research on consent decrees and their impact is troubling given their
significant cost. For example, the consent decree for the LAPD is estimated to
have cost between $ 30 and $ 50 million annually (totaling  [*45]  $ 250 million
over five years), and the Cincinnati Police Department consent decree entailed $
13 million in start-up costs alone.  n211

C. Federal Civil Litigation over the NYPD's Stop-and-Frisk Program

   The widespread deployment stop-and-frisk by the NYPD resulted in two major §
1983 lawsuits alleging racial profiling. In 1999, the Center for Constitutional
Rights (CCR) filed a class action lawsuit against the NYPD, Daniels v. City of
New York, alleging that NYPD officers were selectively targeting individuals on
the basis of their race and national origin, without reasonable suspicion, in
violation of the Fourth and Fourteenth Amendments to the U.S. Constitution.
n212 Of particular concern was the NYPD's Street Crime Unit (SCU), a
plainclothes unit comprised of more than 300 officers, several of whom were
responsible for killing Amadou Diallo in February 1999.  n213 The death of
Diallo ignited citywide demonstrations against police brutality, and the SCU
unit was eventually disbanded in 2002.  n214 In September 2003, the NYPD and CCR
agreed to settle the civil suit through an out-of-court consent decree approved
by Judge Shira Scheindlin (who would eventually preside over the Floyd case).
n215 As part of the consent decree, the NYPD agreed to: maintain a written
anti-racial profiling policy; train officers on legal issues in stop-and-frisk
(and cultural diversity); require that officers record stop data on a UF-250
form; conduct audits of the UF-250 forms; and maintain an electronic database of
stops (based on the UF-250 forms) that would be provided quarterly to
plaintiffs.  n216

   The Daniels settlement did not include an independent monitor, and the
evidence suggests that the NYPD's compliance with the consent decree was  [*46]
mixed, at best.  n217 As a result, the CCR filed a second class-action lawsuit
against the NYPD in 2008, Floyd v. City of New York,  n218 as well as a new
companion case in Daniels.  n219 The Floyd case proceeded to trial in early
2013, again under Judge Shira Scheindlin. The allegations against the NYPD were
supported by the expert reports of Criminologist Jeffrey Fagan,  n220 as well as
analyses carried out by CCR.  n221 Fagan's expert reports in the Floyd case
analyzed the NYPD's stop-and-frisk data from 2004 through 2009, and from January
2010 through June 2012. After controlling for crime, neighborhood context, and
the concentration of police officers in specific areas, Fagan found that Blacks
and Latinos were still disproportionately targeted by the NYPD's stop-and-frisk
program, in support of the plaintiff's Fourth and Fourteenth Amendment claims
(see Table 1).  n222

    [*47]  Table 1. Summary of Dr. Jeffrey Fagan's Statistical Findings for the
Floyd Litigation

Fourth Amendment Claims
. Nearly 150,000, or 6.71% of all discretionary stops lack legal justification.
An additional 544,252, or 24.37% of all discretionary stops lack sufficiently
detailed documentation to assess their legality.
. Officers rely heavily on two constitutionally problematic stop justifications
for nearly half of all stops: furtive movements and proximity to a high crime
area.
. Documented stop justifications do little to explain overall variations in stop
patterns and do not substantially influence the racial disparities that
characterize stop practices between police precincts.
. The rate of gun seizure is 0.15%, or nearly zero, and arrests take place in
less than 6% of all stops.
. Black and Hispanic suspects are treated more harshly once the decision is made
that a crime has occurred. Black and Hispanic suspects are more likely to be
arrested than issued a summons when compared to White suspects. They are more
likely to be subjected to use of force.
Fourteenth Amendment Claims
. NYPD stop activity is concentrated in precincts with high concentrations of
Black and Hispanic residents even after controlling for the influences of crime,
social conditions, and the allocation of police resources.
. NYPD stops are significantly more frequent for Black and Hispanic citizens
than for white citizens, even after adjusting for precinct crime rates, the
racial composition, and other social and economic factors predictive of police
activity.
. Black and Hispanics are more likely to be stopped than whites even in areas
where there are low crime rates and where residential populations are racially
heterogeneous or predominantly White.

   In August 2013, Judge Scheindlin ruled that the NYPD was engaging in
unconstitutional stop-and-frisk practices that targeted predominately Black and
Latino New Yorkers.  n223 In a separate decision, Judge Scheindlin ordered
several remedies to address the NYPD's racially discriminatory stop-and-frisk
program.  n224 She appointed an independent monitor to oversee compliance with
the remedies, which included reformation of policies, training, supervision,
documentation, and disciplinary action, as well as the publication of monitor
reports that detail the  [*48]  NYPD's compliance with the ordered reforms.
n225 Judge Scheindlin also ruled that the citizens most affected by
stop-and-frisk should play a role in the reforms, and that the NYPD begin a
one-year pilot study of body-worn cameras in the seventy-fifth precinct.  n226

   Events continued to unfold in New York City in the months following the
landmark Floyd ruling. First, the City appealed Judge Scheindlin's ruling to the
U.S. Court of Appeals for the Second Circuit and sought a stay of her remedies,
pending the outcome of the appeal. The appellate court granted the City's motion
for a stay pending appeal.  n227 The Second Circuit also determined that Judge
Scheindlin had failed to avoid the appearance of impartiality and therefore
ordered her removal from the case.  n228 Importantly, though, the Second Circuit
did not overturn the substance of Judge Scheindlin's rulings.

   Second, several police unions filed motions to intervene in the appeal
alleging that Judge Scheindlin had erred in her interpretations of evidence and
the law.  n229 The police union motions were denied on multiple grounds,
including being untimely, and the unions having "no significant protectable
interests relating to the subject of the litigation that would warrant
intervention."  n230

   Third, the NYPD's stop-and-frisk program (and the Floyd case) became a
defining feature of the New York City mayoral election in fall 2013. In effect,
the mayoral election became a referendum on stop-and-frisk, and mayoral
candidate William de Blasio was elected in part because of his opposition to the
NYPD stop-and-frisk program. Upon taking office, Mayor de Blasio replaced NYPD
Commissioner Raymond Kelly with former Commissioner William Bratton.
Commissioner Bratton pledged to address NYPD reform through the inclusion of
"more oversight and training . . . [and] more guidance."  n231 In January 2014,
the Mayor pledged to drop the City's appeal of the Floyd ruling, though it was
not officially dropped until October 2014.  n232 Since then, the City and
Commissioner Bratton have been working to implement the remedies ordered in
Judge  [*49]  Scheindlin's original ruling, including a joint remedial process
that will "develop a set of reforms with the direct input of the people most
affected by the NYPD's discriminatory stop-and-frisk practices."  n233

D. The Current Study

   Though federal civil litigation has become one of the primary mechanisms for
addressing widespread unconstitutional policing, there have been very few
empirical examinations of the effectiveness of such litigation. The lack of
evaluative work on the impact of federal civil litigation has left the mechanism
vulnerable to criticism,  n234 and has raised questions about the proper role of
the federal government in overseeing local law enforcement practices (i.e.,
federalism).  n235 As a result, we have little understanding of the role that
federal civil litigation has played in police reform to date, or its potential
to effect change and reduce unconstitutional policing in the 21st century. Given
the gravity of the constitutional violations, as well as the implications and
cost for local law enforcement agencies, the lack of knowledge regarding the
effectiveness of federal civil litigation is concerning.

Dr. Fagan's analyses in the Floyd case demonstrate that the stipulations of the
original Daniels settlement had little effect on the manner in which the NYPD
executed stop-and-frisk activities between 2005 and 2012. In the wake of the
Floyd ruling, however, significant events transpired as a result of the
litigation and the accompanying federal court oversight. The current study
descriptively examines the impact of the Floyd case on the nature and prevalence
of NYPD stops, through a comparison of stop activity and outcomes from 2011
(when the program was at its height) and 2014 (the year after the Floyd ruling).

   VI. METHODS

A. Data

   To determine whether the litigation in Floyd positively influenced
stop-and-frisk activities by the NYPD, the authors compare and contrast official
stop-and-frisk data from 2011 and 2014 as recorded by officers on UF-250 forms.
The data are drawn from the NYPD's Stop, Question, and Frisk Report Database,
which is  [*50]  publicly available online. The data are available as both a
portable file and a comma separated values (CSV) file. For the descriptive
analyses presented here, the portable files were used in conjunction with SPSS
Version 22, whereas the CSV files were used to create a map in ArcGIS 10.2.

   Officers are mandated to fill out a UF-250 form if a police officer uses
force, the person stopped refuses to identify him or herself, or the individual
stopped is frisked, searched, and/or arrested.  n236 The following information
is found on a UF-250 form:


     . The suspect's sex, race, age, height, weight, hair color, eye color,
     and other features such as scars and tattoos.
     . The location of the stop, including address number, street name,
     intersection, city, state, zip code, police beat, police section, and
     police borough, along with the longitudinal (X) and latitudinal (Y)
     coordinates.
     . The reason or reasons that led up to the stop, frisk, and/or search.

     . The reason for police use of force and the type of force employed.
     . Whether the suspect was frisked, searched, and/or arrested.
     . Whether contraband or a weapon was found on the suspect.  n237


B. Analytic Strategy

   The authors explore five research questions using NYPD stop-and-frisk data
from 2011 and 2014:


     1. How has the prevalence of stop-and-frisk changed from 2011 to 2014?

     2. Has the geographic concentration of stop-and-frisk changed notably
     from 2011 to 2014?
     3. Has the nature of what transpires during stops changed notably from
     2011 to 2014 (i.e., frisks, searches, arrests, weapons and contraband
     seized)?
     4. Have the racial disparities among those subjected to stop-and-frisk
     changed notably from 2011 to 2014?
     5. Have crime trends in New York City changed in the wake of pressure
     to reform the stop-and-frisk program (post-Floyd ruling)?

    [*51]  To address these research questions, the authors first examine the
prevalence of NYPD stops annually from 2003 through 2014. Second, the authors
identify the geographic locations of all stops in 2011 and 2014, at the precinct
level, and examine the percent change in stop locations pre- and post-Floyd
ruling. This analysis is of particular interest because the Fagan analyses in
the Floyd case demonstrated that NYPD stop activity disproportionately targeted
neighborhoods and precincts where the majority of residents were ethnic
minorities. The analyses here will assess whether the racially geographic
concentration of stops has persisted post-Floyd ruling. Third, Fagan's analyses
in the Floyd case demonstrated that not only were minorities more likely to be
stopped, they were also disproportionately likely to be subjected to frisk,
search, and arrest. The authors descriptively compare stop outcomes both
overall, and by citizen race/ethnicity, to determine whether the racial
disparity finding has persisted in the wake of the Floyd ruling. Fourth, as an
indicator of the effectiveness of stops, the authors compare the rates at which
stops produce guns, other weapons, and contraband pre- and post-Floyd ruling.
Finally, the authors explore trends in violent and property crime rates, as well
as total homicides, through 2014 to determine whether reforms in stop-and-frisk
(if they occurred) may be associated with changes in crime in New York.

   The current study does suffer from several limitations that should be
acknowledged. First, the current study presents a descriptive year-to-year
comparison only, which restricts statements about causality between the federal
civil litigation and changes in stop-and-frisk practices. Second, the findings
are based on NYPD administrative data, and several critics have suggested that
the UF-250 data may not be complete and accurate. In fact, there are indications
that a substantial proportion of stops occur without formal documentation.
Consider that Jones-Brown and colleagues reported that although one study
estimated that approximately 70% of all stops were captured on UF-250 forms, an
NYPD commander estimated that "only 1 in 10 stops" was documented by officers on
the UF-250.  n238 Finally, the earlier discussion demonstrates that a number of
events after the Floyd ruling may have shaped the NYPD's stop-and-frisk program
including media attention, a new mayor, and a new police commissioner--though
many of these events are directly related to the Floyd ruling. Results should be
interpreted in the context of these limitations.

    [*52]  VII. RESULTS

A. Stop Counts and Geographic Concentration  n239

   Figure 1 illustrates that the number of stops has dropped precipitously since
peaking at 685,724 in 2011. The number declined by 22% in 2012 (to 532,911
stops), and by another 64% in 2013 (191,851 stops). In 2014, the NYPD recorded
just 45,788 stops, a 93% decrease from 2011--the peak of the program just three
years earlier. In terms of the Floyd case, the number of stops declined before
the case went to trial in early 2013. But the litigation had been pending since
2008, and the pressure on the NYPD regarding the stop-and-frisk program was
enormous in the years leading up to the court case. It is reasonable to assert
an association between the Floyd case--as well as the attention it garnered--and
the substantial decline in stop-and-frisk that began in 2012. Certainly, the
change in mayor and police commissioner in early 2014--and their highly
publicized decision to drop the Floyd appeal and curtail the stop-and-frisk
program--explains the continued decline in 2014.

 Figure 1. NYPD Stop Data by Year

    [*53]  Figure 2 illustrates the degree of change in the concentration of
stop-and-frisk activity from 2011 to 2014.  n240 Although every NYPD precinct
experienced a significant decline in the overall number of stops, some precincts
did experience an increase in their proportion of the total number of stops,
from 2011 to 2014 (darker shades, such as the 122nd and 123rd precincts).
Overall, 44 of the 76 precincts experienced a decline in their proportion of the
total percentage of stops (reflected by the lighter shades). Moreover, that
decrease was particularly notable in precincts that had previously been
disproportionally affected by racially disparate stop-and-frisk activities.

 Figure 2. Stop Composition by Precincts

    [*54]  Table 2 illustrates the finding in a different way. Prior research
indicates that ten precincts with large minority populations have experienced a
disproportionate share of stop-and-frisks.  n241 Those precincts include:


     . 23rd - East Harlem (south)
     . 40th - Mott Haven, Melrose
     . 44th - Concourse, Highbridge
     . 73rd - Ocean Hill, Brownsville
     . 75th - East New York, Starret City
     . 77th - Crown Heights (north), Prospect Heights
     . 79th - Bedford-Stuyvesant (west)
     . 103rd - Jamaica (south), Hollis
     . 115th - Jackson Heights
     . 120th - St. George, West Brighton, Port Richmond

   In 2011, these ten precincts were responsible for 27.13% of all stops in New
York, ranging from 1.66% to 4.53% of the total percentage of stops (77th and
75th precincts, respectively). Table 2 shows that the same ten precincts were
responsible for just 19.68% of all stops in 2014. Moreover, seven of the ten
precincts experienced a decline in the percentage of total stops, with five of
the precincts experiencing drops of nearly 50% or more. For example, in the
Floyd ruling Judge Scheindlin singled out the 75th precinct for its misuse of
stop-and-frisk, and she selected it as the location for the body-worn camera
pilot study. In 2011, the 75th precinct was responsible for 4.53% of the total
stops that year. By 2014, the 75th precinct was responsible for just 2.0% of all
stops, representing a decline of 55.85%.  n242 In sum, the concentration of
stop-and-frisk activity in mostly minority precincts has declined considerably
following the Floyd ruling.

    [*55]  Table 2. Stop Percentages among Precincts with Large Minority
Populations
                                                      Percent
                 2011                  2014           Change
Precinct      (n=685,724)           (n=45,788)       2011-2014
         # stops      % of     # stops      % of
                  total stops           total stops
   23     17,498      2.55       719        1.57      -38.43
   40     17,690      2.58       898        1.96      -24.03
   44     16,903      2.46      1,330       2.9        17.89
   73     25,167      3.67       866        1.89      -48.50
   75     31,100      4.53       917        2.00      -55.85
   77     11,405      1.66       373        0.81      -51.20
   79     14,498      2.11      1,452       3.17       50.24
  103     17,152      2.50       325        0.71      -71.60
  115     18,156      2.65       205        0.45      -83.02
  120     16,490      2.40      1,934       4.22       75.83
 Total   186,059     27.13%     9,019      19.68%


 [*56]  B. Stop Outcomes: Frisks, Searches, Arrests, Weapons and Contraband

   After a stop occurs, law enforcement officers may take any number of
subsequent actions--such as frisking a suspect, conducting a full-blown search
of the suspect, placing the suspect under arrest, and seizing guns, other
weapons and contraband--depending on the totality of the facts and circumstances
they encounter.  n243 Arguably, any increases in the outcomes of post-stop
events could signal improvements in stop activity, as officers are more
accurately assessing reasonable suspicion of criminal activity. Their more
accurate assessments of reasonable suspicion then lead to more formal outcomes,
such as searches, arrests, and confiscation of weapons and contraband.

   Figure 3 illustrates that since 2011, frisks, searches, and arrests have all
occurred with greater frequency. Frisks increased from approximately 55.7% to
66.3%, searches increased from 8.5% to 15.9%, and arrests more than doubled,
from 6.0% in 2011 to 15.1% in 2014.  n244 One of the most important criticisms
of the NYPD's stop-and-frisk program was the low rate for recovering weapons and
contraband, as demonstrated by the 2011 figures in Table 3. For example, in 2011
only 0.12% of stops resulted in seizure of a firearm and 1.1% resulted in
seizure of another type of weapon. The seizure rates remain low in 2014, but in
each case, the percent increase from 2011 is notable. For example, gun seizures
increased from 0.12% of all stops to 0.44%--an increase of 267%. Seizures of
other weapons and contraband increased by 185% and 104%, respectively. Given the
more than 90% drop in the total number of stops, these data demonstrate that
NYPD stop-and-frisk activity improved notably in terms of efficiency and
accuracy from 2011 to 2014.

    [*57]   Figure 3. Frisk, Search, and Arrest Percentages

   Table 3. Percentage of Weapons and Contraband Seizure
                                                       Percent
    Found            2011                2014          Change
   During         (n=685,724)         (n=45,788)      2011-2014
   Search     Percentage   Total  Percentage   Total
                          number              Number
Knives/other     1.1%      7,444     3.13%     1,431    185%
    Guns         0.12%      819      0.44%      202     267%
 Contraband      1.7%     11,803     3.46%     1,585    104%


 [*58]  C. Stop, Frisk, and Racial Disparities

   The court ruled in the Floyd case that the NYPD unconstitutionally targeted
young Black and Latino citizens, in violation of their Fourth and Fourteenth
Amendment rights. Table 4 assesses the extent to which racial disparities
persisted in stop-and-frisk activity after the court ruling, and unlike the
findings on prevalence, geographic concentration, and outcomes, there appears to
be little change in the racial make-up of those subjected to stop-and-frisk.
n245 For example, racial/ethnic make-up of citizens stopped in 2011 and 2014 are
virtually identical: Black (51.1%-53.1%), Black-Hispanic (7.1%-6.1%),
White-Hispanic (25.6%-21.2%), White (9.0%-11.9%), and other (7.2%-7.7%). The
ethnic and racial make-up among those frisked changed slightly in 2014, but
changes were 5% or less (frisks of Black citizens increased by about 3% and
frisks of White-Hispanic citizens decreased by 5.5%). Similar stability is seen
among those searched and arrested. In sum, the racial disparities among those
subjected to stop-and-frisk by NYPD officers has changed little since the Floyd
ruling.

    [*59]  Table 4. Racial and Ethnic Composition of Stops, Frisks, Searches &
Arrests
Variable Description    2011    2014
Stop Percentage
 Black                 51.1%    53.1%
 Black-Hispanic         7.1%    6.1%
 White-Hispanic        25.6%    21.2%
 White                  9.0%    11.9%
 Other                  7.2%    7.7%
Total (n)             685,724  45,787
Frisk Percentage
 Black                 53.2%    56.0%
 Black-Hispanic         7.4%    6.3%
 White-Hispanic        26.0%    20.5%
 White                  7.2%    10.1%
 Other                  6.2%    7.1%
Total (n)             381,704  30,345
Search Percentage
 Black                 50.6%    50.6%
 Black-Hispanic         7.0%    7.7%
 White-Hispanic        25.9%    24.5%
 White                  9.8%    10.4%
 Other                  6.7%    6.8%
Total (n)              58,363   7,283
Arrest Percentage
 Black                 51.0%    50.0%
 Black-Hispanic         7.3%    8.3%
 White-Hispanic        25.0%    25.5%
 White                 10.3%    10.3%
 Other                  5.4%    5.9%
Total (n)              40,883   6,898


 [*60]  D. Stop, Frisk, and Crime in New York City

   In the weeks following the Floyd ruling, city and police department leaders
appeared on local and national media, intimating that any changes to the
stop-and-frisk program would produce increases in crime. Appearing on NBC's
"Meet the Press," for example, former Police Commissioner Kelly said, "No
question about it, violent crime will go up."  n246 Table 5 shows trends in
violent and property crime rates, as well as overall homicides, in New York City
from 2005-2014, and the results refute former Commissioner Kelly's claim.
Violent crime rates continued a slow decline from 2005 to 2009 (from 67.3 to
55.2 per 10,000 residents), before increasing through 2012 (63.9).
Interestingly, this slight uptick in violent crime occurred during the peak
years of stop-and-frisk (2010-2011). Violent crime rates then declined slightly
in 2013 and 2014 (62.4 and 59.7 per 10,000 residents, respectively), as the use
of stop-and-frisk dropped off precipitously. Property crime rates followed a
nearly identical pattern. The trends in overall homicide directly contradict any
claim that reduced use of stop-and-frisk caused an increase in violence in New
York. In 2011, there were 515 homicides. In 2013 and 2014, there were 335 and
333, respectively--a 35% decline.  n247 In short, there is no evidence to
suggest that reforms to stop-and-frisk compromised the NYPD's ability to
effectively fight crime.

    [*61]  Table 5. Crime Trends in New York City, 2005-2014  n248
           2005  2006  2007  2008  2009  2010  2011  2012  2013  2014
 Violent
  Crime    67.3  63.8  61.4  58.0  55.2  58.2  62.4  63.9  62.4  59.7
 Property
  Crime    200.2 187.9 181.9 179.7 169.0 167.5 171.0 172.2 169.1 160.2
  Total
Homicides   539   596   496   523   471   536   515   419   335   333

   VIII. DISCUSSION AND CONCLUSION

   The last 40 years have arguably been the most innovative in the history of
policing.  n249 Since the mid-1970s, a host of new strategies have emerged on
the law enforcement landscape, from problem-oriented policing (POP) and
community-oriented policing (COP), to hot spots policing, focused
deterrence/pulling levers (e.g., targeted offender strategies), intelligence-led
policing, and even predictive policing. The innovation in strategies has been
matched by the development of new technologies such as geographic information
systems (GIS), crime analysis and advanced analytics, CompStat, DNA and
forensics, license plate readers, less-lethal alternatives (pepper spray,
TASER), body-worn cameras, and gunshot  [*62]  detection systems.  n250 During
this period of innovation, stop-and-frisk has emerged as a preferred tactic for
controlling crime and disorder.

   Despite the tremendous innovation in policing, one phenomenon that has
remained unchanged is the undercurrent of racial injustice. The misuse and abuse
of stop-and-frisk appears to be the next iteration of that injustice. The
stories of stop-and-frisk in Newark, Philadelphia, Chicago, Pittsburgh, and New
York illustrate that Williams and Murphy's "minority view" of policing remains a
stark reality. The deaths of Eric Garner, Michael Brown, and Freddie Gray, among
others, demonstrate the centrality of stop-and-frisk to the persistent racial
crisis in policing. These tragic deaths have led to unprecedented attention on
racial disparities in police actions, best exemplified by the President's Task
Force on 21st Century Policing,  n251 and they have facilitated a national
dialogue on the need for police accountability and reform.

   As part of this dialogue, federal civil litigation has received considerable
attention as a potential mechanism for police reform. Federal civil litigation
can be employed through a variety of mechanisms, such as individual or
class-action § 1983 lawsuits and U.S. Department of Justice actions via § 14141.
Unfortunately, very little research has examined the impact of federal civil
litigation on unconstitutional police practices, and as a result, there is
little understanding of its effectiveness (or lack thereof) as an instrument of
police reform.

A. Federal Civil Litigation and Police Reform in New York

   The current study examines the New York City confluence of racial injustice
in policing, misuse of stop-and-frisk by officers, and federal civil litigation
designed to precipitate police reform. The results provide direct evidence of
the impact of federal civil litigation on unconstitutional stop-and-frisk
practices in New York specifically, as well as some more general insights on the
potential for federal civil litigation to generate police reform.

   The year-to-year comparison of stop-and-frisk in New York highlights a number
of positive findings, suggesting that the federal civil litigation has begun to
alter the unconstitutional practices outlined in the Floyd case. First, the
sheer number of stops conducted by officers has dropped dramatically, by more
than 90%. Second, the geographic concentration of stops in mostly minority
precincts has also declined. An examination of ten precincts with large minority
populations showed that the racial/ethnic concentration of stops has dropped by
nearly 10% overall in those precincts, with some precincts experiencing declines
of 50% or more. Third, stops appear to be more efficient and accurate. The
percentage of stops resulting in arrest has more than doubled. The percentage of
stops where weapons and contraband were seized remain low but those percentages
have  [*63]  doubled or tripled compared to the 2011 rates. In short, the NYPD
has altered its day-to-day practices with regard to stop-and-frisk, to the
benefit of thousands of New Yorkers. And importantly, the reforms in the NYPD's
stop-and-frisk program coincided with continued declines in crime and violence
in New York, especially homicides which declined by 35% from 2011 to 2014.

   The one negative finding is the persistence of racial disparities in those
subjected to stop-and-frisk: minorities remain overrepresented among those
stopped, frisked, searched, and arrested by the NYPD. According to the 2010
Census Bureau, the racial and ethnic composition of New York City is
approximately 33.3% White, 22.8% Black, 28.6% Hispanic, 12.6% Asian, and 2.7%
"other."  n252 In 2014, the percentage of Whites, Blacks, and Hispanics
(combining Black-Hispanic with White-Hispanic) stopped was 11.9%, 53.1%, and
27.3%, respectively. The authors acknowledge that the racial composition of a
population is a rough, at best, benchmark for assessing racial disparities.
Other benchmarks, such as the racial composition of the arrestee population in
New York, would suggest much smaller racial disparities.  n253 Nevertheless, the
stability in race/ethnicity among those who were stopped in 2011 and in 2014 is
troubling, given that the federal court determined that the NYPD was engaged in
unconstitutional stop-and-frisks in 2011. Notably, the persistence of racial
disparities in New York is consistent with findings from the few studies that
have examined the impact of consent decrees on discriminatory police practices
in other jurisdictions (e.g., New Jersey and Los Angeles).  n254

   It is clear that more work needs to be done in New York, but this fact should
not overshadow the considerable progress that the NYPD has made during the last
few years. And importantly, the structure for effective police reform in New
York is in place. For example, recent changes have been made to training and
policy. The 2015 student guide for patrol recruits presents officers with a more
inclusive understanding of diversity issues:


     As police officers, you are required to enforce the law impartially
     without regard to actual or perceived race, class, ethnicity, culture,
     religion, age, gender, sexual orientation, disability, immigration or
     housing status. At the same time, we are members of a larger society
     in which bias and discrimination against certain groups of people are
     matters of historical and statistical fact. . . . As noted in a recent
     speech by Police Commissioner Bratton, American policing has been part
     of the  [*64]  best of American history, but unfortunately some of the
     worst parts as well. Understanding this history and how it has shaped
     perceptions will help you become a better, more effective police
     officer.  n255


The NYPD is also in the process of revising the Patrol Guide to provide clearer,
more accurate guidance on the proper legal standards for stop-and-frisk,
including:


     (1) . . . what constitutes a stop, when a stop may be conducted, when
     a frisk may be conducted, and when a search may be conducted;
     (2) . . . a definition of "reasonable suspicion," the standard needed
     for a stop based on Terry v. Ohio;
     (3) . . . that officers must have separate reasonable suspicion that a
     person is armed and dangerous in order to conduct a frisk of that
     person;
     (4) require[ing] officers to document the stop and reasonable
     suspicion, and, if conducted, the frisk, on both a stop report form
     (formerly called a UF-250) and in their activity logs;
     (5) require[ing] supervisory review of stops, including review of the
     constitutionality of the stop, not just that a stop report form was
     filled out; and
     (6) provid[ing] for supervisors to identify officers needing further
     training and/or potential discipline.  n256

   Last, the federal monitor reviews NYPD activities, analyzes data, and issues
public reports with recommendations for change. The monitor's reports can
document progress, but they can also highlight deficiencies in supervision,
policy, and training. The reporting of deficiencies provides a roadmap for
continued reform, and the public nature of this reporting places tremendous
pressure on the NYPD to follow that roadmap and address the identified
deficiencies. In sum, the findings presented here show that the NYPD has made
significant progress since 2011, and the proper mechanisms are in place to
ensure that the department will continue to move toward widespread
constitutional policing.

 [*65]  B. Larger Lessons for Federal Civil Litigation as an Instrument for
Police Reform

   The federal court litigation in New York was relatively unique. Since the
case was filed as a § 1983 class-action lawsuit, plaintiffs first had to satisfy
the four requirements for class certification under Federal Rule of Civil
Procedure 23(b)(2), namely numerosity, commonality, typicality, and adequacy.
n257 Then plaintiffs were required to demonstrate Fourth and Fourteenth
Amendment liability for the certified class as a result of the NYPD's
stop-and-frisk program. Margeson highlighted the power of this federal civil
litigation approach:


     Politics, socio-economic inequality, and the accumulation of precedent
     that has diminished the likelihood of legal redress for Fourth and
     Fourteenth Amendment violations have effectively deregulated police
     power to conduct investigative Terry stops. The Floyd litigation
     demonstrates the immense value of judicial process to advocates of
     social reform, especially where the prospective beneficiaries have
     been underserved by the democratic process. In Floyd, the democratic
     and judicial processes worked in tandem to effect a policy shift in
     the oversight of police conduct that either branch, acting in
     isolation, most probably would not have achieved.  n258

   Though the Floyd case began as a class-action suit in 2008, the judge's
ruling in 2013 mimicked the oversight process outlined in § 14141. As a result,
the progress made by the NYPD in the three years since the Floyd ruling speaks
directly to the potential for § 14141 consent decrees to effect change in police
departments. Only a handful of studies have sought to assess the effectiveness
of § 14141 consent decrees on law enforcement agencies engaged in pattern or
practice unconstitutional policing. The research is mixed, but there are
modestly promising findings from that small body of work (e.g., enhanced public
satisfaction, implementation of new processes and policies, reductions in use of
force and citizen complaints during the consent decree, and greater transparency
via access to department data and independent monitor reports).  n259 More
generally, the experiences of agencies under § 14141 consent decrees demonstrate
that police reform is a complex, multi-year process with a high level of
difficulty. It involves organizational change in a profession characterized by
resistance to change, and the remedies target functions that go to the very core
of policing: supervision, training, policy, and accountability. In short, police
reform is a marathon, not a  [*66]  sprint. The results from this study
demonstrate that important police reforms can be achieved early on during the
marathon, as a result of federal civil litigation.

Legal Topics:

For related research and practice materials, see the following legal topics:
Criminal Law & ProcedureCriminal OffensesWeaponsGeneral OverviewCriminal Law &
ProcedureSearch & SeizureWarrantless SearchesStop & FriskDetentionCriminal Law &
ProcedureSearch & SeizureWarrantless SearchesStop & FriskReasonable Suspicion

FOOTNOTES:





n1  Sam B. Warner, The Uniform Arrest Act, 28 VA. L. REV. 315, 315 (1942).





n2  MICHAEL D. WHITE & HENRY F. FRADELLA, STOP AND FRISK: THE USE AND ABUSE OF A
CONTROVERSIAL POLICING TACTIC (2016).





n3  2 WILLIAM HAWKINS, A TREATISE OF THE PLEAS OF THE CROWN 129 (London, 8th ed.
1824) (1716).





n4  Warner, supra note 1, at 319-20.





n5  Id. at 316.





n6  Id. at 317.





n7  Terry v. Ohio, 392 U.S. 1 (1968).





n8  Id. at 21-23. See generally JOHN N. FERDICO, HENRY F. FRADELLA & CHRISTOPHER
D. TOTTEN, CRIMINAL PROCEDURE FOR THE CRIMINAL JUSTICE PROFESSIONAL 306-37 (12th
ed. 2015).





n9  Terry, 392 U.S. at 23-24; see also FERDICO, FRADELLA & TOTTEN, supra note 8,
at 337-40.





n10  See, e.g., Brown v. Texas, 443 U.S. 47 (1979); United States v. Mendenhall,
446 U.S. 544 (1980); Michigan v. Long, 463 U.S. 1032 (1983).





n11  See generally WHITE & FRADELLA, supra note 2, passim.





n12  Id. See also Jeffrey Bellin, The Inverse Relationship between the
Constitutionality and Effectiveness of New York City "Stop-and-Frisk," 94 B.U.
L. REV. 1495 (2014); Bennett Capers, Rethinking the Fourth Amendment: Race,
Citizenship, and the Equality Principle, 46 HARV. C.R.-C.L. L. REV. 1 (2011);
David A. Harris, Frisking Every Suspect: The Withering of Terry, 28 U.C. DAVIS
L. REV. 1 (1994); Lewis R. Katz, Terry v. Ohio at Thirty-Five: A Revisionist
View, 74 MISS. L.J. 423 (2004); Tracey Maclin, Terry v. Ohio's Fourth Amendment
Legacy: Black Men and Police Discretion, 72 ST. JOHN'S L. REV. 1271 (1998);
Thomas B. McAffee, Setting Us Up for Disaster: The Supreme Court's Decision in
Terry v. Ohio, 12 NEV. L.J. 609 (2012).





n13  ELIOT SPITZER, THE NEW YORK CITY POLICE DEPARTMENT'S "STOP-AND-FRISK"
PRACTICES: A REPORT TO THE PEOPLE OF THE STATE OF NEW YORK FROM THE OFFICE OF
THE ATTORNEY GENERAL (1999),
http://www.oag.state.ny.us/sites/default/files/pdfs/bureaus/civil_rights/stp_frs
k.pdf.





n14  Complaint, Daniels v. City of New York, 1:99-cv-01695-SAS (S.D.N.Y. Mar. 8,
1999); see also Daniels v. City of New York, 138 F. Supp. 2d 562 (S.D.N.Y.
2001).





n15  Complaint and Demand for Jury Trial, Floyd v. City of New York,
08-cv-01034-SAS (S.D.N.Y. Jan. 31, 2008),
http://ccrjustice.org/files/Floyd_Complaint_08.01.31.pdf; see also Floyd v. City
of New York, 959 F. Supp. 2d 540 (S.D.N.Y. 2013); id. at 668 (S.D.N.Y. 2013),
stay granted sub nom Ligon v. City of New York, 538 Fed. Appx. 101 (2d Cir.
2013), vacated in part by 743 F.3d 362 (2d Cir. 2014).





n16  Floyd, 959 F. Supp. 2d at 540.





n17  Complaint, Bailey v. City of Philadelphia, No. 210CV05952, 2010 WL 4662865
(E.D. Pa. Nov. 4, 2010),
http://www.aclupa.org/download_file/view_inline/669/198/; see also Settlement
Agreement, Class Certification & Consent Decree, Bailey v. City of Philadelphia,
No. 10-5952 (E.D. Pa. June 21, 2011),
http://www.aclupa.org/download_file/view_inline/744/198/.





n18  UDI OFER & ARI ROSMARIN, AM. CIVIL LIBERTIES UNION OF N.J., STOP-AND-FRISK:
A FIRST LOOK 5 (2014),
https://www.aclu-nj.org/files/8113/9333/6064/2014_02_25_nwksnf.pdf.





n19  See PRESIDENT'S TASK FORCE ON 21ST CENTURY POLICING, FINAL REPORT OF THE
PRESIDENT'S TASK FORCE ON 21ST CENTURY POLICING (2015),
http://www.cops.usdoj.gov/pdf/taskforce/TaskForce_FinalReport.pdf.





n20  Stop-and-Frisk Data, N.Y. CIVIL LIBERTIES UNION,
http://www.nyclu.org/content/stop-and-frisk-data (last visited Aug. 23, 2016);
see also N.Y. POLICE DEP'T, STOP, QUESTION AND FRISK REPORT DATABASE
[hereinafter NYPD STOP-AND-FRISK DATABASE],
http://www.nyc.gov/html/nypd/html/analysis_and_planning/stop_question_and_frisk_
report.shtml (last visited Aug. 23, 2016).





n21  Benjamin Weiser & Joseph Goldstein, Mayor Says New York City Will Settle
Suits on Stopand-Frisk Tactics, N.Y. TIMES (Jan. 30, 2014),
http://www.nytimes.com/2014/01/31/nyregion/deblasio-stop-and-frisk.html.





n22  Portions of Part II are adapted from WHITE & FRADELLA, supra note 2, at ch.
3.





n23  John A. Ronayne, The Right to Investigate and New York's "Stop-and-Frisk"
Law, 33 FORDHAM L. REV. 211 (1964).





n24  Id. at 214.





n25  2 MATTHEW HALE, THE HISTORY OF THE PLEAS OF THE CROWN 96 (Philadelphia,
Robert H. Small 1847); see also Lawrence v. Hedger, 3 Taunt. 14, 128 Eng. Rep. 6
(C.P. 1810).





n26  HAWKINS, supra note 3, at 129.





n27  Warner, supra note 1, at 319-20.





n28  Id. at 319 (citing 1932 MASS. GEN. LAWS c. 41, § 98; 1926 N.H. Pub. Laws c.
363, § 12).





n29  FERDICO, FRADELLA & TOTTEN, supra note 8, at 308.





n30  Warner, supra note 1, at 317.





n31  Id. at 316-17.





n32  Id. at 317.





n33  Id. at 320-21.





n34  Id. at 325.





n35  1941 N.H. Laws 242, ch. 163 (codified as amended at N.H. REV. STAT. ANN. §§
594:1-594:23 (1955)); 1941 R.I. Pub. Laws 21, ch. 982 (codified as amended at
R.I. GEN. LAWS ANN. §§ 12-7-1 to 12-7-17 (1956)).





n36  48 Del. Laws 769, ch. 304 (1951) (codified as amended in DEL. CODE ANN.
tit. 11, §§ 1901-1912 (1953)).





n37  Ronayne, supra note 23, at 215.





n38  It should be noted that laws against vagrancy and loitering exacerbated the
problems attendant to unclear stop-and-frisk authority. Indeed, vagrancy and
loitering laws blurred suspicion with criminal conduct by permitting the police
to make arrests--and searches incident to arrest--whenever someone seemed
out-of-place or presented as an "undesirable" in a particular location. See
Caleb Foote, Vagrancy-Type Law and Its Administration, 104 U. PA. L. REV. 603,
604 (1956).

     It is important to note that two quite different kinds of suspicion
     are involved. The alleged vagrant may be suspected of past criminality
     , the arrest for vagrancy offering the opportunity to investigate
     whether the suspect is wanted in another jurisdiction or has committed
     other crimes. On the other hand, the suspicion may be of future
     criminality, the inference being that purposeful poverty is likely to
     lead to other crimes unless the state steps in.

Id. at 625 (footnote omitted). In other words, much of the crime-prevention work
accomplished by modern stop-and-frisk procedures used to be accomplished by
vagrancy and loitering law arrests. Perhaps it is therefore unsurprising that
within four years of the Terry, Sibron, and Peters stop-and-frisk triumvirate,
the U.S. Supreme Court invalidated a vagrancy ordinance on vagueness grounds.
See Papachristou v. City of Jacksonville, 405 U.S. 156 (1972).





n39  392 U.S. 1 (1968).





n40  392 U.S. 40 (1968).





n41  For a more detailed and in-depth analysis of the facts, holdings,
rationale, and impact of these important cases, see WHITE & FRADELLA, supra note
2, at ch. 3.





n42  Terry, 392 U.S. at 6.





n43  Id. at 8, 10, 16-27. Notably, the majority decision in Terry did not
clearly distinguish the stop from the frisk. See id. at 10-12. Justice Harlan's
concurring opinion did so and clarified that a stop is distinct from an arrest
and a frisk is different from a search, even though the Fourth Amendment applies
to both police activities. Terry, 392 U.S. at 31-34 (Harlan, J., concurring).
Subsequent cases adopted his formulation. See John Q. Barrett, Deciding the Stop
and Frisk Cases: A Look Inside the Supreme Court's Conference, 72 ST. JOHN'S L.
REV. 749, 813 (1998).





n44  FERDICO, FRADELLA & TOTTEN, supra note 8, at 309.





n45  Terry, 392 U.S. at 20-21.





n46  Id. at 21.





n47  Id. at 30.





n48  Sibron, 392 U.S. at 45.





n49  Id.





n50  Id. at 62.





n51  Id. at 64.





n52  Id. at 48-49 (footnotes omitted).





n53  Id. at 66.





n54  443 U.S. 47 (1979).





n55  444 U.S. 85 (1979).





n56  United States v. Cortez, 449 U.S. 411, 417 (1981).





n57  Id. at 421-22 (emphasizing that the relevant line of inquiry in the case
was "whether, based upon the whole picture, they, as experienced Border Patrol
officers, could reasonably surmise that the particular vehicle they stopped was
engaged in criminal activity"). For an analysis of how deference to police
experience factors into the reasonable suspicion standard, see David A. Harris,
Factors for Reasonable Suspicion: When Black and Poor Means Stopped and Frisked,
69 IND. L.J. 659, 666 (1994).





n58  United States v. Mendenhall, 446 U.S. 544 (1980).





n59  Id. at 554-55.





n60  I.N.S. v. Delgado, 466 U.S. 210 (1984).





n61  Florida v. Bostick, 501 U.S. 429, 435 (1991).





n62  Michigan v. Long, 463 U.S. 1032, 1035 (1983).





n63  Alabama v. White, 496 U.S. 325, 329 (1990).





n64  Mich. Dep't of State Police v. Sitz, 496 U.S. 444, 447 (1990). City of
Indianapolis v. Edmond, 531 U.S. 32 (2000), curtailed law enforcement authority
to use drug-sniffing dogs at roadblocks on the grounds that the DUI checkpoints
sanctioned in Sitz were "designed to serve special needs, beyond the normal need
for law enforcement," id. at 37 (internal quotations omitted), whereas
suspicionless searches using drug-sniffing dogs at roadblocks impermissibly
extended into the realm of investigating "ordinary criminal wrongdoing." Id. at
38. Nonetheless, Sitz remains good law insofar as it permits stops of vehicles
at DUI checkpoints without any particularized suspicion of impaired driving.





n65  Vernonia School Dist. 47J v. Acton, 515 U.S. 646, 664-65 (1995). The
majority in Vernonia employed a "special needs" rationale similar to the road
safety one utilized in Sitz. Specifically, concern over the safety of minors
under governmental after-school supervision--and not normal law enforcement
investigation of criminal wrongdoing--prompted the school district to drug test
student-athletes randomly. Id. at 652-53.





n66  Bd. of Edu. of Indep. Sch. Dist. No. 92 of Pottawatome Cty. v. Earls, 536
U.S. 822, 825 (2002).





n67  Illinois v. Wardlow, 528 U.S. 119, 124 (2000).





n68  Hundreds of cases have relied on evasion in a high-crime area to justify
Terry stops. See Andrew Guthrie Ferguson & Damien Bernache, The "High-Crime
Area" Question: Requiring Verifiable and Quantifiable Evidence for Fourth
Amendment Reasonable Suspicion Analysis, 57 AM. U. L. REV. 1587, 1590 n.12
(2008).





n69  Whren v. United States, 517 U.S. 806, 811-12 (1996).





n70  Minnesota v. Dickerson, 508 U.S. 366, 371 (1993).





n71  Janet Koven Levit called such pretexts "the Death of Terry v. Ohio." Janet
Koven Levit, Pretextual Traffic Stops: United States v. Whren and the Death of
Terry v. Ohio, 28 LOY. U. CHI. L.J. 145, 145 (1996); see also Gabriel J. Chin &
Charles J. Vernon, Reasonable but Unconstitutional: Racial Profiling and the
Radical Objectivity of Whren v. United States, 83 GEO.WASH. L. REV. 882 (2015).





n72  Portions of Part III are adapted from WHITE & FRADELLA, supra note 2, at
ch. 6.





n73  WHITE & FRADELLA, supra note 2, passim.





n74  Terry v. Ohio, 392 U.S. 1, 9-10 (1968).





n75  John Q. Barrett, Appendix B: State of Ohio v. Richard D. Chilton and State
of Ohio v. John W. Terry: The Suppression Hearing and Trial Transcripts, 72 ST.
JOHN'S L. REV. 1387 (1998).





n76  Id. at 1465.





n77  Id. at 1456.





n78  Delores Jones-Brown & Brian A. Maule, Racially Biased Policing: A Review of
the Judicial and Legislative Literature, in RACE, ETHNICITY, AND POLICING: NEW
AND ESSENTIAL READINGS 140, 145 (Stephen K. Rice & Michael D. White eds., 2010).





n79  Katz, supra note 12, at 430-32 (footnotes omitted).





n80  See McAffee, supra note 12, at 612-13; Maclin, supra note 12, at 1278-79.





n81  George L. Kelling & Mark H. Moore, The Evolving Strategy of Policing, 4
PERSPECTIVES ON POLICING 2 (1988),
http://www.innovations.harvard.edu/sites/default/files/114213.pdf.





n82  Hubert Williams & Patrick V. Murphy, The Evolving Strategy of Police: A
Minority View, 13 PERSPECTIVES ON POLICING 1 (1990),
http://www.ncjrs.gov/pdffiles1/nij/121019.pdf.





n83  Complaint at 21, Bailey v. City of Philadelphia, No. 210CV05952, 2010 WL
4662865 (E.D. Pa. Nov. 4, 2010),
http://www.aclupa.org/download_file/view_inline/669/198/.





n84  Settlement Agreement, Class Certification & Consent Decree at 3-5, Bailey
v. City of Philadelphia, No. 10-5952 (E.D. Pa. June 21, 2011),
http://www.aclupa.org/download_file/view_inline/744/198/.





n85  Plaintiffs' Third Report to Court and Monitor on Stop and frisk Practices
at 4, Bailey v. City of Philadelphia, No. 10-5952 (E.D. Pa. Mar. 19, 2013),
http://www.clearinghouse.net/chDocs/public/PN-PA-0013-0003.pdf.





n86  Id. at 4-5 (footnote omitted).





n87  Plaintiffs' Fifth Report to Court and Monitor on Stop and Frisk Practices
at 7-15, Bailey v. City of Philadelphia, No. 10-5952 (E.D. Pa. Feb. 24, 2015),
http://www.aclupa.org/download_file/view_inline/2230/198/.





n88  Ofer & Rosmarin, supra note 18, at 6.





n89  Id. at 6-7.





n90  Id. at 9.





n91  Alice Brennan & Dan Lieberman, Florida City's "Stop and Frisk" Nabs
Thousands of Kids, Finds 5-year-olds "suspicious," FUSION (May 9, 2014),
http://fusion.net/story/5568/florida-citys-stop-frisk-nabs-thousands-of-kids-fin
ds-5-year-olds-suspicious/.





n92  AM. CIVIL LIBERTIES UNION OF ILL., STOP AND FRISK IN CHICAGO 2 (2015),
http://www.acluil.org/wp-content/uploads/2015/03/ACLU_StopandFrisk_6.pdf.





n93  See Williams & Murphy, supra note 82, passim.





n94  See Jericka Duncan, Eric Garner Case: Video of Chokehold's Aftermath Raises
New Questions, CBS NEWS (Dec. 6, 2014),
http://www.cbsnews.com/news/second-tape-of-nypd-chokehold-raises-new-questions-i
n-eric-garner-case/.





n95  Id.; see also J. David Goodman & Al Baker, Wave of Protests After Grand
Jury Doesn't Indict Officer in Eric Garner Chokehold Case, N.Y. TIMES (Dec. 3,
2014),
http://www.nytimes.com/2014/12/04/nyregion/grand-jury-said-to-bring-no-charges-i
n-staten-island-chokehold-death-of-eric-garner.html.





n96  Matt Pearce, Back Story: What Happened in Michael Brown Shooting in
Ferguson, Mo.?, L.A. TIMES (Nov. 24, 2014),
http://www.latimes.com/nation/la-na-back-story-ferguson-shooting-story.html.





n97  U.S. DEP'T OF JUSTICE, DEPARTMENT OF JUSTICE REPORT REGARDING THE CRIMINAL
INVESTIGATION INTO THE SHOOTING DEATH OF MICHAEL BROWN BY FERGUSON, MISSOURI
POLICE OFFICER DARREN WILSON 16-26 (Mar. 4, 2015),
https://www.justice.gov/sites/default/files/opa/press-releases/attachments/2015/
03/04/doj_report_on_shooting_of_michael_brown_1.pdf.





n98  Id. at 27-35.





n99  Monica Davey & Julie Bosman, Protests Flare After Ferguson Police Officer
Is Not Indicted, N.Y. TIMES (Nov. 24, 2014),
http://www.nytimes.com/2014/11/25/us/ferguson-darren-wilson-shooting-michael-bro
wn-grand-jury.html?_r=0.





n100  David A. Graham, The Mysterious Death of Freddie Gray, ATLANTIC (Apr. 22,
2015),
http://www.theatlantic.com/politics/archive/2015/04/the-mysterious-death-of-fred
die-gray/391119/.





n101  Justin Fenton, Autopsy of Freddie Gray Shows 'High-energy' Impact, BALT.
SUN (June 24, 2015),
http://www.baltimoresun.com/news/maryland/freddie-gray/bs-md-ci-freddie-gray-aut
opsy-20150623-story.html.





n102  Richard Pérez-Pe[#xF1]a, Six Baltimore Officers Indicted in Death of
Freddie Gray, N.Y. TIMES (May 21, 2015),
http://www.nytimes.com/2015/05/22/us/six-baltimore-officers-indicted-in-death-of
-freddie-gray.html.





n103  Justin Fenton & Kevin Rector, Mistrial Declared in Trial of Officer
William Porter in Death of Freddie Gray, BALT. SUN (Dec. 16, 2015),
http://www.baltimoresun.com/news/maryland/freddie-gray/bs-md-porter-trial-jury-w
ednesday-20151216-story.html.





n104  See Williams & Murphy, supra note 82, passim.





n105  For a full discussion on the NYPD prior to 1994, see JAMES LARDNER &
THOMAS REPPETTO, NYPD: A CITY AND ITS POLICE (2000).





n106  See generally Roland G. Fryer, Jr., Paul S. Heaton, Steven D. Levitt &
Kevin M. Murphy, Measuring Crack Cocaine and Its Impact, 51 ECON. INQUIRY 1651
(2013).





n107  Michael D. White, The New York City Police Department, Its Crime Control
Strategies and Organizational Changes, 1970-2009, 31 JUST. Q. 74, 79 (2014).





n108  GEORGE L. KELLING & CATHERINE M. COLES, FIXING BROKEN WINDOWS: RESTORING
ORDER AND REDUCING CRIME IN OUR COMMUNITIES 117-18 (1996).





n109  Bruce D. Johnson, Andrew Golub & James E. McCabe, The International
Implications of Quality-of-Life Policing as Practiced in New York City, 11
POLICE PRAC. & RES. 17, 18 (2010).





n110  KELLING & COLES, supra note 108, at 117-18.





n111  The Life and Times of Incoming NYPD Commissioner William Bratton, N.Y.
DAILY NEWS, (Dec. 5, 2013),
http://www.nydailynews.com/news/politics/timeline-new-nypd-commissioner-bratton-
article-1.1538689.





n112  See George L. Kelling & James Q. Wilson, Broken Windows: The Police and
Neighborhood Safety, ATLANTIC MONTHLY, Mar. 1982, at 29.





n113  See Ana Joanes, Does the New York City Police Department Deserve Credit
for the Decline in New York City's Homicide Rates? A Cross-City Comparison of
Policing Strategies and Homicide Rates, 33 COLUM. J.L. & SOC. PROBS. 265 (2000)
(citing Jackson Toby, Reducing Crime: New York's Example, WASH. POST, July 23,
1996, at A17).





n114  Kelling & Wilson, supra note 112.





n115  Id. at 37.





n116  Id.





n117  Joanes, supra note 113, at 265.





n118  Alison Mitchell, Giuliani Appoints Bostonian to Run New York's Police,
N.Y. TIMES (Dec. 3, 1993),
http://www.nytimes.com/1993/12/03/nyregion/giuliani-appoints-bostonian-to-run-ne
w-york-s-police.html.





n119  N.Y. CITY POLICE DEP'T, POLICE STRATEGY NO. 5: RECLAIMING THE PUBLIC
SPACES OF NEW YORK (1994).





n120  N.Y. CITY POLICE DEP'T, POLICE STRATEGY NO. 1: GETTING GUNS OFF THE
STREETS OF NEW YORK (1994).





n121  See Dennis C. Smith & William J. Bratton, Performance Management in New
York City: Compstat and the Revolution in Police Management, in QUICKER, BETTER,
CHEAPER: MANAGING PERFORMANCE IN AMERICAN GOVERNMENT 453 (Dall W. Forsythe ed.,
2001).





n122  White, supra note 107, at 84.





n123  Jeffrey Fagan & Garth Davies, Street Stops and Broken Windows: Terry,
Race, and Disorder in New York City, 28 FORDHAM URB. L.J. 457, 476 (2000).





n124  Sarah E. Waldeck, Cops, Community Policing, and the Social Norms Approach
to Crime Control: Should One Make Us More Comfortable with the Others?, 34 GA.
L. REV. 1253, 1282 (1999).





n125  White, supra note 107, at 82 (citing Judith A. Greene, Zero Tolerance. A
Case Study of Police Policies and Practices in New York City, 45 CRIME &
DELINQUENCY 171 (1999)).





n126  See Garen Wintemute, Guns and Gun Violence, in THE CRIME DROP IN AMERICA
45 (Alfred Blumstein & Joel Wallman eds., rev. ed. 2006).





n127  Amanda Geller & Jeffrey Fagan, Pot as Pretext: Marijuana, Race, and the
New Disorder in New York City Street Policing, 7 J. EMPIRICAL LEGAL STUD. 591,
592 (2010).





n128  NYPD STOP-AND-FRISK DATABASE, supra note 20.





n129  David Weisburd, Cody W. Telep & Brian A. Lawton, Could Innovations in
Policing Have Contributed to the New York City Crime Drop Even in a Period of
Declining Police Strength?: The Case of Stop, Question and Frisk as a Hot Spots
Policing Strategy, 31 JUST. Q. 129, 136-37 (2014).





n130  NYPD STOP-AND-FRISK DATABASE, supra note 20.





n131  DELORES JONES-BROWN, JASPREET GILL & JENNIFER TRONE, STOP, QUESTION &
FRISK POLICING PRACTICES IN NEW YORK CITY: A PRIMER 10-11 (2010),
http://static.prisonpolicy.org/scans/PRIMER_electronic_version.pdf.





n132  Id. at 10-13 fig.8B.





n133  Id. at 14 fig.9.





n134  Waldeck, supra note 124, at 1273-74.





n135  Fagan & Davies, supra note 123, at 468.





n136  Waldeck, supra note 124, at 1274.





n137  Fagan & Davies, supra note 123, at 471-72.





n138  Michael D. White, Henry F. Fradella & James R. Coldren, Jr., Why Police
(and Communities) Need 'Broken Windows,' CRIME REPORT (Aug. 11, 2015),
http://thecrimereport.org/2015/08/11/2015-08-why-police-and-communities-need-bro
ken-windows/.





n139  See generally MICHAEL HAMMER & JAMES CHAMPY, REENGINEERING THE
CORPORATION: A MANIFESTO FOR BUSINESS REVOLUTION (1993).





n140  Id.; see also James J. Willis, Stephen D. Mastrofski & David Weisburd,
Making Sense of COMPSTAT: A Theory-Based Analysis of Organizational Change in
Three Police Departments, 41 LAW & SOC'Y REV. 147, 151 (2007).





n141  White, supra note 107, at 81.





n142  See Weisburd et al., supra note 129, at 2; see also FRANKLIN E. ZIMRING,
THE CITY THAT BECAME SAFE: NEW YORK'S LESSONS FOR URBAN CRIME AND ITS CONTROL
(2012).





n143  New York Police Commissioner Ray Kelly Calls Stop-and-Frisk Decision
'Disturbing and Offensive' (Transcript), N.Y. DAILY NEWS (Aug. 12, 2013),
http://www.nydailynews.com/news/politics/new-york-police-commissioner-ray-kelly-
comments-stop-and-frisk-decision-article-1.1424689.





n144  Michael R. Bloomberg, Opinion, Michael Bloomberg: 'Stop and Frisk' Keeps
New York Safe, WASH. POST (Aug. 18, 2013),
https://www.washingtonpost.com/opinions/michael-bloomberg-stop-and-frisk-keeps-n
ew-york-safe/2013/08/18/8d4cd8c4-06cf-11e3-9259-e2aafe5a5f84_story.html.





n145  For full treatment of this question, see 31 JUST. Q. 1 (2014) (special
issue on the New York City crime decline).





n146  Hope Corman & Naci Mocan, Carrots, Sticks, and Broken Windows, 48 J.L. &
ECON. 235, 255 tbl.3 (2005); see also ROBERT C. DAVIS & PEDRO MATEU-GELABERT,
RESPECTFUL AND EFFECTIVE POLICING: TWO EXAMPLES IN THE SOUTH BRONX (1999),
http://archive.vera.org/sites/default/files/resources/downloads/respectful_polic
ing.pdf.





n147  GEORGE L. KELLING & WILLIAM H. SOUSA, JR., MANHATTAN INST., DO POLICE
MATTER? AN ANALYSIS OF THE IMPACT OF NEW YORK CITY'S POLICE REFORMS Executive
Summary (2001), http://www.manhattan-institute.org/pdf/cr_22.pdf.





n148  DENNIS C. SMITH & ROBERT PURTELL, AN EMPIRICAL ASSESSMENT OF NYPD'S
"OPERATION IMPACT": A TARGETED ZONE CRIME REDUCTION STRATEGY 9 (2007),
http://wagner.nyu.edu/files/faculty/publications/impactzoning.doc.





n149  See Report of Dennis C. Smith, Ph.D. at 19 & 63, n.32, Floyd v. City of
New York, 813 F.Supp.2d 457 (S.D.N.Y. Nov. 15, 2010) (No. 08 Civ. 01034), 2010
WL 9532297 (citing Dennis Charles Smith & Robert Purtell, Does Stop-and-Frisk
Stop Crime? (paper presented at the Annual Research Conference of the
Association of Public Policy and Management in Nov. 2008)); see also Dennis C.
Smith, Opinion, Stop and Frisk Has Lowered Crime in Other Cities, N.Y. TIMES
(July 19, 2012),
http://www.nytimes.com/roomfordebate/2012/07/17/does-stop-and-frisk-reduce-crime
/stop-and-frisk-has-lowered-crime-in-other-cities.





n150  ZIMRING, supra note 142, passim.





n151  Magdalena Cerdá, Melissa Tracy, Steven F. Messner, David Vlahov, Kenneth
J. Tardiff & Sandro Galea, Misdemeanor Policing, Physical Disorder, and
Gun-Related Homicide: A Spatial Analytic Test of "Broken-Windows" Theory, 20
EPIDEMIOLOGY 533, 537-38 (2009); Magdalena Cerdá, Steven F. Messner, Melissa
Tracy, David Vlahov, Emily Goldmann, Kenneth J. Tardiff & Sandro Galea,
Investigating the Effect of Social Changes on Age-Specific Gun-Related Homicide
Rates in New York City During the 1990s, 100 AM. J. PUB. HEALTH 1107, 1111-12
(2010); Richard Rosenfeld, Robert Fornango & Andres F. Rengifo, The Impact of
Order-Maintenance Policing on New York City Homicide and Robbery Rates:
1988-2001, 45 CRIMINOLOGY 355, 375-77 (2007).





n152  Richard Rosenfeld & Robert Fornango, The Impact of Police Stops on
Precinct Robbery and Burglary Rates in New York City, 2003-2010, 31 JUST. Q. 96,
116 (2014).





n153  Bernard E. Harcourt & Jens Ludwig, Broken Windows: New Evidence From New
York City and a Five-City Social Experiment, 73 U. CHI. L. REV. 271, 276-77
(2006).





n154  John MacDonald, Jeffrey Fagan & Amanda Geller, The Effects of Local Police
Surges on Crime and Arrests in New York City, 11 PLoS ONE e0157223, at 1 (Colum.
Pub. L. Res. Paper No. 14-468 (June 16, 2016),
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2614058).





n155  JENNIFER FRATELLO, ANDRÉS F. RENGIFO, JENNIFER TRONE & BRENDA VELAZQUEZ,
COMING OF AGE WITH STOP AND FRISK: EXPERIENCES, PERCEPTIONS, AND PUBLIC SAFETY
IMPLICATIONS, iii, 34 fig.14 (2013),
http://archive.vera.org/sites/default/files/resources/downloads/stop-and-frisk_t
echnical-report.pdf.





n156  Jeffrey A. Fagan, Amanda Geller, Garth Davies & Valerie West, Street Stops
and Broken Windows Revisited: The Demography and Logic of Proactive Policing in
a Safe and Changing City, in RACE, ETHNICITY, AND POLICING: NEW AND ESSENTIAL
READINGS 309, 337 (Stephen K. Rice & Michael D. White eds., 2010).





n157  See, e.g., Ray Kelly, Commentary, The NYPD: Guilty of Saving 7,383 Lives,
WALL ST. J. (July 22, 2013),
http://www.wsj.com/articles/SB10001424127887324448104578616333588719320.





n158  Jennifer Fermino, Mayor Bloomberg on Stop-And-Frisk: It Can Be Argued 'We
Disproportionately Stop Whites Too Much. And Minorities Too Little,' N.Y. DAILY
NEWS (June 28, 2013),
http://www.nydailynews.com/new-york/mayor-bloomberg-stop-and-frisk-disproportion
ately-stop-whites-minorities-article-1.1385410.





n159  Graham Rayman, New NYPD Tapes Introduced in Stop and Frisk Trial, VILLAGE
VOICE (Mar. 22, 2013),
http://www.villagevoice.com/news/new-nypd-tapes-introduced-in-stop-and-frisk-tri
al-6721026.





n160  CTR. FOR CONSTITUTIONAL RIGHTS, STOP AND FRISK: THE HUMAN IMPACT 1 (2012),
http://ccrjustice.org/sites/default/files/attach/2015/08/the-human-impact-report
.pdf.





n161  POLICE EXEC. RESEARCH FORUM, CIVIL RIGHTS INVESTIGATIONS OF LOCAL POLICE:
LESSONS LEARNED 1 (2013),
http://www.policeforum.org/assets/docs/Critical_Issues_Series/civil%20rights%20i
nvestigations%20of%20local%20police%20-%20lessons%20learned%202013.pdf; Stephen
Rushin, Federal Enforcement of Police Reform, 82 FORDHAM L. REV. 3189 (2014).





n162  An Act to Enforce the Provisions of the Fourteenth Amendment to the
Constitution of the United States, and for Other Purposes, ch. 22, § 1, 17 Stat.
13 (1871) (codified as amended at 42 U.S.C. § 1983 (2000)).





n163  Id.





n164  Ken Gormley, Private Conspiracies and the Constitution: A Modern Vision of
42 U.S.C. Section 1985(3), 64 TEX. L. REV. 527, 537 (1985); Monell v. Dep't of
Soc. Serv. of N.Y., 436 U.S. 658, 665 (1978) (citing CONG. GLOBE, 42d Cong., 1st
Sess., 522 (1871)).





n165  See Monroe v. Pape, 365 U.S. 167, 167 (1961), overruled on other grounds
by Monell v. Dep't of Soc. Serv. of N.Y., 436 U.S. 658 (1978) (holding
municipalities may be sued under Section 1983); Memphis Cmty. Sch. Dist. v.
Stachura, 477 U.S. 299, 305 (1986).





n166  JIM THOMAS, PRISONER LITIGATION: THE PARADOX OF THE JAILHOUSE LAWYER 37
(1988).





n167  Robert C. Harrall, Prisoners' Section 1983 Cases: A Study of Palmigiano v.
Garrahy (unpublished Ph.D. dissertation, University of Connecticut).





n168  365 U.S. 167.





n169  Id. at 191-92.





n170  Id. at 187-92.





n171  436 U.S. 658.





n172  Id. at 690-91.






n173  See, e.g., MARTIN A. SCHWARTZ, SECTION 1983 LITIGATION 97 (3d ed. 2014);
see also City of St. Louis v. Praprotnik, 485 U.S. 112, 127 (1988) (quoting
Adickes v. S.H. Kress & Co., 398 U.S. 144, 167-68 (1970)).





n174  See, e.g., William A. Margeson, Bringing the Gavel Down on Stops and
Frisks: The Equitable Regulation of Police Power, 51 AM. CRIM. L. REV. 739, 756
(2014).





n175  Angelo N. Ancheta, Defendant Class Actions and Federal Civil Rights
Litigation, 33 UCLA L. REV. 283, 298 (1985).





n176  JEROME H. SKOLNICK & JAMES J. FYFE, ABOVE THE LAW: POLICE AND THE
EXCESSIVE USE OF FORCE 202 (1993).





n177  INDEP. COMM'N ON THE L.A. POLICE DEP'T, REPORT OF THE INDEPENDENT
COMMISSION ON THE LOS ANGELES POLICE DEPARTMENT 56 (1991),
http://michellawyers.com/wp-content/uploads/2010/06/Report-of-the-Independent-Co
mmission-on-the-LAPD-re-Rodney-King_Reduced.pdf.





n178  Iver Peterson & David M. Halbfinger, New Jersey Agrees to Pay $ 13 Million
in Profiling Suit, N.Y. TIMES (Feb. 3, 2001),
http://www.nytimes.com/2001/02/03/nyregion/new-jersey-agrees-to-pay-13-million-i
n-profiling-suit.html.





n179  Marc L. Miller & Ronald F. Wright, Secret Police and the Mysterious Case
of the Missing Tort Claims, 52 BUFF. L. REV. 757, 776 (2004).





n180  In 1985, the U.S. Supreme Court established a national mandatory minimum
requirement for the use of deadly force in Tennessee v. Garner, 471 U.S. 1
(1985). Abraham Tennenbaum examined the effects of the Garner decision on use of
deadly force nationwide and concluded that it reduced the number of police
killings by 60 homicides a year--a 16% decrease. Abraham N. Tennenbaum, The
Influence of the Garner Decision on Police Use of Deadly Force, 85 J. CRIM. L. &
CRIMINOLOGY 241, 257 (1994).





n181  Candace McCoy, How Civil Rights Lawsuits Improve American Policing, in
HOLDING POLICE ACCOUNTABLE 111, 112 (Candace McCoy ed., 2010).





n182  Id. at 144.





n183  Id.





n184  Id. at 144-46.





n185  Id. at 150.





n186  Pub. L. No. 103-322, 108 Stat. 1796 (1994) (codified in scattered sections
of the U.S.C.).





n187  See, e.g., David M. Jaros, Preempting the Police, 55 B.C. L. REV. 1149,
1159-60 (2014) (describing legislative action following the Rodney King
beating); Stephen Rushin, Using Data to Reduce Police Violence, 57 B.C. L. REV.
117 (2016).





n188  42 U.S.C. § 14141 (2012).





n189  Stephen Rushin, Structural Reform Litigation in American Police
Departments, 99 MINN. L. REV. 1343, 1347 (2015).





n190  Rushin, supra note 161, at 3220-24.





n191  Id. at 3219-26.





n192  Id. at 3224-29; see also Rushin, supra note 189, at 1370-71.





n193  Rushin, supra note 161, at 3228-29; see also Rachel A. Harmon, Promoting
Civil Rights Through Proactive Policing Reform, 62 STAN. L. REV. 1, 16 (2009).





n194  Rushin, supra note 161, at 3228; see also POLICE EXEC. RESEARCH FORUM,
supra note 161, at 27.





n195  It is important to note that until relatively recently, settlements have
been the norm, but this may be changing--perhaps as the defendants realize what
it might cost to comply. Consider, for example, that Alamance, North Carolina,
went to trial on a § 14141 claim and prevailed (although the DOJ is appealing).
Michael D. Abernethy, Judge Dismisses DOJ Case Against Johnson, Finds No
Evidence of Unconstitutional Practices, TIMES-NEWS (Aug. 7, 2015),
http://www.thetimesnews.com/article/20150807/NEWS/150809283. Ferguson, Missouri
originally participated in negotiations for a consent decree, but subsequently
withdrew from the agreement. Matt Ford, United States v. Ferguson: Attorney
General Loretta Lynch Announced the Justice Department is Suing the Missouri
Municipality After an Agreement on Reform Broke Down, ATLANTIC (Feb. 11, 2016),
http://www.theatlantic.com/politics/archive/2016/02/doj-ferguson-lawsuit/462300/
. As a result, DOJ filed suit against Ferguson in February 2016; as of this
writing, Ferguson contests the substantive allegations that the municipality has
engaged in "a pattern or practice of law enforcement conduct that violates the
Constitution and federal civil rights laws" and is, therefore, actively
defending the litigation. Id.





n196  POLICE EXEC. RESEARCH FORUM, supra note 161, at 29-31.





n197  Rushin, supra note 161, at 3247; Rushin, supra note 189, at 1377; see also
Darrell L. Ross & Patricia A. Parke, Policing by Consent Decree: An Analysis of
42 U.S.C. § 14141 and the New Model for Police Accountability, 10 POLICE PRAC. &
RES. 199, 200 (2009). For additional insight into the consent decree process,
see SAMUEL WALKER & CAROL A. ARCHBOLD, THE NEW WORLD OF POLICE ACCOUNTABILITY
25-26 (2d ed. 2014); Michael D. White, Preventing Racially Biased Policing
Through Internal and External Controls: The Comprehensive Accountability
Package, in RACE, ETHNICITY, AND POLICING: NEW AND ESSENTIAL READINGS 468, 480
(Stephen K. Rice & Michael D. White eds., 2010); Debra Livingston, Police Reform
and The Department of Justice: An Essay on Accountability, 2 BUFF. CRIM. L. REV.
815 (1999).





n198  See Rushin, supra note 189, at 1383-84, 1401-03; POLICE EXEC. RESEARCH
FORUM, supra note 161, passim.





n199  ROBERT DAVIS, NICOLE HENDERSON & CHRISTOPHER ORTIZ, CAN FEDERAL
INTERVENTION BRING LASTING IMPROVEMENT IN LOCAL POLICING?: THE PITTSBURGH
CONSENT DECREE 4 (2005),
http://www.vera.org/sites/default/files/resources/downloads/277_530.pdf.





n200  Noah Kupferberg, Transparency: A New Role for Police Consent Decrees, 42
COLUM. J.L. & SOC. PROBS. 129, 129 (2008).





n201  Elliot Harvey Schatmeier, Reforming Police Use-of-Force Practices: A Case
Study of the Cincinnati Police Department, 46 COLUM. J.L. & SOC. PROBS. 539, 539
(2013).





n202  CHRISTOPHER STONE, TODD FOGLESONG & CHRISTINE M. COLE, POLICING LOS
ANGELES UNDER A CONSENT DECREE: THE DYNAMICS OF CHANGE AT THE LAPD (2009),
http://www.lapdonline.org/assets/pdf/Harvard-LAPD%20Study.pdf.





n203  Joshua M. Chanin, Examining the Sustainability of Pattern or Practice
Police Misconduct Reform, 18 POLICE Q. 163, 163 (2015).





n204  Joshua Chanin, On the Implementation of Pattern or Practice Police Reform,
15 CRIMINOLOGY, CRIM. JUST., L. & SOC'Y 38, 38 (2014).





n205  See DAVIS, HENDERSON & ORTIZ, supra note 199; Schatmeier, supra note 201;
STONE, FOGLESONG & COLE, supra note 202, at 6.





n206  See DAVIS, HENDERSON & ORTIZ, supra note 199; Kupferberg, supra note 200,
at 151-52, 154-55, 158-59; STONE, FOGLESONG & COLE, supra note 202, at i.





n207  See Chanin, supra note 203, at 165; Schatmeier, supra note 201, at 560;
STONE, FOGLESONG & COLE, supra note 202, at 1.





n208  See Chanin, supra note 203, at 183; DAVIS, HENDERSON & ORTIZ, supra note
199, at 42.





n209  See DAVIS, HENDERSON & ORTIZ, supra note 199, at 35, 38; Schatmeier, supra
note 201, at 563; STONE, FOGLESONG & COLE, supra note 202, i-ii.





n210  See Kupferberg, supra note 200; STONE, FOGLESONG & COLE, supra note 202,
at ii.





n211  Ross & Parke, supra note 197, at 204; Samuel Walker, The New Paradigm of
Police Accountability: The U.S. Justice Department "Pattern or Practice" Suits
in Context, 22 ST. LOUIS U. PUB. L. REV. 3, 49 (2003).





n212  Stipulation of Settlement at 1-2, Daniels v. City of New York, No. 99 Civ.
1695 (S.D.N.Y. Sept. 24, 2003) [hereinafter Daniels Settlement].





n213  See Michael Cooper, Officers in Bronx Fire 41 Shots, and an Unarmed Man Is
Killed, N.Y. TIMES, Feb. 5, 1999, at Al.





n214  Kupferberg, supra note 200, at 142 (citing Ginger Thompson, 1,000 Rally to
Condemn Shooting of Unarmed Man by Police, N.Y. TIMES, Feb. 8, 1999, at B1;
Kevin Flynn, Police Killing Draws National Notice, N.Y. TIMES, Feb. 8, 1999, at
B5; Andy Newman, Prayer in New York, Protest in Washington, N.Y. TIMES, Feb. 16,
1999, at B5).





n215  See Current Developments, City Torts: Wrongful Death: City Settled Diallo
Suit, 10 CITY L. 43 (2004).





n216  Daniels Settlement, supra note 212, at 5. The year after the Daniels
settlement, New York City enacted a law codifying a provision of the settlement
by prohibiting "the use of race, color, ethnicity, religion or national origin
as the determinative factor for initiating police action." Kupferberg, supra
note 200, at 156.





n217  For a detailed discussion of the shortcomings of the Daniels settlement
and its implementation, see Kupferberg, supra note 200, at 144-45, 155-58.





n218  Complaint and Demand for Jury Trial, Floyd v. City of New York, 08 Civ.
1034 (S.D.N.Y. Jan. 31, 2008),
http://ccrjustice.org/files/Floyd_Complaint_08.01.31.pdf.





n219  Daniels v. City of New York, No. 99 Civ. 1695, 2007 WL 2077150, at *3
(S.D.N.Y. July 16, 2007).





n220  Report of Jeffrey Fagan, Ph.D. at 1-2, Floyd v. City of New York, 08 Civ.
1034 (S.D.N.Y. Oct. 15, 2010) [hereinafter Fagan Report],
https://ccrjustice.org/files/Expert_Report_JeffreyFagan.pdf; Second Supplemental
Report of Jeffrey Fagan, Ph.D. at 1-2, Floyd v. City of New York, 08 Civ. 1034
(S.D.N.Y. Nov. 29, 2012) [hereinafter Fagan Second Supplement Report],
http://www.ccrjustice.org/files/FaganSecondSupplementalReport.pdf.





n221  CTR. FOR CONSTITUTIONAL RIGHTS, RACIAL DISPARITY IN NYPD STOPS-AND-FRISKS:
THE CENTER FOR CONSTITUTIONAL RIGHTS PRELIMINARY REPORT ON UF-250 DATA FROM 2005
THROUGH JUNE 2008 4 (2009),
https://ccrjustice.org/files/Report-CCR-NYPD-Stop-and-Frisk.pdf.





n222  Fagan Report, supra note 220, at 3-4; Fagan Second Supplemental Report,
supra note 220, at 2-6.





n223  Floyd v. City of New York, 959 F. Supp. 2d 540 (S.D.N.Y. 2013) (liability
decision).





n224  Floyd v. City of New York, 959 F. Supp. 2d 668, 669 (S.D.N.Y. 2013)
(remedy decision).





n225  Id. at 675-90.





n226  Id. at 684-86.





n227  Ligon v. City of New York, 538 Fed. Appx. 101 (2d Cir. 2013).





n228  Id. at 102-103.





n229  Opposition of Sergeants Benevolent Association to Motion of City of New
York for Limited Remand to the District Court for the Purpose of Exploring a
Resolution at 1-2, Floyd v. City of New York, No. 13-3088 (2d Cir. Feb. 7,
2014),
http://ccrjustice.org/files/SBA%20Opp%20to%20City%27s%20Motion%20to%20Remand.%20
2%207%202014.pdf.





n230  Floyd v. City of New York, 302 F.R.D. 69, 76 (S.D.N.Y. 2014).





n231  Azi Paybarah, Bill Bratton: There Will Always Be Stop-and-Frisk, POLITICO
(June 14, 2013, 12:16 PM),
http://www.politico.com/states/new-york/city-hall/story/2013/06/bill-bratton-the
re-will-always-be-stop-and-frisk-000000.





n232  Floyd v. City of New York, 770 F.3d 1051 (2d Cir. 2014) (granting City of
New York's motion for voluntary dismissal of the appeals with prejudice).





n233  Joint Remedial Process in Floyd v. City of New York: What You Need to Know
, CTR. FOR CONSTITUTIONAL RIGHTS (June 23, 2014),
https://web.archive.org/web/20160413131113/https://ccrjustice.org/home/get-invol
ved/tools-resources/fact-sheets-and-faqs/timeline-floyd-v-city-new-york.





n234  McCoy, supra note 181; Ross & Parke, supra note 197.





n235  Samuel P. Jordan, Federalism, Democracy, and the Challenge of Ferguson, 59
ST. LOUIS U. L.J. 1103, 1103 (2015).





n236  SPITZER, supra note 13, at 63-64.





n237  For a complete list of information listed by police officers on UF-250
forms, see NYPD STOP-AND-FRISK DATABASE, supra note 20, Database File
Specifications.





n238  DELORES JONES-BROWN, BRETT G. STOUDT, BRIAN JOHNSTON & KEVIN MORAN, STOP,
QUESTION AND FRISK POLICING PRACTICES IN NEW YORK CITY: A PRIMER (REVISED) 3
(July 2013),
http://www.atlanticphilanthropies.org/app/uploads/2015/09/SQF_Primer_July_2013.p
df; see also Weisburd et al., supra note 129, at 148; Rosenfeld & Fornango,
supra note 152, at 98.





n239  The results reported in this section, including those contained in tables
and figures, come from our own analyses of the raw data reported in the official
NYPD STOP-AND-FRISK DATABASE, supra note 20.





n240  NYPD STOP-AND-FRISK DATABASE, supra note 20. Note that the 121st precinct
was excluded from the map because it did not contain stop data in 2011 for a
comparison to be made against 2014.





n241  JONES-BROWN, STOUDT, JOHNSTON & MORAN, supra note 238, at 41-42.





n242  NYPD STOP-AND-FRISK DATABASE, supra note 20.





n243  See generally FERDICO, FRADELLA & TOTTEN, supra note 8, at 307-58.





n244  NYPD STOP-AND-FRISK DATABASE, supra note 20.





n245  NYPD STOP-AND-FRISK DATABASE, supra note 20. Note that the race/ethnicity
categories of Asian/Pacific Islander, American Indian/Alaskan Native, and other
were all collapsed into a single category entitled "other" because of their
small sample size.





n246  Amanda Terkel, Ray Kelly on Stop-and-Frisk: 'No Question' Violent Crime
Will Rise If Program Is Stopped, HUFFINGTON POST (Aug. 18, 2013),
http://www.huffingtonpost.com/2013/08/18/ray-kelly-stop-and-frisk_n_3776035.html
.





n247  From 2011 to 2014, New York City's population increased from 8,211,875 to
8,473,938. Uniform Crime and Reporting, Offenses Known to Law Enforcement by
City: New York (2011-2014), FED. BUREAU OF INVESTIGATION:

     2011:
     https://ucr.fbi.gov/crime-in-the-u.s/2011/crime-in-the-u.s.-2011/table
     s/table8statecuts/table_8_offenses_known_to_law_enforcement_new_york_b
     y_city_2011.xls
     2014:
     https://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/2014/crime-in-t
     he-u.s.-2014/tables/table-8/table-8-by-state/Table_8_Offenses_Known_to
     _Law_Enforcement_by_New_York_by_City_2014.xls







n248  Uniform Crime and Reporting, Offenses Known to Law Enforcement by City:
New York (2005-2014), FED. BUREAU OF INVESTIGATION:

     2005: https://www2.fbi.gov/ucr/05cius/data/table_08_ny.html
     2006: https://www2.fbi.gov/ucr/cius2006/data/table_08_ny.html
     2007: https://www2.fbi.gov/ucr/cius2007/data/table_08_ny.html
     2008: https://www2.fbi.gov/ucr/cius2008/data/table_08_ny.html
     2009: https://www2.fbi.gov/ucr/cius2009/data/table_08_ny.html
     2010:
     https://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/2010/crime-in-t
     he-u.s.-2010/tables/table-8/10tbl08ny.xls
     2011:
     https://ucr.fbi.gov/crime-in-the-u.s/2011/crime-in-the-u.s.-2011/table
     s/table8statecuts/table_8_offenses_known_to_law_enforcement_new_york_b
     y_city_2011.xls
     2012:
     https://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/2012/crime-in-t
     he-u.s.-2012/tables/8tabledatadecpdf/table-8-statecuts/table_8_offense
     s_known_to_law_enforcement_by_new_york_by_city_2012.xls
     2013:
     https://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/2013/crime-in-t
     he-u.s.-2013/tables/table-8/table-8-statecuts/table_8_offenses_known_t
     o_law_enforcement_new_york_by_city_2013.xls
     2014:
     https://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/2014/crime-in-t
     he-u.s.-2014/tables/table-8/table-8-by-state/Table_8_Offenses_Known_to
     _Law_Enforcement_by_New_York_by_City_2014.xls







n249  WHITE & FRADELLA, supra note 2, at ch. 6.





n250  WHITE & FRADELLA, supra note 2, at ch. 6.





n251  PRESIDENT'S TASK FORCE ON 21ST CENTURY POLICING, supra note 19.





n252  U.S. CENSUS BUREAU, PROFILE OF GENERAL HOUSING CHARACTERISTICS: 2010, NEW
YORK CITY,NEW YORK,
http://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src
=bkmk.





n253  GREG RIDGEWAY, ANALYSIS OF RACIAL DISPARITIES IN THE NEW YORK POLICE
DEPARTMENT'S STOP, QUESTION, AND FRISK PRACTICES xii (2007),
http://www.rand.org/content/dam/rand/pubs/technical_reports/2007/RAND_TR534.pdf.





n254  Kupferberg, supra note 200; STONE, FOGLESONG & COLE, supra note 202.





n255  First Report of the Independent Monitor at 36, Floyd v. City of New York,
08-cv-01034-AT (S.D.N.Y. July 9, 2015),
http://nypdmonitor.org/wp-content/uploads/2015/08/MonitorsFirstReport-AsFiledInF
loydDocket.pdf.





n256  Final Recommendations Regarding Patrol Guide 212.11 and Patrol Guide
203.25 at 3, Floyd v. City of New York, 08-cv-01034-AT (S.D.N.Y. Aug. 24, 2015),
http://nypdmonitor.org/wp-content/uploads/2015/09/Revision-to-Stop-and-Frisk-Pre
venting-Racial-Profiling-Preventing-Racial-Profiling-212-211.pdf.





n257  See Floyd v. City of New York, 283 F.R.D. 153, 160 (S.D.N.Y. 2012) (class
certification opinion); see also Margeson, supra note 174, at 756-64.





n258  Margeson, supra note 174, at 771-72.





n259  See Chanin, supra note 203; Chanin, supra note 204; DAVIS, HENDERSON &
ORTIZ, supra note 199; Kupferberg, supra note 200; STONE, FOGLESONG & COLE,
supra note 202.


                               13 of 41 DOCUMENTS


                           Star-News (Wilmington, NC)

                             October 2, 2016 Sunday
                             NC Wilmington Edition

BYLINE: NC Tiller Rose; Los Angeles Times

SECTION: 1,A; GateHouse Media GM9; Pg. 22

LENGTH: 717 words


LOS ANGELES   Can police prevent hate crimes by monitoring racist banter on
social media?

Researchers will be testing this concept over the next three years in Los
Angeles, marking a new frontier in efforts by law enforcement to predict and
prevent crimes.

During a three-year experiment, British researchers working with the Santa
Monica, Calif.-based RAND Corp. will be monitoring millions of tweets related to
the L.A. area in an effort to identify patterns and markers that
prejudice-motivated violence is about to occur in real time.

The researchers then will compare the data against records of reported violent
acts. The U.S. Department of Justice is investing $600,000 in research by
Cardiff University Social Data Science Lab, which has been at the forefront of
predictive social media models

Cardiff University professor Matthew Williams said the research is designed to
eventually enable authorities to predict when and where hate crime is likely to
occur and deploy law enforcement resources to prevent it.

The insights provided by our work will help U.S. localities to design policies
to address specific hate crime issues unique to their jurisdiction and allow
service providers to tailor their services to the needs of victims, especially
if those victims are members of an emerging category of hate crime targets.

His lab s previous research in the United Kingdom found that Twitter data can be
used to identify areas where hate speech is occurring but where no hate crimes
have been committed. This can be useful, researchers said, in neighborhoods with
many new immigrants, who are unlikely to report the crime because of fear of
deportation.

In 2012, an estimated 293,800 nonfatal violent and property hate crimes occurred
in the United States, according to the Bureau of Justice Statistics. About 60
percent of those were not reported, the Justice Department found.

Of course, there is a big difference between someone spouting off on Twitter or
Snapchat and an actual hate crime.

It is a great idea in the abstract. But it is not the panacea you might think,
said Brian Levin, executive director of Cal State San Bernardino s Center on
Hate and Extremism.  The problem is the correlation and reliability. ... There
are many different forms of social media.

Levin, who has tracked both Middle Eastern terror groups and local neo-Nazi
organizations, also noted that some hate groups don t advertise their work on
social media.

Local tensions may arise to fly and be absent from social media,  he said.  Some
segments of the community shun social media ... so examining social media as a
predictor can be a bit like having one screwdriver and sometimes it doesn t
work.

Predictive policing already is in use at the Los Angeles Police Department and
other agencies. The LAPD uses a predictive policing algorithm to deploy officers
to locations where prior crime patterns strongly suggest similar crimes may
occur. As crime during the last two decades has dropped dramatically across the
nation and Los Angeles, police commanders are increasingly looking for any edge
they can get in cutting crime.

L.A. County is particularly useful because a huge volume of social media
produces massive data sets that increase the accuracy of predictive models over
traditional crime analysis and trend-chasing, said Pete Burnap, from Cardiff
University s School of Computer Science and Informatics.

Predictive policing is a proactive law enforcement model that has become more
common partially due to the advent of advanced analytics such as data mining and
machine-learning methods,  he said.

Traditional predictive police modeling has paired historical crime records with
geographical locations and then made a probable calculation to predict future
crimes. But Twitter and social media-based models work in real time using what
people are talking about now. The algorithms look for particular language that
is likely to indicate the imminent occurrence of a crime.

British researchers began looking at cyber-hate in the aftermath of the killing
of British Army soldier Lee Rigby at the hands of Islamic extremists on a London
street in 2013. Analysts collected Twitter data and tested a text classifier
that distinguished between hateful and antagonistic responses focusing on race,
ethnicity and religion.

LOAD-DATE: October 2, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                         Copyright 2016 Star-News, Inc.
                              All Rights Reserved


                               14 of 41 DOCUMENTS


                         The Christian Science Monitor

                             June 2, 2016 Thursday

Can police big data stop Chicago's spike in crime?;
More police departments are using algorithms to predict crimes. But as Chicago's
police department has discovered, having data isn't enough to prevent violence.

BYLINE: Nissa Rhee Correspondent

SECTION: USA

LENGTH: 1440 words


From a computer at Chicago's police headquarters on the city's South Side,
Deputy Chief Jonathan Lewin pulls up a list of about 1,400 names of people with
criminal records. Attached to each name is a mug shot, demographics, prior
arrest record, and gang affiliation. There is also a score.

Determined by a computer algorithm based on 11 weighted variables, the score
measures the likelihood of a person to be involved in a shooting, either as a
victim or an offender. The scores range from 1 to 500, and the higher the score
the more likely the person will be a party to violence.

"This is really evidence-based policing," says Deputy Chief Lewin.

Chicago is at the forefront of a growing trend in police departments across the
United States to use big data and algorithms to determine the individuals and
places that are most as risk for violence. Some of these risk assessments are
astonishingly accurate.

But while the people-centered model pioneered in Chicago is now spreading,
predictive policing so far has not succeeded in bringing down the murder rate
here. That's led some to question whether big data alone can prevent crimes.

It is certainly possible that other factors - such as a breakdown in trust
between police and minority communities, a need to hire more officers, or the
overturning of the city's gun laws in federal court - may be driving the
increase in the murder rate, which is up 84 percent over this time last year.
Supporters of the data program, for their part, say they believe the murder
spike would be worse without the predictive tools.

"The idea that one might be able to target and approach the human drivers and do
something about that is obviously incredibly attractive to police departments,"
says Andrew Ferguson, a law professor at the University of the District of
Columbia in Washington. "The difficulty with Chicago as a laboratory is that [
predictive policing] is obviously not working. That might not be the fault of
the theory, but just empirically we're seeing the bodies pile up in the city."

Other cities, however, have seen success in using data to bring down the crime
rate: The Los Angeles Police Department (LAPD) expanded a program to predict
where to deploy its officers to 14 of its 21 divisions (up from three in 2013),
after a 2015 University of California at Los Angeles study showed that the
computers prevented twice as much crime as trained analysts.

Chicago uses a different algorithm, and it also may have aggravating factors
contributing to its rise in murders. In the wake of shootings of unarmed
minorities, the city has been wracked by months of turmoil and protests that led
to the firing of the former police chief. The federal government is
investigating the shooting of unarmed teenager Laquan McDonald, and a
months-long investigation by the police accountability task force concluded in
April that the Chicago Police Department has a history of using excessive force
against minorities and perpetuating a code of silence.

"Can you imagine where we'd be if everyone wasn't working as hard as they were
now?" says Christopher Mallette, executive director of the Chicago Violence
Reduction Strategy. "The reason that we struggle with a solution is that people
don't want to look at the problem in its totality. We want to look at the part
that makes sense to us."

Can math save lives?

Predictive policing has its origins in a program started in 2008 by the LAPD.
That early program used analytical techniques to determine locations that were
most at risk for criminal activity.

Chicago became the first city to use a people-centered model when it launched
the first version of its Strategic Subject List algorithm in 2012. Based on the
public health concept that crime is like a contagion that can spread from person
to person, the model analyzes social networks to determine who is most likely to
be involved in violent crimes. Since then, Kansas City, Los Angeles, and New
Orleans have started using big data to determine who among their population is
most at risk.

Sixty-six people were killed in the city in May alone, making last month the
deadliest May in 21 years. More than 74 percent of shooting victims and 80
percent of individuals arrested for shootings in 2016 so far have been on the
SSL.

So why hasn't the accuracy of the algorithm translated into less crime on the
street? Professor Ferguson says that while many initially saw big data as a
panacea for reducing crime, realistically it may be better at identifying
problems that preventing murders.

"People should recognize that big data does provide real insights and allows you
to see things that you might not see without the data," says Ferguson. "But the
solution is not in the data, it's in what you do with the data. I think what a
lot of people have done is take the first step, which is the easier step, to
crunch the numbers. And not taken the second step, which is to ask: Now that
we've identified these risks, how do we remedy this?"

The home visit model

In Chicago, law enforcement officers, community members, and social service
agencies all take part in the home visits - called custom notifications - the
police department does for people on the Strategic Subject List.

During the home visit, police officers warn the person on the SSL and their
family that they are in danger of either being shot, killed, or put in prison.
Then a community partner offers help in the form of job-training opportunities,
substance abuse counseling, and better housing options.

This carrot-and-stick model comes from a realization on the police department's
part that, as new Superintendent Eddie Johnson said in an interview, "we cannot
arrest our way out of this situation."

But at the same time, Superintendent Johnson says that those who do not accept
the offer of help on custom notification visits should not expect leniency.

"What those individuals need to know if they choose to stay in that lifestyle,
we'll come after them with everything that we have," says Johnson.

Rand Corp. is currently studying the effectiveness of Chicago's SSL and its
data-informed interventions. According to the individuals who go on home visits,
results thus far have been mixed.

Roughly 1 in 4 home visits results in someone accepting an offer of help,
according to Mr. Mallette, who invites representatives from one of six outreach
and support organizations to each house call. He says that the police have
connected with between 700 and 750 individuals through custom notification
during the past three years.

While it's too early to tell the long-term effect of the house visits, Mallette
says that he's seen some changes in those individuals in the short term.

Chicago Police Deputy Chief Dave McNaughton recalls one occasion where he went
to do a custom notification for a young man. He says his mother was in complete
denial about her son's risk for gun violence.

"She pretty much told us to leave the home, which we did of course," says Deputy
Chief McNaughton. "I remember three days later there was a person shot right
behind her house that was playing with her son."

On the same day that McNaughton met the mother, he did a custom notification for
a person who was deeply involved in the violence in the 8th police district on
Chicago's Southwest side. He met with the subject's significant other and she
accepted their offers of help.

The couple got services to move out of the neighborhood, and McNaughton says
that person has not been involved in violence since.

Who should take the lead?

Ferguson says that part of the problem with Chicago's data-driven interventions
might be the very fact that the police are the ones leading them.

Like risk assessment lists in many cities, Chicago's Strategic Subject List is
made available only to law enforcement officers and is not given out to the
social service agencies who lead violence prevention programs or to the
community groups who may know the individuals most at risk.

"To me, the big mistake of all of this is putting predictive policing in the
hands of the police," says Ferguson. "The identifying of risk within a society
should be put in the hands of other social service entities. It should be with
the larger city rather than just the police."

Mallette agrees that the community should play an important role in data-driven
interventions.

"Our focus isn't on locking people up. Our focus is on saving people's lives,"
says Mallette. "We're trying to take active measures to try and provide
assistance from multiple angles. Law enforcement is doing what law enforcement
is doing. Our message is that the community loves you, we value you, but we need
you in your rightful place."

LOAD-DATE: June 2, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


              Copyright 2016 Christian Science Publishing Society
                              All Rights Reserved


                               15 of 41 DOCUMENTS


                         The Mercury News (California)

                              July 11, 2016 Monday

Police: tech contract meant to predict, prevent crime in Milpitas nixed

BYLINE: By Ian Bauer, Milpitas Post

SECTION: BREAKING; Communities; News

LENGTH: 754 words


Three years ago, Milpitas Police Department had hopes of employing a new
crime-fighting technology that bordered on something one might see in a science
fiction movie.

But about a year after the city authorized a three-year, $37,000 contract with
California-based PredPol Inc. for so-called predictive policing software --
which uses mathematics, social science and probability to geographically
pinpoint and ultimately reduce crime -- the department pulled the plug on the
agreement.

"After approximately one year of usage, it was our experience that the minimal
benefit did not justify continuing costs," Milpitas Police Chief Steve
Pangelinan said last week.

In 2013, police here were interested in PredPol's web-based algorithmic software
that calculates historic crime trends, demographics and even the weather in
order to deploy officers to areas that experience the most crime. At the time,
Pangelinan told this newspaper the predictive technology had the ability to
locate crime to an area as small as 500 feet by 500 feet.

"In total, it will hopefully reduce crime," Pangelinan previously said.

Fast forward three years and the police chief found the software less than
stellar.

"It was our experience that we often did not have sufficient staff to post
officers at PredPol-identified locations and still remain responsive to priority
calls for service," Pangelinan said.

He added his police force discovered that within Milpitas' approximately 14
square miles the "existing internal processes of tracking crime and identifying
potential areas of exposure were often more accurate than results received from
PredPol."

Since ditching PredPol, Pangelinan asserted Milpitas police are not using
similar, crime-predictive technologies in part due to the size of the city.

"I think the PredPol system may have greater benefit to law enforcement
organizations policing much larger geographical jurisdictions where greater
variables in crime patterns may exist," he said.

When the city's police force had envisioned using PredPol, the technology had
come with some fanfare.

That included Time magazine, which called the predictive policing software one
of the best inventions of 2011. Similarly, a 2012 Associated Press story on the
new technology stated Los Angeles Police Department was the largest agency to
embrace the technology.

PredPol's website states its tool was developed over the course of six years by
a team of mathematicians and social scientists at the University of California
at Los Angeles, Santa Clara University and University of California at Irvine in
close collaboration with crime analysts and line-level officers at the Los
Angeles and Santa Cruz police departments.

PredPol states the mission for its software is simple: place officers at the
right time and location to give them the best chance of preventing crime.

To accomplish this, PredPol processes crime data in order to: assign
probabilities of future crime events to regions of space and time; present
estimated crime risk in a useable framework to law enforcement decision makers;
and lead to more efficient and more accurate resource deployment by local law
enforcement agencies.

Besides Los Angeles police, the Santa Cruz, Modesto and Atlanta police
departments have implemented PredPol's software and claim reductions in crime in
those cities, the firm's website states.

According to Pangelinan, there was no real cost to the city for using PredPol
software. A 2013 Citizen Options for Public Safety (COPS) grant -- generally
awarded by State of California to law enforcement agencies each year -- helped
finance the purchase.

"We utilized state grant funds of $12,500 for the one-year subscription," he
said.

Meanwhile, Pangelinan asserted that crime rates, which can be cyclical, rising
and falling year over year, in the city of Milpitas has been declining as of
late.

He said the Federal Bureau of Investigation's Part 1 serious, violent crimes
such as murder, rape, robbery, aggravated assault, auto theft, arson, burglary
have all seen decreases in Milpitas in the last year or so.

"In 2013 we realized a 2-percent increase in FBI Part 1 crimes, and in 2014 a
4-percent increase. However, in 2015 crime in these same categories declined by
more than 8 percent," Pangelinan said. "Through May of 2016 crime in these same
categories are down 13 percent below year-to-date numbers in 2015."

But Pangelinan would not comment as to the reason -- whether its old-fashinoned
police work or some other factor -- why crime here appears to be on the decline.

LOAD-DATE: July 11, 2016

LANGUAGE: ENGLISH

GRAPHIC: Steve Pangelinan
Steve Pangelinan

PUBLICATION-TYPE: Newspaper


            Copyright 2016 MediaNews Group, Inc. and ANG Newspapers
                              All Rights Reserved


                               16 of 41 DOCUMENTS

            Copyright (c) 2016 University of Pennsylvania Journal of
                               Constitutional Law
            University of Pennsylvania Journal of Constitutional Law

                                 February, 2016

            University of Pennsylvania Journal of Constitutional Law

                           18 U. Pa. J. Const. L. 933

LENGTH: 17093 words

ARTICLE: Fourth Amendment Time Machines (And What They Might Say About Police
Body Cameras)

NAME: Stephen E. Henderson*

BIO: * Judge Haskell A. Holloman Professor of Law, the University of Oklahoma
College of Law; B.S. in Electrical Engineering, University of California at
Davis; J.D., Yale Law School. I am grateful to the University of Pennsylvania
Journal of Constitutional Law for the invitation to participate in the
symposium, and to Nathan Hall and Jeffrey Vogt for excellent research
assistance. Several years ago, George Asllani and Adrienne Robertson also
performed some research which I have finally incorporated. Better late than
never. Finally, I am grateful to Kiel Brennan-Marquez, Jules Epstein, Andrew
Ferguson, Harold Krent, Christopher Slobogin, and Joseph Thai for providing
comments and suggestions on previous drafts.

HIGHLIGHT:

   Abstract


   When it comes to criminal investigation, time travel is increasingly
possible. Despite longstanding roots in traditional investigation, science is
today providing something fundamentally different in the form of remarkably
complete digital records. And those big data records not only store our past,
but thanks to data mining they are in many circumstances eerily good at
predicting our future. So, now that we stand on the threshold of investigatory
time travel, how should the Fourth Amendment and legislation respond? How should
we approach bulk government capture, such as by a solar-powered drone employing
wide-area persistent stare technology? Is it meaningfully different from
civilian equivalents that find their way into government hands, whether it be
tomorrow's drone flight, or today's record of all of our internet activity
compiled by our internet service provider, or a current record of all of our
movements compiled by our mobile phone company? What of targeted time machines
such as government over-seizure of digital data in every computer search? This
Article considers the benefits and costs of these miraculous time-machine
technologies, including as evidenced by several recent court opinions.
Considering the very serious privacy implications - from the individual to the
relational and societal - we have good reason to be wary of their coming
ubiquity. Yet perhaps in very limited spheres we should welcome them, going so
far as to entirely abandon front-end acquisition restrictions and rely solely
upon ex post access, use, and disclosure limitations to protect the security in
our persons, houses, papers, and effects. I suggest that one such sphere might
be law enforcement body cameras, an instance in which full capture has great
benefits, and via which we can experiment upon the utility of solely ex post
restraints.


 TEXT:
 [*934]

   Introduction

 Time travel fascinates, whether it is the 1895 science fiction of H.G. Wells,
n1 the 1985 humor of Back to the Future, n2 or the 2015 Hollywood manifestations
in Terminator Genisys, n3 Project Almanac, n4 and Tomorrowland. n5 The reality
is quite a bit more pedantic. Astronauts travel into the future via the
relativistic effects of time dilation, it is true, but in an amount measured in
milliseconds. n6 To do anything more impressive would require greater speeds
than are currently possible. n7 Gazing at the stars is seeing events of time
past, it is true, n8 but I can do the same by inserting a DVD or opening a book.
Travel into the past remains the domain and dispute of theoretical physics and
its Einstein-Rosen Bridges, more commonly known as wormholes,  [*935]  meaning
that, so far as we know, traveling backwards in time might prove forever
impossible. n9 So much for science. n10

   Yet when it comes to criminal investigation, time travel seems increasingly
possible. It is not actually time travel, of course, and it has longstanding
roots in traditional investigation. But science has provided us remarkably
complete historical records in the form of digital data. n11 Well over a half
century ago, Justice Robert H. Jackson recognized that "it would, no doubt,
simplify enforcement of all criminal laws if each citizen were required to keep
a diary that would show where he was at all times, with whom he was, and what he
was up to." n12 The law requires no such diary. Only in certain sector-specific
instances, such as banking, prescription records, or hotel registries, has the
law itself created comprehensive records. n13 Nonetheless, we increasingly
create a diary like that Justice Jackson envisioned via our smartphones and
online technologies, and we even helpfully carry it with us wherever we go.
Further, the National Security Agency ("NSA") has demonstrated that data from
various third party sources might be gathered, stored, and later queried for
evidence of criminality (or, in that case, evidence of threats to national
security). n14 In short, we are "living in the golden age of surveillance." n15

   And lest we think criminal investigation can only offer that elusive travel
back in time, developments in data mining and machine learning  [*936]  are
demonstrating that significant human behavior is predictable. For example, one
study using mobile phone data found that location is 93% predictable, n16 and
based only upon Facebook "likes," a computer was able to better predict
personality and personal problems, including substance abuse, than real-life
friends. n17 So, the more we learn about the past, the better we can predict the
future. n18 We have not reached anything like the world of Philip K. Dick's The
Minority Report with its mutant forward-seeing precogs, n19 or the world of
Lewis Padgett's Private Eye with its ever-recording surroundings. n20 But, as is
so often the case, today's science is creeping towards yesterday's science
fiction.

   So what happens as technology increasingly permits capture of almost all
information? How should we, and our constitutional jurisprudence, approach bulk
government capture, such as by a solar-powered drone employing wide-area
persistent-stare technology, n21 or by a massive system of interconnected ground
cameras? n22 Is it equivalent  [*937]  to a general warrant that can never be
reasonable, or is that too simplistic an analogy? n23 The general warrant
permitted indiscriminate searching, not merely storing. Is such direct gathering
meaningfully different from what the government could obtain from a private
party gathering such data, either by drone n24 or by a vast network of
interconnected cameras? n25 Is it meaningfully different from what is available
via an internet service provider that logs all of our online activity? Or from a
mobile phone company tracking all of our movements? What about searches of our
own devices that spy upon us, like our computers that log information we do not
realize or desire? Can the government forever freeze and store that data,
creating a mini, targeted time machine? Can it do the same by recording every
home that officers enter, perhaps via officer body cameras?

   While it may not be immediately obvious what to do about these disparate
Fourth Amendment time machines, there is value in considering them for what they
are. We should consider how they affect the security in our persons, houses,
papers, and effects. n26 And we should consider their benefits to criminal
investigation and, perhaps, separately to front-end deterrence. We have always
known that limited government norms like that expressed in the Fourth Amendment
are anti-accuracy: if police could enter any home at will, or even were
quartered there, we would have less crime. n27 But life would be insufferable,
and so we accept more crime in return for more liberty,  [*938]  while always
attempting not only the ideal balance - whatever that might be - but also always
seeking pareto superior moves that increase one without lessening the other. As
science increasingly permits capture without immediate human observation, does
this call for a fundamental rethinking? Should we in certain instances abandon
entirely front-end limitations on capture so long as we are guaranteed
evenhanded treatment that traditional investigation lacks, and back-end
limitations on access, use, and distribution? Can we ever feel secure if there
is a government "database of ruin" that could be accessed at any moment? n28 Yet
can we turn our backs on the ability to save lives and livelihoods, and in a
manner that uniformly distributes the privacy costs? n29

   For some, perhaps the failed East German state and its Stasi is sufficient
answer, a view to which I am personally sympathetic. n30 But, of course, access
to those secret police files was not strictly circumscribed by fair legal
process, and, more importantly, the data in the files were created by and for
officers of the state. Should the same rules apply when data are created for
other, beneficial purposes, or will never be subject to human analysis except
upon demonstrated cause? n31 And if it becomes the case that, either on account
of lack of political will, or perhaps on account of very broadly interpreted
First Amendment rights, private third parties retain all data, n32 is there a
realistic way to keep them out of government hands, or do the more important
questions essentially once again amount to access, use, and  [*939]  disclosure?
If a store-everything world is so abhorrent - and I personally believe it might
be - then why do we keep rushing towards precisely that? n33

   Big questions rarely have small or singular answers, and this Article will
hardly provide either. But it can begin the conversation or, more accurately,
continue it under different framing. It does so in the following manner. Part I
reminds us what the National Security Agency was attempting with its bulk
telephone metadata collection, and then looks at two recent court decisions, one
by a Second Circuit panel in United States v. Ganias (now headed en banc) n34
and one from the United States Supreme Court in Riley v. California, n35 each of
which articulates a realization that historic digital data are meaningfully
different for Fourth Amendment purposes. It then considers the Supreme Court's
most recent Fourth Amendment decision, City of Los Angeles v. Patel, in which
the Court floats the proposition that record-keeping for purposes of deterrence
might be a "special need" subject to more lenient Fourth Amendment rules. n36
All three decisions and the NSA metadata program concern what might be
considered Fourth Amendment time machines.

   Part II canvasses the important principles of information privacy that are at
stake. Part III then travels back in time to consider a 1995 proposal by Harold
Krent in which he argues the Fourth Amendment should employ use restrictions
upon data law enforcement has lawfully acquired. n37 The Second Circuit panel in
Ganias would have recognized  [*940]  such a restriction. n38 It would of course
be a significant further move to argue that the Fourth Amendment might be
satisfied by such restrictions alone, a move I believe is fraught with great
danger in most contexts. But perhaps there are limited contexts in which a move
to solely use restrictions is one that legislatures, courts, agencies, and
commentators should at least debate, if not begin to experiment with.
Particularly when designed by legislatures, perhaps programs of uniform
applicability should generally be considered constitutionally reasonable. And if
there is any chance we are ever to rely solely upon back-end limitations in the
world of Fourth Amendment time machines, it would be best to start learning now,
in smaller spheres, whether such means can ever alone guarantee the securities
promised by the Fourth Amendment. Thus, perhaps an ideal sphere for
experimentation might be officer body cameras. Here the benefits of always
recording are sufficiently great, and the domain sufficiently narrow, that it
seems reasonable - and perhaps wise - to always record and to rely upon access,
use, and disclosure limitations to protect our security interests.

   I. The NSA, Hard Drives, Cell Phones, and Hotel Registries

 On June 6, 2013, Glenn Greenwald broke the first story based upon the
disclosures of former NSA contractor Edward Snowden. n39 Pursuant to an order
from the secret Foreign Intelligence Surveillance Court, Verizon Business was
providing the National Security Agency, "on an ongoing daily basis," "all call
detail records or "telephony metadata' created ... for communications (i)
between the United States and abroad; or (ii) wholly within the United States,
including local telephone calls." n40 "Telephony metadata" was defined to
include "originating and terminating telephone number" and "time and duration of
the call." n41 The NSA was creating a database of all telephone calls made on
the Verizon Business network. Similar orders  [*941]  were issued to other
carriers, such that the NSA was databasing virtually all telephone calls made or
received in the United States. n42

   Why? Perhaps no program of surveillance is surprising for an agency that
eerily declares its "collection posture" as "Sniff it All - Know it All -
Collect it All - Process it All - Exploit it All - Partner [Share] it All." n43
But why in particular did the NSA want to gather these phone records? Because
the NSA wanted a time machine. n44 Say on August 1, 2015, the agency obtained
reason to believe a particular telephone number, 301-688-6524, was being used by
a terrorist. That might lead to a court order requiring the provider to place a
pen register and trap and trace device on that line, n45 but of course the line
might at this point be abandoned, or at least this would not reveal
communications made in the past. So, a court order might require the provider to
produce historic records. n46 Only the provider might have retained those
records for only a limited duration. Moreover, the NSA wanted guaranteed access
not only to the numbers with which 301-688-6524 had communicated (first "hop"),
but also the numbers with which those first hop numbers had communicated (second
"hop"), and further the numbers with which those second hop persons had
communicated (third "hop"). n47 The amount of data is growing exponentially,
such that if each telephone number communicated with one hundred others, the NSA
is looking at one million records. Quite convenient, then, to have everything
stored and ready to query in their own servers. Time machines are handy like
that. n48

   The NSA claimed statutory authorization to create this "historical
repository" n49 was found in Section 215 of the USA PATRIOT Act. n50  [*942]
Whether or not it would be ideal to create such time machines, the NSA was
certainly wrong in claiming it had been granted here. n51 Thus, the co-author of
USA PATRIOT worked to enact legislation that has, for now, shut down this
particular program, at least in the sense that the telephone records are no
longer being centralized from all providers and held by the government. n52 But
this has not been the first such government attempt, n53 and it would be
startling if it is the last. There is nothing particularly special about
telephone numbers that make them the only useful time machine metadata: the same
use could be made of financial, internet, and other data. n54 In rejecting the
NSA's contention that its bulk collection satisfied the required relevance
threshold, the Second Circuit reasoned as follows:



   If information can be deemed relevant solely because of its necessity to a
particular process that the government has chosen to employ, regardless of its
subject matter, then so long as "the government develops an effective means of
searching through everything in order to find something, ... everything becomes
relevant to its investigations" - and the government's  [*943]  "technological
capacity to ingest information and sift through it efficiently" would be the
only limit to what is relevant. n55

 This criticism, first made by the Privacy and Civil Liberties Oversight Board,
is a fair criticism of the NSA's interpretation of "relevance," in that it is an
interpretation inconsistent with legal tradition. But notice the proposition is
not illogical: if later searches would prove useful in investigating national
security threats (or crime), the existence of the database is relevant to a
legitimate government role, and the program did include audit, security, and
reporting requirements. n56

   But again, in this case it was clear this novel interpretation was not one
Congress intended. The Second Circuit was correct that:



   Such expansive development of government repositories of formerly private
records would be an unprecedented contraction of the privacy expectations of all
Americans. Perhaps such a contraction is required by national security needs in
the face of the dangers of contemporary domestic and international terrorism.
But we would expect such a momentous decision to be preceded by substantial
debate, and expressed in unmistakable language. n57

 Instead, USA PATRIOT and its legislative sponsors intended, and therefore used,
the traditional language of legal relevance. n58 But what if the debate occurred
and that unmistakable language did come about? Then there would of course be the
question of whether it is a method of investigation the Constitution will abide.
Although the Second Circuit did not decide this constitutional issue, it
recognized the issue as "one of the most difficult issues in Fourth Amendment
jurisprudence: the extent to which modern technology alters our traditional
expectations of privacy." n59

   Is this an issue of technology? After all, was not the first investigating
"time machine" an officer taking notes on what she hears and sees, not to
mention the myriad recordkeeping requirements imposed by the modern industrial
State? Three recent decisions shed more light on this issue: a panel decision in
the Second Circuit (now headed en banc) considering a digital time machine in
the form of  [*944]  government preservation of private computer hard drives,
n60 a decision by the United States Supreme Court considering a voluntarily
compiled and carried digital time machine in the form of a mobile phone, n61 and
another decision by the Supreme Court considering much more old-fashioned
recordkeeping in the form of a hotel guest registry. n62

   A. Ganias and Preservation of Hard Drives

 In November of 2003, federal agents executed a search warrant on the accounting
offices of Stavros Ganias. n63 Ganias himself was not the target, but rather the
Army was investigating one of his clients with whom the Army contracted. n64 The
agents executing the warrant therefore did not remove Ganias's three computers,
respecting his as an ongoing business, but instead mirrored the hard drives,
making exact duplications thereof. n65 Forensics examiners thereafter copied
that data onto two sets of identical DVDs, thereby preserving the government
originals from any harm occasioned by access. n66

   That access would not occur for eight months, until July 2004, when Army
forensics agents began to review the DVDs pursuant to the search warrant. n67
When they discovered the suspect business might have committed tax fraud, they
shared a copy of the data with the IRS, n68 and together the two sets of
investigators ultimately identified all responsive material by December of 2004.
n69 Nonetheless, the agents did nothing to try and delete or return the
non-responsive material. Unlike for seized physical items, these agents never
consider deleting or returning non-responsive digital data. n70 "You never know
what data you may need in the future," testified one. n71

   In July of 2005, some twenty months after the search of Ganias's office and
corresponding seizure of his computer data, Army and IRS investigators came to
believe that Ganias might have been underreporting  [*945]  income, and
therefore expanded their investigation to include him as a suspect. n72 They
therefore wanted to have another look at his files, but appropriately did not
consider their mere possession of those files to authorize further searches
thereof. n73

   To understand why, one must first consider traditional searches and basic
Fourth Amendment law. When police search a home pursuant to a warrant, they may
look only where sought-after items can be. n74 And they may seize only things
the warrant authorizes, or things so located for which authority for seizure is
"immediately apparent," such as child pornography or obviously illegal drugs.
n75 These things are said to be in "plain view." n76 So, for example, police
searching for a large knife should not open a small book at all - it cannot
contain the sought-after knife, and therefore is not subject to search. Whereas
police searching for a knife and any threatening communications could peruse the
small book. But upon finding it to contain entirely unrelated material, police
of course must leave the book behind unless that material is independently
subject to seizure, meaning the officer has probable cause to believe it either
the fruit of crime (it appears to be a rare book that was reported stolen), an
instrumentality of crime (it appears to be the very book used to lure a young
victim), contraband (it appears to contain child pornography), or evidence of
crime (it appears to contain the planning for a recent bank robbery). n77 In
rare instances, large quantities of physical documents might be impossible to
sort onsite, but then special rules are to be followed. n78

   With computers, everything is done differently. Because they contain so much
disparate data, and in so many formats, police cannot reasonably be expected to
bring experts to sufficiently sort through it on site. n79 Thus, courts all
permit over-seizure of digital evidence in every  [*946]  instance: the entire
hard drive, say, can be seized even though much, most, or even all of its
contents - entire libraries of digital materials, let alone files arguably
equivalent to that small book found in the hypothetical home search - are in
fact entirely innocent. n80

   Investigators have thus obtained a time machine. Following the November 2003
execution of the search warrant, Ganias modified the relevant files. n81
Therefore, had the government not over-seized and then retained digital content
that it knew was not relevant to the first investigation, and therefore which
was not covered by the original warrant, this evidence would not have existed.
n82 Yet because agents did retain not only the exact copies of his hard drive
but also the DVDs, the data did exist. And they might retain such data for ten,
twenty, or a hundred years. n83 So, pursuant to another warrant obtained in
April 2006 - some two-and-a-half years after the data's seizure - the government
once again searched the data and found incriminating evidence. Time machines are
handy like that.

   The Second Circuit panel addressed just this time machine functionality,
although its opinion is now vacated pending en banc review n84 :



   We consider a [] limited question: whether the Fourth Amendment permits
officials executing a warrant for the seizure of particular data on a computer
to seize and indefinitely retain every file on that computer for use in future
criminal investigations. We hold that is does not. n85

 The over two-year retention of Ganias's unresponsive data, retained a year and
a half after the government had concluded it was non-responsive, violated the
Fourth Amendment. n86 Or, at the very least, its use in a future criminal
investigation did. n87

    [*947]  I agree, though I differ from the panel's reasoning. The panel
believed the government's position would mean that "every warrant to search for
particular electronic data would become, in essence, a general warrant." n88
That does not seem quite apt, as a general warrant permitted the executive to
search anyone's house for information of interest, n89 or at least one person's
house for anything incriminating, n90 whereas both in 2003 and in 2006 the
government obtained a warrant demonstrating particularized suspicion towards
Ganias's data, and in each instance agents thereafter only looked for the
responsive data. Instead, the government's position would turn every computer
warrant into an investigative time machine.

   It is a serious invasion if the government can over-seize massive amounts of
private information and forever retain it for indefinite later search. One can
understand the concern of the government, which is that if the data are not
retained in their original form it might be difficult to answer later claims of
unreasonable search or challenges to authentication. n91 But, like the panel, I
do not see that  [*948]  as an impossible hurdle. n92 So, perhaps the panel's
answer is broadly the right answer: maybe the Fourth Amendment bans even
relatively small digital time machines, no matter how useful, no matter how
regulated, and no matter how democratically conceived and applied. The
government can retain the data for its original purposes as long as it must, but
cannot search the data for any other. Or, perhaps such time machines are only
permissible where government need is at its highest, such as for purposes of
national security, or where the retention was pursuant to a carefully structured
- and fairly inclusive - legislative authorization. I will return to these
questions below. The immediate point is merely to highlight that digital
evidence has made these questions increasingly pressing.

   The Supreme Court came to the same realization when it considered searches of
cell phones incident to lawful arrest.

   B. Riley and Searches of Cell Phones

 David Riley was stopped for a minor traffic infraction, his car was searched
pursuant to impoundment, and he was arrested for illegally possessing two
handguns found therein. n93 As police are permitted to do as a routine incident
of any lawful arrest, n94 officers searched Riley's person and found a
smartphone in his pocket. n95 A search of that phone onsite and a couple of
hours later at the station yielded relevant evidence in the form of
incriminating text messages, videos, and images. n96

   The Supreme Court consolidated Riley's case with that of Brima Wurie, who was
arrested following an apparent drug sale. n97 At the police station, officers
seized two phones from his person, and one of them - a flip phone - continued to
receive calls from a number the phone identified as "my house." n98 Officers
opened the phone and accessed the call log, thereby obtaining the phone number
associated with these calls. n99

   The Court resoundingly rejected both searches:

    [*949]

Modern cell phones are not just another technological convenience. With all they
contain and all they may reveal, they hold for many Americans "the privacies of
life." [quoting Boyd v. United States, 116 U.S. 616, 630 (1886)] The fact that
technology now allows an individual to carry such information in his hand does
not make the information any less worthy of the protection for which the
Founders fought. Our answer to the question of what police must do before
searching a cell phone seized incident to an arrest is accordingly simple - get
a warrant. n100

 Established doctrine would allow similar searches of non-digital containers
immediately associated with an arrestee's person, including any found in the
same pocket as Riley's phone. n101 So, why did all nine Justices reject these
mobile phone searches? Lacking both precedent and any "precise guidance from the
founding era," n102 the Court had to make its own assessment of what constitutes
an "unreasonable" search, n103 and that is done "by assessing, on the one hand,
the degree to which it intrudes upon an individual's privacy and, on the other,
the degree to which it is needed for the promotion of legitimate governmental
interests." n104

   The governmental interests motivating searches incident to arrest - officer
safety and evidence preservation n105 - are not particularly relevant to this
Article. But, very briefly, what swayed the Court was that the interests are
generally less significant in the digital context. n106 As for officer safety,
there is no possibility the digital data will harm the arresting officers,
unlike, say, a surreptitious knife or razor blade. n107 As for the remote
possibility the data would inform officers of indirect harm - for example, that
dangerous confederates were en route - the Court properly held this to be a
case-specific exigent circumstance  [*950]  sufficiently accounted for by that
doctrine. n108 In other words, it will be the exception, not the rule.
Similarly, there is little risk of evidence destruction once the officers seize
the mobile phone, as even the typically negligible possibility of the device
being remotely wiped can be countered with a Faraday bag, the cheap version of
which is wrapping the phone in aluminum foil. n109

   More importantly for the purposes of this Article, the privacy interest in
digital data is very significant, both in terms of quality and quantity. n110
While the government urged "that a search of all data stored on a cell phone is
"materially indistinguishable' from" searches of wallets and purses, to the
Court, "that is like saying a ride on horseback is materially indistinguishable
from a flight to the moon." n111

   As for quality, "[A] cell phone collects in one place many distinct types of
information - an address, a note, a prescription, a bank statement, a video -
that reveal much more in combination than any isolated record." n112 As for
quantity, a "phone's capacity allows even just one type of information to convey
far more than previously possible." n113 Such is the marvel of digital data and
its modern storage. n114 Indeed, "it is no exaggeration to say that many of the
more than 90% of American adults who own a cell phone keep on their person a
digital record of nearly every aspect of their lives - from the mundane to the
intimate." n115 It did not come at government behest, as Justice Jackson feared
in 1948, but it came nonetheless. n116 Each such person is carrying a time
machine, and the Court has now recognized how especially private are the digital
data contained therein. As the Court  [*951]  recognized, a single mobile phone
will often contain more information than an entire home. n117 Time machines are
useful like that. In the words of the Court, "In the cell phone context, ... it
is reasonable to expect that incriminating information will be found on a phone
regardless of when the crime occurred." n118

   So, while Riley perhaps left things unanswered that it could have addressed,
n119 it made very clear that when it comes to the Fourth Amendment, digital is
different. And while compelled government access therefore required a warrant,
this does not necessarily mean the Court is generally averse to the existence of
digital time machines. The Court's most recent Fourth Amendment decision, which
considered records that could be either analog or digital, contains a facially
surprising claim that is a nod to time machines' utility.

   C. Patel and Searches of Hotel Registries

 City of Los Angeles v. Patel is a case about mini, government-mandated time
machines in the form of hotel guest registries. n120 A provision of the Los
Angeles Municipal Code requires that hotels record and maintain information
about their guests, including name and address, vehicle license plate of any car
parked on the premises, and method of payment. n121 Under certain circumstances
additional identification information must be recorded, such as when a guest
pays by cash, rents a room without a reservation, or stays for fewer  [*952]
than twelve hours. n122 Registry information must be maintained for a period of
ninety days, and must be made available upon officer request. n123 As the recent
publicity regarding the hack of cheating or "adultery" website Ashley Madison
demonstrates, n124 it is not hard to imagine some of the privacy interests
implicated by knowledge of hotel stays. n125

   At the same time, such a recordkeeping requirement is hardly novel, and the
hotels did not challenge it. n126 A group of hotel operators did, however,
challenge the provision requiring that the registry "shall be made available to
any officer of the Los Angeles Police Department for inspection." n127 They
contended such unrestrained access violated their Fourth Amendment rights, and a
closely divided Supreme Court agreed. n128 According to the five Justice
majority, the officer demand requirement is unconstitutional because it offers
no opportunity for pre-compliance legal challenge, n129 essentially combining
the ease of an administrative subpoena with the effectiveness of a warrant.
Patel is an important opinion, because it permits meaningful facial challenges
under the Fourth Amendment, n130 and because it limits  [*953]  what has been a
nebulous "closely regulated industry exception." n131 But what is of interest
for this Article is the Court's dictum regarding deterrence.

   The Court assumed, without deciding, that the government purpose for the
registry program was a "special need" outside of ordinary crime control, thus
lessening the Fourth Amendment burden. n132 Since the ordinance was clearly
aimed at solving crime, it is hard to imagine what this special need would be.
Although the boundaries have always been unclear, in the automobile context, for
example, the Court has differentiated roadblocks aimed at preventing highway
fatalities and carnage (a special need), from those aimed at interdicting drugs
(ordinary crime control). n133 Officers accessing the historic registry were
unlikely to prevent imminent threatened harm akin to that posed by drunk
drivers, as opposed to finding the clues necessary to prosecute past offenses.
This seems true by definition for a registry dating back three months.

   Yet the Court assumed a special need, namely deterring criminality. n134 It
seems hard to imagine deterrence of criminality can be a meaningful special
need: deterrence is not the reason for legitimate police investigation that
constitutes a search or a seizure, but instead is the happy - albeit very
important - byproduct of investigating actual crime. In other words, surely
police cannot routinely make warrantless entry into homes and claim the "special
need" of deterring crimes that might otherwise be committed therein. Instead,
when law enforcement officers enter homes pursuant to lawful warrants or
exceptions thereto, and people learn of those events including subsequent
[*954]  prosecutions, they are deterred from themselves engaging in such
criminality.

   So, why the odd assertion of deterrence as a special need? Presumably because
of the intuition that the registry requirement, like other and more significant
time machines, is an effective - and perhaps smart - way to go after criminal
behavior. But even if that might be so, the Court was right to find problematic
the complete absence of access restrictions given the privacy interests at
stake. Indeed, it is worth stepping back to broadly consider these interests of
information privacy before contemplating what they implicate for investigatory
time machines.

   II. Privacy

 As integral as privacy is to most of our lives - or at least as integral as I
believe it is to mine - there is considerable controversy and confusion as to
its definition, including as to whether it is a state of being or a right. n135
In other words, is "perfect" privacy achieved only when nobody has any
information about and access to my person (which sounds rather awful), or also
when I have complete control over those modes of access but have volitionally
granted them in certain amounts (which sounds rather utopian)? n136 Learned
philosophical minds have debated these concepts for years and presumably will
for as long as there are philosophers to debate. My less philosophically tutored
mind finds useful - and for criminal procedure purposes seemingly sufficient -
the construct that information privacy is the ability of a person to control
what information about her is given to others, and for what purposes. n137 Such
a control construct was most notably  [*955]  articulated by Alan Westin n138
and Charles Fried, n139 and has been recognized by the Supreme Court. n140

   So understood, privacy can be seen as a constitutive element of human
autonomy, or as a key element in the identity formation and mental freedom that
is central to a fully realized autonomy. n141 In the words of Thomas Nagel, "The
boundary between what we reveal and what we do not, and some control over that
boundary, are among the most important attributes of our humanity." n142 Without
privacy, people will engage in harmful self-censorship not only in what they
will say and in what they will do, but even in what they will think as they
internalize an awareness that they are always watched. n143 And the ability
[*956]  to think freely and critically is essential to full development of one's
moral character. n144 This is not to deny, of course, that social pressures can
be beneficial ones, n145 but instead only to recognize that they can also be
debilitating in the extreme. n146

   Furthermore, without privacy people are (at best) stunted in their ability to
form meaningful and diverse relationships, as those relationships depend upon a
volitional, gradual, and granular mutual sharing of information. n147 As Nagel
explains, "selective intimacy permits some interpersonal relations to be open to
forms of exposure that are needed for the development of a complete life. No one
but a maniac will express absolutely everything to anyone, but most of us
[*957]  need someone to whom we can express a good deal that we would not reveal
to others." n148 As Ferdinand Shoeman explains, "information appropriate in the
context of one relationship may not be appropriate in another." n149 Indeed,
devoid of intended and appropriate context, information can present a vastly
incomplete if not completely inaccurate assessment. n150 A spouse, for example,
should have sufficient knowledge of a partner that she can place any new
information in nearly its correct context, but a stranger, acquaintance, or even
fairly good friend might totally misperceive its relevance. As Andrew Taslitz
has noted, not only does other-assessment have practical manifestations (e.g.,
loss of a job opportunity), but psychologically we hold other-assessment dear.
n151

   Without privacy, people thus have less fully developed characters and
relationships, which in turn are the constituent elements of a robust
marketplace of ideas, associations, and religions. n152 In other words, privacy
may be critical to the individual in a manner necessary to identity formation
and to robust small-scale personal relationships, but it is ultimately of
collective societal importance, especially to a democracy. n153 Thus, it is not
surprising that Alan Westin found a correlation between political philosophy and
privacy throughout western civilization. n154 And there are other ramifications.
Without privacy there is increased identity theft, stalking, and other
information-  [*958]  based or assisted crimes. n155 And given asymmetries of
power, distortions in information privacy tend to run solely in one direction,
or at least are not distributed equally, benefiting some at the costs of others.
n156

   Of course, to assert that information privacy is about control is not to say
that one must exercise absolute control. Most rights, and perhaps all rights,
are not absolute, and in this case absolute control is unthinkable. First,
nobody would benefit from exercising control to achieve absolute seclusion. n157
And society could not permit absolute control, not only because it would have
too great a cost to the social order, but also because once any information
about me is known to another person, my right of privacy control runs up against
their right of free expression. n158

   Fortunately, people innately understand this and rarely, if ever, expect
absolute control. But they do wish to exercise some control, even as they are
becoming increasingly disillusioned regarding their ability to do so. n159 As
sociologist Christena Nippert-Eng explains based upon her recent studies, "It
became clear that what I now think of as the process of "selective concealment
and disclosure' plays an important role in how we try to achieve privacy. This
is the daily activity of trying to deny or grant varying amounts of access to
our  [*959]  private matters to specific people in specific ways." n160
Nippert-Eng unsurprisingly found disparate people each trying to achieve their
preferred balance. n161

   Thus, while any replacement is far less crisp and easy, I have long been a
critic of the Fourth Amendment's third party doctrine, which tries to
artificially categorize all information as either totally secret (purely
private) or freely available to law enforcement (effectively purely accessible).
n162 Attempting to force people to maintain absolute secrecy in order to have
any degree of constitutional protection is unrealistic and counter-productive.
n163

   But what does a control theory of information privacy have to say about
investigatory time machines? Obviously at least as to government created ones,
there is a serious tension, and it is a tension that goes to the heart of
privacy's motivations. Can we fully develop as human beings, with the
necessarily divergent ideas and willingness to express them that a thriving
democracy requires, if the government is  [*960]  always watching? No. Of
course, in even the most totalitarian regimes there have proved to be some
persons who exercise unpopular autonomy, but then truly pervasive technology
like we have today has never before been available. And, more importantly, as
Ruth Gavison explains, "Even if we grant that privacy may not be a necessary
condition for autonomy for all, ... it is enough to justify it as a value that
most people may require it. We are not all giants, and societies should enable
all, not only the exceptional, to seek moral autonomy." n164 An ideal democracy
requires thoughtful participation from far more than just a few.

   Thus, there is good reason to be extremely skeptical of any
government-mandated time machines, and outside of the particular instances in
which they have historically been used (e.g., banking, pharmaceuticals, and
hotels), we might do best to forbid them, whether constitutionally or otherwise.
Indeed, it might be wise to reconsider even those we have historically
permitted; the Supreme Court in Patel struck down a 116-year-old reporting
ordinance. n165 But at the very least, a drone hovering high overhead that
records all public movements seems problematic, as do mammoth databases of
digital information that can later be searched. On the other hand, broad-based
surveillance does have benefits. More inclusive surveillance benefits from a
genuine check in the political process, and can more evenly distribute the costs
and provide superior accountability. n166 So, is it possible to have our cake
and eat it too? If there are sufficiently robust access, use, and disclosure
limitations, can they ever ameliorate the very serious privacy concerns? I first
address whether such use restrictions could be found within the Fourth
Amendment, and then turn to the wisdom of their adoption in the very limited
context of police body cameras.

   III. Fourth Amendment Use Restrictions and Police Body Cameras

 In a prescient article from 1995, Harold Krent argued that - whatever
definitions of search and seizure are required to make it happen - the uses to
which law enforcement can put lawfully acquired  [*961]  information should be
governed by the Fourth Amendment's reasonableness requirement. n167 According to
Krent, "Rapidly developing technology has thrust the use issue to the forefront:
what the government does with information may now threaten privacy more than the
collection itself." n168 The Ganias Second Circuit panel adopted such a use
restriction: even if it was permissible for investigators to retain the
nonresponsive computer data for such a long period, it was not permissible to
search through that data - to use that data - in a new investigation, even
pursuant to a newly obtained search warrant. n169 Although it is not clear that
Krent would agree with this particular use limitation, n170 he recognized that
generally such limits are conducive to the control theory of information
privacy: each different use of the data interferes with a person's ability to
control for what purposes information about her is utilized. n171

   Neither the Ganias panel nor Krent argued that use restrictions should be the
sole Fourth Amendment restrictions: the original law enforcement acquisition
remains subject to traditional restraints. For example, merely agreeing to limit
use would of course not itself justify compulsory copying of Ganias' hard
drives. But there might be circumstances when it is impossible to get the
desired law enforcement safety benefit without completely abandoning front-end
acquisition restraints, as with broad scale, panvasive drone surveillance, or
with broad scale, panvasive internet surveillance for malware. n172 In  [*962]
each instance, assuming complete automation, the key privacy harm seems to occur
only upon human viewing, or use. Of course, this does not mean the sole privacy
harm occurs upon use. If human-programmed algorithms are making decisions based
upon content, that seems a relevant use regardless of the lack of direct human
observation. n173 And, as described above, knowing that all of our movements,
online or off, will be recorded for potential later perusal can very
meaningfully chill those actions. Jeremy Bentham long ago realized that constant
observation was not necessary in his Panopticon; merely its potential was
sufficient to achieve the same results. n174 Thus, European courts have recently
rejected requirements that internet service providers retain information for
defined periods of time. n175

   So, we should be extremely cautious in accepting ex-post use and
dissemination controls as a substitute for - as opposed to a supplement to -
front-end acquisition controls. But as part of this calculus we should recognize
the benefits of broad access, including its more uniform distribution and thus
greater political accountability. As I argued some ten years ago, whether the
issue is DNA databanking or a thermal scan of homes or a millimeter wave scan of
persons (as now takes place at airports), advanced notice and broad and uniform
applicability trigger the protections of the political process in a way that
most contemporary policing does not, and this should factor into Fourth
Amendment reasonableness. n176 In this, I was building upon  [*963]  the
arguments of William Stuntz n177 and the Supreme Court's school drug testing
cases. n178 Christopher Slobogin has recently developed the concept into a more
rich theory of representative democracy - relying upon the constitutional
scholarship of John Hart Ely - that would provide judicial review even where the
government activity does not constitute a Fourth Amendment "search" or
"seizure." n179

   But again, whatever the benefits of even a well-functioning political
process, there are strong reasons to be cautious. As Justice Sandra Day O'Connor
argued in personally rejecting the Court's permissive regime of drug testing for
student athletes, we have a strong tradition against general warrants, and
"blanket searches, because they can involve thousands or millions of searches,
pose a greater threat to liberty than do suspicion-based ones, which affect one
person at a time." n180 Nonetheless, it would be just as wrong to ignore the
fairness benefit of broad applicability, as it would to think a "misery loves
company" conception would be ideal across the board (the latter of which would
adopt wholesale the hated general warrants of our founding period). n181

   It seems there might be limited, relatively narrow circumstances in which we
should embrace solely use restrictions, and I submit that one of them might be
for law enforcement body cameras. Of course, perhaps this is an unfairly easy
case, because in order for the camera to capture anything, the law enforcement
officer should already be lawfully present, a criterion that brings its own
sometimes-significant front-end restrictions. But such recording nonetheless
creates time machines, and lots of them: there are almost a million law
enforcement officers in the United States. n182 With officers on duty at all
[*964]  times, watching over mostly innocent behavior as well as some criminal,
if every one records his or her entire shift, that is a staggering amount of
data.

   Those recordings will psychologically affect the officers, and not only in
the sense of promoting good behavior. As discussed above, nobody does well to be
under constant surveillance (though, interestingly, to many thousands of
Americans working in retail and other industries it is probably already their
daily reality - albeit without accompanying audio - and these workers might have
little to no promises regarding ex-post use and dissemination). Nor is it the
case that these recordings will merely duplicate what officers could themselves
personally explain. Instead, high quality cameras would record all sorts of
events and details never noticed by the officers, and potentially permanently
store them for later high-tech perusal (e.g., zoom in and slow down). n183
Moreover, for things an officer does notice - which will include highly
traumatic events - the digital record will remain forever pristine, whereas
memories quickly degrade and even fade entirely. n184 Such cameras would record
not "only" events taking place in public, but instead would record everywhere
officers go, including the interiors of our homes and therefore potentially
under every bed and into every drawer. So even if officer presence already has
an access (and thus acquisition) limitation, it would not necessarily follow
that nothing more should be required for the further intrusion of recording.
n185

   However, these panvasive qualities of officer recording also make for some of
its benefits. As long as there have been police, we have had to rely not only
upon their perceptions of what they observe, but upon their memories of those
perceptions. Both perception and  [*965]  memory are fallible, and recollection
thereof subject to falsification. Of course, we have done what we can. Because
memory dissipates quickly, it is helpful when police contemporaneously record
their perceptions, and hence we value the ubiquitous police report (which also
"freezes" the account, making later fabrication more difficult). With the advent
of readily mobile photography, police could better preserve those observations
deemed sufficiently important, and photography of crime scenes thus became
routine. n186 With the advent of tape recording, certain police-citizen
interactions were recorded. n187 And with the advent of videotaping, we became
accustomed to its benefits in certain contexts, such as video recordings of
traffic stops via cameras fixed in police vehicles. But when that videotaping
made it to the interior of the home, it caused concern, a concern that reached
the Supreme Court in 1999 in the case of Wilson v. Layne. n188

    [*966]  As part of "Operation Gunsmoke," United States Marshals were working
with local Maryland police to apprehend dangerous criminals, including one
Dominic Wilson. n189 Unfortunately, the address in police files was that of
Wilson's parents, so when police entered the home to execute an arrest warrant -
accompanied by invited representatives of the media - what they found was
Dominic's father roused from bed and dressed only in briefs and Dominic's mother
in a nightgown. n190 Before police were made aware of, or at least were
convinced of, their mistake, they forcibly subdued the elder Mr. Wilson at
gunpoint while a photographer from the Washington Post took photographs. n191
The Court unanimously held that the officers violated the Fourth Amendment by
bringing representatives of the media into a home entered pursuant to a warrant.
n192 However, the Court acknowledged government interests that could be
furthered by law enforcement's own recording: accurately publicizing efforts to
combat crime (furthering education and deterrence), deterring and detecting
police abuse, protecting the safety of officers, and preserving evidence. n193
Thus, "it might be reasonable for police officers to themselves videotape home
entries." n194

   The benefits the Court proffered are real and can be significant. As for
evidence preservation, recording can preserve evidence without requiring its
physical removal; n195 preserve evidence that would  [*967]  otherwise be
destroyed by investigatory or non-investigatory government actions, or simply by
the passage of time; n196 and preserve evidence in its most pristine form,
allowing a judge or juror to view it herself. n197 One could imagine recordings
being used to routinely decide such contested issues as whether a person
consented to an entry or search, and if so, the scope of that consent; whether a
reasonable officer would have believed a person to be in need of immediate
assistance; whether there was a fair probability that evidence would be
imminently destroyed; whether police exceeded the authorization of a warrant; or
whether an officer reasonably believed deadly force was justified. n198 To be
sure, no single video is "perfect," as the camera  [*968]  perspective can
itself suggest a cognitive frame and thereby affect these myriad determinations.
n199 But it is far better than without. In the straightforward words of the
Alaska Supreme Court in the context of recording custodial interrogations, "a
recording will help trial and appellate courts to ascertain the truth." n200

   Thus, preservation has secondary benefits, including in deterring and
detecting police abuse. There are ample recorded examples, from detectives
playing Wii Bowling during a home search, n201 to accident investigators "doing
a little Walt Disney to protect [a] cop" who rear-ended another vehicle. n202
The most prominent recent examples  [*969]  might be the shootings of Walter
Scott and Samuel Dubose, each of which resulted in murder charges against the
police officer. n203 It seems self-evident that video would deter (and where
that fails, detect) abuse, an inference supported by police recording in Rialto,
California. In the first year of body camera recording, complaints against
officers fell by 88% and use of force by officers fell by almost 60%. n204 Thus,
in Judge Shira A. Scheindlin's 2013 order holding unconstitutional the New York
Police Department's stop and frisk tactics, she required a trial program of
officer body cameras. n205 To be most effective, that video must record all
police-citizen interaction - lest officers only turn it on when it serves their
purposes n206 - and be  [*970]  tamper-resistant. n207 And when it comes to
deterring and detecting abuse, turnabout is fair play. Recording can shield
police against false allegations of abuse as well as deter or at least detect
poor citizen decisions, perhaps including some that caused those previously
unrecorded use of force incidents.

   So, given the myriad benefits of tamper-resistant, always-on officer
recording - where "always on" includes cameras with a significant,
typically-overwritten buffer meant to become permanent when triggered by an
officer-citizen interaction - it seems such recording is worth the privacy cost.
But this merely means police should record. It remains to be determined - or
should remain to be determined - what can be done with those recordings, which
of course preserve immense amounts of otherwise ephemeral irrelevant information
like the takedown of an innocent man in his bedclothes in Wilson v. Layne. The
mere preservation of that information is a meaningful harm, if nothing else
because the relevant parties know there is always a risk of its further
consumption and dissemination. n208 And thus recording can also harm law
enforcement interests if it deters citizen cooperation and assistance where
persons fear criminal reprisal. Thus, as an administrative matter in police
department guidelines, as a legislative matter, and - I would argue - as a
matter of Fourth Amendment (and state constitutional analog) reasonableness,
there should be use and disclosure limitations on that data. These would include
security from unauthorized access, need-to-know limitations, audit logs, and
destruction schedules. n209

   For example, viewing the footage of a home search should at least sometimes
itself constitute a Fourth Amendment search, just like perusing a seized
computer. Reentering the home after completion of the search would of course
require a new warrant, n210 and just as a  [*971]  search of a seized hard drive
yields previously unknown information, viewing of video will yield information
not noticed by officers, and - given video enhancement capabilities -
information not previously noticeable. Moreover, the resource and legal
restraints are far different when any number of officers can view video in their
offices than when those officers are on the scene executing a search warrant
governed by the constraints of the Fourth Amendment, potentially including a
judicial warrant. Thus, just as courts have begun to recognize that "digital is
different" in other contexts, courts should here recognize a meaningful
difference in kind despite law enforcement officers traditionally being
permitted to re-examine physical items in their possession. The over-seizure
inherent in the recording merits a different result.

   So understood, in the limited context of police body cameras, the benefits of
complete recording seem to outweigh the costs, and therefore this is a
government time machine that I would permit subject only to meaningful access,
use, and dissemination controls. This of course leaves for future work the
development of a taxonomy as to when acquisition restrictions are more or less
important, and what should be the constitutional and statutory rules and
administrative best practices. But it provides a critical perspective as we
approach these decisions, seeing them for what they are: Fourth Amendment time
machines.

   Conclusion

 We are in the midst of dramatic techno-social change. In the words of Christena
Nippert-Eng:



   It's as if a distinct cultural climate change is underway. The ocean has
risen, shrinking our islands of privacy and even submerging many of them
altogether. Like Atlantis, perhaps, some private spaces and times and matters
are fading into the realm of folklore - even legend - their very existence
destined to rest one day on the unsubstantiated claims of prior generations.
n211

 The ability of technology for the first time to feasibly record and store most
all behavior - both online and off - is certainly a tectonic shift. It seriously
threatens privacy, and thus all of privacy's myriad individual and societal
benefits.

   Of course, any such shift can be exaggerated, and in some sense little is
ever new. In 1890, with the advent of the portable camera, a newspaper bemoaned
that, "This season there is something at the  [*972]  seaside worse than sharks.
It is the amateur photographer." n212 Yet we somehow made it through, sufficient
privacy intact. Laws have long required that certain records be retained, and
businesses have long retained far more than what the laws require.

   Nonetheless, differences in scope at some point become differences in kind,
and I believe there is utility in recognizing today's digital records for what
they are - investigative time machines - and openly confronting whether their
benefits justify their costs. Where they do, we should utilize access, use, and
dissemination restrictions for our privacy. And in those instances in which only
a panvasive time machine will do, and in which its benefits still outweigh its
costs, we can rely solely upon those ex post restrictions. n213 But these time
machines are fraught with great danger to our humanity and to our democracy, and
thus should be approached with a healthy, if not vigorous distrust. Thus, in
this Article I have taken only a baby step, recommending a use restriction
regime for police officer body cameras, recognizing that officer presence builds
in acquisition restraints. Legislatures should provide frameworks for these
recordings, requiring reasonable guarantees of secure storage and appropriately
restricting and disciplining errant access, use, and dissemination. n214 If
those restrictions ultimately prove unworkable or insufficient in this  [*973]
limited context, then we will have learned that they certainly cannot alone be
trusted in other spheres.

Legal Topics:

For related research and practice materials, see the following legal topics:
Constitutional LawBill of RightsFundamental FreedomsGeneral OverviewCopyright
LawConstitutional ProtectionsGeneral OverviewGovernmentsFederal
GovernmentDomestic Security

FOOTNOTES:




n1.  H.G. Wells, The Time Machine (1895).





n2.  Back to the Future (Universal City Studios, Inc. 1985).





n3.  Terminator Genisys (Paramount Pictures 2015).





n4.  Project Almanac (Paramount Pictures 2015).





n5.  Tomorrowland (Walt Disney Pictures 2015). Time travel has been a feature of
hundreds of films. See Kenneth Krabat, All Time Travel Movies from 1896 and on,
Kenneth Krabats 1000 stemmer (Oct. 30, 2015),
http://krabat.menneske.dk/kkblog/all-time-travel-movies/.





n6.  See Time Dilation, Wikipedia, https://en.wikipedia.org/wiki/Time_dilation
(last visited Feb. 13, 2016).





n7.  Id.





n8.  How far is a light year?, EarthSky (Nov. 27, 2015),
http://earthsky.org/astronomy-essentials/how-far-is-a-light-year.





n9.  See Wormhole, Wikipedia, https://en.wikipedia.org/wiki/Wormhole (last
visited Oct. 31, 2015).





n10.  If my statements are proved dramatically wrong and we do learn to travel
into the past, I will look to rewrite this.





n11.  See Stephen E. Henderson, Our Records Panopticon and the American Bar
Association Standards for Criminal Justice, 66 Okla. L. Rev. 699, 700-06 (2014)
(chronicling the massive increase in digital information).





n12.  Shapiro v. United States, 335 U.S. 1, 71 (1948) (Jackson, J., dissenting)
(arguing against creation of the required records exception to the Fifth
Amendment privilege against self-incrimination).





n13.  See City of Los Angeles v. Patel, 135 S. Ct. 2443, 2456 (2015) (striking
down an ordinance giving police unrestricted and unchallengeable access to
mandatory hotel guest registries); Whalen v. Roe, 429 U.S. 589, 598-600, 603-04
(1977) (permitting state prescription registry against constitutional
challenge); United States v. Miller, 425 U.S. 435 (1976) (permitting government
access to bank records required by Bank Secrecy Act of 1970). The most robust
category of ongoing, population-wide acquisition and databasing would seem to be
health information, but such acquisition has been little analyzed, perhaps
because it is typically acquired for civil purposes. But that of course does not
take it outside of the ambit of the Fourth Amendment, and Wendy Mariner has
written a critical analysis of this historic "pass." See generally Wendy K.
Mariner, Reconsidering Constitutional Protection for Health Information Privacy,
18 U. Pa. J. Const. L. 935 (2016).





n14.  See infra at 940-43.





n15.  Bruce Schneier, Data and Goliath: The Hidden Battles to Collect Your Data
and Control Your World 4 (2015).





n16.  Chaoming Song et al., Limits of Predictability in Human Mobility, 327
Science 1018, 1021 (2010),
http://www.barabasilab.com/pubs/CCNR-ALB_Publications/201002-19_Science-Predicta
bility/201002-19_Science-Predictability.pdf; see also Dr Seldon, I Presume,
Economist, Feb. 23, 2013, at 76.





n17.  See Clifton B. Parker, New Stanford Research Finds Computers Are Better
Judges of Personality Than Friends and Family, Stanford Rep. (Jan. 12, 2015),
http://news.stanford.edu/news/2015/january/personality-computer-knows-011215.htm
l; Wu Youyou et al., Computer-based Personality Judgments Are More Accurate Than
Those Made by Humans, 112 Nat'l Acad. Sci. 1036, 1036-39 (2015),
http://www.pnas.org/content/112/4/1036.full.pdf.





n18.  Police are increasingly interested in such prediction. See Andrew Guthrie
Ferguson, Big Data and Predictive Reasonable Suspicion, 163 U. Pa. L. Rev. 327,
369-73 (2015) (explaining predictive policing); Andrew Guthrie Ferguson,
Predictive Policing and Reasonable Suspicion, 62 Emory L.J. 259, 265-85 (2012)
(same).





n19.  See The Minority Report, Wikipedia,
https://en.wikipedia.org/wiki/The_Minority_Report (describing the film) (last
visited Oct. 7, 2015).





n20.  Lewis Padgett, Private Eye, in Mirror of Infinity: A Critic's Anthology of
Science Fiction 99 (Robert Silverberg ed. 1970).





n21.  See Ryan Gallagher, Could the Pentagon's 1.8 Gigapixel Drone Camera Be
Used for Domestic Surveillance?, Slate (Feb. 6, 2013, 10:14 AM),
http://www.slate.com/blogs/future_tense/2013/02/06/argus
_is_could_the_pentagon_s_1_8_gigapixel_drone_camera_be_used_for_domestic.html
(describing government drone capability for data collection); Tyler Rogoway,
Drones in Afghanistan Have the Most Advanced Aerial Surveillance Ever, FoxTrot
Alpha (Apr. 6, 2015, 9:40 AM),
http://foxtrotalpha.jalopnik.com/drones-in-afghanistan-have-the-most-advanced-ae
rial-sur-1695912540 (describing the aptly named Gorgon Stare Increment II, which
combines images from 368 integrated cameras); Tyler Rogoway, How One New Drone
Tech Finally Allows All-Seeing Surveillance, FoxTrot Alpha (Aug. 18, 2014, 12:45
PM),
http://foxtrotalpha.jalopnik.com/how-one-new-drone-tech-finally-allows-all-seein
g-survei-1553272901 (explaining several such technologies and both their
utilities and their dangers).





n22.  See Elizabeth E. Joh, Policing by Numbers: Big Data and the Fourth
Amendment, 89 Wash. L. Rev. 35, 48-50 (2014) (describing New York's "Domain
Awareness System"); Somini Sengupta, Privacy Fears Grow as Cities Increase
Surveillance, N.Y. Times (Oct. 13, 2013),
http://www.nytimes.com/2013/10/14/technology/privacy-fears-as-surveillance-grows
-in-cities.html (describing systems in several cities).





n23.  The general warrant in the form of the writs of assistance was a major
impetus for the American Revolution and for the Constitution's Fourth Amendment.
See Boyd v. United States, 116 U.S. 616, 625-27 (1886). For an analysis of the
Fourth Amendment law of government drone flight, see Marc Jonathan Blitz, James
Grimsley, Stephen E. Henderson & Joseph Thai, Regulating Drones Under the First
and Fourth Amendments, 57 Wm. & Mary L. Rev. 49, 65-72 (2015). See also David
Gray & Danielle Citron, The Right to Quantitative Privacy, 98 Minn. L. Rev. 62,
71-72 (2013) (citations omitted) ("In our view, the threshold Fourth Amendment
question should be whether a technology has the capacity to facilitate broad and
indiscriminate surveillance that intrudes upon reasonable expectations of
quantitative privacy by raising the specter of a surveillance state if
deployment and use of that technology is left to the unfettered discretion of
law enforcement officers or other government agents.").





n24.  See generally Blitz et al., supra note 23, at 70-71 (explaining the First
Amendment right to fly recording drones and its connection to the Fourth
Amendment).





n25.  See, e.g., Diane Cardwell, A Light Bulb Goes On, Over the Mall, N.Y.
Times, July 20, 2015, at B1 (describing systems of internet connected cameras
placed in lighting).





n26.  See U.S. Const. amend. IV.





n27.  See, e.g., United States v. Ganias, 755 F.3d 125, 139 (2d Cir. 2014) ("The
Fourth Amendment clearly embodies a judgment that some evidence of criminal
activity may be lost for the sake of protecting property and privacy rights.").





n28.  See Paul Ohm, Don't Build a Database of Ruin, Harv. Bus. Rev. (Aug., 23,
2012), https://hbr.org/2012/08/dont-build-a-database-of-ruin (arguing against
thoughtless databasing in the private sphere).





n29.  The details of any such claim to decreasing crime would be difficult, and
would typically rely less on preventing crime than on deterrence via raising the
likelihood of apprehension and conviction, thereby raising crime's expected
cost. Whereas ex ante detection via data mining is extremely difficult and in
some contexts currently impossible, ex post sifting through data to find
then-evident connections is much easier. See Schneier, supra note 15, at 136-40.
And it is not hard to see that knowing everything tends to discourage crime and
facilitate its apprehension.





n30.  See, e.g., Gary Bruce, The Firm: The Inside Story of the Stasi (2010);
Anna Funder, Stasiland: Stories from Behind the Berlin Wall (2011); Robert H.
Sloan & Richard Warner, The Self, the Stasi, the NSA: Privacy, Knowledge, and
Complicity in the Surveillance State (forthcoming 2016) (manuscript at 5),
http://ssrn.com/abstract=2577308. For a beautiful film fictionalizing some of
the personal costs - and triumphs - of the human spirit in such surveillance
conditions, see The Lives of Others (Sony Pictures 2006).





n31.  See, e.g., Persistent Stare Through Imagination, U. Ariz. Sch. Info.:
Sci., Tech., and Arts, http://w3.sista.arizona.edu/minds-eye.html (last visited
Nov. 4, 2015) (seeking to build an artificially intelligent surveillance
system).





n32.  See Citizens United v. Fed. Election Comm'n, 558 U.S. 310, 342-43, 367-71
(2010) (recognizing robust First Amendment rights of corporations).





n33.  Information security expert and frequent commentator Bruce Schneier
declared "game over" in 2013:



   So, we're done. Welcome to a world where Google knows exactly what sort of
porn you all like, and more about your interests than your spouse does. Welcome
to a world where your cell phone company knows exactly where you are all the
time. Welcome to the end of private conversations, because increasingly your
conversations are conducted by e-mail, text, or social networking sites.



And welcome to a world where all of this, and everything else that you do or is
done on a computer, is saved, correlated, studied, passed around from company to
company without your knowledge or consent ... . Welcome to an Internet without
privacy, and we've ended up here with hardly a fight.

 Bruce Schneier, The Internet Is a Surveillance State, CNN, (Mar. 16, 2013, 2:04
PM),
http://www.cnn.com/2013/03/16/opinion/schneier-internet-surveillance/index.html.
Perhaps, however, at least some of the problem is one of market failure that
could be remedied via regulation requiring internalizing of privacy harms. See
A. Michael Froomkin, Regulating Mass Surveillance as Privacy Pollution: Learning
from Environmental Impact Statements, 2015 U. Ill. L. Rev. 1713, 1728-37 (2015).





n34.  755 F.3d 125 (2d Cir. 2014), reh'g granted, 791 F.3d 290 (2d Cir. 2015)
(en banc).





n35.  134 S. Ct. 2473 (2014).





n36.  135 S. Ct. 2443 (2015).





n37.  Harold J. Krent, Of Diaries and Data Banks: Use Restrictions Under the
Fourth Amendment, 74 Tex. L. Rev. 49 (1995).





n38.  See infra at 945-46.





n39.  Glenn Greenwald, NSA Collecting Phone Records of Millions of Verizon
Customers Daily, Guardian (June 6, 2013),
http://www.theguardian.com/world/2013/jun/06/nsa-phone-records-verizon-court-ord
er. Many others would follow. See Glenn Greenwald, No Place to Hide: Edward
Snowden, the NSA, and the U.S. Surveillance State 90-169 (2014) (discussing the
programs Snowden disclosed).





n40.  Secondary Order, In re Application of the Federal Bureau of Investigation
for an Order Requiring the Production of Tangible Things, No. BR 13-80, at 1-2
(FISC Apr. 25, 2013),
http://www.theguardian.com/world/interactive/2013/jun/06/verizon-telephone-data-
court-order.





n41.  Id. at 2.





n42.  See Am. Civil Liberties Union v. Clapper, 785 F.3d 787, 796-97 (2d Cir.
2015); Privacy and Civil Liberties Oversight Bd., Report on the Telephone
Records Program Conducted under Section 215 of the USA PATRIOT Act and on the
Operations of the Foreign Intelligence Surveillance Court 8 (2014),
http://fas.org/irp/offdocs/pclob-215.pdf [hereinafter PCLOB Report].





n43.  Greenwald, supra note 39, at 97.





n44.  This particular time machine would also be useful as, over time, the
world's largest social network map.





n45.  See 50 U.S.C. § 1842 (2012) (authorizing approved use of pen register or
trap and trade device for investigation).





n46.  See 50 U.S.C. § 1861 (2012) (authorizing such orders).





n47.  See Clapper, 785 F.3d at 797; PCLOB Report, supra note 42, at 9, 28-29.





n48.  The bulk telephony metadata program was not the NSA's only time machine.
See, e.g., Bruce Schneier, More about the NSA's XKEYSCORE, Schneier on Security
(July 7, 2015, 6:38 AM),
https://www.schneier.com/blog/archives/2015/07/more_about_the_.html (explaining
another program by which the NSA pulled massive amounts of internet data from
fiber optic backbone cables).





n49.  Clapper, 785 F.3d at 812.





n50.  Uniting and Strengthening America By Providing Appropriate Tools Required
to Intercept and Obstruct Terrorism ("USA PATRIOT ACT") Act of 2001 § 215, Pub.
L. 107-56, 115 Stat. 272, 287-88 (codified at 50 U.S.C. § 1861 (2012))
[hereinafter USA PATRIOT Act].





n51.  See Clapper, 785 F.3d at 812-21 (holding that Section 215 did not
authorize the telephony data collection program); PCLOB Report, supra note 42,
at 10 ("concluding that Section 215 does not provide an adequate legal basis to
support the [telephone records] program"); Stephen E. Henderson, A Rose By Any
Other Name: Regulating Law Enforcement Bulk Metadata Collection, 94 Tex. L. Rev.
See Also 28 (2016) (same).





n52.  See Uniting and Strengthening America by Fulfilling Rights and Ensuring
Effective Discipline Over Monitoring Act of 2015 ("USA FREEDOM Act of
2015")§§101-10, Pub. L. 114-23, 129 Stat. 268-76 (to be codified at 50 U.S.C. §
1861); Lisa Mascaro, House Overwhelmingly Approves Bill to Curb NSA Domestic
Spying, L.A. Times (May 22, 2014),
http://www.latimes.com/nation/politics/la-na-nsa-reforms-20140523-story.html.
According to Representative Jim Sensenbrenner, the NSA interpretation was "like
scooping up the entire ocean to guarantee you catch a fish." Jennifer
Valentino-DeVries & Siobhan Gorman, Secret Court Ruling Expanded Spy Powers,
Wall St. J., July 8, 2013, at A4.





n53.  For years, the DEA collected massive amounts of telephone metadata for
international calls under its administrative subpoena authority, an apparent
precursor to the NSA bulk collection. See Brad Heath, U.S. Secretly Tracked
Billions of Calls for Decades, USA Today (Apr. 8, 2015),
http://www.usatoday.com/story/news/2015/04/07/dea-bulk-telephone-surveillance-op
eration/70808616/. And there was of course the ill-fated Total Information
Awareness program. See Joshua Partlow, Senate Votes to Deny Funding To Computer
Surveillance Effort, Wash. Post, July 19, 2003,
https://www.washingtonpost.com/archive/business/2003/07/19/senate-votes-to-deny-
funding-to-computer-surveillance-effort/251243f1-8a66-4693-9970-f714130b783f/
(discussing the Senate's denial of funding to the Total Information Awareness
initiative, a computer surveillance program that would enable the government to
amass and search databases of records for potential terrorist activity).





n54.  Clapper, 785 F.3d at 818.





n55.  Id. at 818 n.10 (quoting PCLOB Report, supra note 42, at 62).





n56.  Id. at 797-98 (terming them "minimization procedures"); PCLOB Report,
supra note 42, at 33-36. Those requirements did not, however, protect data that
had been found responsive to seed queries and thus was placed in the NSA
"corporate store." PCLOB Report, supra note 42, at 30-31. In other words, access
to once responsive data was thereafter unrestricted.





n57.  Clapper, 785 F.3d at 818.





n58.  Id. at 811.





n59.  Id. at 822.





n60.  United States v. Ganias, 755 F.3d 125, 128 (2d Cir. 2014), reh'g granted,
791 F.3d 290 (2d Cir. 2015) (en banc).





n61.  Riley v. California, 134 S. Ct. 2473, 2480 (2014).





n62.  City of Los Angeles v. Patel, 135 S. Ct. 2443, 2447 (2015).





n63.  Ganias, 755 F.3d at 128.





n64.  Id.





n65.  Id.





n66.  Id. at 129.





n67.  Id.





n68.  Id.





n69.  Id.





n70.  Id.





n71.  Id.





n72.  Id.





n73.  Id. at 129, 133 n.7.





n74.  Horton v. California, 496 U.S. 128, 140-41 (1990).





n75.  Id. at 136-37.





n76.  Id.





n77.  Warden, Md. Penitentiary v. Hayden, 387 U.S. 294, 301-02 (1967).





n78.  Ganias, 755 F.3d at 135 (citing United States v. Tamura, 694 F.2d 591,
595-96 (9th Cir. 1982)).





n79.  See Office of Legal Educ., Exec. Office of U.S. Attorneys, Searching and
Seizing Computers and Obtaining Electronic Evidence in Criminal Investigations
76-79 (2009),
http://www.justice.gov/sites/default/files/criminal-ccips/legacy/2015/01/14/ssma
nual2009.pdf. For an analysis of the law regulating the forensic search, see
Stephen E. Henderson, What Alex Kozinski and the Investigation of Earl Bradley
Teach About Searching and Seizing Computers and the Dangers of Inevitable
Discovery, 19 Widener L. Rev. 115, 130-36 (2013).





n80.  See Ganias, 755 F.3d at 135-36 (collecting cases).





n81.  Id. at 130.





n82.  Id. at 130, 138 n.11.





n83.  For the various FBI retention policies, see Records Control Schedules,
National Archives and Records Administration,
http://www.archives.gov/records-mgmt/rcs/schedules/?dir=/departments/department-
of-justice/rg-0065; see also U.S. Dep't of Justice, Federal Bureau of
Investigations, A Guide to Conducting Research in FBI Records (2010),
https://www.fbi.gov/foia/a-guide-to-conducting-research-in-fbi-records. The
harms are of course even greater when law enforcement has seized the originals
and not merely image copies. See, e.g., United States v. Gladding, 775 F.3d
1149, 1152 (9th Cir. 2014) (requiring the government to prove it is not feasible
to disaggregate, and then return, innocent over-seized data).





n84.  Ganias, 791 F.3d 290.





n85.  Ganias, 755 F.3d at 137. Cf. United States v. Johnston, 789 F.3d 934,
941-43 (9th Cir. 2015) (holding, without considering Ganias, that a five-year
delay in searching a computer pursuant to the original warrant is not
constitutionally problematic).





n86.  Ganias, 755 F.3d at 138. In so holding, the court importantly sided with
those arguing Fourth Amendment seizure is implicated by any meaningful
deprivation in the exclusive possession of property. Id. at 137 ("The
Government's retention of copies of Ganias's personal computer records for
two-and-a-half years deprived him of exclusive control over those files for an
unreasonable amount of time... . This was a meaningful interference with
Ganias's possessory rights in those files and constituted a seizure within the
meaning of the Fourth Amendment."). See Paul Ohm, The Fourth Amendment Right to
Delete, 119 Harv. L. Rev. F. 10, 12 (2005) (arguing for such an interpretation).





n87.  Ganias, 755 F.3d at 139 ("Even if we assumed it were necessary to maintain
a complete copy of the hard drive solely to authenticate evidence responsive to
the original warrant, that does not provide a basis for using the mirror image
for any other purpose."). Id. at 138 ("The Government clearly violated Ganias's
Fourth Amendment rights by retaining the files for a prolonged period of time
and then using them in a future criminal investigation." (emphasis added)). Id.
at 139 ("Because the Government has demonstrated no legal basis for retaining
the non-responsive documents, its retention and subsequent search of those
documents were unconstitutional." (emphasis added)); id. at 141 ("We conclude
that the Government violated Ganias's Fourth Amendment rights by seizing and
indefinitely retaining non-responsive computer records, and then searching them
when it later developed probable cause." (emphasis added)).





n88.  Id. at 139.





n89.  See William J. Cuddihy, The Fourth Amendment: Origins and Original Meaning
602-1791, at 233 (2009). Thus, a warrant for stolen sheep in 1749 instructed the
local constable to "diligently search every suspected House and Place within
your Parish, which you and the ... [owner of the sheep] shall think convenient
to search." Id. (citations omitted). A 1661 warrant authorized the executive "to
make diligent search ... throughout the whole town of Milford and the precincts
thereof ... ; and this to be in all dwelling houses, barnes or other buildings
whatsoever, and vessels in the harbor." Id. at 234-36 (citations omitted).





n90.  See, e.g., United States v. Stefonek, 179 F.3d 1030, 1032-33 (7th Cir.
1999) (rejecting a warrant permitting seizure of "evidence of crime" as an
impermissible general warrant).





n91.  See Ganias, 755 F.3d at 139; Recent Cases, Fourth Amendment - Search and
Seizure and Evidence Retention - Second Circuit Creates a Potential "Right to
Deletion" of Imaged Hard Drives. - United States v. Ganias, 755 F.3d 125 (2d
Cir. 2014)., 128 Harv. L. Rev. 743, 748-50 (2014).





n92.  Ganias, 755 F.3d at 139.





n93.  Riley v. California, 134 S. Ct. 2473, 2480 (2014).





n94.  United States v. Robinson, 414 U.S. 218, 235-36 (1973).





n95.  Riley, 134 S. Ct. at 2480.





n96.  Id. at 2480-81.





n97.  Id. at 2481.





n98.  Id.





n99.  Id.





n100.  Id. at 2494-95; see also id. at 2495 (Alito, J., concurring in part and
in the judgment but expressing reservations with the majority's limiting theory
of search incident to arrest and expressing a willingness to reconsider if
legislatures lead the way); United States v. Camou, 773 F.3d 932, 941-43 (9th
Cir. 2014) (extending Riley's protection of mobile phones to exempt them from
the automobile exception to the warrant requirement).





n101.  See Riley, 134 S. Ct. at 2484 (discussing United States v. Chadwick, 433
U.S. 1, 15 (1977), which distinguished between searches of items "immediately
associated with the person of the arrestee" and those otherwise within the
arrestee's reach (quoting Chadwick, 433 U.S. at 15)).





n102.  Riley, 134 S. Ct. at 2484 (recognizing that not only was there no
equivalent at the time of the founding, but that even the less sophisticated
flip-phones "are based on technology nearly inconceivable just a few decades
ago").





n103.  Id. at 2482 ("As the [Fourth Amendment] text makes clear, the ultimate
touchstone of the Fourth Amendment is reasonableness." (quoting Brigham City v.
Stuart, 547 U.S. 398, 403 (2006)) (internal quotation marks omitted)).





n104.  Id. at 2484 (quoting Wyoming v. Houghton, 526 U.S. 295, 300 (1999)).





n105.  Id. at 2483 (explaining the genesis of these twin aims).





n106.  See id. at 2485-88 (applying the criteria to mobile phones).





n107.  Id. at 2485.





n108.  Id. at 2485-86.





n109.  Id. at 2486-88. The government also raised, for the first time before the
Supreme Court, that the officers might be able to immediately access the data
before the phone "locks," at which point encryption might render the data
unreachable even pursuant to a valid warrant. Id. at 2486-87. The Court had two
responses. First, officers who encounter an unlocked phone and who have probable
cause can perhaps take the minimal steps necessary to turn off the auto-locking
feature. Id. at 2487-88. Moreover, this situation - like the possibility of
dangerous confederates texting of their approach - is sufficiently unlikely that
it is otherwise properly handled via exigent circumstances. Id. at 2487.





n110.  Id. at 2489.





n111.  Id. at 2488.





n112.  Id. at 2489 (explaining that mobile phones "could just as easily be
called cameras, video players, rolodexes, calendars, tape recorders, libraries,
diaries, albums, televisions, maps, or newspapers").





n113.  Id.





n114.  See Henderson, supra note 11, at 700-03 (chronicling the massive increase
in digital storage).





n115.  Riley, 134 S. Ct. at 2490.





n116.  See supra note 12.





n117.  Riley, 134 S. Ct. at 2491. The Court had previously rejected the claim
that officers could search an entire home incident to arrest. Chimel v.
California, 395 U.S. 752, 753, 755, 768 (1969); see also 381 Search Warrants
Directed to Facebook, Inc. v. New York County Dist. Attorney's Off., 2015 WL
4429025, at 7 (N.Y.S.3d July 21, 2015) ("Our holding today [that there is
neither a constitutional nor statutory right to challenge of a search warrant
other than a defendant's motion to suppress] does not mean that we do not
appreciate Facebook's concerns about the scope of the bulk warrants issued here
or about the District Attorney's alleged right to indefinitely retain the seized
accounts of the uncharged Facebook users. Facebook users share more intimate
personal information through their Facebook accounts than may be revealed
through rummaging about one's home. These bulk warrants demanded "all'
communications in 24 broad categories from the 381 targeted accounts. Yet, of
the 381 targeted Facebook user accounts only 62 were actually charged with any
crime.").





n118.  Riley, 134 S. Ct. at 2492.





n119.  See generally Ric Simmons, The Missed Opportunities of Riley v.
California, 12 Ohio St. J. Crim. L. 253 (2014) (arguing that the Riley Court did
not "repair the critically flawed search incident to arrest doctrine" or
"provide useful guidance for law enforcement officers faced with emerging
technologies").





n120.  135 S. Ct. 2443, 2447-48 (2015).





n121.  L.A., Cal., Mun. Code § 41.49(2)(a) (2008),
http://clkrep.lacity.org/onlinedocs/2006/06-0125-s1_ord_179533.pdf.





n122.  Id. § 41.49(4).





n123.  Id. § 41.49(3)(a).





n124.  See, e.g., Dino Grandoni, Ashley Madison, a Dating Website, Says Hackers
May Have Data on Millions, N.Y. Times (July 20, 2015),
http://www.nytimes.com/2015/07/21/technology/hacker-attack-reported-on-ashley-ma
dison-a-dating-service.html; Emma Johnson, Ashley Madison Hack Would Mean "Boon
for Divorce Lawyers and Marriage Therapists,' Forbes (July 20, 2015),
http://www.forbes.com/sites/emmajohnson/2015/07/20/ashley-madison-hack-would-mea
n-boon-for-divorce-lawyers-and-marriage-therapists/.





n125.  See, e.g., Tina Kelly, Mayflower Mystery: Room 871, Where Are You?, N.Y.
Times (Mar. 20, 2008),
http://cityroom.blogs.nytimes.com/2008/03/20/mayflower-mystery-room-871-where-ar
e-you/ (detailing how Governor Eliot Spitzer enjoyed the services of a
prostitute in The Mayflower's room 871); Sarah Kershaw & Michael Powell, Just a
Hotel? For Some, It's an Adventure, N.Y. Times, March 20, 2008, at G1 (generally
describing prostitution at the Mayflower Hotel).





n126.  Patel, 135 S. Ct. at 2454 ("Respondents have not challenged and nothing
in our opinion calls into question those parts of § 41.49 that require hotel
operators to maintain guest registries containing certain information.").





n127.  L.A., Cal. Mun. Code, supra note 121, at § 41.49(3)(a).





n128.  Patel, 135 S. Ct. at 2451.





n129.  Id.





n130.  Id. at 2449 ("We first clarify that facial challenges under the Fourth
Amendment are not categorically barred or especially disfavored."). Even with
facial challenges theoretically available, they could never be successful if
defeated by the possibility that an officer possessing a valid warrant could
make the records request, that an officer in an emergency could make the records
request, or that the subject of a request could consent. Fortunately, the Court
recognized an unrestricted access statute can be facially unconstitutional
regardless of those possibilities, because they are properly understood as
independent from the grounds of a statutory access not requiring any of them.
Id. at 2450-51. Cf. id. at 2464-66 (Alito, J., dissenting) (arguing otherwise).





n131.  Id. at 2454-56. The Court has declared four closely regulated industries,
for which it permits systems of routine, suspicionless inspection: liquor
distribution, firearms distribution, mining, and automobile junkyards. Id. at
2454. Before Patel, it was unclear whether a legislature could effectively get
around the Fourth Amendment: subject a business to sufficient regulation, such
that it is pervasively regulated, and now the Fourth Amendment has little play.
The Court majority signaled this would not be possible, finding the exception to
apply only when something "inherent in the operation of [the business] poses a
clear and significant risk to the public welfare." Id. This remains somewhat
nebulous, especially given the disparate existing four categories, but at least
it is a more limited sort of nebulous.





n132.  Id. at 2452.





n133.  See City of Indianapolis v. Edmond, 531 U.S. 32, 48 (2000) (striking down
drug interdiction checkpoints); Michigan Dep't of State Police v. Sitz, 496 U.S.
444, 455 (1990) (allowing sobriety checkpoints).





n134.  Patel, 135 S. Ct. at 2452 ("Here, we assume that the searches authorized
by § 41.49 serve a "special need' other than conducting criminal investigations:
They ensure compliance with the recordkeeping requirement, which in turn deters
criminals from operating on the hotels' premises.").





n135.  See, e.g., Ruth Gavison, Privacy and the Limits of Law, 89 Yale L.J. 421,
425-28 (1980) (arguing privacy is a "condition of life," not a claim or form of
control). See generally Philosophical Dimensions of Privacy: An Anthology
(Ferdinand David Schoeman ed., 1984); Daniel J. Solove, A Taxonomy of Privacy,
154 U. Pa. L. Rev. 477 (2006); Daniel J. Solove, Conceptualizing Privacy, 90
Cal. L. Rev. 1087 (2002).





n136.  See Gavison, supra note 135, at 428.





n137.  See ABA Standards for Criminal Justice: Law Enforcement Access to Third
Party Records 49-52, 57-58 (3d ed. 2013); Stephen E. Henderson, Expectations of
Privacy in Social Media, 31 Miss. C. L. Rev. 227, 229-34 (2012). Information
privacy can be contrasted with decision privacy, the latter encompassing
decisions about bodily autonomy like what medical treatment to receive. See U.S.
Dep't of Justice v. Reporters Comm. for Freedom of the Press, 489 U.S. 749, 762
(1989) ("As we have pointed out before, "the cases sometimes characterized as
protecting "privacy' have in fact involved at least two different kinds of
interests. One is the individual interest in avoiding disclosure of personal
matters, and another is the interest in independence in making certain kinds of
important decisions.'" (quoting Whalen v. Roe, 429 U.S. 589, 598-600 (1977))).





n138.  See Alan F. Westin, Privacy and Freedom 7 (1967) ("Privacy is the claim
of individuals, groups, or institutions to determine for themselves when, how,
and to what extent information about them is communicated to others."). "Most
definitions of privacy agree on a core concept: that privacy is the claim of an
individual to determine what information about himself or herself should be
known to others. This also involves when such information will be communicated
or obtained and what uses will be made of it by others." Alan F. Westin,
Historical Perspectives on Privacy: From the Hebrews and Greeks to the American
Republic 4 (presented and distributed at the 2009 Privacy Law Scholars
Conference, and quoted with permission).





n139.  See Charles Fried, Privacy, 77 Yale L.J. 475, 493 (1968) ("Privacy is
that aspect of social order by which persons control access to information about
themselves."). Others like to frame privacy as a right to deprive. See, e.g.,
Jeffrey Reiman, Driving to the Panopticon: A Philosophical Exploration of the
Risks to Privacy Posed by the Highway Technology of the Future, 11 Santa Clara
Computer & High Tech. L.J. 27, 32 (1995). Others frame it is a limitation on
others' access. See, e.g., Gavison, supra note 135, at 423 ("Our interest in
privacy, I argue, is related to our concern over our accessibility to others:
the extent to which we are known to others, the extent to which others have
physical access to us, and the extent to which we are the subject of others'
attention. This concept of privacy as a concern for limited accessibility
enables us to identify when losses of privacy occur.").





n140.  See Reporters Comm., 489 U.S. at 763 ("Both the common law and the
literal understandings of privacy encompass the individual's control of
information concerning his or her person."). The Court rejected a more "cramped
notion of personal privacy" relying upon secrecy. Id.





n141.  See Helen Nissenbaum, Privacy in Context: Technology, Policy, and the
Integrity of Social Life 81-82 (2010). Nissenbaum's insightful gathering and
characterization of philosophies is highly recommended. See id. at 67-78; see
also Thomas P. Crocker, From Privacy to Liberty: The Fourth Amendment After
Lawrence, 57 UCLA L. Rev. 1, 23-25 (2009) (explaining autonomy through a privacy
lens).





n142.  Thomas Nagel, Concealment and Exposure, 27 Phil. & Pub. Aff. 3, 4 (1998).





n143.  See Nissenbaum, supra note 141, at 75-76; Margot E. Kaminski & Shane
Witnov, The Conforming Effect: First Amendment Implications of Surveillance,
Beyond Chilling Speech, 49 U. Rich. L. Rev. 465, 483-93 (2015); Reiman, supra
note 139, at 41-42. Even merely a reminder of the concept of surveillance
affects behavior. See, e.g., Melissa Bateson et al., Cues of Being Watched
Enhance Cooperation in a Real-World Setting, 2 Biology Letters 412 (2006),
http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1686213/ (finding that people
contributed nearly three times as much for drinks when an image of human eyes
was displayed nearby); Terence C. Burnham & Brian Hare, Engineering Human
Cooperation, 18 Hum. Nature 88, 99 (2007),
http://link.springer.com/article/10.1007%2Fs12110-007-9012-2 (finding an
increase in simulated public good behavior when an image of a robot with human
eyes was displayed); Max Ernest-Jones et al., Effects of Eye Images on Everyday
Cooperative Behavior: A Field Experiment, 32 Evolution & Hum. Behav. 172, 176
(2011), https://www.staff.ncl.ac.uk/daniel.nettle/ernestjonesnettlebateson.pdf
(finding that people littered half as often when an image of human eyes was
displayed nearby); see also Michel Foucault, Discipline and Punish 195-228 (Alan
Sheridan trans., 1977) (recognizing the internal significance of feeling
watched); Christopher Slobogin, Privacy at Risk 92-95 (2007) (building off
Foucault's work and others to describe the impact of losing "public anonymity").

   In the words of Edward Bloustein, "the man who is compelled to live every
minute of his life among others and whose every need, thought, desire, fancy or
gratification is subject to public scrutiny, has been deprived of his
individuality and human dignity. Such an individual merges with the mass. His
opinions, being public, tend never to be different; his aspirations, being
known, tend always to be conventionally accepted ones; his feelings, being
openly exhibited, tend to lose their quality of unique personal warmth and to
become the feelings of every man. Such a being, although sentient, is fungible;
he is not an individual." Edward J. Bloustein, Privacy as an Aspect of Human
Dignity: An Answer to Dean Prosser, 39 N.Y.U. L. Rev. 962, 1003 (1964). Or in
the words of Ruth Gavison, if subjected to a world without privacy, "we would
probably try hard to suppress our daydreams and fantasies once others had access
to them. We would try to erase from our minds everything we would not be willing
to publish, and we would try not to do anything that would make us likely to be
feared, ridiculed, or harmed. There is a terrible flatness in the person who
could succeed in these attempts." Gavison, supra note 135, at 443.





n144.  See Jeroen van den Hoven, Information Technology, Privacy, and the
Protection of Personal Data, in Information Technology and Moral Philosophy 301,
315-16 (Jeroen van den Hoven & John Weckert eds., 2008); Nissenbaum, supra note
141, at 78.





n145.  See William H. Simon, Rethinking Privacy, Bos. Rev. (Oct. 20, 2014),
http://bostonreview.net/books-ideas/william-simon-rethinking-privacy-surveillanc
e ("The second trope of the paranoid style is the portrayal of virtually all
tacit social pressure as insidious.").





n146.  See, e.g, Azar Nafisi, Surveillance States, N.Y. Times (June 11, 2015),
http://www.nytimes.com/2015/06/14/books/review/surveillance-states.html ("It
stays with you, that fear. It burrows under the skin. Even after you escape and
are thousands of miles or many years away, you will still sometimes feel you are
being watched. Something within you has been permanently damaged by the terrible
knowledge of the human capability for cruelty and your own weaknesses in the
face of it.").





n147.  See Nissenbaum, supra note 141, at 84; Jeffrey Rosen, The Unwanted Gaze:
The Destruction of Privacy in America 89, 209-18 (2000); Fried, supra note 139,
at 477; Gavison, supra note 135, at 450. See generally Irwin Altman & Dalmas A.
Taylor, Social Penetration: The Development of Interpersonal Relationships
(1973).





n148.  Nagel, supra note 142, at 10.





n149.  Ferdinand Schoeman, Privacy and Intimate Information, in Philosophical
Dimensions, supra note 135, at 403, 408.





n150.  See William James, The Principles of Psychology (1890),
http://psychclassics.asu.edu/James/Principles/prin10.htm ("Properly speaking, a
man has as many social selves as there are individuals who recognize him and
carry an image of him in their mind. To wound any one of these his images is to
wound him. But as the individuals who carry the images fall naturally into
classes, we may practically say that he has as many different social selves as
there are distinct groups of persons about whose opinion he cares. He generally
shows a different side of himself to each of these different groups." (emphasis
omitted)).





n151.  Andrew E. Taslitz & Stephen E. Henderson, Reforming the Grand Jury to
Protect Privacy in Third Party Records, 64 Am. U. L. Rev. 195, 218-19 (2014).





n152.  See Nissenbaum, supra note 141, at 86; Priscilla M. Regan, Legislating
Privacy 221 (1995).





n153.  See Julie E. Cohen, What Privacy Is For, 126 Harv. L. Rev. 1904, 1912-18
(2013) (arguing that diminished privacy shrinks the capacity for democratic
self-government); Gavison, supra note 135, at 455 ("Privacy is also essential to
democratic government because it fosters and encourages the moral autonomy of
the citizen, a central requirement of a democracy."); Paul M. Schwartz, Privacy
and Participation: Personal Information and Public Sector Regulation in the
United States, 80 Iowa L. Rev. 553, 560-63 (1995).





n154.  See Westin, Historical Perspectives, supra note 138, at 4-5, 9.





n155.  See Nissenbaum, supra note 141, at 78; Van den Hoven, supra note 144, at
311-12 ("information-based harm").





n156.  See Nissenbaum, supra note 141, at 79; Van den Hoven, supra note 144, at
312-13 ("informational inequality").





n157.  See Gavison, supra note 135, at 440 ("We start from the obvious fact that
both perfect privacy and total loss of privacy are undesirable. Individuals must
be in some intermediate state - a balance between privacy and interaction - in
order to maintain human relations, develop their capacities and sensibilities,
create and grow, and even to survive.").





n158.  Cf. Cox Broadcasting Corp. v. Cohn, 420 U.S. 469, 496-97 (1975) (striking
down a state statute prohibiting the publication of a rape victim's name).





n159.  See Mary Madden et al., Pew Research Center, Public Perceptions of
Privacy and Security in the Post-Snowden Era 30 (2014),
http://www.pewinternet.org/files/2014/11/PI_PublicPerceptionsofPrivacy_111214.pd
f (finding "91% of [American] adults "agree' or "strongly agree' that "consumers
have lost control over how personal information is collected and used by
companies.'"); Peter H. Schwartz et al., Patient Preferences in Controlling
Access to Their Electronic Health Records: A Prospective Cohort Study in Primary
Care, 30 J. Gen. Internal Med., S25, S27 (2014) (finding almost half of patients
will hide certain health information from their health-care providers if given
the choice). The Schwartz study is perhaps especially interesting, because as
Amitai Etzioni has pointed out, merely asking a person if she would like more
privacy is akin to asking whether she would like more health; better information
requires recognizing that more of "x' might have some other cost. Amitai
Etzioni, The Limits of Privacy, in Contemporary Debates in Applied Ethics 253,
253 (Andrew I. Cohen & Christopher Heath Wellman eds., 2005).





n160.  Christena Nippert-Eng, Islands of Privacy 2 (2010). Thus, consistent with
a control theory, "The goal is to achieve selectivity in both [disclosure and
concealment] - to carefully choose exactly what is disclosed and concealed, to
whom, and how." Id. at 7. When people were individually interviewed and asked
the very general question, "What does privacy mean to you?", a large majority in
some manner described the control theory. See id. (noting that the answers of
forty-five of fifty-seven participants could be so classified); see generally
Mary Madden et al., Pew Research Center, Americans' Attitudes About Privacy,
Security and Surveillance (2015),
http://www.pewinternet.org/files/2015/05/Privacy-and-Security-Attitudes-5.19.15_
FINAL.pdf (finding that Americans want to control who can access their personal
information but doubt they are currently able to do so).





n161.  Nippert-Eng, supra note 160, at 8 ("For the people in this study []
"good' privacy exists when the things they want to be private are as private as
they want them to be. It's a wonderfully subjective, relativistic standard ... .
Control over the amount and type of disclosure and concealment is what really
defines their assessment of the situation." (emphasis omitted)); see also id. at
5 (positing "when we think of privacy [] what we really think of is a condition
of relative inaccessibility. Any point on the scale has both a degree of
privateness and a degree of publicness associated with it" (emphasis omitted)).





n162.  See generally Stephen E. Henderson, After United States v. Jones, After
the Fourth Amendment Third Party Doctrine, 14 N.C. J.L. & Tech 431 (2013);
Stephen E. Henderson, The Timely Demise of the Fourth Amendment Third Party
Doctrine, 96 Iowa L. Rev. Bull. 39 (2011) [hereinafter Timely Demise]; Stephen
E. Henderson, Beyond the (Current) Fourth Amendment: Protecting Third-Party
Information, Third Parties, and the Rest of Us Too, 34 Pepp. L. Rev. 975 (2007);
Stephen E. Henderson, Learning from All Fifty States: How to Apply the Fourth
Amendment and Its State Analogs to Protect Third Party Information from
Unreasonable Search, 55 Cath. U. L. Rev. 373 (2006); Stephen E. Henderson,
Nothing New Under the Sun? A Technologically Rational Doctrine of Fourth
Amendment Search, 56 Mercer L. Rev. 507 (2005) [hereinafter Nothing New].





n163.  See Nippert-Eng, supra note 160, at 5 ("Acquiring privacy is only part of
the problem ... . The totality of the task is to achieve a balance between the
need and desire for both privacy and publicity - for a certain degree of
concealment and disclosure, for denying and granting access to others."
(emphasis omitted)).





n164.  Gavison, supra note 135, at 450.





n165.  See City of Los Angeles v. Patel, 135 S. Ct. 2443, 2464 (2015) (Alito,
J., dissenting).





n166.  See Simon, supra note 145 ("Broad-reach electronic mechanisms have an
advantage in addressing the danger that surveillance will be unfairly
concentrated on particular groups; targeting criteria, rather than reflecting
rigorous efforts to identify wrongdoers, may reflect cognitive bias or group
animus.").





n167.  Harold J. Krent, Of Diaries and Data Banks: Use Restrictions Under the
Fourth Amendment, 74 Tex. L. Rev. 49, 49-51, 51 n.14 (1995).





n168.  Id. at 51. Krent went on to argue for a more specific rule, namely that
the only reasonable uses are ones "disclosed or implicit at the time of the
underlying seizure," requiring the state to "precommit to all uses of
information and items seized." Id. at 53; see id. at 85-92 (developing this
proposed limitation).





n169.  See supra notes 84-92 and accompanying text; see also United States v.
Davis, 690 F.3d 226, 246, 250 (4th Cir. 2012) (holding the warrantless DNA
testing of lawfully seized items from a non-arrestee to constitute an
unreasonable Fourth Amendment search); Orin S. Kerr, Executing Warrants for
Digital Evidence: The Case for Use Restrictions on Nonresponsive Data, 48 Tex.
Tech L. Rev. 1 (2015) (arguing that limited use restrictions are plausible given
the necessary over-seizure in the digital search context); cf. Commonwealth v.
Arzola, 470 Mass. 809, 820 (Mass. 2015) (holding the DNA testing of lawfully
seized items from an arrestee did not constitute a Fourth Amendment search).





n170.  Krent would permit a later use when "the subsequent use would have itself
legitimated the initial search." Krent, supra note 167, at 93. That would seem
true of the later search warrant in Ganias. However, as prescient as Krent's
article was in 1995, he did not consider the unique nature of computer searches,
which might (or might not) alter his conclusions.





n171.  Id. at 51 nn.14 & 18, 92 n.199.





n172.  Christopher Slobogin has coined the term "panvasive" "to capture the idea
that modern government's efforts at keeping tabs on the citizenry routinely and
randomly reach across huge numbers of people, most of whom are innocent of any
wrongdoing." Christopher Slobogin, Panvasive Surveillance, Political Process
Theory, and the Nondelegation Doctrine, 102 Geo. L.J. 1721, 1723 (2014).





n173.  See Henderson, Timely Demise, supra note 162, at 47-48 (responding to
argument of Richard Posner); see also Schneier, supra note 15, at 130 ("Whether
or not anyone actually looks at our data, the very facts that (1) they could,
and (2) they guide the algorithms that do, make it surveillance.").





n174.  See The Panopticon, UCL Bentham Project,
https://www.ucl.ac.uk/Bentham-Project/who/panopticon (last visited Feb. 19,
2016). George Orwell used the same concept in his 1984: "There was of course no
way of knowing whether you were being watched at any given moment. How often, or
on what system, the Thought Police plugged in on any individual wire was
guesswork. It was even conceivable that they watched everybody all the time. But
at any rate they could plug in your wire whenever they wanted to. You had to
live - did live, from habit that became instinct - in the assumption that every
sound you made was overheard, and, except in darkness, every movement
scrutinized." George Orwell, 1984, at 4 (1949).





n175.  See Davis v. Sec'y of State for Home Dep't, [2015] QBD 3665,
https://www.judiciary.gov.uk/wp-content/uploads/2015/07/davis_watson_order.pdf
(invalidating UK data retention law); Case C-293, Dig. Rights Ir. Ltd. v.
Minister for Commc'ns, 2014 E.C.R. 845,
http://curia.europa.eu/juris/document/document.jsf?text=&docid=150642&pageIndex=
0&doclang=EN (invalidating the 2006 Data Retention Directive).





n176.  See Henderson, Nothing New, supra note 162, at 555-59.





n177.  See William J. Stuntz, Local Policing After the Terror, 111 Yale L.J.
2137, 2166 (2002) ("Spreading the cost of policing through a larger slice of the
population ... reduces the odds of voters demanding harsh and intrusive police
tactics secure in the knowledge that those tactics will be applied only to
others.").





n178.  See Vernonia Sch. Dist. 47J v. Acton, 515 U.S. 646, 664 (1995) ("In many
respects, we think, testing based on "suspicion' of drug use would not be
better, but worse."). In its drug testing cases, the Court has also been swayed
by use restrictions, holding searches reasonable in part based upon the limited
government use of positive testing. See Henderson, Nothing New, supra note 162,
at 560-61.





n179.  See Slobogin, supra note 172, at 1724, 1733-37.





n180.  Vernonia, 515 U.S. at 667 (internal quotation marks omitted).





n181.  See Delaware v. Prouse, 440 U.S. 648, 664 (1979) (Rehnquist, J.,
dissenting) (deriding a "misery loves company" Fourth Amendment jurisprudence).





n182.  National Law Enforcement Officers Memorial Fund, Law Enforcement Facts:
Key Data About the Profession, http://www.nleomf.org/facts/enforcement/ (last
visited Mar. 3, 2016); see also By the Numbers: How Many Cops Are There In the
USA?, The Skeptical Librarian (Aug. 26, 2014),
http://blog.skepticallibertarian.com/2014/08/26/by-the-numbers-how-many-cops-are
-there-in-the-usa/.





n183.  Of course, sometimes a camera's preserving things unnoticed is precisely
its utility. See Marc Jonathan Blitz, Police Body-Worn Cameras: Evidentiary
Benefits and Privacy Threats 5-6 (2015).





n184.  On the benefits of human forgetting, see Henderson, supra note 11, at
708-09. As Bruce Schneier has stated in the online context, "I used to say that
Google knows more about what I'm thinking of than my wife does. But that doesn't
go far enough. Google knows more about what I'm thinking than I do, because
Google remembers all of it perfectly and forever." Schneier, supra note 15, at
22. And it gets still more privacy invasive, because via data mining Google can
learn correlations and patterns in your thinking of which you have never been
consciously aware.





n185.  At the very least such videos should not all become public records, as
might be the default in some jurisdictions. See, e.g., Jessica Bruha, Local Law
Enforcement Testing Body Cams, Norman Transcript (Sept. 21, 2014),
http://www.normantranscript.com/news/local-law-enforcement-testing-body-cams/art
icle_c61e8ff4-4052-11e4-b4eb-eb2c7f02e600.html ("Due to a law going into effect
... the video becomes public record and the department is obligated to turn over
a copy to any member of the public.").





n186.  Yet that photography has sometimes proved controversial when used to fill
"gang books" of known and suspected gang members for use in future
investigations, when part of a restaged arrest to permit the press a perp walk,
or - in its most modern manifestation - when an officer took his own selfie
during a perp walk. See Lauro v. Charles, 219 F.3d 202, 213 (2d Cir. 2000)
(holding unconstitutional a restaged perp walk because it had no legitimate law
enforcement purpose); Brown v. Pepe, 42 F. Supp. 3d 310, 316 n.10 (D. Mass.
2014) (holding an officer's "selfie" was at most a de minimis privacy
intrusion); Commonwealth v. Cao, 644 N.E.2d 1294, 1296-99 (Mass. 1995) (holding
the procedure used to obtain a photograph for a gang book did not constitute a
seizure); People v. Rodriguez, 26 Cal. Rptr. 2d 660, 663-64 (Cal. Ct. App. 1993)
(holding unconstitutional a stop used to obtain a photograph for a gang book).





n187.  Tape recording likewise sometimes proved controversial, especially in the
undercover context. See, e.g., United States v. White, 401 U.S. 745, 753 (1971);
Lopez v. United States, 373 U.S. 427, 439 (1963).





n188.  526 U.S. 603 (1999); see also Oziel v. Superior Court of L.A. Cnty., 223
Cal. App. 3d 1284, 1296, 1302 (Cal. Ct. App. 1990) (not deciding the
constitutionality of police videotaping the execution of a search warrant but
refusing media access to that footage). Since Wilson, media presence has
continued to cause potential Fourth Amendment violations. See, e.g., United
States v. Hendrixson, 234 F.3d 494, 496 (11th Cir. 2000) (holding that media
involvement at the execution of a search warrant in a home was a Fourth
Amendment violation, but did not require exclusion of evidence); Smart v. City
of Miami, 2015 WL 3409329, at 12-13 (S.D. Fla. May 27, 2015) (finding
plaintiff's § 1983 claim sufficient to overcome summary judgment based on the
theory that police inviting a crew from "First 48" to film plaintiff's home was
a violation of the Fourth Amendment); Carr v. Montgomery Cnty., 59 F. Supp. 3d
787, 798 (S.D. Tex. 2014) (finding a plausible § 1983 claim for bringing a
third-party film crew into a home to videotape a warrantless search); Frederick
v. Biography Channel, 683 F. Supp. 2d 798, 799-802 (N.D. Ill. 2010) (finding a
plausible § 1983 claim against a media company where plaintiffs were detained
longer than police needed for arrest, just so that a film crew could arrive to
cover it); Conradt v. NBC Universal, Inc., 536 F. Supp. 2d 380, 383 (S.D.N.Y.
2008) (finding plausible § 1983 and intentional-infliction-of-emotional-distress
claims against media defendant for their show "To Catch a Predator" having an
unusually pervasive presence and influence throughout an investigation that led
the target to eventually commit suicide); Thompson v. State, 824 N.E.2d 1265,
1266, 1268-69, 1271 (Ind. Ct. App. 2005) (holding that a film crew's presence
during a strip search in the defendant's motel room violated the defendant's
Fourth Amendment rights and warranted exclusion of the evidence gained during
that search).





n189.  Wilson, 526 U.S. at 606.





n190.  Id. at 607.





n191.  Id.





n192.  Id. at 614. Eight Justices believed, however, that before this decision
the law was not clearly established, and therefore that the officers enjoyed
qualified immunity. See id. at 615; id. at 618 (Stevens, J., dissenting in
part). On the merits, the Court also distinguished circumstances in which a
party is brought in the home to assist the police in their task, as when a
citizen is brought along to identify stolen property. See id. at 611-12.





n193.  See id. at 612-13.





n194.  Id. at 613.





n195.  This can serve First Amendment, privacy, law enforcement, and practical
values. As for the First Amendment, see, for example, City of Cincinnati v.
Contemporary Arts Center, 566 N.E.2d 207, 213 (Ohio Mun. 1990) (approving of
officers executing a search warrant by videotaping an allegedly obscene art
exhibit, which negates otherwise serious concerns of pre-adjudication
censorship). As for privacy, in some circumstances it might be difficult for
police to distinguish what is subject to seizure, and if probable cause
justifies a greater seizure, recording might provide a lesser invasion. For
example, in Commonwealth v. Balicki, 762 N.E.2d 290, 294-95 (Mass. 2002),
defendants were believed to have purchased household items with public funds. In
such a case, there might be nothing about tainted items that immediately
commands attention, yet there might be probable cause (fair probability) to
seize a great portion of them. Similarly, federal agents involved in the 2005
search of Representative William Jefferson's home opted to photograph documents
for which they alleged probable cause, and thus for which they could have
executed a "plain view" warrantless seizure, because the documents were not
directly responsive to the warrant's list of seizable items. United States v.
Jefferson, 571 F. Supp. 2d 696, 700 (E.D. Va. 2008). As for practicality, there
will of course be instances in which physical seizure is impractical or even
impossible. See, e.g., People v. Bambino, N.Y. L.J. 25 (Aug. 4, 1992) (Nassau
Cnty. Justice Ct. 1992) (photography/videography where defendants were believed
to have an apartment in their basement in violation of applicable zoning law);
State v. Dickerson, 313 N.W.2d 526, 530 (Iowa 1981) (photography of tire
tracks). And as for law enforcement interests, it might be necessary to preserve
evidence without tipping off a suspect. See, e.g., United States v. Villegas,
899 F.2d 1324, 1330 (2d Cir. 1990) (authorizing a "sneak and peak" or "covert
entry" warrant to search a property for evidence of cocaine manufacturing that
would be photographed but not physically seized).





n196.  This interest arises whenever police entry is predicated upon emergency
aid, during which their protective actions will sometimes destroy unseen or
in-the-moment unappreciated evidence (or during which a malicious officer could
destroy "undesirable" evidence). It also arises when victims' bodies are to be
moved. See, e.g., Forbes v. State, 1995 WL 241722, 5-6 (Tex. App. 1995)
(permitting photography and videotaping prior to medical examiner and
photography by medical examiner); State v. Wright, 558 A.2d 946, 950-51 (R.I.
1989), abrogated on other ground recognized by State v. Brennan, 627 A.2d 842,
848 (R.I. 1993) (same); State v. Anderson, 599 P.2d 1225, 1230 (Or. App. 1979)
(permitting videotaping prior to removal of victim's body); Patrick v. State,
227 A.2d 486, 488-90 (Del. 1967) (permitting photography prior to removal of
victim's body). Or when there is a fire. See, e.g., Michigan v. Clifford, 464
U.S. 287, 289 (1984) (reaffirming and applying these principles); Michigan v.
Tyler, 436 U.S. 499, 510-12 (1978) (establishing three tiered structure for
searches of fire scenes); Schultz v. State, 593 P.2d 640, 643 (Alaska 1979)
(permitting photography during emergency fire search); Dubbs v. State, 157
S.W.2d 643, 645 (Tex. Crim. App. 1942). And sometimes evidence is naturally
evanescent, such as a pool of blood not yet dried into a carpet, which might
indicate something about the time of an attack or other relevant event. See,
e.g., Ortega v. State, 669 P.2d 935, 942 (Wyo. 1983) (permitting photography to
preserve evanescent evidence, though in an opinion fraught with scientific error
and weak legal reasoning), overruled in part on other grounds, Jones v. State,
902 P.2d 686, 692 (Wyo. 1995).





n197.  See, e.g., Scott v. Harris, 550 U.S. 372 (2007) (relying upon dash camera
video to hold officers acted reasonably in using deadly force). The Supreme
Court has noted this evidentiary advantage in the context of undercover
recordings. See United States v. White, 401 U.S. 745, 753 (1971); Lopez v.
United States, 373 U.S. 427, 439 (1963).





n198.  See, e.g., Ohio v. Robinette, 519 U.S. 33, 35 (1996) (noting dash camera
video that was presumably used in determining consent to search); United States
v. Bah, 794 F.3d 617, 622 n.1 (6th Cir. 2015) (noting use of dash camera video
to determine reasonable suspicion); Rudlaff v. Gillispie, 791 F.3d 638, 639 (6th
Cir. 2015) (using dash camera to determine excessive force); Green v.
Throckmorton, 681 F.3d 853, 862 (6th Cir. 2012) (using dash camera to determine
whether reasonable suspicion was materially disputed); Lee v. Anderson, 616 F.3d
803, 812 (8th Cir. 2010) (noting jury's use of video in determining whether
deadly force was reasonable and relying upon video in denying claim of
insufficient evidence); United States v. Nicholson, 17 F.3d 1294, 1296 (10th
Cir. 1994) (noting magistrate's use of dash camera video in determining
consent); United States v. Abarza, No. 1:14-cr-179-MC, 2015 WL 69556684, at 1-3
(D. Or. Nov. 6, 2015) (noting the usefulness of dash camera footage and using it
to negate allegations like "high-crime area" and nervousness); Burnett v.
Unified Gov. of Athens-Clarke Cnty., No. 3:08-CV-04 (CDL), 2009 WL 5175296, at 6
(M.D. Ga. Dec. 22, 2009) (noting defendant's refusal to consent in dash camera
video); Commonwealth v. Griffin, 116 A.3d 1139, 1143-44 (Pa. Super. Ct. 2015)
(using dash camera footage to determine the extent of physical manipulation
during a Terry stop); Lampkin v. State, 470 S.W.3d 876, 888-89 (Tex. Ct. App.
2015) (using dash camera footage used to determine whether defendant was
intoxicated); Scott v. State, 559 So. 2d 269, 272 (Fla. Dist. Ct. App. 1990)
(noting that video of search warrant execution did not conflict with trial
court's findings regarding knock and announce); Kimberly Kindy & Julie Tate,
Police Withhold Videos Despite Vows of Transparency, Wash. Post (Oct. 8, 2015),
http://www.washingtonpost.com/sf/national/2015/10/08/police-withhold-videos-desp
ite-vows-of-transparency/ (discussing utility of police body cameras in fatal
shootings); Richard Perez-Pena, Officer Indicted in Shooting Death of Unarmed
Man, N.Y. Times, July 29, 2015, at A1 (describing use of officer body camera in
murder indictment). This is of course a benefit in the videotaping of
interrogation. See, e.g., State v. Hajtic, 724 N.W.2d 449, 454-56 (Iowa 2006)
(relying upon and encouraging such recording).





n199.  See generally Kwangbai Park & Jimin Pyo, An Explanation for Camera
Perspective Bias in Voluntariness Judgment for Video-Recorded Confession:
Suggestion of Cognitive Frame, 36 Law & Hum. Behav. 184-85 (2012).





n200.  Stephan v. State, 711 P.2d 1156, 1161 (Alaska 1985).





n201.  See Steve Andrews, Polk Sheriff Disciplines Wii-Playing Deputies, Tampa
Trib., Nov. 11, 2009, at 4; Steve Andrews, A Wii Bit Distracted, Tampa Trib.,
Sept. 22, 2009, at 1.





n202.  See Tonya Alanez, Ex-Hollywood Officers Accused of Falsifying Crash
Report Now Face Federal Lawsuit, Sun Sentinel (June 4, 2010),
http://articles.sun-sentinel.com/2010-06-04/news/fl-hollywood-cops-federal-lawsu
it-20100604_1_andrea-tomassi-officer-dewey-pressley-officer-joel-francisco;
Tonya Alanez, DUI Charge Dropped After Cops Accused of Crash Cover-Up, Sun
Sentinel (July 30, 2009),
http://articles.orlandosentinel.com/2009-07-30/news/hollywood_1_dui-charge-finke
lstein-broward-state-attorney; see also Jim Dwyer, Videos Challenge Accounts of
Convention Unrest, N.Y. Times, April 12, 2005, at A1, B4 (reporting on videotape
contradicting police reports concerning arrests at the 2004 Republican National
Convention); Jim Dwyer, A Switch Is Flipped, and Justice Listens In, N.Y. Times
(Dec. 8, 2007),
http://www.nytimes.com/2007/12/08/nyregion/08about.html?pagewanted=print&_r=0
(reporting on an officer falsely claiming a recorded interrogation had never
taken place); John Eligon, No Jail for Ex-Officer Over Toppled Bicyclist, N.Y.
Times, July 15, 2010, at A26 (reporting on an incident in which a New York City
officer body slammed a bicyclist and then, adding insult to injury, charged him
with attempted assault and disorderly conduct); Sasha Goldstein, Police Dash Cam
Video Exonerates New Jersey Man, Leads to Indictment of Cops, N.Y. Daily News
(Feb. 25, 2014),
http://www.nydailynews.com/news/crime/police-dash-cam-video-exonerates-nj-man-im
plicates-cops-article-1.1701763 (reporting on dash camera footage that
exonerated a man from evading arrest and proved police had falsified records);
David A. Graham, The Death of Jeremy Mardis and the Honesty of the Police,
Atlantic (Nov. 12, 2015),
http://www.theatlantic.com/national/archive/2015/11/the-death-of-jeremy-mardis-a
nd-trustworthy-police/415437/ (reporting police lying about an incident that
left a 6-year-old boy dead and the body camera footage that proved it); Kim
Minugh, Faked Reports Put Cop in Jail, Sacramento Bee (Apr. 20, 2013),
http://www.sacbee.com/mobile/bees-best/article2577255.html (reporting on an
officer who provided false information in a number of police reports); Joe
Sharkey, A Constitutional Case in a Box of Cash, N.Y. Times, Nov. 17, 2009, at
B5 (reporting on an illegitimate and abusive detention of an airplane passenger
for carrying a significant amount of cash).





n203.  See Alan Blinder & Timothy Williams, Ex-South Carolina Officer Is
Indicted in Shooting Death of Black Man, N.Y. Times, June 9, 2015, at A12; see
also Perez-Pena, supra note 198; Damien Cave & Rochelle Oliver, The Videos That
Are Putting Race and Policing into Sharp Relief, N.Y. Times (updated Oct. 27,
2015), www.nytimes.com/interactive/2015/07/30/us/police-videos-race.html
(gathering videos depicting numerous instances of alleged excessive use of force
by the police).





n204.  See Ian Lovett, In California, a Champion for Police Cameras, N.Y. Times
(Aug. 21, 2013),
http://www.nytimes.com/2013/08/22/us/in-california-a-champion-for-police-cameras
.html; see generally Michael D. White, Police Officer Body-Worn Cameras:
Assessing the Evidence (2014),
https://www.ojpdiagnosticcenter.org/sites/default/files/spotlight/download/Polic
e%20Officer%20Body-Worn%20Cameras.pdf (articulating the strengths and weaknesses
of available empirical evidence).





n205.  Floyd v. City of New York, 959 F. Supp. 2d 540, 563 (S.D.N.Y. 2013).





n206.  See Lindsay Miller & Jessica Toliver, Police Executive Research Forum,
Implementing a Body-Worn Camera Program: Recommendations and Lessons Learned
12-14 (2014), http://www.justice.gov/iso/opa/resources/472014912134715246869.
pdf (describing ACLU position that would require recording all police-citizen
interaction, but also describing counter arguments); see id. at 40-42 (making
particular recommendations); Ill. S.B. 1304 § 10-20(a)(3) (requiring, with
articulated exceptions, that "cameras must be turned on at all times when the
officer is in uniform and is responding to calls for service or engaged in any
law enforcement-related encounter or activity").





n207.  See, e.g., Dwyer, supra note 202 (describing prosecution use of a
misleadingly edited police video; the prosecution was dropped when defense
attorneys obtained the unedited version); Allesandra Ram, Sandra Bland's Arrest
Footage Shows How Fallible Video Can Be, Wired (July 22, 2015, 6:32 PM),
http://www.wired.com/2015/07/sandra-blands-arrest-footage-shows-fallible-video-c
an/ (describing recent instance in which odd edits to a controversial police
video seem to be only technical glitches).





n208.  For a telling example, see Commonwealth v. Balicki, 762 N.E.2d 290,
295-96 (Mass. 2002), in which the court describes in detail the many innocent
details preserved by the recording of a home search. In today's "reality
television" pseudo-celebrity obsessed culture, many might be most interested in
the criminally irrelevant portions of a search.





n209.  See, e.g., Standards for Criminal Justice: Law Enforcement Access to
Third Party Records§§25-6.1, 25-6.2 (3d ed. 2013); see also Ill. S.B. 1304 §
10-20(a)(7).





n210.  Wayne R. LaFave et al., 2 Crim. Proc. § 3.4(j).





n211.  Nippert-Eng, supra note 160, at 3-4.





n212.  Every Step You Take, Economist (Nov. 16, 2013),
http://www.economist.com/news/leaders/21589862-cameras-become-ubiquitous-and-abl
e-identify-people-more-safeguards-privacy-will-be.





n213.  In the context of the NSA bulk telephony metadata surveillance, the
Privacy and Civil Liberties Oversight Board recognized that to justify a program
solely restricted by use restrictions should require "a strong showing of
efficacy." PCLOB Report, supra note 42, at 13.





n214.  A growing chorus of voices recognizes the role a legislature should play,
and in the relevance of that role to constitutionality. See, e.g., ACLU v.
Clapper, 785 F.3d 787, 824-25 (2d Cir. 2015) ("We note first that whether
Congress has considered and authorized a program such as this one is not
irrelevant to its constitutionality. The endorsement of the Legislative Branch
of government provides some degree of comfort in the face of concerns about the
reasonableness of the government's assertions of the necessity of the data
collection ... . The legislative process has considerable advantages ... . A
congressional judgment as to what is "reasonable' under current circumstances
would carry weight - at least with us, and, we assume, with the Supreme Court as
well - in assessing whether the availability of information to telephone
companies, banks, internet service providers, and the like, and the ability of
the government to collect and process volumes of such data that would previously
have overwhelmed its capacity to make use of the information, render obsolete
the third-party records doctrine or, conversely, reduce our expectations of
privacy and make more intrusive techniques both expected and necessary to deal
with new kinds of threats ... . Ideally, such issues should be resolved by
courts only after [executive and legislative] debate, with due respect for any
conclusions reached by the coordinate branches of government.").


                               17 of 41 DOCUMENTS


                              Emergency Management

                     Distributed by Tribune Content Agency

                           September 12, 2016 Monday

The Role of Data Analytics in Predictive Policing

BYLINE: Eyragon Eidam, Emergency Management

SECTION: STATE AND REGIONAL NEWS

LENGTH: 3039 words


Sept. 12--From the right vantage point, it is almost possible to watch the
steady tide of technology seeping into the briefing rooms and patrol cars of
American law enforcement agencies.

The devices and technologies that may have once started as benign civilian
conveniences have transformed into powerful tools that enable agencies to
pinpoint their resources, prevent crime and cast a wider net for wrongdoers. The
exponential escalation of mobile computing and analytics has given officers
intelligence on the go and greatly improved their chances of being in the right
place at the right time.

While these tools come with profound benefits to the men and women behind the
badges and the communities they serve, there are ramifications that ripple far
into the public space as well as considerations that must be made to prevent
misuse and infringement on civil rights.

But we still seem far from the broad-stroke reports of many in the mainstream
media who might tell you that cops everywhere can peer into your life with the
click of a mouse or a well placed drone -- at least at the local level. Despite
some of these overblown stories of advanced surveillance capabilities, many in
local law enforcement would tell you that funding for boots on the ground will
almost always win out over bids for the latest NSA-style tech. Even if smaller
agencies want it, they probably can't afford it.

This is not to say there aren't those with a spy-style kit they can't or won't
talk about. These methods tend to encourage public distrust and suspicion, but
we'll cover that a bit later on.

Despite the gloomy and often mischaracterized capabilities of police powers in
the U.S. and the tools they use daily, a wider look at the profession and its
emerging capabilities can show us just how important technology is and will
become in policing.

Seeing Crime Before It Happens

It's 4 p.m. on a Tuesday in June in Santa Cruz, Calif., and the squad car radio
echoes off with chatter about a strong-arm robbery near the rail bridge that
connects the popular boardwalk with a nearby beachfront neighborhood. The
suspect, a woman with a backpack, has taken another woman's belongings by force
and was last seen making her way toward the network of vacation homes and
beachgoers enjoying the sunny afternoon.

But Santa Cruz police officers are already nearby and move in to track the
perpetrator within moments of the first report. There's nothing random about
their presence in the area. What on the outside might look like blind luck or
coincidence is actually part of a predictive system the department has been
perfecting with the help of academic partners turned businessmen since 2011.

And this is not someone sitting in a room with a crystal ball or tarot cards
trying to pinpoint the next crime; this is the intersection of advanced
probabilistic algorithms and community policing. It's appropriately called
PredPol, short for Predictive Policing.

Crime data fed into the PredPol system provides officers with 15 different zones
for four types of crime -- auto theft, vehicle burglary, burglary and
gang-related activity -- at the start of each shift. Each zone covers an area of
500 square feet.

In a city where tourism can double the population in a single night, the deputy
chief said maximizing the efficacy of his department was a no-brainer. The
technological edge provided by the advanced software would help to close the gap
between what was, at the time, increasing crime and staffing limitations.

"Time is a zero-sum game. I only have the number of officers times the number of
hours that they're working to address crime issues in the city. If now all of a
sudden a chunk of our time is dealing with radio calls for service, that greatly
reduces my proactive policing time. The only way to increase that is you either
lower the demand or you get more officers to dilute or diffuse the calls for
service so you have more proactive time," said Deputy Chief Steve Clark. "I
couldn't afford more officers, so I had to get smarter about how we were going
to deal with our limited time resources."

Despite giving officers a substantial leg up when it comes to patrolling the
city, Clark said the system still requires them to interact with the community
and walk the beat, as it were. They cannot, and do not, rely solely on the
system's predictions to do their jobs. They still patrol the city as any cop
would, but they're looking for any indication that the predictions were correct.

However effective the system might be in predicting crime, Clark said the job of
policing is more than simply following the data. "You can't become too reliant
on these things. The officers have to continue to sharpen their saws as far as
their instincts, their training, their experience, their instincts -- those
things that we spend a lot of money to teach them and train them, those years of
experience," he said. "Public safety is a discipline or a field, if you will,
that you can never lose the human element in."

Clark demonstrates different aspects of Santa Cruz's predictive policing system.
Photo by Eyragon Eidam.

From Clark's perspective, the platform does more than just point cops in the
right direction; it also removes the potential for race- and income-based biases
so often a concern in policing. The predictive platform doesn't see race,
financial status or any of the other indicators that often lead to the
perception of police profiling. All PredPol sees are the reports of crimes that
have occurred, which are then translated into where they are likely to occur
next.

"There's nothing in there about demographics," Clark said. "Whether it be the
population type or monetary demographics. These are actual crime reports, and
that's what it makes its predictions from."

Halfway across the country in Eden Prairie, Minn., a town of about 63,000
people, predictive policing has taken on a slightly different form. Officers
rely on a dedicated analyst for up-to-the-moment intelligence on their patrols.

The public safety system may not rely on advanced probabilities and mapping, but
rather law enforcement analyst Ryan Kapaun, who tracks each crime and translates
it into usable intelligence for the department, which averages 60,000 calls for
service a year.

Using fairly simple tools, like the Microsoft Office suite and IBM's Analyst's
Notebook, Kapaun funnels officers' suspect descriptions, potential patterns and
anything else that may help stop or catch a criminal.

"To just map every burglary, for me, doesn't tell me a lot, because it doesn't
tell me that those burglaries are linked. So one might be an overnight garage
burglary [and] one might be a front-door-kicked-in burglary during the day while
people are at work," he said. "What I'm most interested in is not aggregating
and mapping all of the burglaries. What I want to know is, what are the
anomalies? What doesn't fit? What are the burglaries, as an example, that aren't
fitting the other burglaries?"

The concept took time to catch on with his badge-wielding colleagues, according
to the analyst. But now Kapaun's work represents one more tool in each officer's
belt that can help them make split-second decisions on patrol.

Santa Cruz's predictive policing system on a tablet. Photo by Eyragon Eidam.

"Everyone is using data, and they might not either be aware of it or understand
it, and if you think of it, a police department has a wealth of data -- they're
data-rich. It's just figuring out how to take that data and use that data in a
way that's meaningful," he said. "I think a lot of agencies end up using the
data to just say, 'Burglaries are up 15 percent from this week over last week.'
For a patrol officer, when I used to do that, eyes would glaze over. What does
that mean? You have to tell the story with the data."

Kapaun said the program's successes have the department looking at how to expand
it and potentially bring in other analysts.

The Rise of Biometrics and Fingerprint Alternatives

In recent years the push to include alternative identification methods in daily
police work has exploded past fingerprinting and the classic mug shot. Law
enforcement agencies are now looking toward options like facial recognition to
help "finger the right perp."

At the federal level, the FBI's Next Generation Identification program has given
new identity tools to federal, state and local law enforcement, and has stoked
the flames of critics, who believe the system is little more than a way to
catalog people -- the guilty, the innocent and those somewhere in the middle.

But the program seems to be the next logical step in a national process where
fingerprints and photographs don't always tell the whole story of a person's
criminal past. The larger program, which extends its database services to
participating state and local agencies, relies on a growing index of finger and
palm prints as well as facial and iris scans to identify persons of interest.

In San Diego, the city's police department (SDPD) employs facial recognition
equipment to identify people its officers come in contact with. For example, if
an individual does not produce an ID during a traffic stop, facial recognition
could close the information gap for the officer.

According to Officer Steve Thorn, the SDPD facial recognition program
coordinator, around 100 facial scanners have served the department well since
the city first signed on with the Automated Regional Justice Information System,
a larger regional law enforcement collective.

"Officers use the devices to assist in the identification of individuals
lawfully detained or arrested when those persons are unwilling or unable to
provide identity. A typical situation would be when officers contact an
individual for a crime. The crime could be minimal in nature, such as littering
or jay-walking, or more severe such as battery or theft," he said. "If the
individual has no identification on them or would not provide their name, the
officers could use the device to verify their identity and issue a citation in
the field versus having to transport the individual to a police station and take
fingerprints, which could be very time-consuming."

But the usefulness of the tools extends far beyond identifying criminals. Thorn
said officers also use the department's 100 or so scanners to work with the
homeless community and identify potential missing persons.

"I have spoken to a number of officers who use the device regularly. They all
say the device works very well, saves time and helps prevent misidentification.
The device is extremely useful for officers assigned to the quality-of-life team
and homeless outreach team. Both teams are a resource to the homeless
population, but also take enforcement action as necessary. A vast majority of
homeless peoples have no identification in their possession, and the device
enables the officers to make quick identification and take appropriate action."

For critics, programs like these represent a way to capture and store permanent,
vital information about civilians with little oversight. Most recently, the Next
Generation Identification program took fire from critics when the FBI petitioned
to exempt it from federal privacy regulations, which critics say would prevent
the misuse and abuse of data.

In a U.S. Government Accountability Office report, published in May, the agency
pointed to gaps in the FBI's processes and recommended steps the top domestic
law enforcement agency could take to improve the program's accuracy and
transparency.

Video: Anytime, Anywhere?

Police video is not a new concept by any stretch of the imagination. What
started as the occasional camera capturing a liquor store or bank robbery has
grown into cameras being installed on seemingly every street corner. In the past
few years, law enforcement agencies across the country have started equipping
officers with body cameras to document interactions with citizens.

The prevalence of video and its societal benefits are the reason that
researchers at Purdue University are working on the CAM2, a cloud-based platform
that links publicly available cameras through a single, easily accessible
portal. Despite how popular reports may have painted the research to this point,
the team scoffs at the idea that it's a way for police to peer into the lives of
unsuspecting Americans.

Yung-Hsiang Lu leads the team behind CAM2. From his perspective as a
technologist, the system has applications in law enforcement environments, but
it doesn't give them anything sensitive.

"We do not use any data that requests passwords, and furthermore we actually
take reasonable efforts to exclude any camera we think may look at a private
space," he said. "Most of the cameras we have in our system come from
Departments of Transportation of different governments, different states,
different cities. For obvious reasons, because our research is about data
management, it is not about looking at whether you are sitting on your sofa or
not."

Santa Cruz officers begin each shift with a report detailing predicted hot spots
and items of interest. Photo by Eyragon Eidam.

The scalable video platform allows users to log in and view a wealth of publicly
available cameras collected from around the world, which can be watched in real
time or recorded for later. In terms of potential, Lu said the analyzable data
from the platform could ultimately help in a number of sectors, including
transportation planning.

The problem facing the system is the fragmented sources of the video feeds, Lu
said. Engineers have had to work around the multitude of camera systems to adapt
them to a singularly accessible platform.

The larger challenge of video is inextricably linked to big data and has
unsurprisingly been the focus of researchers around the world. While the
platform may not equate to the next big surveillance tool, there are undeniable
benefits for police, first responders and the communities they serve.

David Ebert heads up Purdue University's Visual Analytics for Command, Control
and Interoperability Environments in conjunction with the Department of Homeland
Security's Centers of Excellence, and said the video platform has sparked the
interest of some in the larger law enforcement environment who see more
potential applications.

"One of the things that I see as a great potential for this also is in the
emergency response and disaster response fields," he said. "Basically a tornado
comes through or hurricane comes through, you're trying to do assessment of
damage and where your resources should be allocated. Being able to pull up that
information through this sort of system is a good way to crowdsource the
information instead of having to wait until people upload photos, or look
through Twitter images or Snapchat information and things like that."

But the tool comes with the need for the inclusion of best practices, Ebert
added. While it may not be peering into the living rooms of everyday citizens,
he likens it to how local agencies address the collection of information on
publicly available social media platforms.

"I think a similar set of guidelines for these type of cameras would be very
appropriate. Depending on your current interpretation of the laws, the view is
that all of the information that people put out on social media they're making
publicly available if they don't have privacy settings turned on, so there is no
violation of privacy. That's the perception, but the question is, have the laws
caught up with what the public expects?"

The Evolution of Data Analytics and Collection

And now to the stuff agencies seem a bit shy about.

The Stingray made recent national news as information slowly trickled out that
the U.S. Justice Department had provided local agencies with the funds to
purchase so-called cell-site simulators. The devices are designed to intercept
cellular communications, access the data within them and track locations. But as
quickly as the technology made its way to the headlines, legislation began to
consider the implications of what many considered to be the possibility of mass
surveillance by local agencies.

States like Illinois and Nebraska began to propose legislation to strip agencies
of their simulators and bar them from buying new ones. But this isn't the only
kind of tech that has some people concerned. The Los Angeles Police Department
declined interview requests about its use of a software platform produced by a
company called Palantir, which also won't discuss its work with law enforcement
agencies.

On the upside, the department talked about the product and its potential for a
company testimonial, so we do have a small idea about what it is capable of,
even if it's just the stuff the company needs to sell it to other departments.
While the lack of transparency might seem like a cause for concern for
residents, the system appears to be little more than an advanced data analytics
platform geared toward law enforcement applications.

Basically Palantir's platform uses available data sources to "make sense of all
of the noise that is out there," according to Police Chief Charlie Beck in a
2013 testimonial. "For years we've had stovepipe systems that have a lot of
information, but don't talk to each other and don't compare that information,
and Palantir allows us to do that," he added.

While details are limited, as of a few years ago, the company was gaining
momentum. In 2012, Palantir founder Alex Karp told TechCrunch that while he
could not disclose how many government contracts the company had, he did say
that doubling his staff would help it meet demand.

By pulling untapped or underutilized data sets into the investigative process,
officers are now able to piece together information that might otherwise appear
unrelated. Combining information like crime and arrest records, field interview
cards, automatic license plate readers, Department of Motor Vehicle information
and rap sheets, as well as publicly available camera footage and police body
cameras, is helping to usher in effective predictive policing programs across
the country.

This article was originally published in Government Technology.

___ (c)2016 Emergency Management Visit Emergency Management at
www.emergencymgmt.com Distributed by Tribune Content Agency, LLC.

LOAD-DATE: September 19, 2016

LANGUAGE: ENGLISH

ACC-NO: 20160912-1EM-The-Role-of-Data-Analytics-in-Predictive-Policing
-0912-20160912

PUBLICATION-TYPE: Newspaper

JOURNAL-CODE: 1EM


                      Copyright 2016 Emergency Management


                               18 of 41 DOCUMENTS


                         The Christian Science Monitor

                             August 2, 2016 Tuesday

'Predictive policing' isn't in science fiction, it's in Sacramento;
Surveillance and other technologies give police new tools to fight crime. But
privacy advocates and civil liberties groups ask: At what price?

BYLINE: Jessica Mendoza Staff writer

SECTION: USA

LENGTH: 1666 words


Officer Matt McPhail happened to be at his desk when the first alert went off.

A Nissan sedan had crossed the intersection of San Juan and Truxel where the
Sacramento police had just placed one of two custom-built surveillance cameras.
The system ID'd the vehicle as stolen.

"I said, 'Hey, if anybody's in the area, you know, keep an eye out for this
car,' " recalls Mr. McPhail, a public information officer for the department.
"And a helicopter was in the area and some officers went by and found it."

That was 2014. The city has since installed 32 police observation devices, or
PODs. Now Sacramento - like New York, Houston, Miami, St. Louis, and other
cities before it - is looking at the next step: the launch in October of a
"real-time crime center," a central location from which officers could monitor
all their existing surveillance technologies, PODs included.

The idea is that consolidating information about criminal activity - from
stalking complaints to potential lone wolf terrorist attacks - would make law
enforcement more effective at investigating and perhaps preventing some
incidents. The process would also promote accountability and transparency at a
time of rising tension between police and the black community, providing
evidence of both police and suspect behavior during tense encounters, proponents
say.

But the technology raises big privacy issues. Already concerned about PODs,
privacy advocates are concerned by the prospect of centralizing law-enforcement
data, especially in a post-9/11 world where data is being shared more widely
across federal, state, and local lines. The technology is already causing a
populist backlash.

"The theory of policing has changed," says Rebecca Lonergan, a University of
Southern California law professor who spent 16 years prosecuting public
corruption and national security cases for the United States Attorney's Office
in Los Angeles. "There's an understanding now that we really need to centralize
all of our information."

Protection for large gatherings

McPhail is usually off on Fridays, but he clocked in the day after Micah Xavier
Johnson shot and killed five police officers in Dallas last month.

That same day, McPhail explained how the city's new crime center would help
prevent future tragedies in large public gatherings. The department is planning
to install 10 new cameras at the city's Golden 1 Center arena. The crime center
itself will have banks of state-of-the-art screens showing live, high-definition
video feeds of major traffic and transportation sites, as well as trained
personnel who can provide real-time information to officers in the field and use
data analysis tools to interpret any data being collected.

"It's not a replacement for old-fashioned police work," McPhail says. But "this
is kind of like a natural progression ... of how we do business, the questions
we would ask. It's like the first bread crumb along a trail where at least our
investigators know where to start looking."

It's called predictive policing, and law enforcement agencies in other cities
are already making it happen. In New York City, home to the oldest and arguably
most sophisticated real-time crime center in the country, police can use
surveillance and data analysis technology to identify suspected criminals or
terrorists based on anything from a birthmark to a limp.

The idea is that people who have a record get their identifying marks loaded
into a database. So if police need to identify someone they see, they can type
in the visible characteristics and then get that person's name and information.

With terrorism, "it's so hard to find those few [radicals] that really are
serious about it," says Professor Lonergan at USC. "The only way you find them
is by doing the kind of data collection and data mining that we're talking
about."

The technology can also be used for more routine policing, such as addressing
stalking claims. If complainants have a license plate number and are able to
give at least three places where they might have seen the stalker, the POD
system can be queried to see if the vehicle was there, McPhail says.

"Now I might have a stronger case to substantiate a stalking claim in advance of
something potentially much more serious happening to our victim," he says. "And
it has been used to that effect."

More policing not the answer?

For some privacy and civil liberties advocates, such predictive strategies in
routine police work is a problem, not a solution.

"There's a shift in the primary modality of policing, where it's not just the
old investigating methods being employed, but preemptive policing based on
hunches," says Hamid Khan, a coordinator with the Stop LAPD Spying Coalition, an
alliance of community groups that aims to prevent undue surveillance of
marginalized communities in Los Angeles. "It's become part of a larger
architecture of surveillance."

He and other critics say that sort of predictive policing reinforces racial
profiling and violates civil liberties, with little accountability on the part
of the officers who employ such methods. Worse, the strategy fails to address
the underlying reasons for which people often commit crimes.

"[T]he deepest flaw in the logic of predictive policing is the assumption that
... what the model predicts is the need for policing, as opposed to the need for
any other less coercive social tools to deal with the trauma of economic
distress, family dislocation, mental illness, environmental stress and racial
discrimination that often masquerade as criminal behavior," writes Aderson
Francois, a professor of law at Howard University in Washington, in an op-ed for
The New York Times.

Law enforcement should stay out of the surveillance and data collection
business, critics say - at least, until lawmakers are able to develop clear
policies that regulate their use.

"Technology can be liberating or it can be a tool for control," notes Shahid
Buttar, director of grassroots advocacy at the Electronic Frontier Foundation
(EFF), a civil liberties nonprofit based in San Francisco. Conscientiously
developing and implementing policy to govern that technology and its use, he
says, could spell the difference between the two.

Take body cameras, Mr. Buttar says. More police departments are adopting the
devices, hailing them as a tool for improving transparency and accountability,
and rebuilding trust in communities. Yet a recent report from the Brennan Center
suggests that some departments continue to struggle with privacy concerns months
after making body cameras a requirement for officers.

In Dallas, for example, officers don't need to inform residents they are
recording as long as they are "in a private residence in an official capacity."
And in Baltimore, homes are treated the same as any other property, though
officers "have discretion not to record in 'sensitive circumstances,' "
according to the report.

Some drivers are staging their own protests, snapping up anticamera
license-plate covers, even sprays, that keep their plates visible but difficult
to photograph.

New county law

A couple of interstates down from Sacramento, Santa Clara County passed an
ordinance that tries to address these concerns. The first of its kind at the
county level, it requires the sheriff's department and the district attorney's
office to inform the Board of Supervisors and the public before they purchase
any new technology. They also have to lay out any privacy and due process
implications of the devices, develop a set of policies that would regulate their
use, and submit an annual report on the technology's use to the board.

"This notion that we have to choose between public safety and privacy protection
is wholly false," says Joe Simitian, a county supervisor and former California
state senator. "We can protect the public and respect their privacy and due
process rights at the same time."

Privacy advocates have praised the ordinance.

"What protects privacy is a straightforward explanation of what we've got, what
we're using, when we're going to use it, and what the boundaries are," says
Tracy Rosenberg, executive director of Media Alliance, a nonprofit media group
that aims to defend press freedom and civil rights. The Santa Clara County
ordinance does just that, she says, and should be raised as a model for other
local legislatures to look into.

Limiting the cameras

Standing at the corner of Fruitridge Road and Franklin Boulevard on a sunny July
day, McPhail points to a traffic light, where three small, domed cameras jut out
from a beige metal box marked with the logo of the Sacramento Police Department.
Sacramento does not have anything in the books resembling Santa Clara County's
new ordinance, but McPhail points out that all three cameras face only the
streets, avoiding even the businesses that line the two main streets.

The department also works closely with community leaders through its "Cops and
Clergy" program, McPhail says.

And while he understands concerns over data collection - footage from the PODs
is stored in a third-party database and is accessible to Sacramento police for
up to two years - he says that for his city, at least, residents have little to
worry about.

"It's not as if there's somebody sitting here waiting for a particular [person]
to walk by everyday and using [the cameras] as some means to follow people or
monitor their daily lives. That's not what it's for," he says. "We don't have
time for that."

"People do value their privacy," he adds. "Even police officers value that. When
I'm at home with my family, I don't want to have to watch what I'm doing or be
cognizant of where I'm having to go out of concern that somebody ... might be
watching me.

"But," he says, "I think there's also a recognition of the value that this can
add, in terms of us having a positive impact on the lives of people in these
areas with reduction of crime, ability to respond quickly to things that are
occurring, and the potential to solve crimes that might otherwise be
unsolvable."

LOAD-DATE: August 2, 2016

LANGUAGE: ENGLISH

GRAPHIC: Officer Matt McPhail of the Sacramento Police Department stands before
a bank of monitors at the surveillance offices of Sacramento Regional Transit.
The two agencies are collaborating on a new real-time crime center, set to
launch in the city in October. Jessica Mendoza/The Christian Science Monitor

PUBLICATION-TYPE: Newspaper


              Copyright 2016 Christian Science Publishing Society
                              All Rights Reserved


                               19 of 41 DOCUMENTS


                            Dayton Daily News (Ohio)

                             October 2, 2016 Sunday

Racist tweets may help predict hate crimes;
Researchers in L.A. will monitor social media for trends.

BYLINE: By Richard Winton

SECTION: ; Pg. A15

LENGTH: 563 words


LOS ANGELES - Can police prevent hate crimes by monitoring racist banter on
social media?

Researchers will be testing this concept over the next three years in Los
Angeles, marking a new frontier in efforts by law enforcement to predict and
prevent crimes.

During a three-year experiment, British researchers working with the Santa
Monica, Calif.-based RAND Corp. will be monitoring millions of tweets related to
the L.A. area in an effort to identify patterns and markers that
prejudice-motivated violence is about to occur in real time.

The researchers then will compare the data against records of reported violent
acts. The U.S. Department of Justice is investing $600,000 in research by
Cardiff University Social Data Science Lab, which has been at the forefront of
predictive social media models.

Cardiff University professor Matthew Williams said the research is designed to
eventually enable authorities to predict when and where hate crime is likely to
occur and deploy law enforcement resources to prevent it.

"The insights provided by our work will help U.S. localities to design policies
to address specific hate crime issues unique to their jurisdiction and allow
service providers to tailor their services to the needs of victims, especially
if those victims are members of an emerging category of hate crime targets."

His lab's previous research in the United Kingdom found that Twitter data can be
used to identify areas where hate speechisoccurringbutwhere no hate crimes have
been committed. This can be useful, researchers said, in neighborhoods with many
new immigrants, who are unlikely to report the crime because of fear of
deportation.

In 2012, an estimated 293,800 nonfatal violent and propertyhatecrimesoccurred in
the United States, according to the Bureau of Justice Statistics. About 60
percent of those were not reported, theJusticeDepartmentfound.

Of course, there is a big difference between someone spouting off on Twitter or
Snapchat and an actual hate crime.

"It is a great idea in the abstract. But it is not the panacea you might think,"
said Brian Levin, executive director of Cal State San Bernardino's Center on
Hate and Extremism. "The problem is the correlation and reliability. ... There
are many different forms of social media."

Levin,whohastrackedboth Middle Eastern terror groups and local neo-Nazi
organizations, also noted that some hate groups don't advertise their work on
social media.

"Local tensions may arise to fly and be absent from social media," he said.
"Some segments of the community shun social media ... so examining social media
as a predictor can be a bit like having one screwdriver and sometimes it doesn't
work."

Predictive policing already is in use at the Los Angeles Police Department and
other agencies. The LAPD uses a predictive policing algorithm to deploy officers
to locations where prior crime patterns strongly suggest similar crimes may
occur. As crime during the last two decades has dropped dramatically across the
nation and Los Angeles, police commanders are increasingly looking for any edge
they can get in cutting crime.

L.A. County is particularly useful because a huge volume of social media
produces massive data sets that increase the accuracy of predictive models over
traditional crime analysis and trend-chasing, said Pete Bur-nap, from Cardiff
University's School of Computer Science and Informatics.

LOAD-DATE: October 2, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                     Copyright 2016 Dayton Newspapers, Inc.


                               20 of 41 DOCUMENTS



                                US Official News

                          September 29, 2016 Thursday

Can \x91predictive policing' prevent crime before it happens?

LENGTH: 832  words

DATELINE: New York



 Washington: American Association for the Advancement of Science has issued the
following news release:



 Riding high in their squad car, officers Jamie Pascucci and Joe Kania are
cruising the neighborhood of Homewood, scanning the streets for trouble.
Pittsburgh, Pennsylvania, has one of the highest murder rates among large U.S.
cities, and violent crime is particularly severe in Homewood, a 98% black pocket
of aging, pock-marked Victorians on the east side. Young, white officers from
outside the neighborhood, Pascucci and Kania patrol using a mixture of police
radio, calls to their department's communications center, and instinct. They get
occasional help from ShotSpotter, a network of sensors that detects gunshots and
relays the information to a laptop mounted between the front seats.





 But starting next month, Pascucci and Kania may get a new type of guidance.
Homewood is set to become the initial pilot zone for Pittsburgh's "predictive
policing" program. Police car laptops will display maps showing locations where
crime is likely to occur, based on data-crunching algorithms developed by
scientists at Carnegie Mellon University here. In theory, the maps could help
cops do a better job of preventing crime.



 Many other cities have already adopted similar systems, which incorporate
everything from minor crime reports to criminals' Facebook profiles. They're
catching on outside the United States as well. Drawing on approaches from fields
as diverse as seismology and epidemiology, the algorithms can help bring down
crime rates while also reducing bias in policing, their creators say. They
replace more basic trendspotting and gut feelings about where crimes will happen
and who will commit them with ostensibly objective analysis.



 That's a strategy worth trying at a time when relations between U.S. police and
minorities are at an all-time low, says Pittsburgh Police Chief Cameron McLay,
who acknowledges that policing has a long way to go to fix bias. (Last year,
McLay showed up at a New Year's Eve celebration holding a sign that read, "I
resolve to end racism @ work.") McLay sees the use of big data --combined with
more community-focused strategies--as part of a palliative for policing's ills.



     They're not predicting the future. What they're actually predicting is
where the next recorded police observations are going to occur.

     William Isaac, the Human Rights Data Analysis Group



 But civil liberties groups and racial justice organizations are wary. They
argue that predictive policing perpetuates racial prejudice in a dangerous new
way, by shrouding it in the legitimacy accorded by science. Crime prediction
models rely on flawed statistics that reflect the inherent bias in the criminal
justice system, they contend--the same type of bias that makes black men more
likely to get shot dead by the police than white men. Privacy is another key
concern. In Chicago, Illinois, one scientist has helped the police department
generate a list of individuals deemed likely to perpetrate or be victims of
violent crime in the near future; those people are then told they're considered
at risk, even if they have done nothing wrong.



 To what degree predictive policing actually prevents crime, meanwhile, is up
for debate. Proponents point to quick reductions in crime rates. But John
Hollywood, an analyst for RAND Corporation in Arlington, Virginia, who
co-authored a report on the issue, says the advantage over other best-practice
techniques is "incremental at best."



 The notion of crime forecasting dates back to 1931, when sociologist Clifford
R. Shaw of the University of Chicago and criminologist Henry D. McKay of
Chicago's Institute for Juvenile Research wrote a book exploring the persistence
of juvenile crime in specific neighborhoods. Scientists have experimented with
using statistical and geospatial analyses to determine crime risk levels ever
since. In the 1990s, the National Institute of Justice (NIJ) and others embraced
geographic information system tools for mapping crime data, and researchers
began using everything from basic regression analysis to cutting-edge
mathematical models to forecast when and where the next outbreak might occur.
But until recently, the limits of computing power and storage prevented them
from using large data sets.



 In 2006, researchers at the University of California, Los Angeles (UCLA), and
UC Irvine teamed up with the Los Angeles Police Department (LAPD). By then,
police departments were catching up in data collection, making crime forecasting
"a real possibility rather than just a theoretical novelty," says UCLA
anthropologist Jeffrey Brantingham. LAPD was using hot spot maps of past crimes
to determine where to send patrols--a strategy the department called "cops on
the dot." Brantingham's team believed they could make the maps predictive rather
than merely descriptive.



 In case of any query regarding this article or other content needs please
contact: editorial@plusmediasolutions.com

LOAD-DATE: September 30, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newswire


              Copyright 2016 Plus Media Solutions Private Limited
                              All Rights Reserved


                               21 of 41 DOCUMENTS



                                US Official News

                          September 29, 2016 Thursday

Can \x91predictive policing' prevent crime before it happens?

LENGTH: 832  words

DATELINE: New York



 Washington: American Association for the Advancement of Science has issued the
following news release:



 Riding high in their squad car, officers Jamie Pascucci and Joe Kania are
cruising the neighborhood of Homewood, scanning the streets for trouble.
Pittsburgh, Pennsylvania, has one of the highest murder rates among large U.S.
cities, and violent crime is particularly severe in Homewood, a 98% black pocket
of aging, pock-marked Victorians on the east side. Young, white officers from
outside the neighborhood, Pascucci and Kania patrol using a mixture of police
radio, calls to their department's communications center, and instinct. They get
occasional help from ShotSpotter, a network of sensors that detects gunshots and
relays the information to a laptop mounted between the front seats.





 But starting next month, Pascucci and Kania may get a new type of guidance.
Homewood is set to become the initial pilot zone for Pittsburgh's "predictive
policing" program. Police car laptops will display maps showing locations where
crime is likely to occur, based on data-crunching algorithms developed by
scientists at Carnegie Mellon University here. In theory, the maps could help
cops do a better job of preventing crime.



 Many other cities have already adopted similar systems, which incorporate
everything from minor crime reports to criminals' Facebook profiles. They're
catching on outside the United States as well. Drawing on approaches from fields
as diverse as seismology and epidemiology, the algorithms can help bring down
crime rates while also reducing bias in policing, their creators say. They
replace more basic trendspotting and gut feelings about where crimes will happen
and who will commit them with ostensibly objective analysis.



 That's a strategy worth trying at a time when relations between U.S. police and
minorities are at an all-time low, says Pittsburgh Police Chief Cameron McLay,
who acknowledges that policing has a long way to go to fix bias. (Last year,
McLay showed up at a New Year's Eve celebration holding a sign that read, "I
resolve to end racism @ work.") McLay sees the use of big data --combined with
more community-focused strategies--as part of a palliative for policing's ills.



     They're not predicting the future. What they're actually predicting is
where the next recorded police observations are going to occur.

     William Isaac, the Human Rights Data Analysis Group



 But civil liberties groups and racial justice organizations are wary. They
argue that predictive policing perpetuates racial prejudice in a dangerous new
way, by shrouding it in the legitimacy accorded by science. Crime prediction
models rely on flawed statistics that reflect the inherent bias in the criminal
justice system, they contend--the same type of bias that makes black men more
likely to get shot dead by the police than white men. Privacy is another key
concern. In Chicago, Illinois, one scientist has helped the police department
generate a list of individuals deemed likely to perpetrate or be victims of
violent crime in the near future; those people are then told they're considered
at risk, even if they have done nothing wrong.



 To what degree predictive policing actually prevents crime, meanwhile, is up
for debate. Proponents point to quick reductions in crime rates. But John
Hollywood, an analyst for RAND Corporation in Arlington, Virginia, who
co-authored a report on the issue, says the advantage over other best-practice
techniques is "incremental at best."



 The notion of crime forecasting dates back to 1931, when sociologist Clifford
R. Shaw of the University of Chicago and criminologist Henry D. McKay of
Chicago's Institute for Juvenile Research wrote a book exploring the persistence
of juvenile crime in specific neighborhoods. Scientists have experimented with
using statistical and geospatial analyses to determine crime risk levels ever
since. In the 1990s, the National Institute of Justice (NIJ) and others embraced
geographic information system tools for mapping crime data, and researchers
began using everything from basic regression analysis to cutting-edge
mathematical models to forecast when and where the next outbreak might occur.
But until recently, the limits of computing power and storage prevented them
from using large data sets.



 In 2006, researchers at the University of California, Los Angeles (UCLA), and
UC Irvine teamed up with the Los Angeles Police Department (LAPD). By then,
police departments were catching up in data collection, making crime forecasting
"a real possibility rather than just a theoretical novelty," says UCLA
anthropologist Jeffrey Brantingham. LAPD was using hot spot maps of past crimes
to determine where to send patrols--a strategy the department called "cops on
the dot." Brantingham's team believed they could make the maps predictive rather
than merely descriptive.



 In case of any query regarding this article or other content needs please
contact: editorial@plusmediasolutions.com

LOAD-DATE: September 29, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newswire


              Copyright 2016 Plus Media Solutions Private Limited
                              All Rights Reserved


                               22 of 41 DOCUMENTS



                            Sheerness Times Guardian

                                 March 30, 2016

The future of policing?

LENGTH: 722  words


What if police could detect a crime before it has even happened?

Could nab a burglar before he's even broken a window?

Or stop a fight before the first punch has even been thrown?

It might sound like a fantasy; like a Minority Report-style piece of cinematic
imagination, but the reality is that these things are being done all around you.

Mark Johnson is the head of analysis at Kent Police and it is his job to
identify crime patterns and build intelligence for officers to use in
operational duties.

Over the last three years, the 47-year-old has worked to help develop crime
fighting technology across the whole county but his work didn't begin in Kent,
or even the UK for that matter, it started in Los Angeles, USA, back in 2012.

Mark and his colleagues had heard about a new computer programme that was
drastically cutting crime in some of the most dangerous, underprivileged
neighbourhoods of LA.

So with a healthy dose of scepticism, Mark's colleague Deputy Chief Constable
Paul Brandon, boarded a flight to the City of Angels to learn more about it.

On his return, the team - convinced the programme could work in Kent -
immediately enlisted the help of American anthropologist Jeff Brantingham and
began working with US-based company PredPol to tailor a system to be used here.

Mark is quick to stress the reality of using predictive policing is very
different to Tom Cruise swiping a gloved hand through a 3D virtual reality
computer screen.

"It's a Google map on a computer screen and dotted on that map there are little
red boxes - some as small as part of a road - that signal where a crime is
likely to happen.

"Some of these predictive policing boxes will appear and disappear and then
they're boxes that don't go away.

"The ones that don't disappear mean longer-term issues, like it is covering a
deprived area, or that location has a shop that sells alcohol to under-age
kids," he said.

Since the predictive policing programme was rolled-out in Kent in May 2013,
low-level street crime, like common assault and anti-social behaviour, has
dropped by 7%.

Mark admits it has not all been smooth sailing, with a number of the force's
officers dubious at the beginning: "There's a thing called copper's nose, which
is the experience they have, the understanding they have, a sense when something
doesn't feel right, which a computer doesn't have.

"Without good, old-fashioned policing it wouldn't have worked. It's 21st century
technology meets old-fashioned policing."

One incident that convinced a number of officers happened in Medway when the
sergeant there asked his PCs to print off the map when they went out on patrol
that evening and, when they had a quieter moment, to drive to the red location
box nearest to them, even if their local knowledge told them it wasn't one of
the usual crime hotspots.

That night, in an area they would never normally go, officers found a mother and
her child in the street who had both just minutes before been sexually
assaulted. The suspect was arrested nearby later that night.

While Mark says cases like these are rare, it is a powerful example of what a
complex computer algorithm can do: Lead coppers straight to a sex offender
wanted by the Metropolitan Police.

As the technology gets more sophisticated, officers can make sure they are in an
area before something has even occurred, their presence alone stopping even the
most brazen criminal from striking.

PredPol technology uses three data points (past type, place and time of crime)
to create a unique algorithm based on criminal behaviour patterns.

The PredPol software allows police forces across the world to tailor their
system to their location.

When Kent Police began it's predictive policing pilot in December 2012, it
started by feeding in data, including five years' worth of details of recorded
crimes and three years of incidents of antisocial behaviour, into a computer.

Mark Johnson calls the PredPol programme akin to a "living thing" in that it
must constantly be fed new information to keep being able to accurately predict
where crimes will happen.

Kent's PredPol system costs the equivalent of abour two police officers per
year.

It is successful in predicting 'space-dependent' crimes, which are incidents
that are linked to certain location, like anti-social behaviour and burglary, as
opposed to crimes like murder or rape.

LOAD-DATE: March 31, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                       Copyright 2016 KM Media Group Ltd
                              All Rights Reserved


                               23 of 41 DOCUMENTS



                              The Monday Messenger

                                 April 4, 2016

Sci-fi policing keeping officers one step ahead of law-breakers

LENGTH: 732  words


What if police could detect a crime before it happened?

Say they could nab a burglar before he's even broken a window?

Or stop a fight before the first punch has even been thrown?

It might sound like a fantasy, like a Minority Report-style piece of cinematic
imagination, but the reality is that these things are being done all around you.

Mark Johnson is head of analysis at Kent Police, and it is his job to identify
crime patterns and build intelligence for officers to use in operational duties.

Over the past three years, the 47-year-old has worked to help develop
crime-fighting technology across the whole county.

But his work didn't begin in Kent, or even the UK for that matter; it started in
Los Angeles back in 2012.

Mark and his colleagues had heard about a brand new computer programme that was
drastically cutting crime in some of the most dangerous and underprivileged
neighbourhoods of LA.

So with a healthy dose of scepticism, Mark's colleague, deputy chief constable
Paul Brandon, boarded a flight to the City of Angels to learn more about it.

On his return, the team - convinced the programme could work in Kent -
immediately enlisted the help of American anthropologist Jeff Brantingham, and
began working with US-based company PredPol to tailor a system to be used here.

Mark is quick to stress the reality of using predictive policing is very
different to Tom Cruise swiping a gloved hand through a 3D virtual-reality
computer screen.

He says: "It's a Google map on a computer screen, and dotted on that map there
are little red boxes - some as small as part of a road - that signal where a
crime is likely to happen.

"Some of these predictive policing boxes will appear and disappear, and then
there are boxes that don't go away.

"The ones that don't disappear mean a longer-term issues, like it is covering a
deprived area, or that location has a shop that sells alcohol to underage kids."

Since the predictive policing programme was rolled out in Kent in May 2013,
low-level street crime, such as common assault and antisocial behaviour, has
dropped by 7%.

But Mark admits it has not all been smooth sailing, with a number of the force's
officers dubious at the beginning.

He explains: "There's a thing called copper's nose, which is the experience they
have, the understanding they have, a sense when something doesn't feel right,
which a computer doesn't have.

"Without good, old-fashioned policing it wouldn't have worked. It's 21st-century
technology meets old-fashioned policing."

One incident that convinced a number of officers happened in Medway when the
sergeant asked his PCs to print off the map when they went out on patrol that
evening and, when they had a quieter moment, to drive to the red location box
nearest to them - even if their local knowledge told them it wasn't one of the
usual crime hot spots.

That night, in an area they would never normally visit, officers found a mother
and her child in the street who had both been sexually assaulted just minutes
before. The suspect was arrested nearby later that night.

While Mark says cases like these are rare, it is a powerful example of what a
complex computer algorithm can do - lead coppers straight to a sex offender
wanted by the Metropolitan Police.

And as the technology gets better and more sophisticated, officers can make sure
they are physically in an area before something has even occurred - their
presence alone stopping even the most brazen criminal from striking.

PredPol technology uses three data points (past type, place and time of crime)
to create a unique algorithm based on criminal behaviour patterns.

The PredPol software allows police forces across the world to tailor their
systems to their locations.

When Kent Police began its predictive policing pilot in December 2012, it
started by feeding in data, including five years' worth of details of recorded
crimes and three years of incidents of antisocial behaviour, into a computer.

Mark Johnson calls the PredPol programme akin to a "living thing", in that it
must constantly be fed new information to keep being able to accurately predict
where crimes will happen.

Kent's PredPol system costs the equivalent of around two police officers per
year.

It is successful in predicting 'space-dependent' crimes, which are incidents
that are linked to certain locations, like antisocial behaviour and burglary, as
opposed to crimes such as murder or rape.

LOAD-DATE: April 4, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                       Copyright 2016 KM Media Group Ltd
                              All Rights Reserved


                               24 of 41 DOCUMENTS


                      Times of India (Electronic Edition)

                              June 20, 2016 Monday
                                 Delhi Edition

Predictive policing to nail criminal minds

BYLINE: Rajshekhar.Jha@timesgroup.com

SECTION: TIMES CITY

LENGTH: 533 words


Predictive policing is an idea whose time has come, say senior officers.While
admitting that the project has been in a limbo for long, they assert that it
needs to be put on the fast track.

In February , Delhi Police tied up with the Indian Space Research Organisation
for developing a predictive policing tool called CMAPS -Crime Mapping, Analytics
and Predictive System. This, officers said, would arm the cops with relevant and
timely data in the fight against organised crime.

The technology may not be as fanciful as it sounds and has already been tried in
cities such as New York, Los Angeles, London and Berlin.

Coupled with MHA-approved call interceptions, it would give the police an edge
over the criminals who were regularly coming up with unique ways to communicate,
said an officer. The project, if completed, would use space technology to help
the sleuths collect and assess data. The cops on the ground would be equipped
with per

sonal digital assistant devices, connected to a central processor storing
records of more than 2 lakh criminals.

The technology , cops said, would thus allow real-time access to vital
information at the crime scene itself, so that the officers don't have to go
back to the police station for filing a report. The system would convert every
distress call into a digital message with the location of the caller being
flashed through GPS.

Crime-mapping is currently a periodical process conducted manually by gathering
electronic data at an interval of 15 days. The reports are prepared by the joint
commissioners and forwarded to special commissioners (law and order), who then
brief the police chief.

With the new system, the police would be able to identify gangs in specific
areas on a real-time basis. For instance, to curb chain-snatching cases, the
cops could ascertain information about specific locations prone to such
incidents and take preventive measures.

The tactic, already in use in the West, was a part of a

project called Enterprise Information Integration Solution (EI2S). This system
put petabytes of information

from more than a dozen crime databases at the fingertips of the police. Using
this data, the cops implemented

their 'Crime Forecast' plan to predict when and where criminals could strike.
The software would analyse police data for patterns and compare them with
information from jails, courts and other crime-fighting agencies. The cops would
have access to data on not only the suspects but also likely victims.

Another technique that the police are likely to put into use is neighbourhood
analysis. This would help the sleuths understand crime events and the
circumstances behind them in a small area on the basis of the previous record.
Cases will be classified into multiple categories to understand what types of
crime a particular area was prone to and the measures needed thereof.

Another technique, called proximity analysis, would provide information about
criminals, victims, witnesses and people who are or were within a certain
distance of the crime scene. By analysing demographic and social trends,
investigators would be able to understand changes that had taken place in an
area and their possible impact on the activity .

LOAD-DATE: June 20, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                   Copyright 2016 Bennett Coleman & Co. Ltd.
                              All Rights Reserved


                               25 of 41 DOCUMENTS


                            The Times of India (TOI)

                              June 20, 2016 Monday

Predictive policing to nail criminal minds

BYLINE: Raj Shekhar

SECTION: DELHI

LENGTH: 541 words


NEW DELHI: Predictive policing is an idea whose time has come, say senior
officers. While admitting that the project has been in a limbo for long, they
assert that it needs to be put on the fast track.

In February, Delhi Police tied up with the Indian Space Research Organisation
for developing a predictive policing tool called CMAPS -- Crime Mapping,
Analytics and Predictive System. This, officers said, would arm the cops with
relevant and timely data in the fight against organised crime.

The technology may not be as fanciful as it sounds and has already been tried in
cities such as New York, Los Angeles, London and Berlin.

Coupled with MHA-approved call interceptions, it would give the police an edge
over the criminals who were regularly coming up with unique ways to communicate,
said an officer. The project, if completed, would use space technology to help
the sleuths collect and assess data. The cops on the ground would be equipped
with personal digital assistant devices, connected to a central processor
storing records of more than 2 lakh criminals.

The technology, cops said, would thus allow real-time access to vital
information at the crime scene itself, so that the officers don't have to go
back to the police station for filing a report. The system would convert every
distress call into a digital message with the location of the caller being
flashed through GPS.

Crime-mapping is currently a periodical process conducted manually by gathering
electronic data at an interval of 15 days. The reports are prepared by the joint
commissioners and forwarded to special commissioners (law and order), who then
brief the police chief.

With the new system, the police would be able to identify gangs in specific
areas on a real-time basis. For instance, to curb chain-snatching cases, the
cops could ascertain information about specific locations prone to such
incidents and take preventive measures.

The tactic, already in use in the West, was a part of a project called
Enterprise Information Integration Solution (EI2S). This system put petabytes of
information from more than a dozen crime databases at the fingertips of the
police. Using this data, the cops implemented their 'Crime Forecast' plan to
predict when and where criminals could strike. The software would analyse police
data for patterns and compare them with information from jails, courts and other
crime-fighting agencies. The cops would have access to data on not only the
suspects but also likely victims.

Another technique that the police are likely to put into use is neighbourhood
analysis. This would help the sleuths understand crime events and the
circumstances behind them in a small area on the basis of the previous record.
Cases will be classified into multiple categories to understand what types of
crime a particular area was prone to and the measures needed thereof.

Another technique, called proximity analysis, would provide information about
criminals, victims, witnesses and people who are or were within a certain
distance of the crime scene. By analysing demographic and social trends,
investigators would be able to understand changes that had taken place in an
area and their possible impact on the activity.

For Reprint Rights: timescontent.com

LOAD-DATE: June 19, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                   Copyright 2016 Bennett Coleman & Co. Ltd.
                              All Rights Reserved


                               26 of 41 DOCUMENTS

            Copyright (c) 2016 The University of Texas School of Law
                        American Journal of Criminal Law

                                  Spring, 2016

                        American Journal of Criminal Law

                             43 Am. J. Crim. L. 157

LENGTH: 7026 words

Article: A Tale of Two Dystopias: Order and Chaos on the Electronic Frontier

NAME: Kevin Bankston*

BIO: * Kevin Bankston (@kevinbankston) is the director of the Open Technology
Institute at New America, which works in the public interest to ensure that all
communities have access to an Internet that is both open and secure. He also
convenes a book club for fellow tech policy professionals who enjoy science
fiction, the book selections for which can be found at @techpoliscifi.

TEXT:
 [*157]

   A Keynote Address For The Frontiers of Cybersecurity Policy and Law
Conference

   The Robert S. Strauss Center for International Security and Law

   University of Texas at Austin Law School

   February 5, 2016

   Good evening everyone, and thank you to Bobby Chesney and the teams at the
Strauss Center and UT Law for having me here and for organizing an exceptional
day of panels. I'm admittedly at a bit of a loss to find myself here at my alma
mater, the University of Texas, nominally keynoting - lecturing! - to a room
filled with so many of the people I have worked with (or against) over the past
fifteen years. There are mentors here, mentees, colleagues from my former
organizations, friends, frenemies, esteemed opponents I've litigated against...
It's an incredible group, which leaves me incredibly humbled and more than a
little freaked out.

   If this were some public keynote with a bunch of civilians I could just do my
usual song and dance on the issue of the moment - most likely  [*158]
encryption and "Going Dark," n1 repeating arguments you've all heard before n2 -
and that would be that. But I owe you guys something more than that: some grand
holistic theory of everything that pulls together all the threads from today's
panels, or some deeply personal and idiosyncratic take that gets to the meat of
why I do what I do. I foolishly will try to do a little bit of both tonight, and
will probably fail to do either one effectively, but success or failure, I hope
the next 25 minutes will provide some light entertainment and some minor food
for thought to complement your dinners.

   I'm going to talk about the path that started for me here at UT and brought
me to this work - perhaps prompting you to stop and reflect a bit on how you got
here - and I'm going to talk about where I think we are now as a community, and
about where I think we are going. Amongst other things, this talk will be a bit
of a love letter to - and a friendly argument with - the Electronic Frontier
Foundation (EFF), n3 the organization where I spent most of my career and that
basically raised me. And as will be no surprise to anyone here who knows me
well, it's also going to address one of my great passions: science fiction, and
how it can be used as a tool to help us think about today's problems.

   Yep. Science fiction. Get used to it, non-nerds.

   The topic of science fiction came up just a couple of weeks ago at another
cybersecurity event, the Hewlett Foundation's cybersecurity grantees' meeting in
Los Angeles. n4 There, thanks to the foundation's president Larry Kramer and its
cybersecurity program officer Eli Sugarman, I was lucky enough to meet Walter
Parkes, the screenwriter of WarGames and Sneakers and the producer of Minority
Report amongst many other hit movies. n5 If you want a good example of the
feedback loop between fiction and especially science fiction and real world tech
and policy, you can't get much better than Walter, since WarGames inspired the
Computer Fraud and  [*159]  Abuse Act that our panelists were arguing about
earlier, n6 Sneakers inspired countless security engineers and hackers and
spooks to do what they do, n7 and the movie version of Minority Report is
probably the second most-cited fictional work in policy discourse about
surveillance and privacy (and an inspiration for a lot of modern interface
design to boot). n8 What's the first most-cited work? I think we all know the
answer, but we'll get to that.

   Walter, being from Hollywood, is all about story. Beginning, middle, and end,
strong protagonists, with clear conflicts and relatable goals, and right now
he'd tell me to stop with all the throat clearing and begin the beginning. So
here's where it starts, for me:

   Fade in on the UT campus, spring of 1993, my freshman year. It was easily one
of the happiest years of my life. Coming from Southern Louisiana, a place where
progressive bookish sci-fi nerds who don't like football didn't really fit in, I
finally felt like I was home, and my only job was reading and thinking and
writing for no other purpose than to explore - a freedom for which I thank Plan
II, UT's incredible liberal arts honors program. It was then that I was put on
the path that led me here, today, though I didn't know it at the time. I
expected I'd just end up an English professor - until that spring of 1993, which
changed the course of my life. And it wouldn't have happened without science
fiction.

   It's a truism at this point that science fiction often predicts or inspires
real world developments, whether it's famous sci-fi author Arthur C. Clarke
coming up with the idea of communications satellites in the 40s, n9 or sadly
less famous sci-fi author John Brunner predicting computer worms in the 70s, n10
or William Gibson in his early-80s cyberpunk classic NeuroHD  [*160]  mancer
coining the term "cyberspace" long before any of us were exposed to the modern
Internet. n11 And if you don't know what cyberpunk is, well, you're in luck,
because 18 year-old me would be super-excited to tell you all about it right now
because he's totally a huge fan!

   The cyberpunk science fiction of the 80s and 90s tossed out the spaceships
and aliens and shiny exciting far futures of previous generations to look closer
to home, painting a dark dystopian picture of a globally networked near future
where multinational corporations were as powerful as states, states looked a lot
more like corporations, and ordinary peoples' lives were dictated by
transnational networks of data and capital far beyond their control or
comprehension. n12 But the prototypical hacker protagonist, that
anti-establishment hero, was not like those ordinary people. Only he -
unfortunately it was almost always a he - could get behind the data, and make
the technology work for him, and turn the tables on the powerful. Indeed, the
hacker protagonist had become such an established trope by the early 90s that
Neal Stephenson's cyberpunk classic Snow Crash - which came out in the fall of
my freshman year - had a hacker protagonist jokingly named Hiro Protaganist. n13

   The teenage me just gobbled this stuff up. So too did several of the original
founders of EFF, which was being born just as I was finishing high school.
Frankly, if you want to understand why EFF was founded, who its constituency is,
and why its culture is what it is now - if you want to understand the birth of
the digital rights movement in the US, really - it very much helps to have read
the cyberpunk fiction of the 80s and 90s. Indeed, EFF's tag line for its recent
anniversary wears the organization's science-fictional origin on its sleeve.
That slogan? "EFF: fighting dystopia for 25 years."

   But I digress, and Walter Parkes is getting impatient. Suffice to say,
cyberpunk left me well primed when four things happened to set me on the path
that brought me here.

   The first thing was simply this: I got on the Internet for the very first
time, to use email for the very first time. And coming fresh off of Gibson's
"cyberspace" and Stephenson's "metaverse," it kind of blew my mind.

    [*161]  Second, I read and was inspired by The Hacker Crackdown, a
non-fiction book by science fiction writer (and Austinite) Bruce Sterling. n14
It was all about the emerging hacker subculture; the Secret Service's
overreaching response to it, including the seizure of all the computers at
Austin-based Steve Jackson Games (since they hosted a BBS to which someone had
posted some proprietary AT&T documents); and about the foundation of EFF, which
was initially created to raise the money and find the lawyers to fight for Steve
Jackson Games to get its computers back. Reading The Hacker Crackdown was kind
of like reading one of the cyberpunk novels that Sterling and Gibson and
Stephenson were writing at the time, but it was real. And just to tie it all up
in a nice bow, one of Steve Jackson's most popular role-playing games at the
time, inspired by those same novels, was called Cyberpunk. That book, well, blew
my mind.

   Third thing: being a fan of Bruce Sterling, I also picked up the first issue
of Wired Magazine since he was on the cover, n15 and then its second issue. That
second issue had on the cover the so-called "cypherpunks," including one of the
founders of EFF, who were fighting the first round of the original Crypto Wars.
n16 (Again, note the EFF/cyberpunk connection.) Those magazines, which I
distinctly remember buying at the UT student union not far from here,
illustrated in a way that I hadn't quite realized before that many of the
technologies I'd been reading about in science fiction were real, or very close
to it. And...it...blew...my...mind.

   After that, fourth and finally: my computer nerd dorm neighbors, who are
still some of my best friends, showed me, the liberal arts wussie who's primary
understanding of technology came from reading sci-fi, this funny new computer
program. It was called Mosaic - the very first web browser, Netscape's
predecessor, and the first concrete glimpse of what the next twenty years would
look like. n17 It - yes, that's right - blew mind.

   As an English Major, my first response was: wow, I would love to see a
hypertext edition of James Joyce's Ulysses! (I was big on Joyce at the time.)

   My second response, though, was: I don't want to be an English  [*162]
professor. I want to help build this. I want to help defend it and grow it. And
if you'd told me then that I'd actually end up doing that by working for nearly
a decade at the EFF in San Francisco - and would eventually end up running a
whole new digital rights shop in Washington, DC fighting for a more open and
secure Internet, called the Open Technology Institute n18 - I would have slapped
you in the face and called you liar for getting my hopes up.

   Yet here we are. Flash-forward to now, Twenty-odd years later. And in a lot
of ways, we're navigating the cyberpunk future that was predicted in the 90s,
although with some unanticipated bright spots - see the fall of the Soviet
Union, which loomed large as a state power in 80s cyberpunk n19 - some tragic
curveballs, see 9/11 - and some technological shifts that we didn't predict, see
the rise of the smartphone.

   But again, Walter is nagging me: what's the story, Kevin? These nice people
want to know: who are the protagonists and what's the conflict? Cut to the
chase! And I'll do that, though it's not a chase. It's a race. It's a race
against two futures - two dystopias - and the protagonists of this tale of two
dystopias are us, here, in this room, and everyone else in our community that is
trying to preserve the security of the Internet.

   One of the dystopias is from a science fiction that you all know: it's 1984,
which I pointed to earlier as the most-cited fiction in privacy policy circles.
n20 1984 was also cited by Walter Parkes in LA as a great example of how
narrative can take a set of complex ideas and simplify them, package them, and
create a powerful shorthand that everyone understands. "Big Brother" has become
our go-to signifier when warning of a technology-enabled surveillance society.
And it is still a relevant warning, as we're looking down the barrel of the kind
of totalitarian surveillance dystopia that 1984 portrays, but updated from a
telescreen-centric to an Internet-centric mode - a world where all of the public
expression and private communication flowing over the Internet can easily be
monitored and manipulated and made to serve the interests of the state. We see
the most virulent strains of this future already reaching into our present,
especially in Russia and China, whose governments are wholly unapologetic in
trying to turn the Internet into the most powerful tool of social control ever
devised. n21 We see a more  [*163]  friendly, velvet-gloved, Brave New World-ish
n22 version of that future infiltrating the West, as intelligence services have
begun to live on the Internet backbone, and mass surveillance has replaced
targeted surveillance, and many are left wondering where our dreams in the 90s
of the Internet as an open frontier have gone. n23 (Imagine here a footnote to
either Jennifer Granick's great keynote at Black Hat last year, "The End of the
Internet Dream," n24 and/or the less apt but still hilarious "Dream of the 90s"
sketch from the comedy show Portlandia, n25 both of which I recommend
wholeheartedly.)

   Or, to reference another much-beloved science fiction: after several decades
of mostly unconstrained growth of the global open Internet, the Empire is
Striking Back. States are acting, in some cases very aggressively, to reassert
their digital sovereignty.

   In contrast to 1984, the other, second dystopia is one that none of you have
ever heard of, from a science fiction book that none of you have read (though
it, and the other books in the trilogy of which it is a part, are available for
free online if you Google for them). n26 It's called The Maelstrom, by Peter
Watts, n27 one of my favorite sci-fi novelists writing today. What is the
Maelstrom, you ask? Well, imagine today's Internet with all its emergent
insecurities, all the spooks and spies and hackers and criminals and state
attackers, and botnets and phishing scams and mass data breaches and backdoors
and bad guys. Imagine all the ugly trends outlined in ProfesHD  [*164]  sor Ron
Deibert's Black Code, n28 a harrowing portrait of the modern Internet that I
highly recommend, and then multiply them by a 1000. Imagine us building new
layer upon new layer over the chaotic, crumbling foundation that is the
Internet, continually trying to make it more secure and continually failing, as
the botnets we talked about in today's panel grow and multiply into a pervasive
infestation of self-evolving automated agents, an electronic war of all against
all, red in tooth and claw, a digital state of nature. Imagine the Internet as a
failed state, where no one wants to go but where everyone has to live, because
we've built our entire society on top of it. That is the maelstrom.

   And those are our two dystopias. 1984 versus the Maelstrom. Order vs. Chaos.
The Scylla and Charybdis that we as a community need to navigate, because none
of us want either of those futures. Sure, some of us fall a bit more on the
order side or the chaos side - or as Dahlia Lithwick put it in one of her more
popular columns, some of us are order muppets and some of us are chaos muppets.
n29 (Google it.) But I know that my oft-time opponents in government ultimately
don't want to live in the liberty-eroding 1984, any more than I want to live in
the anarchic chaos of the Maelstrom where no one is safe. And we need to work
together to plot a course that avoids those futures. Or, even worse, a
combination of those futures, where the totalitarian states of 1984 ride atop
the Maelstrom, and the only choice left to anyone - if they have a choice at all
- is to be left in the utter chaos outside the walls of the state, or to embrace
Big Brother. It's that result that I actually fear the most.

   So I look at the landscape, as many of you do, and try to figure out how to
move the right levers to avoid those futures. But every lever you can move makes
another lever move in the other direction. For every action, there's an equal
and opposite reaction - indeed, many of those actions and reactions are things
that have been in the news, and that we have been talking about in our panels,
just in the past few days. Take, for example, a company like Facebook turning on
HTTPS for all of its traffic. That encryption prevents foreign countries - like,
say, the UK, just in the news today on this issue - from sniffing their
citizens' Facebook messages as they pass through the territory to and from US
servers. n30 That in turn prompts atHD  [*165]  tempts by those countries to
either regulate against encryption, or demand that the data be stored locally,
or try to apply their laws outside of their territory to demand the handover of
data stored in the US, backed by the threat of throwing Facebook execs in jail
if they ever visit. Or, consider the example of users turning to end-to-end
encrypted apps like iMessage or WhatsApp - which prompts demands that the
companies not offer such encryption or build a backdoor into it, and also
prompts government stockpiling of vulnerabilities to hack into the phones as an
alternative to wiretapping. Pushback on one issue leads to more pushback on
another issue, back and forth, tit for tat, a never-ending whack-a-mole. n31

   So how do we respond? Well, we discussed one of the current strategies during
yesterday's dinner panel: the idea of "letting off steam" and trying to give the
governments more of the data they say they need in the least harmful ways, to
avoid the most harmful ways. Last night we discussed the example of trying to
come up with a new framework for cross-border data transfers. If we can come up
with a way for Google or Facebook or whoever to voluntarily hand over data to
the UK in a way that is consistent with human rights and perhaps even raises
standards, the thinking goes, then we can help head off bad things like data
localization or anti-encryption mandates or American Internet execs getting
thrown in jail. Some privacy-minded technologists and advocates have similarly
argued that if we can just routinize and standardize government hacking under
clear and protective standards - I mean, they are doing it already anyway,
right?, just under weak, unclear, secret standards - then we can head off bad
anti-encryption policies. n32

   That's the thinking, anyway, and I have to admit that I'm very sympathetic to
this approach. I'm one of the people trying to figure out what that reasonable
compromise might be on cross-border data transfers. n33 I'm one of those people
who, without endorsing the idea of government hacking, wants to expose the
practice to real regulation and ensure that it is included in the calculus as we
continue to have this never-ending "Going Dark" debate. n34 I'm scared we won't
make any progress and will continue  [*166]  to lose ground on these issues if
we're not willing to have those sorts of conversations. I'm scared we'll fail to
protect the technologies that we need to protect ourselves.

   That said, I'll also admit that I have some serious concerns about this
approach because I fear the governments will be not be placated by our
concessions. I think we may let off steam by conceding in one area, yet still
fail to reduce the pressure elsewhere. The cross-border issue is a good example:
we're willing to compromise to arrive at a human rights-respecting solution when
it comes to accessing stored content in criminal investigations, and yet it's
clear from today's story in the Washington Post that the UK's priority is a
wiretapping solution for its national security investigations. n35 The privacy
advocates that are willing to engage in the cross-border data discussion are
doing it because we're concerned about the alternative of forced data
localization, and yet data localization very well may happen anyway - due to
that national security wiretapping need that we're unwilling to address, or due
to an ultimate failure of the EU data protection safe harbor that allows US
companies to take in European data, or due to a variety of factors we can't
necessarily predict. Similarly, we may end up legitimizing government hacking
through our attempts to expose and regulate it, while still not achieving the
goal of getting law enforcement to stop pushing for limits on encryption.

   This is why many of my friends and mentors - including folks in this room,
like ACLU's Chris Soghoian or my fellow EFF alum Jennifer Granick - would say
"Don't compromise. Just fight it. Just fight it all. Fight on every front and
don't give any ground." That's basically the way I was raised at EFF, and they
do have a point. Why should we be working to give governments more access to
data, when the overall trend is in the direction of a golden age of
surveillance, where the information they don't have access to is just a small
portion of a massive amount of communications data that didn't even exist twenty
years ago and that they can now easily obtain? Why should we be the reasonable
compromisers when the state's appetite for data is essentially unquenchable,
because the operating theory in law enforcement and intelligence seems to be
that every scrap of data that exists or will exist should be technically
accessible to them at any time, that they have a natural right to it, even
though until very recently nearly the entire mass of human communication was
always outside of their reach? Hell, electronic eavesdropping of any sort was an
incredibly rare oddity until the  [*167]  back half of the last century, n36 and
yet now we are asked to build our entire world around the idea of guaranteed
government access to all of our private communications and records? Screw them!

   ...is what they would say.

   And I hear them. And I know where they are coming from. "Just fight it" was
where I was as a younger man, as a litigator. Being young, and being a
litigator, makes it easy to see the world in such blacks and whites. And it may
be where I end up as an older man, assuming I've tired of the horse-trading and
compromise and shifting alliances of the policy game, and have lost faith that
the rules of law and reason can actually restrain the powerful.

   But right now I will do whatever I can to protect the right to encrypt above
all others, even if that means compromising on some other things, even if
pushing them back on that front means they push us back on other fronts. Because
here's the nub: only encryption helps us avoid both dystopias. Only encryption.
It protects us both from the Maelstrom of an insecure Internet and the 1984 of
an unconstrained state that can see into every nook and cranny. It offers the
middle way between order and chaos, the middle way between security of the state
and security from the state. And right now that's where I'm pointing all my
guns, right down the middle, in defense of crypto.

   And maybe I will tire of the middle, at some point. Maybe I will finally get
sick of participating in discussions about cross-border data exchange and
government hacking that make the "just fight it all" side of me worry. But right
now, it's where I'm standing, and I invite you to join me there. Perhaps you'd
prefer not. Maybe your mileage may vary, and your calculus may be different, and
I'll just have to keep having all of these arguments, both with the people who
I'm fighting and with the people who think I'm not fighting hard enough.

   But it's late and it's been a long day, so let's not argue about it now.
Walter is telling me that this story has climaxed, and it's about time to wrap
things up. But before I let you go, let me offer two closing thoughts that might
be useful in your thinking of our future, inspired by two science fiction novels
about the future of our thinking.

    [*168]  The first is a newer sci-fi novel called Nexus, by Ramez Naam. n37
Naam is an interesting character. He spent 13 years at Microsoft leading teams
developing Internet Explorer and Outlook and their search engine Bing, but
really wanted to be a sci-fi writer. n38 Nexus is his first book, and although
it's maybe not the most literary novel - it reads like an airport
techno-thriller on sci-fi steroids - it's premise is a nice take on an old idea,
the hybridization of man and machine. The titular technology, Nexus, is
essentially a nano-technological drug that integrates with your brain and
Internet-enables it, allowing - amongst other things - for people to silently
communicate with each other, to share complex skills and masses of knowledge in
an instant, and even create group minds just like you can network computers.

   It's pretty far out, but it's not totally nuts. In fact, Naam has some
fascinating afterwords in the book and its sequels laying out the current state
of brain/computer interface research, n39 and there's a lot of surprising things
happening in labs right now, such as: paralyzed people moving robot limbs using
their thoughts; n40 blind people whose vision has been restored by inputting
electrical signals directly into their visual cortices; n41 fMRI brain scanners
that "read' what a person is seeing and can reconstruct the video; n42 and
brain-damaged rats whose memories have been restored with computer chips
implanted in the hippocampus - whose memories can be recorded and replayed in
their brains at any time! n43 Just last week, I read a story about researchers
using electrodes to monitor a person's brain and then matching that data against
data collected from previous brains to figure out in near real-time what the
person is looking at. n44 And then there is perhaps my favorite brain research
story, about the two University of Washington researchers who in 2013
cooperatively played a video game by networking their freaking brains. n45 One
researcher could see a video game display but  [*169]  had no controls, while
the other had the controls but no display. When the one with the controls wanted
to shoot, an EEG cap on his skull would transmit a signal across campus, where a
magnetic stimulator on the other researcher's head would send a targeted pulse
through his motor cortex and cause his finger to twitch and hit the fire button.

   Amazing, right? I know, it's still a far cry from having Internet-enabled
brains, but that kind of technology is foreseeable - perhaps even inevitable. So
one science fictional thought experiment for you to consider while you finish
your dessert: how would you approach cybersecurity policy if the things we were
securing were our brains, and the data we were securing were our thoughts? How
would you feel about not being able to encrypt the private thoughts that you
share with your family? How would you feel about the possibility of a government
secretly implanting malware in your brain? Sure, you can say that the whole idea
is just science fiction nonsense, but like all good science fiction, it's a
metaphor that speaks to us about how we live today. Regardless of whether you
think our brains will ever literally merge with computers, in a way they already
have. As the unanimous Supreme Court recently recognized in Riley v. California,
our mobile devices now house an absolutely enormous amounts private thoughts,
images and information, amounts of data we couldn't even conceive of a
generation ago. n46 Every day, these devices are looking more and more like our
outboard brains. At what point does that change how we treat them, as a policy
matter?

   That's closing thought number one. The second and final closing thought was
inspired by Charlie Stross' Accelerando, n47 perhaps my favorite sci-fi novel of
the 20-aughts, and certainly the one with the most crazy new ideas per square
inch. In that book, several characters have an entertaining debate - one that we
could also have ourselves right now - about whether or not the Singularity has
already happened. If you're not familiar with the Singularity, a term bandied
about by AI researchers and sci-fi nerds alike, it's the name for the hockey
stick part of the curve in our technological growth, where the exponential
progress of Moore's law hits a point of accelerating acceleration and the
capacity of our computing power begins to exceed our own grasp and starts
improving on itself, and beyond that point we are supplanted by thinking
machines that we can't even comprehend, and we are unable to predict anything
anymore because what's going to happen next is so far beyond our ken. n48

    [*170]  Some people jokingly call this "The Rapture of the Nerds."

   No, seriously, this is a thing. A thing that some of the architects of our
digital lives, including some people who make big decisions at Google, take very
seriously. And just as you need to understand cyberpunk to understand the origin
of American digital rights groups, you kind of need to understand the
Singularity if you truly want to grok n49 Silicon Valley's weirdo strain of
technolibertarian utopianism.

   But anyway, back to Accelerando. These people in the book are wondering,
seriously arguing at length, about whether they're post-Singularity. And the
joke is this: they are having this argument on a laser-propelled spaceship the
size of a can of soup on its way to the next star system, and the reason they
are able to be having that argument on that spaceship is because they aren't
people at all - they are the digitally uploaded brains of people.

   Kind of a crazy idea, right? But there's a real truth inside the crazy, and
it's this: you can't tell when you're in it when you're in it. We've learned to
take so much of our technology for granted and so quickly that if a time
traveler from even just ten years ago visited us, they'd be totally disoriented
by it, and if we went back even ten years, we'd be kind of helpless without it.
Stross' joke is the sci-fi version of an older joke that was central to a great
commencement speech by not-quite-science-fiction author David Foster Wallace,
entitled "This is Water." n50 (You should Google that too, it's great.) The joke
is: two young fish are swimming one day when an older fish passes by and says
"how's the water?" After the old fish passes, one fish turns to the other and
asks him: "What the hell is water?"

   We have told ourselves so many times that we're in the midst of an epochal
shift in the nature of human society and its relationship to technology that
we've forgotten how true it is. This is water. We are in it right now. And it's
very easy to look at these seismic shifts and feel powerless in the face of
them. But it's actually the opposite. We are only at the beginning of this new
era, still in the early days of what we currently call the Internet, and complex
systems are very sensitive to initial conditions. That's what people mean when
they talk about the "butterfly effect." The decisions we make now matter more
than we know. We are the butterflies.

    [*171]  Or let me put it another way. The NSA has this acronym: NOBUS. It
stands for "Nobody But Us," and it refers to software vulnerabilities that the
NSA thinks only the NSA will ever discover and exploit. n51 I think it's a
profoundly flawed concept, n52 as demonstrated at 2013's Chaos Computer Congress
when Jake Appelbaum did a keynote on the Snowden docs laying out the NSA's
catalog of exploits, and the vulnerability that one of those exploits relied on
had been the subject of a research presentation just the day before. n53 Someone
other than "us" had found it.

   But we don't need to argue about NOBUS right now. Right now, I'm using the
phrase Nobody But Us in a very different way. Right now, what I'm here to say is
that Nobody But Us is going to set the initial conditions for the future of the
Internet. Nobody But Us - those of us in this room, and our communities outside
of this room, and our opponents who want to abuse the Internet to control us or
steal from us or attack us - is going to determine which science fictional
future we're going to live in, whether it looks like the Maelstrom, or Big
Brother, or both, or neither. Nobody But Us is going to create the future that
we want. We are the butterflies. This is water. It's up to us, all of us, chaos
muppets and order muppets alike, to fight dystopia. So join me. Join together.
Fight the Maelstrom. Fight 1984. Fight for your off-board brain. And read more
science fiction. You'll be glad you did.

Legal Topics:

For related research and practice materials, see the following legal topics:
Computer & Internet LawCriminal OffensesComputer Fraud & Abuse ActComputer &
Internet LawPrivacy & SecurityCryptographyGovernmentsFederal GovernmentDomestic
Security

FOOTNOTES:




n1.  Fed. Bureau of Investigation, Going Dark,
https://www.fbi.gov/services/operational-technology/going-dark (last visited
Aug. 22, 2016) (explaining that "going dark" is how law enforcement describes
the problem it faces when it has the legal authority to access data but lacks
the technical ability to do so because of encryption).





n2.  Encryption Technology and Possible U.S. Policy Responses: Hearing before
the U.S. House of Representatives Subcommittee on Information Technology of the
Committee on Oversight and Government Reform (2015)( statement of Kevin S.
Bankston, Policy Director of New America's Open Technology Institute &
Co-Director of New America's Cybersecurity Initiative) (offering ten arguments
why government-mandated surveillance backdoors into encrypted products and
services are a bad idea).





n3.  About EFF, Electronic Frontier Found., https://www.eff.org/about (last
visited Apr. 13, 2016) ( Electronic Frontier Foundation is a non-profit
organization focused on advocating civil liberties on the internet and
protecting user privacy).





n4.  See Cyber Initiative, Hewlett Found.,
http://hewlett.org/programs/special-projects/cyber-initiative (last visited Apr.
23, 2016) (discussing the foundation's funding of a five year initiative to
research cyber security and more: the three grantees being Massachusetts
Institute of Technology, University of California, Berkeley, and Stanford
University).





n5.  Walter F. Parkes Filmography, MDB,
http://www.imdb.com/name/nm0662748/?ref_=tt_ov_wr (last visited Apr. 23, 2016).





n6.  Seth Rosenblatt, Where Did The CFAA Come From and Where Is It Going,
Parallax (Mar. 16, 2016),
https://www.the-parallax.com/2016/03/16/where-did-the-cfaa-come-from-and-where-
is-it-going; Declan McCullagh, From "WarGames' to Aaron Swartz: How U.S.
Anti-Hacking Law Went Astray, Cnet (Mar. 13, 2013),
http://www.cnet.com/news/from-wargames-to-aaron-swartz-how-u-s-anti-hacking-law-
went- astray/.





n7.  Sara Sorcher, Podcast: Screenwriter Walter Parks on How Fiction Can Inspire
Change, Christian Sci. Monitor (Mar. 24, 2016),
http://www.csmonitor.com/World/Passcode/2016/0324/Podcast-Screenwriter-Walter-Pa
rkes-on-how-fiction-can-inspire- change.





n8.  See Nathan Shedroff & Christopher Noessel, Make It So 95 (Rosenfeld Media)
(2012) (citing,the gestural interface in Minority Report as "one of the most
famous interfaces in sci-fi" and "one of the most referenced interfaces in
cinematic history," such that it has now become "the canonical gestural
interface"); see also Jack Marshall, How Has Advertising Lived Up to 'Minority
Report'?, Digiday (Feb. 7, 2014),
http://digiday.com/brands/advertising-really-like-minority-report/ (""Minority
Report' ... is cited at industry conferences the world over as an example of
what's now possible thanks to the collision of tech and media."); Eugene K.
Chow, Is Predictive Policing Making Minority Report a Reality, The Week (Oct. 7,
2013), http://theweek.com/articles/459396/predictive-policing
-making-minority-report-reality





n9.  David Whalen, Communications Satellites: Making the Global Village
Possible, NASA, http://history.nasa.gov/printFriendly/satcomhistory.html (last
updated: Nov. 30, 2010).





n10.  See generally John Brunner, The Shockwave Rider (1975) (describing
fictional computer programs that parallel what would become worm programs).





n11.  William Gibson, Neuromancer 5 (Penguin 2000) (1984).





n12.  Thomas Michaud, Science Fiction and Politics: Cyberpunk Science Fiction as
Political Philosophy, in New Boundaries in Political Science Fiction 75-76
(Donald M. Hassler & Clyde Wilcox eds., 2008).





n13.  Neal Stephenson, Snow Crash 19 (Random House Publishing 2003) (1992).





n14.  Bruce Sterling, The Hacker Crackdown: Law And Disorder On The Electronic
Frontier (freeware, electronic release on the internet 1994),
http://www.mit.edu/hacker/hacker.html.





n15.  Ted Greenwald, Step Behind the Scenes of the Frantic, Madcap Birth of
Wired, Wired (Apr. 16, 2013), http://www.wired.com/2013/04/wired0101/ (scroll to
mid page to find image of first cover with Bruce Sterling).





N16.  Wired May/June 1993, BackIssues.com,
http://backissues.com/issue/Wired-May-1993 (last visited Apr. 24, 2016); Steven
Levy, Crypto Rebels, Wired (Feb. 1, 1993),
http://www.wired.com/1993/02/crypto-rebels/.





n17.  Michael Calore, April 22, 1993: Mosaic Browser Lights Up Web With Color,
Creativity, Wired (Apr. 22, 2010),
http://www.wired.com/2010/04/0422mosaic-web-browser/.





n18.  Open Technology Institute, New America, https://www.newamerica.org/oti/
(last visited Apr. 11, 2016).





n19.  See, e.g., Bruce Sterling & William Gibson, Red Star, Winter Orbit, in
Burning Chrome (1986) (imagining a fictional 1990s where the Soviet Union has
won the space race and become the dominant superpower).





n20.  See Devon Maloney, The 10 Most Important Dystopian Books and Films of All
Time, Wired (May 20, 2014), http://www.wired.com/2014/05/dystopia-101/
(reporting that Orwell's 1984 is "cited most often" as the "most famous example
of dystopian writing").





n21.  See generally James T. Areddy, China Pushes to Rewrite Rules of Global
Internet, Wall Street J. (July 28, 2015),
http://www.wsj.com/articles/china-pushes-to-rewrite-rules-of-global-internet-143
8112980; Simon Denyer, China's Scary Lesson to the World: Censoring the Internet
Works, Wash. Post (May 23, 2016),
https://www.washingtonpost.com/world/asia_pacific/chinas
-scary-lesson-to-the-world-censoring-the-internet-works/2016/05/23/413afe78-fff3
-11e5-8bb1- f124a43f84dc_story.html; Masha Gessen, How Putin Controls the
Internet and Popular Opinion in Russia, Intercept (Sep. 8, 2015),
https://theintercept.com/2015/09/08/how-putin-controls-the-russian-internet/;
Erik C. Nisbet & Sarah Mikati, Russians don't trust the Internet - and it's
making the country worse, Wash. Post (Feb. 18, 2015),
https://www.washingtonpost.com/posteverything/wp/2015/02/18/rus
sians-dont-trust-the-internet-and-its-making-the-country-worse/.





n22.  Aldous Huxley, Brave New World (1932) (describing how advance technology
in the future has profoundly changed society).





n23.  Siobhan Gorman & Jennifer Valentino-Devries, New Details Show Broader NSA
Surveillance Reach: Programs Cover 75% of Nation's Traffic, Can Snare Emails,
Wall St. J. (Aug. 20, 2013),
http://www.wsj.com/articles/SB100014241278873241082045790228740 91732470
(describing mass surveillance by the United States National Security Agency at
key domestic junction points on the Internet backbone); Ewen MacAskill Et Al.,
GCHQ taps fibre-optic cables for secret access to world's communications,
Guardian (Jun. 13, 2013),
https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communicatio
ns-nsa (describing how Great Britain's signals intelligence agency, the
Government Communications Headquarters, conducts mass surveillance on key
fiber-optic cables that carry communications traffic between north America and
western Europe).





n24.  Jennifer Stisa Granick, The End of the Internet Dream, BackChannel (Aug.
17, 2015),
https://backchannel.com/the-end-of-the-internet-dream-ba060b17da61#.ktnr31q4v.





n25.  Portlandia: Farm (IFC television broadcast Jan. 21, 2011), available at
https://www.youtube.com/watch?v=HX8BsX3IIa4.





n26.  All of Peter Watts books are available as free ebooks here:
http://www.rifters.com/real/shorts.htm





n27.  Peter Watts, Maelstrom 41-43 (David G. Hartwell, ed., 2001).





n28.  Ronald J. Deibert, Black Code: Inside the Battle for Cyberspace (2013)
(Criminal cyber-gangs, state cyberwar, cyber espionage, and cyber-attacks on
citizens).





n29.  Dahlia Lithwick, Chaos Theory: A Unified Theory of Muppet Types, Slate
(June 8, 2012), http://www.slate.com/articles/life/low_concept/2012/06/w
hat_kind_of_muppet_are_you_chaos_or_order_.html. (explaining that some people,
the order muppets, tend to be "neurotic, highly regimented, averse to
surprises," and the other people, the chaos muppets, "make their way through
life in a swirling maelstrom of food crumbs, flaming objects, and the letter
C").





n30.  Ellen Nakashima & Andrea Peterson, The British want to come to America -
with wiretap orders and search warrants, Wash. Post (Feb. 4, 2016),
https://www.washingtonpost.com/world/national-security/the-british-want-to-come-
to-america--with-wiretap-orders-and-
search-warrants/2016/02/04/b351ce9e-ca86-11e5-a7b2-5a2f824b02c9_story.html.





n31.  See, e.g., Ellen Nakashima, Comey defends FBI's purchase of iPhone hacking
tool, Wash. Post (May 11, 2016),
https://www.washingtonpost.com/world/national-security/comey-defends-fbis-purcha
se-of-iphone-hacking-
tool/2016/05/11/ce7eae54-1616-11e6-924d-838753295f9a_story.html (describing how
encryption on an iPhone prompted FBI to purchase a hacking tool to break into
the phone).





n32.  See, e.g., Steven M. Bellovin, Lawful Hacking: Using Existing
Vulnerabilities for Wiretapping on the Interne, 12 Nw. J. of Tech. & Intell.
Prop. 1, 64 (2014) (arguing that targeted hacking by law enforcement into
suspects' computers is preferable from a security and privacy perspective to a
broad mandate requiring online services to design their products to be
wiretap-capable).





n33.  See Kevin Bankston, OTI Condemns Plan to Let U.K. Government Use American
Companies for Internet Wiretapping, New Am.'s Open Tech. Inst. (Feb. 5, 2016),
https://www.newamerica.org/oti/press-releases/oti-condemns-plan-let-uk-governmen
t-use-american-companies-internet- wiretapping/ (expressing willingness to
consider reasonable compromise to ensure law enforcement access to cross-border
evidence so long as consistent with human rights).





n34.  See Kevin Bankston, It's Time to End the "Debate" on Encryption Backdoors,
Just Security (Jul. 7, 2015),
https://www.justsecurity.org/24483/end-debate-encryption-backdoors/ (describing
ongoing "Going Dark" debate); see also Andi Wilson et al., Bugs in the System: A
Primer on the Software Vulnerability Ecosystem and its Policy Implications, New
Am.'s Open Tech. Inst. at 22-23 (Jul, 28, 2016),
https://na-production.s3.amazonaws.com/documents/Bugs-in-the-System- Final.pdf
(arguing that Congress should investigate and craft regulations regarding the
practice of government hacking.)





n35.  Ellen Nakashima & Andrea Peterson, supra note 30.





n36.  See Kaplan et al., The History and Law of Wiretapping, Am. Bar Ass'n 1, 3
(2014), http://www.americanbar.org/content/dam/aba/administrative/litig
ation/materials/sac_2012/29-1_history_and_law_of_wiretap ping.authcheckdam.pdf
(noting that wiretapping was an illegal and stigmatized investigative technique
until the late 1960s).





n37.  Ramez Naam, Nexus (2012).





n38.  Ramez Naam, About, http://rameznaam.com/about/ (last visited Apr. 25,
2016).





n39.  Ramez Naam, Apex (2015); Ramez Naam, Crux (2013).





n40.  Benedict Carey, Paralyzed, Moving a Robot With Their Minds, N.Y. Times
(May 17, 2012),
http://www.nytimes.com/2012/05/17/science/bodies-inert-they-moved-a-robot-with-t
heir-minds.html?_r=0.





n41.  See Susan Young Rojahn, What It's Like to See Again with an Artificial
Retina, Mass. Inst.Tech. Tech. Rev. (May 9, 2013),
https://www.technologyreview.com/s/514081/can-artificial-retinas-restore-natural
-sight/ (discussing retinal implants that gives people blinded by retinitis
pigmentosa some amount of sight back).





n42.  Yasmin Anwar, Scientists use brain imaging to reveal the movies in our
mind, Berkeley News (Sept. 22, 2011),
http://news.berkeley.edu/2011/09/22/brain-movies/.





n43.  Jon Cohen, Memory Implants, Mass. Inst.Tech. Tech. Rev.,
https://www.technologyreview.com/s/513681/memory-implants/ (last visited Apr.
25, 2016).





n44.  Ben Taub, Scientists Just Read Someone's Brain Signals and Decoded What
That Person Was Perceiving, IFLScience! (Jan. 29, 2016),
http://www.iflscience.com/brain/reading-brain-signals-helps-scientists-tell-what
-people-are- experiencing.





n45.  Sandi Doughton, Scientists Connect Two Brains Via the Internet, Seattle
Times (Aug. 29, 2013),
http://www.stltoday.com/news/national/scientists-connect-two-brains-via-the-inte
rnet/article_7adac449-9f30-50a2-ae84- c867595e73f8.html.





n46.  Riley v. California, 134 S. Ct. 2473, 2489 (2014).





n47.  Charles Stross, Accelerando (2005).





n48.  Vernor Vinge, The Coming Technological Singularity: How to Survive in the
Post-Human Era, NASA Conference Publication, Vision 21: Interdisciplinary
Science & Engineering in the Era of Cyberspace 12 (Mar. 31, 1993),
http://www.ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/199400 22855.pdf.





n49.  Grok, Merriam-Webster.com (last visited Apr. 14, 2016),
http://www.merriam-webster.com/dictionary/grok (meaning "to understand
profoundly and intuitively" and coined by Robert Heinlein in his book Stranger
in a Strange Land).





n50.  David Foster Wallace, Commencement Address at Kenyon College: This Is
Water (May 21, 2005),http://web.archive.org/web/20080213082423/http://www.marg
inalia.org/dfw_kenyon_commencement.html





n51.  Andrea Peterson, Why everyone is left less secure when the NSA doesn't
help fix security flaws, Wash. Post (Oct. 3, 2013),
https://www.washingtonpost.com/news/the-switch/wp/2013/10/04/why-everyone-is-lef
t-less-secure-when-the- nsa-doesnt-help-fix-security-flaws/.





n52.  See Eric Geller, Encryption Backdoor Critics Pounce on Apparent Theft of
NSA Hacking Tools, Politico Pro (Aug. 17, 2016),
https://www.politicopro.com/cybersecurity/story/2016/08/encrypt
ion-backdoor-critics-pounce-on-apparent-theft-of-nsa-cyber-tools-126756 (quoting
author arguing that the theft of secret NSA hacking tools "undermines the NSA's
claim that there are computer vulnerabilities that nobody but us - the good guys
- could ever discover and exploit... There's no such thing as a hacking tool
that nobody but us can use.")





n53.  Cory Doctorow, Jacob Appelbaum's must-watch 30C3 talk: why NSA spying
affects you, no matter who you are, BoingBoing (Dec. 31, 2013),
http://boingboing.net/2013/12/31/jacob-appelbaums-must-watch.html.


                               27 of 41 DOCUMENTS


                               The Baltimore Sun

                             October 2, 2016 Sunday
                                 4Star Edition

More guns, bigger bullets

BYLINE: Justin George

SECTION: MAIN NEWS; A; Pg. 1

LENGTH: 7317  words



HIGHLIGHT: Detail shows a handgun being fired. Guns now in use on the streets of
Baltimore are higher-caliber than previously. Covington Balloons hang from a
makeshift memorial to an earlier shooting near the scene where eight people,
including a 3-year-old girl, were shot Sept. 24. Baltimore Police Commissioner
Kevin Davis says that about half of shootings in Baltimore are carried out in
the daytime and most are outside. Maryland Shock Trauma Center's Dr. Thomas
Scalea says that he is seeing more "higher-velocity injuries" from high-caliber
guns and more bullet wounds per patient. A bullet wound in a tattoo on Devante
Turner-Fordbey's chest remains a mark of the time he was ambushed and shot 27
times. The city skyline and a nearby playground, below, serve as a backdrop to
the spot on Mount Street where the shooting took place. After more than a year
of recovery, he says he has turned his life around. Darlene Johnson of
Belair-Edison reads the funeral program describing her slain son at the monthly
community meeting for Mothers of Murdered Sons and Daughters United at St.
John's Alpha and Omega Church. Col. Stanley Brandford of the Baltimore Police
Department's Criminal Investigation Division says the department monitors about
600 "trigger pullers."Lloyd Fox/Baltimore Sun Kevin Richardson/Baltimore Sun
Lloyd Fox/Baltimore Sun Lloyd Fox/Baltimore Sun Algerina Perna/Baltimore Sun
Karl Merton Ferron/Baltimore Sun Karl Merton Ferron/Baltimore Sun Amy
Davis/Baltimore Sun Lloyd Fox/Baltimore Sun


He was about 13 years old. Growing up in Baltimore, he knew it was wrong to
shoot a man. Still, he said, he didn't feel remorse. What he did feel was that
his crew had newfound respect for him.

By 15, he was the one doing the shooting. Over the next dozen years, Covington
learned to do it well. He used 9 mm guns that held 16 bullets and Mac-10
submachine guns. He lured victims to his turf, where he could scout for
witnesses and surveillance cameras, in what he called his "Miranda check" - a
macabre reference to the right to remain silent.

He also knew where to aim.

"If I shoot you in the leg, I know what I'm going to get," said Covington, who
is serving a 25-year sentence for murder. "If I shoot you in the stomach, I know
what I'm going to get. If I shoot you in the head, I definitely know what I'm
going to get. I'm going to get your demise."

Covington's evolution into a killer encapsulates a trend driving gun violence
around the country: Increasingly, people are shooting to kill. Criminals are
stockpiling higher-caliber guns, many with extended magazines that hold more
than 20 bullets. Police and hospitals are seeing a growing number of victims who
have been shot in the head or shot repeatedly. And trauma doctors are finding it
more difficult to save gunshot victims.

In many places, if you get shot, you are more likely to die than ever before.

In Baltimore, one of every three people struck by gunfire dies,up from one death
in every four shootings the previous decade. It ranks as one of the most lethal
of America's largest cities, according to a Baltimore Sun analysis. Two other
cities - Washington and New Orleans - shared the brutal distinction of one in
three shootings ending in a homicide in 2015. Like Baltimore, several cities
have seen the death grip tighten. In Chicago, one in 10 people died after being
shot in 2000; now one in six perishes.

Last year, the odds for gunshot victims worsened in at least 10 of the nation's
largest cities, The Sun found.

The Baltimore Sun undertook a yearlong investigation into this rarely studied
phenomenon, documenting patterns of lethality based on hundreds of crime
statistics, hospital data and gun trace reports as well as interviews with
police chiefs, homicide detectives, criminologists, medical experts, community
activists, victims of gun violence and the perpetrators themselves.

Researchers said lethality is a significant part of the homicide equation, with
implications for policing, public health and trauma care, but in-depth study has
been hampered by a paucity of statistics.

Historically, gun violence research in the U.S. has been inhibited by a lack of
federal funding and data - many police departments only track what they are
required to report to the FBI, which doesn't include how often people survive
shootings, where on the body people are shot and how many times.

That leaves a focus on body counts and homicide rates, which can be traced back
nearly a century. While the nation's overall violent crime rate declined,
starting in the 1990s, a city's homicide rate typically fluctuates, sometimes
significantly, leaving criminologists to puzzle over the causes behind spikes
and dips.

Just five years ago, Baltimore public officials were celebrating a drop in the
annual homicide count below 200. This year, that marker was crossed in August.

The latest crime wave in a number of cities - Baltimore, Chicago, Milwaukee and
Washington, to name a few - has prompted deeper soul-searching. Deteriorating
police-community relations have been blamed for a sharp increase in shootings
and homicides, as have gang conflicts and entrenched societal ills such as
segregation, poverty and joblessness.

But one often-overlooked trend has been consistent over the years, the Sun
analysis found: Lethal force has become more so.

In Baltimore, where there were nearly 1,000 shootings last year, a one-in-four
lethality rate means about 250 victims die. A one-in-three rate means more than
330 people die. So even if shootings subside, the number of gun deaths remains
elevated.

On the streets, particularly in poor, black neighborhoods, residents are
witnessing increasingly deadly tactics. More shooters are aiming for the head
and firing multiple rounds into victims.

The number of fatal head shots in the city rose steadily from about 13 percent
two decades ago to 62 percent last year. Meanwhile, the number of cadavers with
10 or more bullets more than doubled in the past decade, according to the
Maryland medical examiner's office, which tallied the bullet wounds at the
request of The Sun.

Now, roughly two-thirds of city homicide victims are either shot in the head or
multiple times. Many suffer both fates.

Guns have also become more deadly, as the weapon of choice for criminals and
then law enforcement shifted from the revolver to the semiautomatic pistol,
which can fire more bullets without reloading. Nationally, the number of 9 mm
and .40-caliber guns taken off the streets surged during the past four years, as
seizures of less powerful .22-caliber guns remained relatively flat.

In Maryland, seizures of 9 mm handguns overtook .22-caliber guns for the first
time last year. Most were recovered from Baltimore's streets, where the saying
goes: "Buy every gun that comes through; don't let it be the gun that kills
you."

Many of the guns are equipped with extended magazines, allowing a shooter to
fire from a distance and "walk down" a victim, continuously firing. The sale of
"extendos" with more than 10 rounds is banned in Maryland, where they are prized
in street cultures, tucked under belts and into pants as a fashion statement. In
Baltimore, police are finding up to 80 shell casings at a single crime scene.

Metropolitan Police Chief Cathy L. Lanier, who retired last month after more
than a decade in Washington, keeps a photo of a 100-round magazine seized by
police on her cellphone as a reminder of the firepower out there.

Law enforcement officials across the country say they've observed insidious
circumstances that are difficult to quantify. Reckless shootings in the daytime.
Vigilante justice and contract killers. Gang rules that codify when violence
should be used - and street rules limiting violence against bystanders being
ignored.

"The criminals are more brazen," said Baltimore police Maj. Donald Bauer, who
leads the homicide unit.

While shooters' motives vary, experts and those caught in the crossfire note a
ruthlessness on the streets where criminals with more sophisticated weaponry
aren't just using guns to intimidate rivals or rob. They are using them to take
people out with greater success.

In Baltimore and other cities with a deeply entrenched "no-snitching" ethos, the
emphasis is on leaving behind no witnesses and no one to retaliate.

"It's very common for someone to walk up and empty a pistol at close range,"
said criminologist David M. Kennedy, describing the "extreme" hold that gangs
and drug crews have in cities like Baltimore, Washington and New Orleans. "It's
going in with a heightened intent to actually kill you."

Those same criminals have honed strategies to keep weapons at the ready. Guns
are stashed in trash cans, hung from gutter grates by string and stashed in
other nooks where they can be quickly recovered when needed. (Covington says he
kept part of his arsenal under an apartment complex's washing machine.)

Or people serve as "human holsters," carrying guns for felons, according to
Milwaukee Police Chief Edward A. Flynn.

And in Baltimore, hit men for hire have become fixtures on the streets.

Police recently began tracking the so-called 10 Grand Club, an organized gang of
hit men willing to kill for that price, and prosecutors say that's double the
typical fee. (Covington became a contract killer but also says he "killed out of
friendship" for free if a woman approached him about taking out her rapist or
her child's molester.)

Not even decades of advancements in trauma medicine can stem the carnage.

Even as patients with major injuries from other assaults and car accidents have
seen their chances improve dramatically, gunshot victims have watched their
chances of survival plummet. Studies by hospitals and trauma centers across the
country, including Baltimore's top-ranked medical systems, have documented this
contrarian trend.

"We feel this represents a true change in violence intensity," researchers with
the Johns Hopkins Medical Institutions concluded a decade ago. Doctors say it
has gotten worse since then.

This has left communities nationwide reeling, with violence concentrated in
traumatized neighborhoods where mothers are forming support groups, not only to
help each other cope but in a desperate search for ways to stop the killing. A
nationwide network of grief is starting to take shape, with more support groups
banding together and becoming politically active.

"We're all facing similar dynamics," said Corneilius Scott, who volunteers as
executive director of Mothers of Murdered Sons and Daughters United in
Baltimore. "There's a lot of concern and not many answers."

At the group's meetings, parents are talking about "sensitizing" young men to
the effects of violence. They believe - and social science is finding - that
their boys need to be taught empathy, lest they become trapped in a cycle,
repeatedly exposed to violence and becoming more likely to commit it.

More guns, bigger bullets

Rodney Chase sensed trouble when three young men approached him on Gay Street in
Baltimore, but he didn't run, saying he's not the kind to back down from anyone.
One of the men pulled a gun; they wanted his NFL Starter jacket, his wallet,
anything of value.

As Chase took off his jacket, one of the men tried to yank it off, and Chase
instinctively hit him. The gunman fired into Chase's belly, and Chase felt as if
hot grease had been thrown at him.

A woman nearby screamed and called an ambulance. He underwent surgery. Doctors
put a screen under his skin to hold in his organs. He wasn't discharged for
nearly two months.

That was more than two decades ago. Had he been shot today, with the kinds of
guns prevalent on Baltimore's streets, he believes he'd be dead.

"Luckily it was a .22," the 58-year-old said recently, lifting his shirt to show
off a scar slicing down the middle of his stomach. "I'm grateful for that. If it
was bigger, I'd be done."

He knows Baltimore's streets because that's where he's spent most of his life.
He was a drug addict living in an abandoned house when he was seriously injured
in a knife attack and ended up at the University of Maryland Shock Trauma Center
nearly a year ago. He also was admitted into a hospital program that connects
patients with social services in hopes of reducing the recidivism of violence.

"I call it 'Clip City,'" Chase said of Baltimore and the proliferation of guns.
"What they got now - they're death dealers. And it's not hard to get 'em."

Gun production in the U.S. set a blistering pace beginning in 2011 through 2014,
the latest years for which data is available, doubling and sometimes tripling
the annual manufacturing reported in the previous 25 years.

Moreover, guns sold now are more powerful - higher-caliber weapons that come
with larger magazines and discharge bullets with more force.

"All of these factors, over the last several decades, have progressed," said Jay
Wachtel, a 20-year agent of the Bureau of Alcohol, Tobacco, Firearms and
Explosives who lectures at California State University Fullerton. That has led
to what he called an "incredible increase in the lethality of guns."

Even an inexperienced shooter, Wachtel said, can do a lot of damage with a
high-caliber semiautomatic gun. "You don't need to be a very good shot because
any organs nearby are going to be pulverized," he said.

Eventually, many of the newer models end up on the streets despite laws aimed at
keeping guns out of the hands of felons. Law enforcement officials nationwide
say they have noticed an increase in the quality of guns wielded by criminals.

"All the cheap guns made in the '80s have either quit functioning or have been
recovered by police," said Los Angeles Homicide Detective John Skaggs, the
protagonist in the best-selling book "Ghettoside," who has closed nearly all of
the homicide cases he's handled. "They seem to all be expensive and high-quality
now."

In Milwaukee, police are tracking this trend. A decade ago, the top guns seized
by police were a 12-gauge shotgun and pistols that cost less than $200 with
standard, eight-bullet magazines. This year, the most seized guns were
.40-caliber and 9 mm handguns that cost more than $400 and come with magazines
that hold nine to 16 bullets.

Flynn, Milwaukee's police chief, said most of the guns used in crime - nearly 90
percent - are bought, not stolen. He blamed "straw purchases," in which people
purchase guns for others who wouldn't pass a background check.

"The gun of choice of street offenders has shifted over time to higher-quality,
higher-caliber of semiautomatic pistols," said Kennedy, the criminologist who
directs the National Network for Safe Communities, a project of the John Jay
College of Criminal Justice in New York City.

"Since those are the guns that gangs and drug-involved offenders are more likely
to have, they're more likely to kill somebody," he said.

In Baltimore, gun seizures this year have already surpassed last year's total by
more than 25 percent. The once-ubiquitous "Saturday night specials" - cheaply
made .22- or .25-caliber handguns that were banned for a time in Maryland - are
no longer as prevalent.

Now 9 mm guns are the top gun seized by police, and a Glock .40-caliber was most
often used in crimes last year. Those weapons are capable of firing a bullet
nearly twice the diameter of the one fired from the original Saturday Night
Special.

"A lot of big guns out there," said James "J.T." Timpson, a community liaison
officer with Safe Streets, the city's violence mediation program, which works in
high-crime neighborhoods to resolve conflicts without police intervention.

Timpson said shooters believe they need "stopping power" to ensure their mark is
dead. "We don't have .22s no more," he said.

Measures aimed at limiting high-capacity magazines haven't kept them off the
streets, either.

A decade after the federal assault weapons ban expired, Maryland again
restricted the number of bullets when lawmakers passed one of the nation's
strictest gun control laws in 2013. The law, which regulates certain gun
purchases, also prohibits the sale of magazines with more than 10 rounds.

Since the law passed, however, dozens of "extendos" have been confiscated in the
city, according to police. Officials don't keep exact statistics on the sizes of
magazines.

Still, only 11 people have been charged in Baltimore and fewer than 100
statewide under the magazine statute. The penalties under the law are stiff. If
convicted of committing a felony or violent crime with an extended magazine,
defendants face a minimum of five years in prison and a maximum of 20.

Baltimore Police Commissioner Kevin Davis said the department's gun violence
enforcement division, a new partnership with prosecutors, would investigate why
more people haven't been charged.

Police in other cities are also finding bigger magazines. In Washington, where
gun seizures by the police gun recovery unit were up nearly 50 percent so far
this year over last, police noticed more rounds being shot at scenes and signs
of multiple shooters. So they began keeping statistics.

Last year, about one-third of guns recovered had high-capacity magazines.
Through June of this year, nearly half had large clips.

With that kind of firepower, homicides spiked in Washington, Baltimore and more
than a quarter of the largest American cities last year, pushing the nation's
annual murder rate up by the largest margin in nearly 50 years. The higher pace
of killing has continued in many cities this year.

At the same time, the odds for gunshot victims worsened last year in a number of
cities, including Washington, Detroit, San Francisco, Milwaukee, Louisville,
Ky., and Charlotte, N.C., The Sun's analysis found. In New York, one in five
shooting victims died last year, up from one in seven in 2014. In Nashville, the
odds of dying increased year-over-year from one in nine shootings to one in
four.

That surprised researchers who said they expect surges in violence to become
more haphazard, less planned - therefore resulting in fewer killed.

The Sun reviewed statistics from the nation's largest cities that tracked the
shooting data necessary to calculate the lethality of gun homicides over the
past five years. Half of the 30 biggest cities do.

In some cities that kept statistics for a decade or longer, including Baltimore
and Chicago,shootings proved to be deadlier over the years, not just last year.

Former D.C. Chief Lanier, who has worked with police chiefs across the U.S.,
sharing ideas and data on the surge in homicides, noted a shift in the mindset
of shooters. Criminals are emptying their clips, she said, leaving crime scenes
littered with 50 to 60 shell casings, and opening fire in the daytime.

"Something's changed in the mentality of the people shooting," she said. "Very
reckless. Everyone's got a gun, and everyone is willing to do these shootouts."

Trauma care falls behind

The first bullet ripped into his thigh, and he crumpled.

Devante Turner-Fordbey dropped to the asphalt on a spring day in West Baltimore
two years ago, turned and saw his assailant in a hoodie pointing what looked
like a 9 mm. The gun was jammed, and Turner-Fordbey began pulling himself up the
street on his elbows and forearms as quick as he could. Then he heard the next
shot blast.

Now the bullets felt like hammer blows. The more the shooter closed in, the more
he felt the force of the bullets, which were moving at more than 900 feet per
second. Turner-Fordbey turned onto his back and put his hands up.

"You're good, you're good!" Turner-Fordbey yelled. "You got me!"

But the shots kept coming. A bullet pierced his chest. Nine sank into his right
thigh. One just missed his heart, striking his chest where the words "Nana" for
his grandmother are tattooed along with some clouds and doves.

Figuring he was going to die, he began to taunt the man standing over him with a
gun. "You're a bitch. You're a bitch."

Then a slug sliced into his head, and he blacked out just as he saw the man run
away. He figures his survival instinct must have taken over, and he came to as
he was trying to crawl away again.

"He heard me shuffling on the ground, and I'm trying to get myself off the
ground," Turner-Fordbey said. "He came right back and slapped in another clip in
the gun. Boom. Boom. Boom. Boom. ... I blacked out."

In and out of consciousness he went, while his mother, who lived nearby and came
running when word reached her, dug out the slug from his skull and pressed her
hand against his neck to stop the bleeding.

"I'm sorry, Ma. I'm sorry, Ma. I feel myself leaving, I feel it," he told her.

As a paramedic called his name in the racing ambulance, he thought it was God.
"Devante! Devante! Devante!"

With advancements in trauma medicine over decades, emergency room patients now
have a far better chance of surviving. Patients who have been stabbed are more
likely to live. Better care, coupled with safety advancements, has driven deaths
from motor vehicle accidents to historic lows.

Gunshot victims, however, are less likely to live.

In Baltimore, at the University of Maryland Shock Trauma Center, the nation's
first hospital devoted to trauma injuries, doctors sought to assess improvements
in care. They studied patients over a dozen years and found that chances for
surviving "improved significantly."

A notable exception: gunshot victims. In 1999, 9.8 percent of those patients
died. By 2008, that rate had risen to 17 percent.

The study's authors, including Thomas Scalea, the physician-in-chief at the
center, blamed the increasing availability of lethal automatic and semiautomatic
weapons on the street. Scalea says that trend continues today. The trauma
surgeon said in an interview that he's seeing more "higher-velocity injuries"
from high-caliber guns and more bullet wounds per patient.

Johns Hopkins researchers also studied trauma outcomes and found that the
fatality rate for patients with gunshot wounds nearly doubled from 9.5 percent
between 2000 and 2003 to 18.3 percent for the period through March 2005.

The study concluded that the overall fatality rate jumped because patients were
arriving in grave shape. More patients were dead on arrival, and more succumbed
to their injuries within minutes of arriving at the hospital.

The median time before they were pronounced dead: six minutes.

The researchers at one of the nation's most respected medical institutions
concluded that there was little they could do. "The only way to save these
patients is to reach out to them in the community before they are victims of
violence," the study concluded.

That was when one in four shooting victims died; now it's one in three.

On the streets in a number of cities, gunmen have increasingly aimed for the
head. The number of fatal head shots in Milwaukee doubled in 2015 over the year
before, and gunshot victims with three to seven bullet wounds jumped 150
percent.

It has been a clear, long-term trend in Baltimore, with the number of fatal head
shots rising fivefold over the past two decades.

Some criminals are cunning enough to know that more of their targets could be
wearing body armor, said Baltimore police Maj. Donald Bauer. This year, police
seized body armor in multiple drug house raids - something veteran officers said
they haven't seen before.

And in a cruel twist, some shooters are taking into account that Baltimore has
top-notch trauma care, said former police commissioner Anthony Batts. That's why
they aim for the head - to "take the trauma center out of the equation," said
Batts, now a consultant with the AWW Group training police commanders.

Gunmen are pumping more bullets into victims. People shot multiple times made up
less than 60 percent of homicide victims in 2005, the earliest year for which
data is available. That rose to 70 percent by last year.

The Maryland office of the chief medical examiner recently studied homicide
autopsy reports of gunshot victims dating to 2005. About one-third of the
victims died from a single gunshot, and that remained constant over the past
decade. But the number of victims shot five to nine times doubled, as did those
shot 10 or more times. In one case last year, a victim had been shot 38 times.

"I never get a single gunshot wound - never," said Sue Carol Verrillo, nurse
manager of the surgical inpatient care unit at Johns Hopkins Hospital.

Hospitals across the nation, including in Denver and Newark, N.J., have reported
the same trends - the severity of wounds and the sheer number of them
increasingyear by year.

Angela Sauaia, professor of public health, medicine, and surgery at the
University of Colorado's Anschutz Medical Campus, was among a team of
researchers that completed a study in June of patients at a Denver trauma
hospital, comparing chances of survival from various injuries.

Again, they found that gunshot victims stood out for falling behind. Their
fatality rate jumped 6 percent - every two years.

"There are more injuries to treat, so no wonder the case fatality is
increasing," Sauaia said. "That was not the norm 10 years ago."

Doctors couldn't keep up. "We do know there are more bullets, and the injuries
of each bullet are more serious," she said. "The holes are bigger."

Turner-Fordbey, now 24, was one of the lucky ones. Shot 27 times two years ago,
he says he was the victim of "karma" after years of Percocet-popping, drug
dealing, fights and shootouts.

He saw his shooter and believes he was targeted by a rival drug crew over turf.
Turner-Fordbey toyed with the idea of retaliating - gathering his "boys,"
finding the suspect, and shooting him and everyone with him, leaving no
witnesses.

But he says he gave up "the game" to focus on being a father to his four
children. He's relearned how to walk with extensive physical therapy and keeps
the bullet his mother dislodged from his head in a box near his bed.

Still, he isn't about to give up his credibility on the streets.

"I can't be labeled a snitch. I can't be labeled a rat, especially in this
city," he said, explaining why he didn't cooperate with police. "Snitches die."

"Code of the streets, period," he added. "Snitches get stitches. I honor the
street code - the G code. I honored it my whole life. I can't tolerate
snitching. I can't. My body, my mindset won't let me tell."

No one has been arrested in his shooting.

'Rocking you to sleep'

The "code" has many connotations on Baltimore streets. To some it's a "gangster"
or street code that strictly prohibits snitching to police. To others it's a set
of guidelines for when violence is prohibited - no shooting near children or the
elderly, for instance - and when violence is warranted, or even required.

The Black Guerrilla Family, Baltimore's most powerful gang, distributes
typewritten and handwritten rule books to members on the streets and in jail
cells. The militaristic rules dictate that infractions can lead to punishment,
sometimes death, and include protocols for carrying out violence, such as no
shooting near "religious institutions."

Covington, the hit man who says he was an enforcer for the BGF gang, describes
the "golden rules" as nuanced in some ways, clear-cut in others.

You're never supposed to snitch, even on your enemy, he said. And you're not
supposed to target your enemy's "law-abiding citizens" - family members who
aren't in the drug game. But if those relatives are "in the life," he said, they
can be targeted.

Nowadays, however, rules that might have helped to keep a lid on random,
collateral violence are regularly broken, according to law enforcement as well
as community activists and residents.

Davis, the police commissioner, noted that about half of shootings in Baltimore
are carried out in the daytime and most are outside.

Baltimore Homicide Detective Vernon Parker said perpetrators no longer use
darkness "as a mask." They are "more bold," he said, shooting near churches,
schools and other public places.

"People more cold-hearted these days than when I was growing up," said
Turner-Fordbey, the man who survived 27 shots. "Everybody wants to be a killer.
It's more killings going on now because everybody feel like they got to prove
themselves.

"Back in the day, I was told, it was like a kind of rule: The old dudes wouldn't
allow outsiders to come in the 'hood, and everybody respected the women and
children. Now, it's like no respect for nothing. People don't care."

In West Baltimore this summer, shooters opened fire at a church after a funeral
and at a candlelight vigil, both being held for other shooting victims. Six
people were wounded in those attacks. Eight people were shot last weekend in
East Baltimore steps from a makeshift memorial where three weeks earlier a man
died and two women were injured in a triple shooting.

In Chicago, a South Side gang war sparked a series of shootings. Last year's
retaliatory execution of 9-year-old Tyshawn Lee, which became emblematic of the
ruthlessness plaguing that city, led his father this year to shoot the
girlfriend of a suspect in his son's killing, according to police.

The challenge for police is knowing when someone might pull the trigger. Police
departments nationwide have turned to predictive policing to try to understand
who might be the next killer, or next on a hit list.

Chicago police have created the Strategic Subject List, the product of an
algorithm that calculates someone's propensity to become a party to violence. A
person's score is based on previous police contacts and criminal activity, known
affiliations with gang members, social connections or networks, and past
injuries from gunshots or assaults.

Once a person lands on the list, Chicago police make in-person visits to warn of
the "consequences that will result should violent activity continue." Police
hope to reach out to 1,500 people this year.

They make up a fraction of the city's population but take part in an outsized
share of the violence - in the first three months of this year, about
three-quarters of the shooting victims and homicide suspects were already on the
list.

In Baltimore, a similar undertaking has identified 600 "trigger pullers," who
police believe are the most likely to shoot or be shot. People land on the list
for a combination of factors, including a history of violent crime or handgun
violations, parole or probation, involvement in previous gun violence.

Officers monitor them with a "laser focus," said Baltimore police Col. Stanley
Brandford.

In many cities, it's a select club. Suspects and targets often know each other.
They may have been friends, lived on the same the street or even be related.
Many are in the drug trade together. That familiarity allows for face-to-face
disagreements that can end with a trigger pull.

"The distance has closed in a lot of these cases, and now they're up on each
other," said Brandford, who has led the Baltimore police homicide unit two times
in his career. "These guys stay in these neighborhoods. They really don't travel
very far. And the opportunity to get close and do some damage is prevalent in
some of these neighborhoods."

Police say a common tactic shooters use to gain proximity is to work with an
accomplice who knows the target. The accomplice lures the target to an area,
putting the person at ease to ensure a blind-side attack.

In gang parlance, it's known as "rocking you to sleep."

Criminals today know to get close to their target and fire a lot of bullets,
said Stuart Myers, a former police officer who runs OpTac International, which
trains law enforcement in Maryland and elsewhere on weapons and tactics. That's
because most criminals aren't good shots, he said.

Even police officers, who train and are certified, miss their targets more than
they hit them. One study put the average hit rate for officers at less than 30
percent.

"If you're close enough to a target, you could close your eyes and pull the
trigger," Myers said. He estimated that range is within three yards. Then, he
said, "you will hit your target."

Shooters are also reaching for high-caliber guns with large magazines to ensure
they hit their mark, according to advocates working to stem the violence. In
some neighborhoods, friends or drug crews pool money to buy guns, and they
become shared weapons on a given street corner.

Chris Wilson said shooters prefer long magazines, as well as hollow-point
bullets, which expand upon impact, causing greater tissue damage and blood loss.
The "extendos," which carry more bullets, have become "an obsession" in street
culture, he said.

"When you get a gun, you got to put an extended on it. You got to. That's
policy. You got to be official," said Wilson, who grew up in Washington, where
he was in more than a dozen shootouts.

He was sentenced to life in prison at 17 after he shot and killed a man. He
served nearly 15 years and moved to Baltimore, where he started a contracting
company that connects ex-offenders and the unemployed with jobs.

Former Baltimore Deputy Police Commissioner Jerry Rodriguez, who spent the last
few years of his law enforcement career in Baltimore after more than 25 years
with the Los Angeles Police Department, said he was struck by the "level of
determination" among killers in Baltimore. He noted the high number of head
shots.

"I think there's a meaning behind that. I think there's a purpose behind that,"
he said. "It's sending a message, but it's also making sure the outcome is what
they want."

Rodriguez, who works for a company developing technological solutions for police
departments, said he found "a much more personal type of killing in Baltimore" -
a city of 92 square miles - compared to Los Angeles, which sprawls over 470
square miles.

But even on the West Coast, police have noted a shift in shooting dynamics. In
Los Angeles, gangs in the 1990s often carried out drive-by shootings, which
could be indiscriminate and ineffective if the intent was to kill someone in
particular. In the last decade, police said, they've been getting out of the
car.

"You want to kill 'em, not wing 'em," said LAPD Homicide Detective Chris
Barling, describing the mentality of shooters.

Police also note an almost cavalier attitude among killers.

In Baltimore, a gunman caught on video burst into a barbershop in 2013 and
pulled the trigger, but his weapon jammed, so he briefly took a step back, fixed
it and took aim again. A gunman who had just shot a man in the head late last
year did a three-point turn in his car with a nonchalance noted by Davis, the
police commissioner, who said he took his time and "drove away like it was
nobody's business."

Covington, who said in a series of jailhouse interviews with The Sun that he
killed 14 or 15 people and helped in a couple of other hits, explained that he
believes the majority of them deserved to die. They were drug dealers, criminals
- "people just like me," he said.

He does say that he wishes he hadn't targeted one young victim, a teenager.

"But generally speaking, I never really think about it," he said.

Hit men for hire

In the Murphy Homes public housing project in West Baltimore, which has since
been demolished, Covington grew up on the floor above Solothal "Itchy Man"
Thomas, one of the city's most notorious hit men.

Covington said he regularly saw people shot, beaten, killed. He was 8 or 9 when
he saw a man he only knew as "Country Dave" shot to death at the corner of West
Lafayette and Argyle avenues. Dave had been a friend, who gave kids in the
neighborhood dollars to buy snacks at the corner market.

But Covington didn't turn away from the streets, despite dreams of becoming a
boxer or an Orioles baseball player like Cal Ripken Jr. Instead, he sized up one
of two paths available to him and other teens in his neighborhood: drug dealing
or becoming a "cowboy," someone who robs drug dealers.

He chose cowboy.

Covington, now 30 and incarcerated in Westover, Md., can't recall whether the
man shot on his first shooting caper survived but said he could have gone to
jail for his involvement.

As a teen his "neighborhood fame" grew - "I had grown men scared of me" - and as
a man he shifted from random violence to targeted murderousness.

He was paid to kill. He once charged as much as $50,000, he says, but that was a
"package deal." He says that he has worked in Maryland, Virginia, West Virginia
and Ohio.

Covington declined to give details about many of his crimes. Baltimore police
have suspected his involvement in six to 14 homicide cases.

He pleaded guilty to one homicide in Baltimore County. He also pleaded guilty to
his role in two other homicides in the city, but received no additional time in
exchange for his testimony against a co-defendant. He has been acquitted in
another homicide and in one shooting.

"He was the guy that would kill people for money, plain and simple - that's how
he made a living," said Baltimore Homicide Detective Frank Miller, adding that
Covington was part of a clique of gunmen who took murder-for-hire contracts and
robbed drug dealers. "There's been several guys over the years that we've
encountered, that was their thing."

Covington joined the Black Guerrilla Family and intimidated witnesses for the
gang. He said inmates held on homicide charges would call and ask him to visit
witnesses in their cases. Being a friend - "I take friendship very seriously" -
he would oblige.

Sometimes he didn't have to say a word; he would smell their fear, see the sweat
rolling down faces. Other times, he had to say "some pretty hard and nasty
words" to make them think twice about testifying.

"I don't want to say witness tampering, but in hindsight, it's sort of what it
was," Covington said.

The Baltimore Police Department has long struggled with closing homicide cases
because investigations are often stymied by a lack of cooperation from
witnesses. So far this year, police have only closed 35 percent of homicide
cases.

As a killer, Covington says, he took steps to evade capture: He wore a ski mask
and gloves unless he planned to shoot a victim when they were alone in the woods
or in a house - he knew they wouldn't survive to identify him. He lured victims
to him so that he could "control the environment."

Covington, who now says he wants to help young people avoid the life he chose,
was part of an insidious underground world of hit men for hire in Baltimore.

Police say these shooters commit an outsized number of homicides in the city.
They embody an intent to kill that's ingrained in the city's street culture.

In some cases, federal authorities suspect a single hit man in more than 20
homicides going back decades.

In recent months, police said they have been tracking the 10 Grand Club, an
organization of hit men. Officers said they learned about the "club" from
confidential informants but didn't want to jeopardize investigations by
releasing more information.

"It's not hard to shop around for a murder for hire," said Assistant U.S.
Attorney Jim Warwick, who has prosecuted a number of hit men in the city. "They
will do it very quickly with no thought involved. They just need the money, the
weapon, preferably a photograph of the person, if they don't know the person,
and where the person can be found."

The typical fee for a hit in Baltimore is $5,000, which may be split between
trusted accomplices and subcontracted shooters the hit man may call into action,
Warwick said. Some hit men have grown savvy over the years and begun to recruit
"younger, violent and cold-blooded individuals" to do the job for them," he
said.

They are hired to settle an outstanding drug debt, to kill a woman owed child
support or to get back at someone who was perceived to be disrespectful. They
typically aim for the head or fire into their victims repeatedly, Warwick said;
witnesses are considered collateral damage.

"The hit man will kill whoever is with the target as well," Warwick said.
"They're expected to finish the job."

Three cousins who were gang hit men - Kenneth "K Slay" Jones, Donatello "Little
Don" Fenner and David Hunter - rank among Baltimore's most notorious shooters,
police said. They grew up in their grandmother's home, and police said they
provided each other alibis.

"Those are some hit men right there," said Baltimore Homicide Detective Dawnyell
Taylor, who considers working Hunter's case, with its sprawling connections to
victims, shooters and the BGF, to be her "life's work."

Taylor said they are suspected in connection with four to five dozen shootings,
often working in tandem to lure victims and then ambush them. Fenner was shot to
death in 2010. Hunter got two life sentences plus 40 years last year for
shooting a man in the back of the head, and Jones got two life sentences plus 15
years in August for shooting one man and killing another who was rumored to be
cooperating with law enforcement.

Jones' lawyer, Fareed Hayat, denied that his client and Hunter were hit men - he
said they were broke. He questioned whether police have evidence they committed
multiple murders because he hasn't seen it. Both men are appealing their
convictions.

Surveillance video recorded Hunter's hit: walking on a sidewalk in the daytime
and passing his victim, who was headed the other way. That's when prosecutors
said Hunter wheeled around, shot Henry Mills in the head, and fled through
traffic on busy Greenmount Avenue in East Baltimore, near a playground.

Deputy Attorney General Thiru Vignarajah, who prosecuted the case, told jurors
it was a "public execution."

Hours after the killing, surveillance video recorded another scene. Hunter and
fellow gang members gathered in Mund Park, a few yards from where police had
just cleared the crime tape. One man points his finger as if it were the barrel
of a gun at another's head. Another man gives Hunter a high five. Prosecutors
said they were celebrating.

Police worry about the cycle of violence continuing. "I guess the next one's
just, you know, just growing up," said Miller, who investigated Covington.

Pat Brown, a criminal profiler in Maryland, said shooters often develop an
"attachment disorder" during troubled childhoods, so that they have difficulty
forming long-term relationships and often fail to develop a conscience. They
often witness death and violence, becoming numb to it.

"It becomes a survival of the fittest and you lose empathy for others," Brown
said. "They see people as tools, objects and things."

Baltimore streets breed this kind of mindset, she said. "It has gotten out of
control with the lawlessness and hopelessness."

At age 5, Hunter witnessed a man shot in the back of the head. His mother,
fearing retaliation, told him not to snitch, to pretend that he saw nothing,
Vignarajah said at Hunter's sentencing. Hunter would grow up to kill a man the
exact same way.

"Mr. Hunter grew up to become the agent of fear, the angel of death that his
mother warned him of," Vignarajah told jurors.

Mothers march

Across the nation, those left behind are consoling each other. Some are reaching
out to others who have lost loved ones to shootings. Others are getting
organized.

Cheryl Hayes, whose 27-year-old son was shot to death last year as he was headed
to his postal route in Chicago, commiserates with a co-worker whose son was
fatally shot after a dispute at a club. They share pictures of their sons, and
of their tombstones. The Chicago Bulls insignia is carved into Anthony Hayes'
grave marker.

"We should be showing each other baby pictures or wedding photos," said Cheryl
Hayes, 54.

Her family, it seems, is surrounded by gun violence.

Hayes' daughter, Veronika Hayes-Copeland, taught at Harlem Park
Elementary/Middle School in Baltimore in 2006 and watched in horror as students
were killed in street violence and at least one was suspected in a homicide.

At one point, when shooting broke out at a church across from the school,
Hayes-Copeland instinctively ducked while her students ran to the window,
unfazed.

Last month, Hayes' cousin, Gregory Anthony Sims Jr., 25, was shot dead in the
afternoon in Chicago. "Shot him in the leg and he was still running," she said.
"Shot him in the leg again, and then when he fell, shot him five times in the
chest. That's overkill."

She said she wants to become more involved in the mothers' movement against
violence but has yet to find the strength.

Support groups for mothers of slain children are cropping up in Baltimore,
Chicago and cities across the country, and their memberships are growing. Once
an insular crowd, they are becoming more active.

Mothers of Murdered Sons and Daughters in Baltimore plans to set up a booth at
festivals and other events to reach more parents and children.

Organizers are trying to devise novel ways to reach out to children, using toys
and games to teach them to get in touch with their feelings and respond
appropriately to the violence to which they have become desensitized.

They are also trying more explicit ways of drawing attention to gun violence.
This summer, with the help of area funeral homes, the group led a march
alongside 10 empty hearses on North Avenue. Similar marches have been held in
Atlanta, Cleveland and other cities.

Escorted by Baltimore police, the demonstrators stopped several times: at a
school, at a church, at a March Funeral Home. During the long walk, they loaded
their children, hot and tired, into the backs of the hearses, which held coolers
of water.

At each destination, the several dozen marchers stopped and prayed.

They prayed for the people of Baltimore, and they prayed for their sons and
daughters in the hearses - the children they had left.

Baltimore Sun reporter Justin Fenton and intern Wyatt Massey contributed to this
article.

jgeorge@baltsun.com

Twitter.com/justingeorge

LOAD-DATE: October 4, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                    Copyright 2016 The Baltimore Sun Company
                              All Rights Reserved


                               28 of 41 DOCUMENTS


                                  thespec.com

                              May 10, 2016 Tuesday

Surveillance and predictive policing: Welcome to the 'safety state' of tomorrow

SECTION: NEWS

LENGTH: 1367 words


Try to imagine what policing will look like in the future. Microwave heat
cannons and sound bazookas dispersing rowdy crowds? Robocops patrolling the
streets while whirring drones keep watch from the sky?

Or maybe we'll arrive at a world where all crime is wiped away, where people
peacefully coexist in sleeper pods while life is played out through virtual
reality helmets.

Maybe.

The more realistic picture, according to police technology experts, is that
surveillance and the collection and analysis of information will play a central
role in solving and preventing crime.

The public safety regime of tomorrow, in other words, is all about data. "This
is the future of policing," says Christopher Schneider, an associate professor
of sociology at Brandon University in Manitoba.

Cops in the coming decades will gather information online, interact with the
public through social media and even use data gleaned from the Internet and past
crimes to predict and prevent future law-breaking, Schneider says. This is
already happening, to varying degrees, in American cities and places such as
Vancouver and Toronto, where police used a program to comb through Twitter to
gather evidence for a recent online harassment trial.

"Policing as an apparatus is going to be much more mediated, and it's going to
be much more community-oriented than it currently is, through the Internet,
through social media," Schneider says. "This is going to expand the gaze, as it
were, toward crime and deviance."

The nexus between police and the public they serve has already expanded beyond
the traditional 911 call. (If you're even more of a troglodyte, just yell:
"Help! Police!") Ritesh Kotak, a police consultant for agencies in Canada and
overseas, said tools such as social media have created space for the
"co-creating of public safety," with new and convenient avenues to report crimes
and follow police data shared over the Internet.

"That's where it's headed with 'next-generation 911.' That's where it's headed
with the ability to see something and communicate right through our smartphones
with police," Kotak said. "Data is the currency of the future."

With an open data mentality and deeper engagement through social media, Kotak
added, police forces can repair and engender trust with the citizenry. "People
feel like they're part of something," he said.

But data collection can also be used for more futuristic means. Ryan Prox, a
special constable with the Vancouver Police Department, is one of the
pre-eminent experts in the emerging field of "predictive policing." Prox prefers
to call it crime "forecasting," in which police forces use complex computer
programs that churn through mountains of data to try and predict when and where
future crimes will occur.

This has yet to catch on in full force in Canada, but police in cities such as
Los Angeles and Miami have signed on to "predictive" programs designed by
companies such as PredPol, Prox explains. PredPol uses three data points - time,
place and type of crime - to draw up boundaries in which crimes are most likely
to occur, then local police patrol these areas in the hopes of catching the bad
guys.

Prox cautions, however, that little independent scientific research has been
done on these programs in the U.S. and suggests they may not be as accurate as
their makers claim.

That's why he's spearheading a six-month predictive-policing pilot project in
Vancouver, which began Feb. 1, that uses an intricate software program designed
by a team of mathematicians and geospatial engineers. The program sifts through
crime data as far back as March 2001, including the time, place and nature of an
offence, Prox says. But it also considers 60 "non-crime" factors, such as
neighbourhood income, area traffic density, locations of illicit graffiti and
even wind speed, to forecast the probability of a future crime being committed
in the coming hours within a 100-metre radius of a given location.

Plainclothes cops will be dispatched to monitor these areas, with uniformed
officers on standby to make an arrest in the event that a crime is witnessed,
Prox says.

Tests have already shown a 60 to 70 per cent accuracy rate for some property
crimes such as break and enters, which are easiest to predict because they're
high frequency and often involve repeat offenders, Prox says. The more police
use the program, the more data they have and the more accurate officials hope it
can become.

"It sounds really sci-fi goofy," he laughs, "but they basically call it an
'artificial learning neural network.' That's the mathematical model."

The endgame of such programs, Prox says, is maximum police efficiency. In an era
of ballooning police budgets - now more than $1 billion a year in Toronto, for
example - that could be a welcome prospect.

But critics point to controversial information-gathering programs such as
"carding" in Toronto, which many argue disproportionately target visible
minorities. To rely on such practices to fuel computer software programs that
dictate how cops are deployed could entrench existing police biases, Schneider
says.

"Are we going to then be criminalizing certain people, certain segments of the
population? Who are the police going to be looking at?" he asks.

Prox acknowledges this is a legitimate concern, but says the Vancouver police
program only considers data from crime reports and other objective factors. It's
generated by the public rather than fuelled by the cops themselves.

Others have brought forward concerns about how predictive policing will affect
individual rights. Brenda McPhail, director of the Canadian Civil Liberties
Association's Privacy, Technology and Surveillance Project, says the main worry
is that the types of data currently used to forecast crime will expand to
include more personal information - social media posts, online purchase
histories, travel bookings or location data from public Wi-Fi use.

This could not only invade individual privacy, it could erode the presumption of
innocence, McPhail adds, citing court decisions in Canada and the U.S. that have
suggested it is disproportionate to comb through data of many individuals to
find a single criminal.

"The concern is that it is the thin edge of a wedge," she says. "Before any such
programs are implemented, we as a society need to compare the benefits with the
costs, particularly the costs to our rights and civil liberties. We need to
consider the risks."

Such worries go beyond crime-forecasting programs. Some point to privacy issues
in the face of intensifying means of surveillance, such as the extensive camera
networks that are used by police in Fresno, Calif., where police can monitor
live feeds throughout the community through their Real Time Crime Center.

David Lyon, a Queen's University sociologist and head of the school's
Surveillance Studies Centre, has argued that people's lives are being watched to
the point that it already makes sense to label many western countries
"surveillance societies." Lyon is coauthor of a 2014 book on the subject, in
which he and his colleagues argue we're at a "historic turning point" for the
expansion of surveillance measures, developments with obvious consequences for
privacy and state power.

Much of this can be viewed as part of a social shift toward a so-called "safety
state," where more and more government policies - and police actions - are
justified through fear of danger, says Charles Raab, a political science
professor at the University of Edinburgh.

"As long as there are some plausible reasons to think we live in exceptionally
dangerous times" - such as terrorist attacks in big cities - "there will be
public fears and demands for more security and safety," says Raab. "Other
values, such as equality, fairness and the exercise of rights and liberties, are
constrained by the imperative to make everything safe and secure."

This isn't inevitable, Raab says. But with terrorism and climate change
dominating the media and politicians routinely emphasizing this danger in their
quests for votes, safety will continue to be a top social priority.

And that probably means the police of tomorrow will find ways to use our data
and train cameras on us in an effort to keep us safe.

LOAD-DATE: May 10, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                  Copyright 2016 Toronto Star Newspapers, Ltd.
                              All Rights Reserved


                               29 of 41 DOCUMENTS


                     Burbank Leader (Glendale, California)

                     Distributed by Tribune Content Agency

                            June 29, 2016 Wednesday

Morale low, lack of improvement felt within Burbank Police Department, survey
shows

BYLINE: Alene Tchekmedyian, Burbank Leader, Glendale, Calif.

SECTION: STATE AND REGIONAL NEWS

LENGTH: 1203 words


June 29--Staffing shortages, fewer opportunities for job growth and a perception
of bias in promotions and policy enforcement are hampering morale at the Burbank
Police Department, according to the results of a police-union-administered
survey.

The Burbank Police Officers' Assn. last month invited 135 members, including
officers of all ranks, as well as seven recent retirees, to take the survey.
They answered 11 questions, some with multiple parts, and were given space to
write comments.

Roughly half of the 118 participants indicated that they'd considered leaving
the department sometime during the last year, while 60% indicated they were
unlikely or extremely unlikely to recommend a career with the agency to their
children, relatives or friends.

About 75% indicated that morale was low, or extremely low, with one member
calling the department a "depressing" place to work, while another wrote that
"pretty much everyone dreads going to work."

Meanwhile, 73% of participants disagreed or strongly disagreed that the agency
has improved its level of service to the community over the last five years.

The goal of the survey, union leaders said, was to identify problems and work
with management to improve working conditions.

Burbank Police Chief Scott LaChasse said in emails Tuesday it would be premature
to comment on the survey without first engaging in "good faith discussions" with
the union, but pointed to the department's 2011 strategic plan, which focused on
changes to ensure officer safety, reduce liability issues and guarantee ethical
behavior.

"The process of cultural change is proceeding and the objectives are being
achieved," LaChasse wrote.

To boost morale, dozens of members who completed the survey advocated that the
agency hire more officers, increase specialty assignments, improve leadership at
the top and rely less on predictive policing technology, which analyzes crime
reports to predict potential problem areas.

Patrol officers are required to spend 15 minutes each in up to three areas
during their 12-hour-and-20-minute shifts.

Critics of the system say that the algorithm sometimes zeroes in on obvious
areas, like the Empire Center, where officers already know there's retail crime,
or silly ones, like the police station, where people often show up to report
crimes.

But top cops say police visibility in the areas helps deter crime.

"When it's adhered to, it shows efficacy in terms of lowering crime," said Capt.
Denis Cremins. "Our No. 1 functional objective is to prevent crime; it's not to
arrest people. You try to prevent it or deter it -- this is just a sophisticated
way of doing it."

In terms of hiring, the agency has made progress filling vacancies and
recruiting diverse candidates to join the force.

Several months into a two-year recruitment plan that involves offering more
testing cycles, attending more recruiting events and targeting military
personnel, the agency has hired five recruits and two police officers, raising
the number of filled sworn positions to 152 of 160.

Within that group, one recruit is Armenian, another is Latino and a third is
black, according to Lt. Eric Deroian, who oversees recruitment. One of them is
also female.

But it'll be awhile before officers feel the additional manpower on the street.
Two of the recruits will graduate the academy in November, the other three in
January. Meanwhile, about a couple dozen officers are eligible to retire.

"When you have low morale, if people aren't happy, that could accelerate, could
affect the retention level," said Sgt. Sean Kelley, a union board member. "The
hiring happening now may not keep up with the people that are leaving in the
future."

Less than a quarter of survey respondents felt that promotions, special
assignment appointments and personnel investigations were handled fairly, while
just 11% felt that department policies were enforced fairly to all ranks.

"We are now in a society that doesn't support police and have a command staff
that will be quick to crush us for any mistake," one participant wrote. "What
motivation is there for me to go out there and place myself in a situation that
could jeopardize mine and my (family's) future."

Police sources supportive of changes made by the current administration disputed
concerns over perceived fairness, while noting that officers are paid well -- a
new contract approved earlier this year involved salary increases -- have access
to working equipment and are supported by the community.

"If I was being investigated now, I would feel comfortable with the
investigation," said one sworn employee, who asked not to be named. "If I was
being investigated with the prior administration, I would be scared to death."

Join the conversation on Facebook >>

Some in the agency feel handcuffed by what they called overly restrictive
policies, including those involving use of force, as well as foot and vehicle
pursuits, but others say those policies are based on best practices in a
changing law enforcement culture.

"Very few agencies now are allowing you to go on a wild pursuit over something
as minimal as a red light violation," said the officer who asked for anonymity.
"There is a probability that someone will crash at a high rate of speed, and
someone -- suspect, officer, bystander -- may be hurt or killed over a traffic
violation that if it's their first time, they can go to traffic school. Is that
really worth it?"

The survey results were critical of the agency's leadership, which consists
mostly of Los Angeles Police Department veterans brought to the helm in 2010 to
reform a department reeling from allegations of police brutality as well as
racism and sexual harassment within its ranks.

Tensions flared recently after the Burbank Leader published emails forwarded in
2012 and 2013 by a key member of LaChasse's reform team that contained
stereotypes of Muslims, blacks, Latinos, women and others.

Former Deputy Chief Tom Angel left the Burbank force last year to return to the
Los Angeles County Sheriff's Department, where he'd previously spent 33 years.
In May, he resigned his post as Sheriff Jim McDonnell's chief of staff in the
wake of the email scandal after numerous civil rights advocates called on him to
step down.

Union leaders criticized how LaChasse handled the discovery of the emails in
2014, which was part of what prompted the survey. Concerns over staffing
shortages, morale and policies also played a role.

The survey results echoed concerns raised in a smaller-scale survey conducted
early last year by the Center for Public Safety Management, which drew responses
from 82 officers.

According to the 2015 report, sworn employees complained about staffing
deficiencies, low morale and poor communication by higher ups.

Alene Tchekmedyian, alene.tchekmedyian@latimes.com

Twitter: @atchek

MORE CRIME & PUBLIC SAFETY

Man dies after exchanging gunfire with Burbank police, then shooting himself

Lifeguard accused of secretly recording girls and women in locker room pleads
not guilty

Local detectives seize weapons, make arrests during gang-enforcement effort

___ (c)2016 the Burbank Leader (Glendale, Calif.) Visit the Burbank Leader
(Glendale, Calif.) at www.burbankleader.com Distributed by Tribune Content
Agency, LLC.

LOAD-DATE: June 29, 2016

LANGUAGE: ENGLISH

ACC-NO:
20160629-1BU-Morale-low-lack-of-improvement-felt-within-Burbank-Police-Departmen
t-survey-shows-0629-20160629

PUBLICATION-TYPE: Newspaper

JOURNAL-CODE: 1BU


                         Copyright 2016 Burbank Leader


                               30 of 41 DOCUMENTS


                                The Toronto Star

                              May 7, 2016 Saturday

To serve, protect, watch and predict;
Experts see data-driven forecasts and surveillance as key pillars of tomorrow's
police 'safety state'

SECTION: GREATER TORONTO; Pg. GT1

LENGTH: 1361 words


Try to imagine what policing will look like in the future. Microwave heat
cannons and sound bazookas dispersing rowdy crowds? Robocops patrolling the
streets while whirring drones keep watch from the sky?

Or maybe we'll arrive at a world where all crime is wiped away, where people
peacefully coexist in sleeper pods while life is played out through virtual
reality helmets.

Maybe.

The more realistic picture, according to police technology experts, is that
surveillance and the collection and analysis of information will play a central
role in solving and preventing crime.

The public safety regime of tomorrow, in other words, is all about data. "This
is the future of policing," says Christopher Schneider, an associate professor
of sociology at Brandon University in Manitoba.

Cops in the coming decades will gather information online, interact with the
public through social media and even use data gleaned from the Internet and past
crimes to predict and prevent future law-breaking, Schneider says. This is
already happening, to varying degrees, in American cities and places such as
Vancouver and Toronto, where police used a program to comb through Twitter to
gather evidence for a recent online harassment trial.

"Policing as an apparatus is going to be much more mediated, and it's going to
be much more community-oriented than it currently is, through the Internet,
through social media," Schneider says. "This is going to expand the gaze, as it
were, toward crime and deviance."

The nexus between police and the public they serve has already expanded beyond
the traditional 911 call. (If you're even more of a troglodyte, just yell:
"Help! Police!") Ritesh Kotak, a police consultant for agencies in Canada and
overseas, said tools such as social media have created space for the
"co-creating of public safety," with new and convenient avenues to report crimes
and follow police data shared over the Internet.

"That's where it's headed with 'next-generation 911.' That's where it's headed
with the ability to see something and communicate right through our smartphones
with police," Kotak said. "Data is the currency of the future."

With an open data mentality and deeper engagement through social media, Kotak
added, police forces can repair and engender trust with the citizenry. "People
feel like they're part of something," he said.

But data collection can also be used for more futuristic means.

Ryan Prox, a special constable with the Vancouver Police Department, is one of
the pre-eminent experts in the emerging field of "predictive policing." Prox
prefers to call it crime "forecasting," in which police forces use complex
computer programs that churn through mountains of data to try and predict when
and where future crimes will occur.

This has yet to catch on in full force in Canada, but police in cities such as
Los Angeles and Miami have signed on to "predictive" programs designed by
companies such as PredPol, Prox explains. PredPol uses three data points - time,
place and type of crime - to draw up boundaries in which crimes are most likely
to occur, then local police patrol these areas in the hopes of catching the bad
guys.

Prox cautions, however, that little independent scientific research has been
done on these programs in the U.S. and suggests they may not be as accurate as
their makers claim.

That's why he's spearheading a six-month predictive-policing pilot project in
Vancouver, which began Feb. 1, that uses an intricate software program designed
by a team of mathematicians and geospatial engineers. The program sifts through
crime data as far back as March 2001, including the time, place and nature of an
offence, Prox says.

But it also considers 60 "non-crime" factors, such as neighbourhood income, area
traffic density, locations of illicit graffiti and even wind speed, to forecast
the probability of a future crime being committed in the coming hours within a
100-metre radius of a given location.

Plainclothes cops will be dispatched to monitor these areas, with uniformed
officers on standby to make an arrest in the event that a crime is witnessed,
Prox says.

Tests have shown a 60 to 70-per-cent accuracy rate for some property crimes such
as break and enters, which are easiest to predict as they're high frequency and
often involve repeat offenders, Prox says. The more police use the program, the
more data they have and the more accurate officials hope it can become.

"It sounds really sci-fi goofy," he laughs, "but they basically call it an
'artificial learning neural network.' That's the mathematical model."

The endgame of such programs, Prox says, is maximum efficiency. In an era of
ballooning police budgets - now more than $1 billion a year in Toronto - that
could be a welcome prospect.

But critics point to controversial information-gathering programs such as
"carding" in Toronto, which many argue disproportionately target visible
minorities. To rely on such practices to fuel computer software programs that
dictate how cops are deployed could entrench existing police biases, Schneider
says.

"Are we going to then be criminalizing certain people, certain segments of the
population? Who are the police going to be looking at?" he asks.

Prox acknowledges this is a legitimate concern, but says the Vancouver police
program only considers data from crime reports and other objective factors. It's
generated by the public rather than fuelled by the cops themselves.

Others have brought forward concerns about how predictive policing will affect
individual rights. Brenda McPhail, director of the Canadian Civil Liberties
Association's Privacy, Technology and Surveillance Project, says the main worry
is that the types of data currently used to forecast crime will expand to
include more personal information - social media posts, online purchase
histories, travel bookings or location data from public Wi-Fi use.

This could not only invade individual privacy, it could erode the presumption of
innocence, McPhail adds, citing court decisions in Canada and the U.S. that have
suggested it is disproportionate to comb through data of many individuals to
find a single criminal.

"The concern is that it is the thin edge of a wedge," she says. "Before any such
programs are implemented, we as a society need to compare the benefits with the
costs, particularly the costs to our rights and civil liberties. We need to
consider the risks."

Such worries go beyond crime-forecasting programs. Some point to privacy issues
in the face of intensifying means of surveillance, such as the extensive camera
networks that are used by police in Fresno, Calif., where police can monitor
live feeds throughout the community through their Real Time Crime Center.

David Lyon, a Queen's University sociologist and head of the school's
surveillance studies centre, has argued that people's lives are being watched to
the point that it already makes sense to label many western countries
"surveillance societies." Lyon is co-author of a 2014 book on the subject, in
which he and his colleagues argue we're at a "historic turning point" for the
expansion of surveillance measures, developments with obvious consequences for
privacy and state power.

Much of this can be viewed as part of a social shift toward a so-called "safety
state," where more and more government policies - and police actions - are
justified through fear of danger, says Charles Raab, a political science
professor at the University of Edinburgh.

"As long as there are some plausible reasons to think we live in exceptionally
dangerous times" - such as terrorist attacks in big cities - "there will be
public fears and demands for more security and safety," says Raab. "Other
values, such as equality, fairness and the exercise of rights and liberties, are
constrained by the imperative to make everything safe and secure."

This isn't inevitable, Raab says. But with terrorism and climate change
dominating the media and politicians routinely emphasizing this danger in their
quests for votes, safety will continue to be a top social priority.

And that probably means the police of tomorrow will find ways to use our data
and train cameras on us in an effort to keep us safe.

LOAD-DATE: May 7, 2016

LANGUAGE: ENGLISH

DOCUMENT-TYPE: COLUMN

PUBLICATION-TYPE: NEWSPAPER


                 Copyright 2016 Toronto Star Newspapers Limited


                               31 of 41 DOCUMENTS


                                The Toronto Star

                              May 7, 2016 Saturday

To serve, protect, watch and predict;
Experts see data-driven forecasts and surveillance as key pillars of tomorrow's
police 'safety state'

SECTION: GREATER TORONTO; Pg. GT1

LENGTH: 1361 words


Try to imagine what policing will look like in the future. Microwave heat
cannons and sound bazookas dispersing rowdy crowds? Robocops patrolling the
streets while whirring drones keep watch from the sky?

Or maybe we'll arrive at a world where all crime is wiped away, where people
peacefully coexist in sleeper pods while life is played out through virtual
reality helmets.

Maybe.

The more realistic picture, according to police technology experts, is that
surveillance and the collection and analysis of information will play a central
role in solving and preventing crime.

The public safety regime of tomorrow, in other words, is all about data. "This
is the future of policing," says Christopher Schneider, an associate professor
of sociology at Brandon University in Manitoba.

Cops in the coming decades will gather information online, interact with the
public through social media and even use data gleaned from the Internet and past
crimes to predict and prevent future law-breaking, Schneider says. This is
already happening, to varying degrees, in American cities and places such as
Vancouver and Toronto, where police used a program to comb through Twitter to
gather evidence for a recent online harassment trial.

"Policing as an apparatus is going to be much more mediated, and it's going to
be much more community-oriented than it currently is, through the Internet,
through social media," Schneider says. "This is going to expand the gaze, as it
were, toward crime and deviance."

The nexus between police and the public they serve has already expanded beyond
the traditional 911 call. (If you're even more of a troglodyte, just yell:
"Help! Police!") Ritesh Kotak, a police consultant for agencies in Canada and
overseas, said tools such as social media have created space for the
"co-creating of public safety," with new and convenient avenues to report crimes
and follow police data shared over the Internet.

"That's where it's headed with 'next-generation 911.' That's where it's headed
with the ability to see something and communicate right through our smartphones
with police," Kotak said. "Data is the currency of the future."

With an open data mentality and deeper engagement through social media, Kotak
added, police forces can repair and engender trust with the citizenry. "People
feel like they're part of something," he said.

But data collection can also be used for more futuristic means.

Ryan Prox, a special constable with the Vancouver Police Department, is one of
the pre-eminent experts in the emerging field of "predictive policing." Prox
prefers to call it crime "forecasting," in which police forces use complex
computer programs that churn through mountains of data to try and predict when
and where future crimes will occur.

This has yet to catch on in full force in Canada, but police in cities such as
Los Angeles and Miami have signed on to "predictive" programs designed by
companies such as PredPol, Prox explains. PredPol uses three data points - time,
place and type of crime - to draw up boundaries in which crimes are most likely
to occur, then local police patrol these areas in the hopes of catching the bad
guys.

Prox cautions, however, that little independent scientific research has been
done on these programs in the U.S. and suggests they may not be as accurate as
their makers claim.

That's why he's spearheading a six-month predictive-policing pilot project in
Vancouver, which began Feb. 1, that uses an intricate software program designed
by a team of mathematicians and geospatial engineers. The program sifts through
crime data as far back as March 2001, including the time, place and nature of an
offence, Prox says.

But it also considers 60 "non-crime" factors, such as neighbourhood income, area
traffic density, locations of illicit graffiti and even wind speed, to forecast
the probability of a future crime being committed in the coming hours within a
100-metre radius of a given location.

Plainclothes cops will be dispatched to monitor these areas, with uniformed
officers on standby to make an arrest in the event that a crime is witnessed,
Prox says.

Tests have shown a 60 to 70-per-cent accuracy rate for some property crimes such
as break and enters, which are easiest to predict as they're high frequency and
often involve repeat offenders, Prox says. The more police use the program, the
more data they have and the more accurate officials hope it can become.

"It sounds really sci-fi goofy," he laughs, "but they basically call it an
'artificial learning neural network.' That's the mathematical model."

The endgame of such programs, Prox says, is maximum efficiency. In an era of
ballooning police budgets - now more than $1 billion a year in Toronto - that
could be a welcome prospect.

But critics point to controversial information-gathering programs such as
"carding" in Toronto, which many argue disproportionately target visible
minorities. To rely on such practices to fuel computer software programs that
dictate how cops are deployed could entrench existing police biases, Schneider
says.

"Are we going to then be criminalizing certain people, certain segments of the
population? Who are the police going to be looking at?" he asks.

Prox acknowledges this is a legitimate concern, but says the Vancouver police
program only considers data from crime reports and other objective factors. It's
generated by the public rather than fuelled by the cops themselves.

Others have brought forward concerns about how predictive policing will affect
individual rights. Brenda McPhail, director of the Canadian Civil Liberties
Association's Privacy, Technology and Surveillance Project, says the main worry
is that the types of data currently used to forecast crime will expand to
include more personal information - social media posts, online purchase
histories, travel bookings or location data from public Wi-Fi use.

This could not only invade individual privacy, it could erode the presumption of
innocence, McPhail adds, citing court decisions in Canada and the U.S. that have
suggested it is disproportionate to comb through data of many individuals to
find a single criminal.

"The concern is that it is the thin edge of a wedge," she says. "Before any such
programs are implemented, we as a society need to compare the benefits with the
costs, particularly the costs to our rights and civil liberties. We need to
consider the risks."

Such worries go beyond crime-forecasting programs. Some point to privacy issues
in the face of intensifying means of surveillance, such as the extensive camera
networks that are used by police in Fresno, Calif., where police can monitor
live feeds throughout the community through their Real Time Crime Center.

David Lyon, a Queen's University sociologist and head of the school's
surveillance studies centre, has argued that people's lives are being watched to
the point that it already makes sense to label many western countries
"surveillance societies." Lyon is co-author of a 2014 book on the subject, in
which he and his colleagues argue we're at a "historic turning point" for the
expansion of surveillance measures, developments with obvious consequences for
privacy and state power.

Much of this can be viewed as part of a social shift toward a so-called "safety
state," where more and more government policies - and police actions - are
justified through fear of danger, says Charles Raab, a political science
professor at the University of Edinburgh.

"As long as there are some plausible reasons to think we live in exceptionally
dangerous times" - such as terrorist attacks in big cities - "there will be
public fears and demands for more security and safety," says Raab. "Other
values, such as equality, fairness and the exercise of rights and liberties, are
constrained by the imperative to make everything safe and secure."

This isn't inevitable, Raab says. But with terrorism and climate change
dominating the media and politicians routinely emphasizing this danger in their
quests for votes, safety will continue to be a top social priority.

And that probably means the police of tomorrow will find ways to use our data
and train cameras on us in an effort to keep us safe.

LOAD-DATE: May 7, 2016

LANGUAGE: ENGLISH

DOCUMENT-TYPE: COLUMN

PUBLICATION-TYPE: NEWSPAPER


                 Copyright 2016 Toronto Star Newspapers Limited


                               32 of 41 DOCUMENTS


                               The New York Times

                              June 26, 2016 Sunday
                              Late Edition - Final

A.I.'s White Guy Problem

BYLINE: By KATE CRAWFORD.

Kate Crawford is a principal researcher at Microsoft and co-chairwoman of a
White House symposium on society and A.I.

SECTION: Section SR; Column 0; Sunday Review Desk; OPINION; Pg. 11

LENGTH: 982 words


ACCORDING to some prominent voices in the tech world, artificial intelligence
presents a looming existential threat to humanity: Warnings by luminaries like
Elon Musk and Nick Bostrom about ''the singularity'' -- when machines become
smarter than humans -- have attracted millions of dollars and spawned a
multitude of conferences.

But this hand-wringing is a distraction from the very real problems with
artificial intelligence today, which may already be exacerbating inequality in
the workplace, at home and in our legal and judicial systems. Sexism, racism and
other forms of discrimination are being built into the machine-learning
algorithms that underlie the technology behind many ''intelligent'' systems that
shape how we are categorized and advertised to.

Take a small example from last year: Users discovered that Google's photo app,
which applies automatic labels to pictures in digital photo albums, was
classifying images of black people as gorillas. Google apologized; it was
unintentional.

But similar errors have emerged in Nikon's camera software, which misread images
of Asian people as blinking, and in Hewlett-Packard's web camera software, which
had difficulty recognizing people with dark skin tones.

This is fundamentally a data problem. Algorithms learn by being fed certain
images, often chosen by engineers, and the system builds a model of the world
based on those images. If a system is trained on photos of people who are
overwhelmingly white, it will have a harder time recognizing nonwhite faces.

A very serious example was revealed in an investigation published last month by
ProPublica. It found that widely used software that assessed the risk of
recidivism in criminals was twice as likely to mistakenly flag black defendants
as being at a higher risk of committing future crimes. It was also twice as
likely to incorrectly flag white defendants as low risk.

The reason those predictions are so skewed is still unknown, because the company
responsible for these algorithms keeps its formulas secret -- it's proprietary
information. Judges do rely on machine-driven risk assessments in different ways
-- some may even discount them entirely -- but there is little they can do to
understand the logic behind them.

Police departments across the United States are also deploying data-driven
risk-assessment tools in ''predictive policing'' crime prevention efforts. In
many cities, including New York, Los Angeles, Chicago and Miami, software
analyses of large sets of historical crime data are used to forecast where crime
hot spots are most likely to emerge; the police are then directed to those
areas.

At the very least, this software risks perpetuating an already vicious cycle, in
which the police increase their presence in the same places they are already
policing (or overpolicing), thus ensuring that more arrests come from those
areas. In the United States, this could result in more surveillance in
traditionally poorer, nonwhite neighborhoods, while wealthy, whiter
neighborhoods are scrutinized even less. Predictive programs are only as good as
the data they are trained on, and that data has a complex history.

Histories of discrimination can live on in digital platforms, and if they go
unquestioned, they become part of the logic of everyday algorithmic systems.
Another scandal emerged recently when it was revealed that Amazon's same-day
delivery service was unavailable for ZIP codes in predominantly black
neighborhoods. The areas overlooked were remarkably similar to those affected by
mortgage redlining in the mid-20th century. Amazon promised to redress the gaps,
but it reminds us how systemic inequality can haunt machine intelligence.

And then there's gender discrimination. Last July, computer scientists at
Carnegie Mellon University found that women were less likely than men to be
shown ads on Google for highly paid jobs. The complexity of how search engines
show ads to internet users makes it hard to say why this happened -- whether the
advertisers preferred showing the ads to men, or the outcome was an unintended
consequence of the algorithms involved.

Regardless, algorithmic flaws aren't easily discoverable: How would a woman know
to apply for a job she never saw advertised? How might a black community learn
that it were being overpoliced by software?

We need to be vigilant about how we design and train these machine-learning
systems, or we will see ingrained forms of bias built into the artificial
intelligence of the future.

Like all technologies before it, artificial intelligence will reflect the values
of its creators. So inclusivity matters -- from who designs it to who sits on
the company boards and which ethical perspectives are included. Otherwise, we
risk constructing machine intelligence that mirrors a narrow and privileged
vision of society, with its old, familiar biases and stereotypes.

If we look at how systems can be discriminatory now, we will be much better
placed to design fairer artificial intelligence. But that requires far more
accountability from the tech community. Governments and public institutions can
do their part as well: As they invest in predictive technologies, they need to
commit to fairness and due process.

While machine-learning technology can offer unexpected insights and new forms of
convenience, we must address the current implications for communities that have
less power, for those who aren't dominant in elite Silicon Valley circles.

Currently the loudest voices debating the potential dangers of superintelligence
are affluent white men, and, perhaps for them, the biggest threat is the rise of
an artificially intelligent apex predator.

But for those who already face marginalization or bias, the threats are here.

Follow The New York Times Opinion section on Facebook and Twitter (@NYTOpinion),
and sign up for the Opinion Today newsletter.




URL:
http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-
guy-problem.html

LOAD-DATE: June 26, 2016

LANGUAGE: ENGLISH

DOCUMENT-TYPE: Op-Ed

PUBLICATION-TYPE: Newspaper


                   Copyright 2016 The New York Times Company


                               33 of 41 DOCUMENTS


                           Canberra Times (Australia)

                              May 22, 2016 Sunday
                                 Final Edition

Think of the crime, do the time

BYLINE: The Canberra Times

SECTION: A; Pg. A017

LENGTH: 2804  words


Hands-on experience: Tom Cruise in Steven Spielberg's 2002 film Minority Report.

Think of the crime, do the time Can technology catch terrorists before they
strike? Paul Biegler reports.

CONTINUED PAGE 19 The P300 spikes were big enough to nab all 12 "culprits".

I n our society, we have no major crimes," says Police Commissioner Anderton in
Philip K. Dick's 1950s classic Minority Report, "but we do have a detention camp
full of would-be criminals."

In the dystopian science fiction story (that became a Hollywood blockbuster
starring Tom Cruise), crimes are predicted by a trio of "pre-cog mutants" so
that officers from "Pre-Crime" can step in to detain aspirational felons before
they strike.

Now a test for "guilty knowledge" being scrutinised by Australian
counter-terrorism experts could bring "Pre-Crime" a step closer to real world
policing.

The technology on which the test is based has been widely researched and
performs well in the lab. But the commercial version, dubbed "Brain
Fingerprinting", is dogged by claims that its creator, a Harvard- trained
neuroscientist, has oversold it. And even if its scientific bona fides are
established, legal experts are worried that acting on the test's findings could
threaten the very pillars of our criminal justice system.

The basic technique is, in fact, relatively uncontroversial, with a scientific
pedigree that has chalked up over a thousand peer-reviewed articles. The "P300
Concealed Information Test" uses EEG to measure brain waves (with headgear
reminiscent of one of those 1950s floral bathing caps).

It exploits the fact that when people recognise things meaningful to them among
miscellaneous bric- a-brac, their EEG blips with a "P" wave, like the Matterhorn
sprouting from the Alps, roughly 300 milliseconds later.

In an era of heightened fears of terrorism, and the difficulty of policing "lone
wolves" and covertly radicalised youths, it's not hard to see why P300 has law
enforcement all a-quiver.

Say John or Jane Doe has been scrolling through a document titled "how to make
an improvised explosive device" and is invited to a fireside chat at Constable
Plod's.

Plod could apply the bathing cap, sit Doe in front of a computer and show him or
her the terror title among irrelevant others such as "how to avoid huge ships"
or "why cats paint".

Unless Doe has very niche literary tastes, the IED guide should provoke a
distinctive peak.

P300 differs from traditional "question and answer" lie- detection in that it
doesn't rely on the fight-or-flight nervous system to moisten palms and quicken
pulses - signs some experts say catch lies with an accuracy little better than
chance. And because EEG independently detects whether a suspect recognises
dubious material, P300 does not rely on people answering questions they would
rather not answer.

But its potential as a conduit to the nefarious plans of would-be terrorists
really took off with the release of a 2011 study that had psychology students
turn jihadist for a day.

The faux insurgents were asked to hatch a mock terrorist plot by selecting one
of four dates in July, one of four locations in Houston and one of four types of
bomb, then jot it all down in a letter to their terrorist boss.

EEG caps on, they were later shown a slew of months of the year, US cities and
varieties of terror attack on a computer; and when "July", "Houston" and "bomb"
appeared among them, the P300 spikes were big enough to nab all 12 "culprits".

But while the results were promising, they didn't provide the fine-grained
detail needed to foil an actual terror strike.

However, Professor Peter Rosenfeld from the Department of Psychology at
Northwestern University, a co-author on the study, says recent research shows a
related technique called "searching CIT" might narrow things down.

If, for example, authorities know Houston is the target, they could show
suspects a map of the city, divide it into quadrants, then sequentially ask if
the attack were planned in each.

"When they recognise the quadrant they'll show the biggest P300. Then you take
that quadrant and break it down into quadrants, and so on, until you get it down
to a specific neighbourhood," says Rosenfeld, who has been studying this field
for decades.

But there's a further obstacle to its adoption by justice departments: If P300
results are to be admitted as evidence in a US court they must satisfy the
Daubert standard, which demands not just scientific credibility in the lab but
also a "known error rate" in the field.

After years of arm-twisting, Rosenfeld is on the cusp of running a study at a
major United States airport that will step baggage handlers off the line and ask
them to load pistols into a distinctive suitcase (aviation authorities have been
understandably reluctant to take part).

Then they'll use the P300 to see if the suitcase, presented on a computer screen
with a duffle bag, attache case, backpack and other assorted luggage, generates
that "guilty" spike.

Law enforcement agencies will be watching the results intently as the pressure
mounts to thwart terrorism at the planning stage, fuelled by the recent attacks
in Paris, Brussels and Lahore.

And tougher Australian terror laws are likely to impel police deeper into the
world of pre-crime and this emerging technology.

It is already an offence to plan or prepare for a terrorist act, even if the act
never happens. And legislation passed by the NSW government in May extends the
time a suspected terrorist can be held without charge from four to 14 days, with
the approval of a judge.

Each state and territory has separate laws allowing police to hold terror
suspects for up to 14 days under a preventative detention order (PDO).

But the February review of commonwealth counter-terrorism laws recommends
ditching the requirement that any attack be deemed "imminent" - likely to happen
within 14 days - before a PDO can be issued.

In this new world of preventive justice, the prospect of a little scientific
help is tantalising. Enter Brain Fingerprinting, a variant of the P300 test
called "P300 MERMER" that swaps bathing caps for sleek headsets and has been
commercially available in Australia for 12 months through the biometrics company
Fingerscan.

Fingerscan general manager Peter Ives says Brain Fingerprinting has been
demonstrated to the NSW and Queensland police forces and to "agencies involved
with counter- terrorism" but, without their consent, he is not prepared to
comment on their responses.

The P300 MERMER patent holder is Dr Larry Farwell, a Harvard graduate with a
doctorate in biological psychology, who was nominated by TIME magazine in 2001
as one of 100 "Innovators Who May Be the Picassos or the Einsteins of the 21st
Century".

Like Rosenfeld, Farwell has researched in the field for decades.

But Farwell's P300 MERMER has made it into the courtroom; in a cold case where a
suspected murderer was ultimately convicted and in a separate case where a
person wrongly convicted of murder was exonerated.

However, the degree to which P300 MERMER evidence was relied upon and whether it
was definitively ruled admissible is unclear. And Farwell's version of the P300
test has its detractors, who dispute that the P300 MERMER differs sufficiently
from the standard test to warrant claims of near infallibility.

A 2013 article in Cognitive Neurodynamics criticised small sample sizes and a
paucity of peer review in studies cited by Farwell to support his claim that
brain fingerprinting is 100 per cent accurate. Those authors said: "Farwell's
finding of 100 per cent accuracy stands in sharp contrast with the available
literature", and concluded he was "misleading and misrepresents the scientific
status of brain fingerprinting technology".

Farwell vigorously rejected those charges in the same journal and in an email to
Fairfax Media says: "Peer-reviewed, published research at the FBI, CIA, and US
Navy has shown that all studies that meet the brain fingerprinting scientific
standards have produced less than 1 per cent error rate (in fact, 0 per cent
error rate / 100 per cent accuracy)".

But while the role of P300 in crime or pre-crime fighting awaits the due
diligence of authorities, other technologies are firming in the race to detect
concealed knowledge.

Dr Jesse Rissman, Assistant Professor at the Integrative Centre for Learning and
Memory at the University of California, Los Angeles, published a study in April
that used MRI scans to, similarly, detect recognition of recent events.

Participants wore a small digital camera around the neck that was programmed to
snap thousands of shots of everyday life for three weeks - studying, eating out,
hiking and sports (there was an "off" button for private moments).

At the end, subjects were put in an MRI scanner and shown their own snapshots
interspersed with photos from the lives of other participants. As people twigged
to their own life shots, the MRI lit up with a distinctive "neural signature" of
recognition that was accurate to near perfection.

"Some might take results like ours to indicate that MRI scans could soon be used
as a forensic tool to detect whether any individual, including people who might
be engaged in criminal Think of the crime, do the time: Technology catching out
terrorists Pre-crime ... may promote the terrorism it sets out to prevent.

FROM PAGE 17 activities, has memory for certain crime-relevant details," Rissman
says. Indeed, US company No Lie MRI claims its brain scan technology is able to
"objectively measure intent, prior knowledge and deception" with an accuracy of
93 per cent.

Rissman is cautious, however, pointing out that canny folk can forge a neural
signature of non- recognition if so inclined. He co- authored a 2015 study that
got subjects to game the system when looking at photos of faces they recognised
by training their attention on the picture's technical features, such as the
exposure, lighting and line edges.

The MRI brain signature of recognition was duly wiped, leaving the door ajar for
shrewd operators to evade the test in the real world - just as people can
deceive existing lie-detectors. But smoothing technical glitches might not be
the biggest challenge for predictive policing.

Lucia Zedner, co-author of the 2014 book Preventive Justice and professor in the
law faculties of the University of Oxford and UNSW, argues that crime detection
with this type of technology may threaten the very tenets of our criminal
justice system.

She says the law has recognised various incarnations of pre-crime for some time:
attempts, incitement and conspiracy to commit a crime are all offences even if
the crime never happens.

Nonetheless, she says, these each involve a clear act of planning.

But some terrorism laws shift the offence to the earlier, fuzzier, pre-crime
phase of "preparation" with the aim of heading off terrorism "further up the
field".

While P300 cannot measure intent or ascribe guilt on its own, it is conceivable
that "preparation" might one day be inferred from brain data, such as a P300
spike of recognition to an IED how-to guide. But Zedner has a big problem with
any scenario that criminalises thoughts alone.

"Where is the harm? I can sit in my office and think evil thoughts about people
all I like, but providing I do nothing about those thoughts there is no harm.
And to that extent the harm principle, which underpins the whole basis of
criminalisation, is not satisfied," Zedner says.

The harm comes, Zedner says, only when the intent is communicated - think a text
to a terrorist colleague with a link to the IED guide - and then the law has its
"guilty act" upon which criminal proceedings might proceed. She concedes that
colleagues argue the legal emphasis on communicating evil intent is not just
because spreading the word makes harm more likely. It has until now been the
only way of knowing what a person is thinking - a truism neuroscience is
challenging.

Monash University Professor of Criminology Jude McCulloch, who released her
co-authored book Pre-Crime: Pre-Emption, Precaution and the Future last year,
takes an even dimmer view of pre-crime.

"I think it is a false idea that pre- crime prevents crime. In fact, I would go
so far as to say that pre- crime creates crime," McCulloch says. "Pre-crimes are
essentially crimes that it is believed people are thinking about doing. When
someone is convicted because it is believed they are going to commit a crime, it
[is] as if that crime has already occurred. It produces the spectre of crime,"
she says.

Worse, McCulloch's analysis of pre-crime suggests it may promote the very
terrorism it sets out to prevent: "Pre-crime prosecutions very much focus on the
political and religious ideology of the person. And if you target a whole
community, some people find it difficult to get over the feeling they are being
persecuted. People go underground and become more dangerous," she says. "People
are being convicted for their beliefs rather than their behaviour. This picks up
on [Philip K.] Dick's core concern that the utopian ideal of eliminating threat
creates a dystopian world of state power."

activities, has memory for certain crime-relevant details," Rissman says.
Indeed, US company No Lie MRI claims its brain scan technology is able to
"objectively measure intent, prior knowledge and deception" with an accuracy of
93 per cent.

Rissman is cautious, however, pointing out that canny folk can forge a neural
signature of non- recognition if so inclined. He co- authored a 2015 study that
got subjects to game the system when looking at photos of faces they recognised
by training their attention on the picture's technical features, such as the
exposure, lighting and line edges.

The MRI brain signature of recognition was duly wiped, leaving the door ajar for
shrewd operators to evade the test in the real world - just as people can
deceive existing lie-detectors. But smoothing technical glitches might not be
the biggest challenge for predictive policing.

Lucia Zedner, co-author of the 2014 book Preventive Justice and professor in the
law faculties of the University of Oxford and UNSW, argues that crime detection
with this type of technology may threaten the very tenets of our criminal
justice system.

She says the law has recognised various incarnations of pre-crime for some time:
attempts, incitement and conspiracy to commit a crime are all offences even if
the crime never happens.

Nonetheless, she says, these each involve a clear act of planning.

But some terrorism laws shift the offence to the earlier, fuzzier, pre-crime
phase of "preparation" with the aim of heading off terrorism "further up the
field".

While P300 cannot measure intent or ascribe guilt on its own, it is conceivable
that "preparation" might one day be inferred from brain data, such as a P300
spike of recognition to an IED how-to guide. But Zedner has a big problem with
any scenario that criminalises thoughts alone.

"Where is the harm? I can sit in my office and think evil thoughts about people
all I like, but providing I do nothing about those thoughts there is no harm.
And to that extent the harm principle, which underpins the whole basis of
criminalisation, is not satisfied," Zedner says.

The harm comes, Zedner says, only when the intent is communicated - think a text
to a terrorist colleague with a link to the IED guide - and then the law has its
"guilty act" upon which criminal proceedings might proceed. She concedes that
colleagues argue the legal emphasis on communicating evil intent is not just
because spreading the word makes harm more likely. It has until now been the
only way of knowing what a person is thinking - a truism neuroscience is
challenging.

Monash University Professor of Criminology Jude McCulloch, who released her
co-authored book Pre-Crime: Pre-Emption, Precaution and the Future last year,
takes an even dimmer view of pre-crime.

"I think it is a false idea that pre- crime prevents crime. In fact, I would go
so far as to say that pre- crime creates crime," McCulloch says. "Pre-crimes are
essentially crimes that it is believed people are thinking about doing. When
someone is convicted because it is believed they are going to commit a crime, it
[is] as if that crime has already occurred. It produces the spectre of crime,"
she says.

Worse, McCulloch's analysis of pre-crime suggests it may promote the very
terrorism it sets out to prevent: "Pre-crime prosecutions very much focus on the
political and religious ideology of the person. And if you target a whole
community, some people find it difficult to get over the feeling they are being
persecuted. People go underground and become more dangerous," she says. "People
are being convicted for their beliefs rather than their behaviour. This picks up
on [Philip K.] Dick's core concern that the utopian ideal of eliminating threat
creates a dystopian world of state power."

LOAD-DATE: May 21, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper

JOURNAL-CODE: ST


       Copyright 2016 The Federal Capital Press of Australia PTY Limited
                              All Rights Reserved


                               34 of 41 DOCUMENTS


                       The Sun Herald (Sydney, Australia)

                              May 22, 2016 Sunday
                                 First Edition

Think of the crime, do the time?

BYLINE: Paul Biegler

SECTION: EXTRA; Pg. 32

LENGTH: 2098  words


Can technology catch terrorists before they strike? Paul Biegler reports.

In our society, we have no major crimes," says Police Commissioner Anderton in
Philip K. Dick's 1950s classic Minority Report, "but we do have a detention camp
full of would-be criminals".

In the dystopian sci-fi story (that became a Hollywood blockbuster), crimes are
predicted by a trio of "pre-cog mutants" so that officers from "Pre-crime" can
step in to detain aspirational felons before they strike.

Now a test for "guilty knowledge" being scrutinised by Australian
counter-terrorism experts could bring "pre-crime" a step closer to real world
policing.

The technology on which the test is based has been widely researched and
performs well in the lab. But the commercial version, dubbed "Brain
Fingerprinting", is dogged by claims that its high profile creator, a
Harvard-trained neuroscientist, has oversold it.

And even if its scientific bona fides are established, legal experts are worried
that acting on the test's findings could threaten the very pillars of our
criminal justice system.

The basic technique is, in fact, relatively uncontroversial with a scientific
pedigree that has chalked up over a thousand peer-reviewed articles.

The "P300 Concealed Information Test" uses EEG to measure brain waves (with
headgear reminiscent of one of those fifties floral bathing caps).

It exploits the fact that when people recognise things meaningful to them among
miscellaneous bric-a-brac, their EEG blips with a "P" wave, like the Matterhorn
sprouting from the Alps, roughly 300 milliseconds later.

In an era of heightened fears of terrorism, and the difficulty of policing "lone
wolves" and covertly radicalised youths, it's not hard to see why P300 has law
enforcement all a-quiver.

Say John or Jane Doe has been scrolling through a document titled "How to make
an improvised explosive device" and is invited to a fireside chat at Constable
Plod's.

Plod could apply the bathing cap, sit Doe in front of a computer and show him or
her the terror title among irrelevant others such as "How to avoid huge ships"
or "Why cats paint".

Unless Doe has very niche literary tastes, the IED guide should provoke a
distinctive peak.

The P300 test differs from traditional "question and answer" lie-detection in
that it doesn't rely on the fight-or-flight nervous system to moisten palms and
quicken pulses - signs some experts say catch lies with an accuracy little
better than chance.

And because EEG independently detects whether a suspect recognises dubious
material, P300 does not rely on reluctant people answering questions they would
rather not answer.

But its potential as a conduit to the nefarious plans of would-be terrorists
really took off with the release of a 2011 study that had psychology students
turn jihadist for a day. The faux insurgents were asked to hatch a mock
terrorist plot by selecting one of four dates in July, one of four locations in
Houston and one of four types of bomb, then jot it all down in a letter to their
terrorist boss.

EEG caps on, they were later shown a slew of months of the year, US cities and
varieties of terror attack on a computer; and when "July", "Houston" and "bomb"
appeared among them, the P300 spikes were big enough to nab all 12 "culprits".

But while the results were promising, they didn't provide the fine-grained
detail needed to foil an actual terror strike.

However, Professor Peter Rosenfeld from the Department of Psychology at
Northwestern University, a co-author on the study, says recent research shows a
related technique called "searching CIT" might narrow things down.

If, for example, authorities know Houston is the target, they could show
suspects a map of the city, divide it into quadrants, then sequentially ask if
the attack were planned in each.

"When they recognise the quadrant they'll show the biggest P300. Then you take
that quadrant and break it down into quadrants, and so on, until you get it down
to a specific neighbourhood," says Rosenfeld.

But there's a further obstacle to its adoption by justice departments: If P300
results are to be admitted as evidence in a US court they must satisfy the
Daubert standard which demands not just scientific credibility in the lab but
also a "known error rate" in the field. After years of arm-twisting, Rosenfeld
is on the cusp of running a study at a major United States airport that will
step baggage handlers off the line and ask them to load pistols into a
distinctive suitcase (aviation authorities have been understandably reluctant to
take part).

Then they'll use the P300 to see if the suitcase, presented on a computer screen
with a duffle bag, attachÃ© case, backpack and other assorted luggage, generates
that "guilty" spike.

Law enforcement agencies will be watching the results intently as the pressure
mounts to thwart terrorism at the planning stage, fuelled by the recent attacks
in Paris, Brussels and Lahore.

And tougher Australian terror laws are likely to impel police deeper into the
world of pre-crime and this emerging technology.

It is already an offence to plan or prepare for a terrorist act, even if the act
never happens.

And legislation passed by the NSW Government in May extends the time a suspected
terrorist can be held without charge from four to 14 days, with the approval of
a judge.

Each state and territory has separate laws allowing police to hold terror
suspects for up to 14 days under a preventative detention order (PDO).

But the February review of commonwealth counter-terrorism laws recommends
ditching the requirement that any attack be deemed "imminent" - likely to happen
within 14 days - before a PDO can be issued.

In this new world of preventive justice, the prospect of a little scientific
help is tantalising.

Enter Brain Fingerprinting, a variant of the P300 test called "P300 MERMER" that
swaps bathing caps for sleek headsets and has been commercially available in
Australia for 12 months through the biometrics company Fingerscan.

Fingerscan's general manager Peter Ives says Brain Fingerprinting has been
demonstrated to the NSW and Queensland police forces and to "agencies involved
with counter-terrorism" but, without those agencies' consent, he is not prepared
to comment on their responses.

The P300 MERMER patent holder is Dr Larry Farwell, a Harvard graduate with a
doctorate in biological psychology, who was nominated by TIME magazine in 2001
as one of 100 "Innovators Who May Be the Picassos or the Einsteins of the 21st
Century".

Like Rosenfeld, Farwell has researched in the field for decades.

But Farwell's P300 MERMER has made it into the courtroom; in a cold case where a
suspected murderer was ultimately convicted and in a separate case where a
person wrongly convicted of murder was exonerated. However, the degree to which
P300 MERMER evidence was relied upon and whether it was definitively ruled
admissible is unclear. And Farwell's version of the test has its detractors, who
dispute that his P300 MERMER differs sufficiently from the standard test.

A 2013 article in Cognitive Neurodynamics criticised small sample sizes and a
paucity of peer review in studies cited by Farwell to support his claim brain
fingerprinting is 100 per cent accurate.

Those authors said: "Farwell's finding of 100 per cent accuracy stands in
contrast with the available literature", and concluded he was "misleading and
misrepresents the scientific status of brain fingerprinting technology".

Farwell rejected those charges in the same journal and in an email to Fairfax
Media says: "Peer-reviewed, published research at the FBI, CIA, and US Navy has
shown that all studies that meet the brain fingerprinting scientific standards
have produced less than 1 per cent error rate (in fact, 0 per cent error rate /
100 per cent accuracy)".

But while the role of P300 in pre-crime fighting awaits the due diligence of
authorities, other technologies are firming in the race to detect concealed
knowledge.

Dr Jesse Rissman, Assistant Professor at the Integrative Centre for Learning and
Memory at the University of California, Los Angeles, published a study in April
that used MRI scans to, similarly, detect recognition of recent events.
Participants wore a digital camera around the neck that was programmed to snap
thousands of shots of everyday life for three weeks - studying, eating out,
hiking and sports (there was an "off" button for private moments).

At the end, subjects were put in an MRI scanner and shown their own snapshots
interspersed with photos from other participants.

As people twigged to their own life shots, the MRI lit up with a distinctive
"neural signature" of recognition that was accurate to near perfection.

"Some might take results like ours to indicate that MRI scans could be used as a
tool to detect whether any individual, including people who might be engaged in
criminal activities, has memory for certain details," says Rissman.

Indeed, US company No Lie MRI claims its brain scan technology is able to,
"objectively measure intent, prior knowledge and deception" with an accuracy of
93 per cent.

Rissman is cautious, however, pointing out that canny folk can forge a neural
signature of non-recognition if so inclined.

He co-authored a 2015 study that got subjects to game the system when looking at
photos of faces they recognised by training their attention on the picture's
technical features, such as the exposure, lighting and line edges.

The MRI brain signature of recognition was duly wiped, leaving the door ajar for
shrewd operators to evade the test in the real world - just as people can
deceive existing lie-detectors.

But smoothing technical glitches might not be the biggest challenge for
predictive policing.

Lucia Zedner, co-author of the 2014 book Preventive Justice and Professor in the
law faculties of the University of Oxford and UNSW, argues that crime detection
with this type of technology may threaten the very tenets of our criminal
justice system.

She points out that the law has recognised various incarnations of pre-crime for
some time: attempts, incitement and conspiracy to commit a crime are all
offences even if the crime never happens.

Nonetheless, she says, these each involve an act of planning.

But some terrorism laws shift the offence to the earlier, fuzzier, pre-crime
phase of "preparation" with the aim of heading off terrorism "further up the
field".

While P300 cannot measure intent or ascribe guilt on its own, it is conceivable
that "preparation" might one day be inferred from brain data, such as a P300
spike of recognition when show an IED how-to guide.

But Zedner has a big problem with any scenario that criminalises thoughts alone.

"Where is the harm? I can sit in my office and think evil thoughts about people
all I like but providing I do nothing about those thoughts there is no harm,"
says Zedner.

"And to that extent the harm principle, which underpins the whole basis of
criminalisation, is not satisfied."

The harm comes, says Zedner, only when the intent is communicated - think a text
to a terrorist colleague with a link to the IED guide - and then the law has its
"guilty act" upon which criminal proceedings might proceed.

She concedes, however, that colleagues argue the legal emphasis on communicating
evil intent is not just because spreading the word makes harm more likely.

It has also, until now, been the only way of knowing what a person is thinking -
a truism that neuroscience is challenging.

Monash University Professor of Criminology Jude McCulloch, who released her
co-authored book Pre-Crime: Pre-Emption, Precaution and the Future last year,
takes an even dimmer view of pre-crime.

"I think it is a false idea that pre-crime prevents crime. In fact, I would go
so far as to say that pre-crime creates crime," says McCulloch.

"Pre-crimes are essentially crimes that it is believed people are thinking about
doing.

"When someone is convicted because it is believed they are going to commit a
crime it [is] as if that crime has already occurred. It produces the spectre of
crime," she says.

Worse, McCulloch's analysis of pre-crime suggests it may promote the very
terrorism it sets out to prevent: "Pre-crime prosecutions very much focus on the
political and religious ideology of the person. And if you target a whole
community, some people find it difficult to get over the feeling they are being
persecuted. People go underground and become more dangerous," she says.

"People are being convicted for their beliefs rather than their behaviour.

"This picks up on Philip K. Dick's core concern that the utopian ideal of
eliminating threat creates a dystopian world of state power."

LOAD-DATE: May 22, 2016

LANGUAGE: ENGLISH

GRAPHIC: STILL AND THREE PHOTOS: Oxford law professor Lucia Zedner warns against
criminalising thoughts. Dr Larry Farwell wants police forces to adopt his brain
fingerprinting technology that he says can detect "guilty knowledge". UCLA's Dr
Jesse Rissman is working on using MRI scans to detect recognition of potentially
incriminating scenes or documents. Will life imitate art? Tom Cruise in Steven
Spielberg's 2002 sci-fi hit Minority Report, based on Philip K. Dick's classic
story, predicted a future where people would be locked up before they committed
a crime.

PUBLICATION-TYPE: Newspaper


                Copyright 2016 John Fairfax Publications Pty Ltd
                              All Rights Reserved


                               35 of 41 DOCUMENTS


                       Sunday Age (Melbourne, Australia)

                              May 22, 2016 Sunday
                                 First Edition

Think of the crime, do the time?

BYLINE: Paul Biegler

SECTION: EXTRA; Pg. 22

LENGTH: 2101 words


Can technology catch terrorists before they strike? Paul Biegler reports.

In our society, we have no major crimes," says Police Commissioner Anderton in
Philip K Dick's 1950s classic Minority Report, "but we do have a detention camp
full of would-be criminals".

In the dystopian sci-fi story (that became a Hollywood blockbuster), crimes are
predicted by a trio of "pre-cog mutants" so that officers from "Pre-crime" can
step in to detain aspirational felons before they strike.

Now a test for "guilty knowledge" being scrutinised by Australian
counter-terrorism experts could bring "pre-crime" a step closer to real world
policing.

The technology on which the test is based has been widely researched and
performs well in the lab. But the commercial version, dubbed "Brain
Fingerprinting", is dogged by claims that its high profile creator, a
Harvard-trained neuroscientist, has oversold it.

And even if its scientific bona fides are established, legal experts are worried
that acting on the test's findings could threaten the very pillars of our
criminal justice system.

The basic technique is, in fact, relatively uncontroversial with a scientific
pedigree that has chalked up over a thousand peer-reviewed articles.

The "P300 Concealed Information Test" uses EEG to measure brain waves (with
headgear reminiscent of one of those fifties floral bathing caps).

It exploits the fact that when people recognise things meaningful to them among
miscellaneous bric-a-brac, their EEG blips with a "P" wave, like the Matterhorn
sprouting from the Alps, roughly 300 milliseconds later.

In an era of heightened fears of terrorism, and the difficulty of policing "lone
wolves" and covertly radicalised youths, it's not hard to see why P300 has law
enforcement all a-quiver.

Say John or Jane Doe has been scrolling through a document titled "How to make
an improvised explosive device" and is invited to a fireside chat at Constable
Plod's.

Plod could apply the bathing cap, sit Doe in front of a computer and show him or
her the terror title among irrelevant others such as "How to avoid huge ships"
or "Why cats paint".

Unless Doe has very niche literary tastes, the IED guide should provoke a
distinctive peak.

The P300 test differs from traditional "question and answer" lie-detection in
that it doesn't rely on the fight-or-flight nervous system to moisten palms and
quicken pulses - signs some experts say catch lies with an accuracy little
better than chance.

And because EEG independently detects whether a suspect recognises dubious
material, P300 does not rely on reluctant people answering questions they would
rather not answer.

But its potential as a conduit to the nefarious plans of would-be terrorists
really took off with the release of a 2011 study that had psychology students
turn jihadist for a day. The faux insurgents were asked to hatch a mock
terrorist plot by selecting one of four dates in July, one of four locations in
Houston and one of four types of bomb, then jot it all down in a letter to their
terrorist boss.

EEG caps on, they were later shown a slew of months of the year, US cities and
varieties of terror attack on a computer; and when "July", "Houston" and "bomb"
appeared among them, the P300 spikes were big enough to nab all 12 "culprits".

But while the results were promising, they didn't provide the fine-grained
detail needed to foil an actual terror strike.

However, Professor Peter Rosenfeld from the Department of Psychology at
Northwestern University, a co-author on the study, says recent research shows a
related technique called "searching CIT" might narrow things down.

If, for example, authorities know Houston is the target, they could show
suspects a map of the city, divide it into quadrants, then sequentially ask if
the attack were planned in each.

"When they recognise the quadrant they'll show the biggest P300. Then you take
that quadrant and break it down into quadrants, and so on, until you get it down
to a specific neighbourhood," says Rosenfeld.

But there's a further obstacle to its adoption by justice departments: If P300
results are to be admitted as evidence in a US court they must satisfy the
Daubert standard which demands not just scientific credibility in the lab but
also a "known error rate" in the field. After years of arm-twisting, Rosenfeld
is on the cusp of running a study at a major United States airport that will
step baggage handlers off the line and ask them to load pistols into a
distinctive suitcase (aviation authorities have been understandably reluctant to
take part).

Then they'll use the P300 to see if the suitcase, presented on a computer screen
with a duffle bag, attachÃ© case, backpack and other assorted luggage, generates
that "guilty" spike.

Law enforcement agencies will be watching the results intently as the pressure
mounts to thwart terrorism at the planning stage, fuelled by the recent attacks
in Paris, Brussels and Lahore.

And tougher Australian terror laws are likely to impel police deeper into the
world of pre-crime and this emerging technology.

It is already an offence to plan or prepare for a terrorist act, even if the act
never happens.

And legislation passed by the NSW Government in May extends the time a suspected
terrorist can be held without charge from four to 14 days, with the approval of
a judge.

Each state and territory has separate laws allowing police to hold terror
suspects for up to 14 days under a preventative detention order (PDO).

But the February review of commonwealth counter-terrorism laws recommends
ditching the requirement that any attack be deemed "imminent" - likely to happen
within 14 days - before a PDO can be issued.

In this new world of preventive justice, the prospect of a little scientific
help is tantalising.

Enter Brain Fingerprinting, a variant of the P300 test called "P300 MERMER" that
swaps bathing caps for sleek headsets and has been commercially available in
Australia for 12 months through the biometrics company Fingerscan.

Fingerscan's general manager Peter Ives says Brain Fingerprinting has been
demonstrated to the New South Wales and Queensland police forces and to
"agencies involved with counter-terrorism" but, without those agencies' consent,
he is not prepared to comment on their responses.

The P300 MERMER patent holder is Dr Larry Farwell, a Harvard graduate with a
doctorate in biological psychology, who was nominated by TIME magazine in 2001
as one of 100 "Innovators Who May Be the Picassos or the Einsteins of the 21st
Century".

Like Rosenfeld, Farwell has researched in the field for decades.

But Farwell's P300 MERMER has made it into the courtroom; in a cold case where a
suspected murderer was ultimately convicted and in a separate case where a
person wrongly convicted of murder was exonerated. However, the degree to which
P300 MERMER evidence was relied upon and whether it was definitively ruled
admissible is unclear. And Farwell's version of the test has its detractors, who
dispute that his P300 MERMER differs sufficiently from the standard test.

A 2013 article in Cognitive Neurodynamics criticised small sample sizes and a
paucity of peer review in studies cited by Farwell to support his claim brain
fingerprinting is 100 per cent accurate.

Those authors said: "Farwell's finding of 100 per cent accuracy stands in
contrast with the available literature", and concluded he was "misleading and
misrepresents the scientific status of brain fingerprinting technology".

Farwell, rejected those charges in the same journal and in an email to The
Sunday Age says: "Peer-reviewed, published research at the FBI, CIA, and US Navy
has shown that all studies that meet the brain fingerprinting scientific
standards have produced less than 1 per cent error rate (in fact, 0 per cent
error rate / 100 per cent accuracy)".

But while the role of P300 in pre-crime fighting awaits the due diligence of
authorities, other technologies are firming in the race to detect concealed
knowledge.

Dr Jesse Rissman, Assistant Professor at the Integrative Centre for Learning and
Memory at the University of California, Los Angeles, published a study in April
that used MRI scans to, similarly, detect recognition of recent events.
Participants wore a digital camera around the neck that was programmed to snap
thousands of shots of everyday life for three weeks - studying, eating out,
hiking and sports (there was an "off" button for private moments).

At the end, subjects were put in an MRI scanner and shown their own snapshots
interspersed with photos from other participants.

As people twigged to their own life shots, the MRI lit up with a distinctive
"neural signature" of recognition that was accurate to near perfection.

"Some might take results like ours to indicate that MRI scans could be used as a
tool to detect whether any individual, including people who might be engaged in
criminal activities, has memory for certain details," says Rissman.

Indeed, US company No Lie MRI claims its brain scan technology is able to,
"objectively measure intent, prior knowledge and deception" with an accuracy of
93 per cent.

Rissman is cautious, however, pointing out that canny folk can forge a neural
signature of non-recognition if so inclined.

He co-authored a 2015 study that got subjects to game the system when looking at
photos of faces they recognised by training their attention on the picture's
technical features, such as the exposure, lighting and line edges.

The MRI brain signature of recognition was duly wiped, leaving the door ajar for
shrewd operators to evade the test in the real world - just as people can
deceive existing lie-detectors.

But smoothing technical glitches might not be the biggest challenge for
predictive policing.

Lucia Zedner, co-author of the 2014 book Preventive Justice and Professor in the
law faculties of the University of Oxford and UNSW, argues that crime detection
with this type of technology may threaten the very tenets of our criminal
justice system.

She points out that the law has recognised various incarnations of pre-crime for
some time: attempts, incitement and conspiracy to commit a crime are all
offences even if the crime never happens.

Nonetheless, she says, these each involve an act of planning.

But some terrorism laws shift the offence to the earlier, fuzzier, pre-crime
phase of "preparation" with the aim of heading off terrorism "further up the
field".

While P300 cannot measure intent or ascribe guilt on its own, it is conceivable
that "preparation" might one day be inferred from brain data, such as a P300
spike of recognition when show an IED how-to guide.

But Zedner has a big problem with any scenario that criminalises thoughts alone.

"Where is the harm? I can sit in my office and think evil thoughts about people
all I like but providing I do nothing about those thoughts there is no harm,"
says Zedner.

"And to that extent the harm principle, which underpins the whole basis of
criminalisation, is not satisfied."

The harm comes, says Zedner, only when the intent is communicated - think a text
to a terrorist colleague with a link to the IED guide - and then the law has its
"guilty act" upon which criminal proceedings might proceed.

She concedes, however, that colleagues argue the legal emphasis on communicating
evil intent is not just because spreading the word makes harm more likely.

It has also, until now, been the only way of knowing what a person is thinking -
a truism that neuroscience is challenging.

Monash University Professor of Criminology Jude McCulloch, who released her
co-authored book Pre-Crime: Pre-Emption, Precaution and the Future last year,
takes an even dimmer view of pre-crime.

"I think it is a false idea that pre-crime prevents crime. In fact, I would go
so far as to say that pre-crime creates crime," says McCulloch. "Pre-crimes are
essentially crimes that it is believed people are thinking about doing.

"When someone is convicted because it is believed they are going to commit a
crime it [is] as if that crime has already occurred. It produces the spectre of
crime," she says.

Worse, McCulloch's analysis of pre-crime suggests it may promote the very
terrorism it sets out to prevent: "Pre-crime prosecutions very much focus on the
political and religious ideology of the person. And if you target a whole
community, some people find it difficult to get over the feeling they are being
persecuted. People go underground and become more dangerous," she says.

"People are being convicted for their beliefs rather than their behaviour.

"This picks up on [Phillip K.] Dick's core concern that the utopian ideal of
eliminating threat creates a dystopian world of state power."

LOAD-DATE: May 22, 2016

LANGUAGE: ENGLISH

GRAPHIC: FOUR PHOTOS: Oxford law professor Lucia Zedner warns against
criminalising thoughts. Dr Larry Farwell wants police forces to adopt his brain
fingerprinting technology that he says can detect 'guilty knowledge'. UCLA's Dr
Jesse Rissman is working on using MRI scans to detect recognition of potentially
incriminating scenes or documents. Tom Cruise in Steven Spielberg's 2002 sci-fi
hit Minority Report, based on Philip K Dick's classic story predicted a future
where people would be locked up before they committed a crime.

PUBLICATION-TYPE: Newspaper


                     Copyright 2016 The Age Company Limited
                              All Rights Reserved


                               36 of 41 DOCUMENTS


                               The New York Times

                        June 25, 2016 Saturday 00:00 EST

Artificial Intelligence's White Guy Problem;
Opinion

BYLINE: KATE CRAWFORD

SECTION: OPINION; sunday

LENGTH: 993 words



HIGHLIGHT: Our world is increasingly shaped by biased algorithms that have been
built with little oversight.


ACCORDING to some prominent voices in the tech world, artificial intelligence
presents a looming existential threat to humanity: Warnings by luminaries like
Elon Musk and Nick Bostrom about "the singularity" - when machines become
smarter than humans - have attracted millions of dollars and spawned a multitude
of conferences.

But this hand-wringing is a distraction from the very real problems with
artificial intelligence today, which may already be exacerbating inequality in
the workplace, at home and in our legal and judicial systems. Sexism, racism and
other forms of discrimination are being built into the machine-learning
algorithms that underlie the technology behind many "intelligent" systems that
shape how we are categorized and advertised to.

Take a small example from last year: Users discovered that Google's photo app,
which applies automatic labels to pictures in digital photo albums, was
classifying images of black people as gorillas. Google apologized; it was
unintentional.

But similar errors have emerged in Nikon's camera software, which misread images
of Asian people as blinking, and in Hewlett-Packard's web camera software, which
had difficulty recognizingpeople with dark skin tones.

This is fundamentally a data problem. Algorithms learn by being fed certain
images, often chosen by engineers, and the system builds a model of the world
based on those images. If a system is trained on photos of people who are
overwhelmingly white, it will have a harder time recognizing nonwhite faces.

A very serious example was revealed in an investigation published last monthby
ProPublica. It found that widely used software that assessed the risk of
recidivism in criminals was twice as likely to mistakenly flag black defendants
as being at a higher risk of committing future crimes. It was also twice as
likely to incorrectly flag white defendants as low risk.

The reason those predictions are so skewed is still unknown, because the company
responsible for these algorithms keeps its formulas secret - it's proprietary
information. Judges do rely on machine-driven risk assessments in different ways
- some may even discount them entirely - but there is little they can do to
understand the logic behind them.

Police departments across the United States are also deploying data-driven
risk-assessment tools in "predictive policing" crime prevention efforts. In many
cities, including New York, Los Angeles, Chicago and Miami, software analyses of
large sets of historical crime data are used to forecastwhere crime hot spots
are most likely to emerge; the police are then directed to those areas.

At the very least, this software risks perpetuating an already vicious cycle, in
which the police increase their presence in the same places they are already
policing (or overpolicing), thus ensuring that more arrests come from those
areas. In the United States, this could result in more surveillance in
traditionally poorer, nonwhite neighborhoods, while wealthy, whiter
neighborhoods are scrutinized even less. Predictive programs are only as good as
the data they are trained on, and that data has a complex history.

Histories of discrimination can live on in digital platforms, and if they go
unquestioned, they become part of the logic of everyday algorithmic systems.
Another scandal emerged recently when it was revealed that Amazon's same-day
delivery service was unavailable for ZIP codes in predominantly black
neighborhoods. The areas overlooked were remarkably similar to those affected by
mortgage redlining in the mid-20th century. Amazon promised to redress the gaps,
but it reminds us how systemic inequality can haunt machine intelligence.

And then there's gender discrimination. Last July, computer scientists at
Carnegie Mellon University found that women were less likely than men to be
shown ads on Google for highly paid jobs. The complexity of how search engines
show ads to internet users makes it hard to say why this happened - whether the
advertisers preferred showing the ads to men, or the outcome was an unintended
consequence of the algorithms involved.

Regardless, algorithmic flaws aren't easily discoverable: How would a woman know
to apply for a job she never saw advertised? How might a black community learn
that it were being overpoliced by software?

We need to be vigilant about how we design and train these machine-learning
systems, or we will see ingrained forms of bias built into the artificial
intelligence of the future.

Like all technologies before it, artificial intelligence will reflect the values
of its creators. So inclusivity matters - from who designs it to who sits on the
company boards and which ethical perspectives are included. Otherwise, we risk
constructing machine intelligence that mirrors a narrow and privileged vision of
society, with its old, familiar biases and stereotypes.

If we look at how systems can be discriminatory now, we will be much better
placed to design fairer artificial intelligence. But that requires far more
accountability from the tech community. Governments and public institutions can
do their part as well: As they invest in predictive technologies, they need to
commit to fairness and due process.

While machine-learning technology can offer unexpected insights and new forms of
convenience, we must address the current implications for communities that have
less power, for those who aren't dominant in elite Silicon Valley circles.

Currently the loudest voices debating the potential dangers of superintelligence
are affluent white men, and, perhaps for them, the biggest threat is the rise of
an artificially intelligent apex predator.

But for those who already face marginalization or bias, the threats are here.

Follow The New York Times Opinion section on Facebook and Twitter (@NYTOpinion),
and sign up for the Opinion Today newsletter.

Kate Crawford is a principal researcher at Microsoft and co-chairwoman of a
White House symposium on society and A.I.

LOAD-DATE: December 7, 2016

LANGUAGE: ENGLISH

DOCUMENT-TYPE: Op-Ed

PUBLICATION-TYPE: Web Blog


                   Copyright 2016 The New York Times Company
                              All Rights Reserved


                               37 of 41 DOCUMENTS


                                  Oxford Mail

                             March 29, 2016 Tuesday

Exploring the magical world of maths with teenagers

BYLINE: Callum Keown

SECTION: NEWS

LENGTH: 654 words


We all studied mathematics: it has been a core part of the school curriculum
from the very first.

However, it is not just a subject for the classroom - maths has a huge range of
applications across many areas of life, and underpins unseen many of the systems
and processes we encounter every day.

Mathematics is used in climate prediction models and to forecast tomorrow's
weather.

It is used to model and understand the spread of disease - as with the Zika
outbreak in South America.

At Oxford, we are even using maths to understand brain injuries.

If you've been shopping online, the encryption protecting your card number was
based on some sophisticated mathematics.

The retailer could even be using maths algorithms to plan the best delivery
route to get your purchases to you.

Not surprisingly, Oxford University's Mathematical Institute is full of people
fascinated by the beauty, challenge and application of mathematics, from the
pure mathematicians whose work underpins technological and scientific
developments, to those who work to apply mathematical techniques and models to
solve problems in engineering, medicine, government and many other areas.

Our desire to share that excitement is why we have always had occasional
lectures open to the public.

However, since 2014, we have run the Oxford Mathematics Public Lectures series
so that people from across Oxford can see the University at work, and find out
what we do and what it means for everyone.

The Oxford Mathematics Public Lectures aim to bring the beauty and rigour of the
subject to a wider audience.

Aimed at sixth-formers and above, the series has featured some of the leading
mathematicians of the day, including Roger Penrose, Andrew Wiles and Cedric
Villani, each of them keen to convey the pleasures - and occasional pains - of
their subject. These lectures demonstrate the connections between mathematics
and the broader world and provide inspiration for the mathematicians of today
and tomorrow, and the wider general public.

There are six or seven lectures each year and our aim is to put top
mathematicians who can communicate the subject in front of an audience of
different ages, backgrounds and mathematical interests.

We don't just arrange lectures from Oxford University mathematicians - over the
last couple of years we have brought speakers from around the world to the city.

All events are free - although you do need to get a ticket - and some quickly
fill up.

We make lectures available online at maths.ox.ac.uk/events so if you can't make
it on the day - or can't get in - there's always an opportunity to see what you
missed. If you get in and enjoy it, you can re-watch what you saw!

In our next lecture, Andrea Bertozzi from the University of California, Los
Angeles will tell the story behind her role on the team that developed a '
predictive policing' computer programme that enables police to anticipate crime.

She will also discuss how mathematics plays an increasing role in studying
crime, especially gang crime.

Later in April, Tadashi Tokieda of Cambridge and Stanford universities will be
demonstrating mathematical toys things you can find or make in minutes yet
which, when played with, reveal surprises that continue to puzzle scientists.

In May, Oxford's own Marcus du Sautoy will ask whether some problems are beyond
the powers of science and mathematics, and even beyond the conception of our
finite human minds.

The popularity of the Oxford Mathematics Public Lectures is multiplying, but
it's not too late to add yourself to the audience.

The next lectures are on April 6 between 5 - 6pm on The Mathematics of Crime by
Andrea Bertozzi, on April 26 between 5 - 6pm on Toy Models by Takashi Tokieda
and on May 12 between 4.30 - 6pm on What we Cannot Know by Marcus du Sautoy.

All will be at the Mathematical Institute, Radcliffe Observatory Quarter,
Woodstock Road, Oxford, OX2 6GG.

Register by emailing external-relations@maths.ox.ac.uk

LOAD-DATE: March 29, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper


                  Copyright 2016 NewsQuest Media Group Limited
                              All Rights Reserved


                               38 of 41 DOCUMENTS



                                  The Guardian

                       August 2, 2016 Tuesday 5:15 PM GMT

NYPD chief Bill Bratton resigns after months of tussling with Bill de Blasio;
Mayor announces Bratton's departure for 1 September, to be replaced by James
O'Neill, amid criticism of racist policing and the numbers of new officers

BYLINE: Amber Jamieson in New York

SECTION: US NEWS

LENGTH: 371 words


The nation's most high-profile police officer, New York City commissioner Bill
Bratton, has resigned after months of political tussling with the city's mayor.

Mayor Bill de Blasio announced Bratton's 1 September departure at a hastily
organized press conference on Tuesday.

"In September, Commissioner Bratton will retire from the NYPD," announced De
Blasio, who called Bratton's contributions to law enforcement "inestimable and
extraordinary".

The new police commissioner will be chief of department James O'Neill. O'Neill
has been an NYPD officer since 1983, promoted to his current role in 2014.

"Jimmy is one of the best-prepared incoming police commissioners this city has
ever seen," said De Blasio.

Bratton was appointed by De Blasio in December 2013. Relations have been
strained between the pair, with arguments over the numbers of new police
officers, criticisms of racist policing and struggles over the city council.

Bratton had already said that he would not stick around for a second term as De
Blasio's police commissioner.

This was Bratton's second time serving as police commissioner of New York City -
he also served under Rudy Giuliani, before heading to Los Angeles to run the
LAPD. He then worked for several years in the private sector before De Blasio
convinced him to be his top cop. Bratton will return to work in the private
sector.

The news comes just one day after Millions March NYC, a Black Lives
Matter-aligned group, began the #ShutDownCityHallNYC protest, taking over the
park next to city hall in Manhattan and sleeping overnight in another nearby
park that was open 24 hours in order to avoid arrests by police. One of their
demands was to have Bratton removed as police commissioner.

Josmar Trujillo, the leader of protest group New Yorkers Against Bratton,
welcomed the news of Bratton's departure. "Long time coming. [He] should have
never been here," he told the Guardian, noting that Bratton's "broken windows"
policing, implementation of CompStat (which collects crime data) and plans for
predictive policing technology would outlast its creator.

"I'm going to keep my eyes on Bill Bratton in the private sector and make sure
his replacement James O'Neill feels the same pressure," said Trujillo.

LOAD-DATE: August 2, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newspaper

JOURNAL-CODE: WEBGNS


  Copyright 2016 The Guardian, a division of Transcontinental Media Group Inc.
                              All Rights Reserved


                               39 of 41 DOCUMENTS



                                US Official News

                            April 13, 2016 Wednesday

When surveillance perpetuates institutional racism

LENGTH: 1406 words

DATELINE: Lahore



 Washington: The International Association of Privacy Professionals has issued
the following news release:



  I have to be honest with you. I've been working as a journalist in the privacy
space for the last six years, and privacy never really mattered that much to me.




 When I first understood, via Snowden, that the U.S. government was collecting
data on all of us, I didn't knee-jerk freak out. I thought about what I do
online, the kinds of data that likely generates about me, and what kind of
surveillance that probably meant as a result. I can't say I was ever in the
"if-you're-not-doing-anything-wrong, you've-got-nothing-to-hide" camp, but I
also wasn't arms-up-in-the-air outraged that some corporation potentially handed
my data over to the police. No, I didn't love the idea that the feds maybe knew
I'd once Googled "is a yam different from a sweet potato?" but, it didn't keep
me up at night.





 As a journalist, it's kind of my job not to freak out. I'm to strip the emotion
from the subject and report on the facts. So, I've spent most of my time
nonplussed at the headlines - whether I'm writing them, or someone else is.



 But then I went to an event at Georgetown Law last week called, "The Color of
Surveillance," and the hair on my arms stood up straight for about eight
continuous hours.



 I'd missed it completely.



 I'd missed the entire reason privacy isn't just a concern for those of us
logged into Ashley Madison or those of us researching something more nefarious
than the difference between starches. I missed that it should matter to me
because there are people for whom it has to matter, by virtue of their
socioeconomic or racial status. And while I have the luxury, by virtue of my own
socioeconomic status and race, of ignoring reality and letting this not be my
problem, that's not how wrongs are righted. Never has been.



 There's this Kanye West lyric that's been chasing me around since I first heard
it. West wrote, in 2004,  "Racism's still alive they just be concealing it / But
I know they don't want me in the damn club / They even make me show ID to get
inside a Sam's Club."



 I never really understood why that particular lyric, of all the powerful rap
lines I've ever heard, has stayed with me for so long. But sitting at Georgetown
last week and hearing speakers, many of them African-American and/or Muslim
themselves, describe the realities on the ground, I realized it's exactly that
kind surveillance, showing ID "to get into Sam's Club," that seems so absurd,
but which persists in much more dangerous contexts than just retail stores like
Sam's.



 Last week, I finally saw surveillance not as something mildly offensive to my
own sense of civil liberties, but as a tool of institutional racism. It suddenly
became clear to me, and I'm so embarrassed it didn't prior, that the people most
stripped of their privacy rights in this surveillance age are the people who are
the most vulnerable. I'm white and grew up in middle-class Portland, Maine, and
I really hadn't had a front-row seat to the kind of experiences I'm talking
about here.



 But the powerful surveilling the powerless is nothing new. It existed even in
the earliest days of slavery. Surveillance and power have long been closely
linked to institutional racism, from slave owners branding their slaves so they
couldn't move freely and privately around to planation owners building homes
tall enough to surveill the entire plantation. Slavery may have been abolished,
but now we see racism and oppression in a new power structure in which the
powerful hold the data on the less powerful, and in that way control a whole lot
of things, including access to services, freedom of movement and, most
egregiously, dignity.



 Here's one example. Khiara Bridges is a professor at Boston University who
studied pregnant women applying to Medicaid. All of them poor, most of them of
color. Her research has found a system "fundamentally flawed by design," in
which women relying on government assistance to have a child were required,
before ever seeing a health practitioner, to be "informationally canvassed" via
coerced consultations that ask the kinds of degrading questions white, privately
insured women would never be asked at a healthcare facility. These women are
routinely drilled on whether they've missed prenatal care appointments, whether
the pregnancy was planned or accidental, whether they've ever abused controlled
substances, been domestically abused, been homeless. And if they say yes, more
information is gathered. That information is then funneled to other state
bureaucracies including immigration, customs enforcement or even criminal
justice. In order to continue their Medicaid care, the women are then tracked
and surveilled in demeaning ways, which Bridges calls the "poverty of privacy
rights."



 And because poor people are seen as social problems, they're situated inside a
tight government net where they can be patrolled, harassed and controlled as
deemed necessary. After all, where are they going to go for medical care if not
government assistance? That's the trade off. You want our help? We'll use your
data how we see fit.



 Or, for further evidence, we can look to black men. It doesn't take much
research to find a startling number of examples of police harassment. According
to research presented by Hamid Khan of the Stop LAPD Spying Coalition, 30
percent of suspicious activity reports in Los Angeles are written on blacks -
even though they make up less than 10 percent of the total population.



 Besides arrests, Khan reported, there are more covert surveillance methods
employed, in which housing authorities are forging partnerships with police to
track movements of residents; government-subsidized cell phones are distributed
and their GPS-chips used to track, and in recent years, police are instituting
wartime counter-insurgency tactics used to smoke out terrorist cells in Iraq and
Afghanistan to surveil black, low socioeconomic-status men.



 Think about walking around your own neighborhood and having policemen watching
your every move suspiciously, waiting for a reason to pull you aside for a
"chat."



 We've all heard the Foucault reference a million times, but, it's relevant
here, too: being watched changes how you move, how you think. Forget about
locking up black men. The way they are harassed and stalked creates, as Foucault
described it, the prison of the mind. And that kind of policing is something
black men in many neighborhoods experience every day.



 And now, other communities of color or ethnicity are affected as well. If
you've watched the news once since 2001, you understand what's happening to
Muslim communities.



 And technology is only making surveillance easier. Between facial-recognition
technology, algorithms used for "predictive policing" and, most recently,
Stingrays, the watching done by the human eye historically will be and already
is being done faster, easier, cheaper and en masse.



 Georgetown's Alvaro Bedoya said that, to him, "privacy is black kids being able
to make mistakes without the law watching their every move."



 I like that. That's the way I grew up. I made mistakes in my neighborhood all
the time. In public. But in my public, there was even still some privacy, or at
least obscurity. And I was allowed to get smarter, more mature from those
mistakes rather than be forever marked by them.



 As always, we're keeping the vulnerable vulnerable. Asserting power just
because we can. Because he who owns the data, who makes decisions on who has
access to what based on that data, holds the power.



 And that's why privacy pros, in this context, are so important. There's been a
lot of talk lately about the need to continue making ethics-based decisions and
not just compliance-based decisions, and I can't think of a context more worthy
than the restoration of human dignity--for everyone.



 As privacy pros, you get to make decisions that have real impacts on people's
lives, though it may sometimes seem more abstract than that. Decisions like,
should we even collect this data to begin with? If we do, who might own it
someday? And it may seem absurd that these questions are related to social
injustice and an imbalance of power, but guess what, they really are.



 Maybe privacy matters more to me than I thought.





 In case of any query regarding this article or other content needs please
contact: editorial@plusmediasolutions.com

LOAD-DATE: April 14, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newswire


              Copyright 2016 Plus Media Solutions Private Limited
                              All Rights Reserved


                               40 of 41 DOCUMENTS



                                US Official News

                            April 14, 2016 Thursday

When surveillance perpetuates institutional racism

LENGTH: 1406 words

DATELINE: Lahore



 Washington: The International Association of Privacy Professionals has issued
the following news release:



  I have to be honest with you. I've been working as a journalist in the privacy
space for the last six years, and privacy never really mattered that much to me.




 When I first understood, via Snowden, that the U.S. government was collecting
data on all of us, I didn't knee-jerk freak out. I thought about what I do
online, the kinds of data that likely generates about me, and what kind of
surveillance that probably meant as a result. I can't say I was ever in the
"if-you're-not-doing-anything-wrong, you've-got-nothing-to-hide" camp, but I
also wasn't arms-up-in-the-air outraged that some corporation potentially handed
my data over to the police. No, I didn't love the idea that the feds maybe knew
I'd once Googled "is a yam different from a sweet potato?" but, it didn't keep
me up at night.





 As a journalist, it's kind of my job not to freak out. I'm to strip the emotion
from the subject and report on the facts. So, I've spent most of my time
nonplussed at the headlines - whether I'm writing them, or someone else is.



 But then I went to an event at Georgetown Law last week called, "The Color of
Surveillance," and the hair on my arms stood up straight for about eight
continuous hours.



 I'd missed it completely.



 I'd missed the entire reason privacy isn't just a concern for those of us
logged into Ashley Madison or those of us researching something more nefarious
than the difference between starches. I missed that it should matter to me
because there are people for whom it has to matter, by virtue of their
socioeconomic or racial status. And while I have the luxury, by virtue of my own
socioeconomic status and race, of ignoring reality and letting this not be my
problem, that's not how wrongs are righted. Never has been.



 There's this Kanye West lyric that's been chasing me around since I first heard
it. West wrote, in 2004,  "Racism's still alive they just be concealing it / But
I know they don't want me in the damn club / They even make me show ID to get
inside a Sam's Club."



 I never really understood why that particular lyric, of all the powerful rap
lines I've ever heard, has stayed with me for so long. But sitting at Georgetown
last week and hearing speakers, many of them African-American and/or Muslim
themselves, describe the realities on the ground, I realized it's exactly that
kind surveillance, showing ID "to get into Sam's Club," that seems so absurd,
but which persists in much more dangerous contexts than just retail stores like
Sam's.



 Last week, I finally saw surveillance not as something mildly offensive to my
own sense of civil liberties, but as a tool of institutional racism. It suddenly
became clear to me, and I'm so embarrassed it didn't prior, that the people most
stripped of their privacy rights in this surveillance age are the people who are
the most vulnerable. I'm white and grew up in middle-class Portland, Maine, and
I really hadn't had a front-row seat to the kind of experiences I'm talking
about here.



 But the powerful surveilling the powerless is nothing new. It existed even in
the earliest days of slavery. Surveillance and power have long been closely
linked to institutional racism, from slave owners branding their slaves so they
couldn't move freely and privately around to planation owners building homes
tall enough to surveill the entire plantation. Slavery may have been abolished,
but now we see racism and oppression in a new power structure in which the
powerful hold the data on the less powerful, and in that way control a whole lot
of things, including access to services, freedom of movement and, most
egregiously, dignity.



 Here's one example. Khiara Bridges is a professor at Boston University who
studied pregnant women applying to Medicaid. All of them poor, most of them of
color. Her research has found a system "fundamentally flawed by design," in
which women relying on government assistance to have a child were required,
before ever seeing a health practitioner, to be "informationally canvassed" via
coerced consultations that ask the kinds of degrading questions white, privately
insured women would never be asked at a healthcare facility. These women are
routinely drilled on whether they've missed prenatal care appointments, whether
the pregnancy was planned or accidental, whether they've ever abused controlled
substances, been domestically abused, been homeless. And if they say yes, more
information is gathered. That information is then funneled to other state
bureaucracies including immigration, customs enforcement or even criminal
justice. In order to continue their Medicaid care, the women are then tracked
and surveilled in demeaning ways, which Bridges calls the "poverty of privacy
rights."



 And because poor people are seen as social problems, they're situated inside a
tight government net where they can be patrolled, harassed and controlled as
deemed necessary. After all, where are they going to go for medical care if not
government assistance? That's the trade off. You want our help? We'll use your
data how we see fit.



 Or, for further evidence, we can look to black men. It doesn't take much
research to find a startling number of examples of police harassment. According
to research presented by Hamid Khan of the Stop LAPD Spying Coalition, 30
percent of suspicious activity reports in Los Angeles are written on blacks -
even though they make up less than 10 percent of the total population.



 Besides arrests, Khan reported, there are more covert surveillance methods
employed, in which housing authorities are forging partnerships with police to
track movements of residents; government-subsidized cell phones are distributed
and their GPS-chips used to track, and in recent years, police are instituting
wartime counter-insurgency tactics used to smoke out terrorist cells in Iraq and
Afghanistan to surveil black, low socioeconomic-status men.



 Think about walking around your own neighborhood and having policemen watching
your every move suspiciously, waiting for a reason to pull you aside for a
"chat."



 We've all heard the Foucault reference a million times, but, it's relevant
here, too: being watched changes how you move, how you think. Forget about
locking up black men. The way they are harassed and stalked creates, as Foucault
described it, the prison of the mind. And that kind of policing is something
black men in many neighborhoods experience every day.



 And now, other communities of color or ethnicity are affected as well. If
you've watched the news once since 2001, you understand what's happening to
Muslim communities.



 And technology is only making surveillance easier. Between facial-recognition
technology, algorithms used for "predictive policing" and, most recently,
Stingrays, the watching done by the human eye historically will be and already
is being done faster, easier, cheaper and en masse.



 Georgetown's Alvaro Bedoya said that, to him, "privacy is black kids being able
to make mistakes without the law watching their every move."



 I like that. That's the way I grew up. I made mistakes in my neighborhood all
the time. In public. But in my public, there was even still some privacy, or at
least obscurity. And I was allowed to get smarter, more mature from those
mistakes rather than be forever marked by them.



 As always, we're keeping the vulnerable vulnerable. Asserting power just
because we can. Because he who owns the data, who makes decisions on who has
access to what based on that data, holds the power.



 And that's why privacy pros, in this context, are so important. There's been a
lot of talk lately about the need to continue making ethics-based decisions and
not just compliance-based decisions, and I can't think of a context more worthy
than the restoration of human dignity--for everyone.



 As privacy pros, you get to make decisions that have real impacts on people's
lives, though it may sometimes seem more abstract than that. Decisions like,
should we even collect this data to begin with? If we do, who might own it
someday? And it may seem absurd that these questions are related to social
injustice and an imbalance of power, but guess what, they really are.



 Maybe privacy matters more to me than I thought.





 In case of any query regarding this article or other content needs please
contact: editorial@plusmediasolutions.com

LOAD-DATE: April 15, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newswire


              Copyright 2016 Plus Media Solutions Private Limited
                              All Rights Reserved


                               41 of 41 DOCUMENTS



                                US Official News

                            October 17, 2016 Monday

Washington: Risky Reform Futures

LENGTH: 667  words

DATELINE: New York



 Washington: National Center for Reason and Justice has issued the following
news release:



 To many, the idea of predictability -- an accurate forecast of who would do
harm in the future, if released -- is alluring in our widely unjust system. Risk
assessments can appear more measured and bias-free than the judgment of police,
judges, corrections officers or psychologists. The logic behind this reform
wave: If police and prosecutors mistakenly target good people, an algorithm
won't. Risk assessment instruments are often seen as better than the status quo
where few people convicted of violent offenses are released on parole or receive
a reduced sentence.





 But is the right question to be asking in this moment really how to balance
professional judgment and a predictive instrument, or even how these algorithms
or tools are inaccurate and racially profile? Instead, perhaps we should be
asking why there is such a profound silence surrounding the elephant in the
room: the structural problems in society that drive harm. Even if Burgess was
right -- that predictability is feasible -- what meanings are drawn from these
relationships? If reoffending can be predicted, why is the problem the person?
Why not the wider environment that shapes our life pathways?



 And why wouldn't we conclude, as Harcourt writes in Against Prediction, "that
there is a problem with prisons, punishment, or the lack of reentry programs"?
And why wouldn't predictability then motivate an examination of the root of
these institutions, rather than a push to seek more reform?



 Take the turn to predictive policing: Los Angeles already spends 54 percent of
its general funds on its police department, says Garcia. With an inability to
acknowledge and address racial bias within its force, continued histories of
corruption, and a long list of lethal actions against unarmed residents, why
isn't the conclusion to shrink policing in LA, rather than produce new and
expensive predictive tools that, according to a 2016 RAND study, don't work?



 Similarly, cities pay to expand facilities to monitor those with convictions
for sex offenses, including civil commitment institutions, despite the fact that
research has demonstrated that registries, and an array of other punitive
responses, have neither protected children nor ended sexual violence. If our
goal is to end, or reduce, sexual violence, why not focus and support proven
preventative measures, including meaningful sex education and non-stigmatizing
mental health care? Why not focus on ending patriarchy?



 For many, this leap, for now, is too much. The lives and the rights of those
with convictions for sex offenses, like Lieberman and Jones, are seen as
necessary collateral damage in the wider march toward greater public safety, or
perhaps exceptions to reform practices that on the whole will work for others.
But as risk assessment in our political moment gains a measure of mainstream
scrutiny, another story could emerge. Perhaps the focus on the supposedly
incorrigible nature of people convicted of sex offenses (and the assumption
that, given the gravity of their acts, many require indefinite detention) deftly
masks our collective reality: Just like prisons, maybe big data can't make us
safe. In fact, it might make things worse.



 Meanwhile, despite all these scores and diagnoses, Smith can't predict her
son's future. With no money for a private lawyer, she does the best she can. She
visits and calls and tries to stay informed about both what is happening at
Rushville and how Jones is doing. She is pleased about the small things: Her
daughter, who is now 18 years old, and therefore no longer a risk according to
Rushville, can finally visit her brother. But for those in indefinite
confinement and their families, the future is a question mark -- and with big
data in charge, the answer is often limitless incarceration.



 In case of any query regarding this article or other content needs please
contact: editorial@plusmediasolutions.com

LOAD-DATE: October 18, 2016

LANGUAGE: ENGLISH

PUBLICATION-TYPE: Newswire


              Copyright 2016 Plus Media Solutions Private Limited
                              All Rights Reserved
